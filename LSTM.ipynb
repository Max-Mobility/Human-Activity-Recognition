{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas imCaseAccelport Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "sess =tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21899, 11)\n",
      "(21899, 1)\n"
     ]
    }
   ],
   "source": [
    "Data=pd.read_csv(\"~/Data/data_lstm.csv\",header=None)\n",
    "print(Data.shape)\n",
    "Label=pd.read_csv(\"~/Data/label_lstm.csv\",header=None)\n",
    "print(Label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 0\n",
      "[5.98146725]\n",
      "[-3.17332602]\n",
      "[9.15479326]\n",
      "feature 1\n",
      "[17.00331688]\n",
      "[-17.63447762]\n",
      "[34.63779449]\n",
      "feature 2\n",
      "[1.33007812]\n",
      "[-1.74121094]\n",
      "[3.07128906]\n",
      "feature 3\n",
      "[1.99993896]\n",
      "[-2.]\n",
      "[3.99993896]\n",
      "feature 4\n",
      "[1.77966309]\n",
      "[-1.45532227]\n",
      "[3.23498535]\n",
      "feature 5\n",
      "[75.85366058]\n",
      "[-119.63414764]\n",
      "[195.48780823]\n",
      "feature 6\n",
      "[85.54878235]\n",
      "[-86.34146881]\n",
      "[171.89025116]\n",
      "feature 7\n",
      "[96.76829529]\n",
      "[-134.63415527]\n",
      "[231.40245056]\n",
      "feature 8\n",
      "[94.60174561]\n",
      "[0.]\n",
      "[94.60174561]\n",
      "feature 9\n",
      "[59.79333115]\n",
      "[0.]\n",
      "[59.79333115]\n",
      "feature 10\n",
      "[179.88510132]\n",
      "[-179.64160156]\n",
      "[359.52670288]\n"
     ]
    }
   ],
   "source": [
    "for i in range(Data.shape[1]):\n",
    "    scaler=MinMaxScaler(feature_range=(-1,1))\n",
    "    scaler=scaler.fit(Data.iloc[:,i].values.reshape(-1,1))\n",
    "    Data.iloc[:,i]= scaler.transform(Data.iloc[:,i].values.reshape(-1,1))\n",
    "    print(\"feature\" ,i)\n",
    "    print(scaler.data_max_)\n",
    "    print(scaler.data_min_)\n",
    "    print(scaler.data_range_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179.88510132]\n",
      "[-179.64160156]\n",
      "[359.52670288]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.data_max_)\n",
    "print(scaler.data_min_)\n",
    "print(scaler.data_range_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.columns= ['CaseSpeed','CaseAccel','AccelX','AccelY','AccelZ','GyroX','GyroY','Gyroz','Roll','Pitch','Yaw']\n",
    "Label.columns=['Push']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=Label\n",
    "#x_data=Data[['CaseSpeed','CaseAccel','Gyroz']]\n",
    "x_data=Data[['CaseSpeed','CaseAccel','AccelX','AccelY','AccelZ','GyroX','GyroY','Gyroz','Roll','Pitch','Yaw']]\n",
    "feature_size=x_data.shape[1]\n",
    "\n",
    "#print(feature_size)\n",
    "#print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 50\n",
    "x_array=[]\n",
    "y_array=[]\n",
    "for i in range(len(y_data)-seq_length):\n",
    "    x_array.append(x_data.iloc[i:i+seq_length].get_values().reshape(1,-1))\n",
    "    y_array.append(y_data.iloc[i+seq_length].get_values().reshape(1,-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21849, 550)\n",
      "(21849,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(np.squeeze(x_array)).shape)\n",
    "print(np.array(np.squeeze(y_array)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals=np.array(np.squeeze(x_array))\n",
    "y_vals=np.array(np.squeeze(y_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "all#print(len(x_vals))\n",
    "train_indices = np.random.choice(len(x_vals),\n",
    "                                 round(len(x_vals)*0.80),\n",
    "                                 replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]\n",
    "#print(y_vals_train)\n",
    "#print(len(y_vals_train))\n",
    "#print(x_vals_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=500\n",
    "new_len=int(x_vals_train.shape[0]/batch)*batch\n",
    "x_vals_train=x_vals_train[:new_len]\n",
    "y_vals_train=y_vals_train[:new_len]\n",
    "#print(x_vals_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_len=int(y_vals_train.shape[0]/batch)*batch\n",
    "x_vals_test=x_vals_test[:new_len]\n",
    "y_vals_test=y_vals_test[:new_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(X,y, batch_size, nb_epoch, neurons):\n",
    "\tX = X.reshape(X.shape[0], seq_length, feature_size)\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1],X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 2s - loss: 1.2198 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 1s - loss: 1.0519 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.9400 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.8601 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7951 - acc: 0.0000e+00\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.7368 - acc: 5.2941e-04\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6836 - acc: 0.0202\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6401 - acc: 0.1228\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.6122 - acc: 0.4402\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5971 - acc: 0.6084\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5860 - acc: 0.6280\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5739 - acc: 0.6086\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5594 - acc: 0.5884\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5422 - acc: 0.5771\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5256 - acc: 0.5740\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.5116 - acc: 0.5779\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4977 - acc: 0.5889\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4827 - acc: 0.6024\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4666 - acc: 0.6165\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4492 - acc: 0.6308\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4299 - acc: 0.6429\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.4104 - acc: 0.6541\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3934 - acc: 0.6622\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3805 - acc: 0.6655\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3703 - acc: 0.6698\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3618 - acc: 0.6735\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3542 - acc: 0.6764\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3476 - acc: 0.6789\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3418 - acc: 0.6807\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3368 - acc: 0.6833\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3323 - acc: 0.6862\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3283 - acc: 0.6909\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3249 - acc: 0.6978\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3218 - acc: 0.7056\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3189 - acc: 0.7135\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3162 - acc: 0.7232\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3139 - acc: 0.7309\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3118 - acc: 0.7378\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3101 - acc: 0.7445\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3084 - acc: 0.7491\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3068 - acc: 0.7532\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3053 - acc: 0.7558\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3039 - acc: 0.7588\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3027 - acc: 0.7607\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3014 - acc: 0.7627\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.3005 - acc: 0.7649\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2992 - acc: 0.7659\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2979 - acc: 0.7679\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2968 - acc: 0.7687\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2958 - acc: 0.7710\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2948 - acc: 0.7736\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2939 - acc: 0.7731\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2931 - acc: 0.7745\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2924 - acc: 0.7759\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2917 - acc: 0.7774\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2910 - acc: 0.7782\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2903 - acc: 0.7794\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2897 - acc: 0.7802\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2891 - acc: 0.7808\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2885 - acc: 0.7812\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2880 - acc: 0.7814\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2874 - acc: 0.7816\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2869 - acc: 0.7821\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2864 - acc: 0.7824\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2859 - acc: 0.7826\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2854 - acc: 0.7833\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2849 - acc: 0.7836\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2845 - acc: 0.7839\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2840 - acc: 0.7848\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2837 - acc: 0.7873\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2830 - acc: 0.7874\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2825 - acc: 0.7857\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2823 - acc: 0.7862\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2844 - acc: 0.7902\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2820 - acc: 0.7891\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2811 - acc: 0.7882\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2805 - acc: 0.7889\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2803 - acc: 0.7892\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2798 - acc: 0.7895\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2794 - acc: 0.7895\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2790 - acc: 0.7896\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2787 - acc: 0.7897\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2783 - acc: 0.7900\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2779 - acc: 0.7899\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2777 - acc: 0.7902\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2771 - acc: 0.7908\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2770 - acc: 0.7905\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2764 - acc: 0.7914\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2761 - acc: 0.7913\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2755 - acc: 0.7906\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2752 - acc: 0.7912\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2748 - acc: 0.7913\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2745 - acc: 0.7911\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2741 - acc: 0.7911\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2737 - acc: 0.7912\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2734 - acc: 0.7918\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2730 - acc: 0.7916\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2727 - acc: 0.7916\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2724 - acc: 0.7918\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2720 - acc: 0.7925\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2716 - acc: 0.7922\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2713 - acc: 0.7924\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2711 - acc: 0.7932\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2708 - acc: 0.7949\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2703 - acc: 0.7959\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2699 - acc: 0.7946\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2696 - acc: 0.7951\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2698 - acc: 0.7962\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2690 - acc: 0.7976\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2686 - acc: 0.7962\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2683 - acc: 0.7962\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2679 - acc: 0.7962\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2676 - acc: 0.7962\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2677 - acc: 0.7966\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2671 - acc: 0.7985\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2666 - acc: 0.7966\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2663 - acc: 0.7961\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2660 - acc: 0.7961\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2657 - acc: 0.7966\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2654 - acc: 0.7966\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2651 - acc: 0.7972\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2648 - acc: 0.7973\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2645 - acc: 0.7974\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2642 - acc: 0.7977\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2640 - acc: 0.7979\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2637 - acc: 0.7981\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2635 - acc: 0.7984\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2632 - acc: 0.7987\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2630 - acc: 0.7991\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2627 - acc: 0.7997\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.2625 - acc: 0.7999\n",
      "Epoch 1/1\n",
      " - 2s - loss: 0.2622 - acc: 0.8002\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2620 - acc: 0.8006\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2618 - acc: 0.8007\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2616 - acc: 0.8012\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2613 - acc: 0.8014\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2611 - acc: 0.8019\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2609 - acc: 0.8022\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2607 - acc: 0.8026\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2605 - acc: 0.8031\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2603 - acc: 0.8039\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2601 - acc: 0.8046\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2602 - acc: 0.8050\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2597 - acc: 0.8055\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2597 - acc: 0.8052\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2595 - acc: 0.8055\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2593 - acc: 0.8059\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2591 - acc: 0.8059\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2589 - acc: 0.8062\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2587 - acc: 0.8065\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2585 - acc: 0.8067\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2583 - acc: 0.8066\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2581 - acc: 0.8069\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2578 - acc: 0.8072\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2576 - acc: 0.8075\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2574 - acc: 0.8075\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2572 - acc: 0.8076\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2570 - acc: 0.8082\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2568 - acc: 0.8084\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2565 - acc: 0.8089\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2563 - acc: 0.8089\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2561 - acc: 0.8091\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2559 - acc: 0.8094\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2556 - acc: 0.8099\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2554 - acc: 0.8102\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2551 - acc: 0.8115\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2550 - acc: 0.8125\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2546 - acc: 0.8125\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2545 - acc: 0.8124\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2542 - acc: 0.8131\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2540 - acc: 0.8131\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2538 - acc: 0.8135\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2536 - acc: 0.8134\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2533 - acc: 0.8140\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2531 - acc: 0.8143\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2528 - acc: 0.8144\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2526 - acc: 0.8146\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2523 - acc: 0.8148\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2521 - acc: 0.8149\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2518 - acc: 0.8152\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2515 - acc: 0.8154\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2512 - acc: 0.8156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 1s - loss: 0.2510 - acc: 0.8162\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2507 - acc: 0.8171\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2504 - acc: 0.8168\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2502 - acc: 0.8166\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2499 - acc: 0.8172\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2497 - acc: 0.8173\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2494 - acc: 0.8176\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2492 - acc: 0.8179\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2489 - acc: 0.8181\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2486 - acc: 0.8181\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2484 - acc: 0.8185\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2481 - acc: 0.8188\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2479 - acc: 0.8189\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2476 - acc: 0.8189\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2473 - acc: 0.8191\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2471 - acc: 0.8194\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2468 - acc: 0.8193\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2466 - acc: 0.8196\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2463 - acc: 0.8197\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2461 - acc: 0.8198\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2458 - acc: 0.8199\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2456 - acc: 0.8201\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2453 - acc: 0.8204\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2451 - acc: 0.8205\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2448 - acc: 0.8206\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2446 - acc: 0.8208\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2443 - acc: 0.8210\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2441 - acc: 0.8214\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2439 - acc: 0.8217\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2436 - acc: 0.8218\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2434 - acc: 0.8221\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2432 - acc: 0.8222\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2429 - acc: 0.8224\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2427 - acc: 0.8227\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2425 - acc: 0.8228\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2422 - acc: 0.8229\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2420 - acc: 0.8230\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2418 - acc: 0.8232\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2416 - acc: 0.8235\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2413 - acc: 0.8234\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2411 - acc: 0.8235\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2409 - acc: 0.8236\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2407 - acc: 0.8236\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2404 - acc: 0.8240\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2402 - acc: 0.8241\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2400 - acc: 0.8241\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2398 - acc: 0.8244\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2396 - acc: 0.8245\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2394 - acc: 0.8249\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2392 - acc: 0.8251\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2389 - acc: 0.8252\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2387 - acc: 0.8253\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2385 - acc: 0.8252\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2383 - acc: 0.8254\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2381 - acc: 0.8255\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2379 - acc: 0.8256\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2377 - acc: 0.8257\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2375 - acc: 0.8260\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2373 - acc: 0.8262\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2371 - acc: 0.8262\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2369 - acc: 0.8263\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2367 - acc: 0.8264\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2365 - acc: 0.8266\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2363 - acc: 0.8267\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2361 - acc: 0.8268\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2359 - acc: 0.8268\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2356 - acc: 0.8270\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2355 - acc: 0.8271\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2352 - acc: 0.8274\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2351 - acc: 0.8275\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2348 - acc: 0.8279\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2346 - acc: 0.8278\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2344 - acc: 0.8282\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2342 - acc: 0.8280\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2340 - acc: 0.8285\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2338 - acc: 0.8282\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2335 - acc: 0.8286\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2334 - acc: 0.8285\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2331 - acc: 0.8289\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2329 - acc: 0.8288\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2326 - acc: 0.8293\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2324 - acc: 0.8294\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2321 - acc: 0.8296\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2318 - acc: 0.8302\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2315 - acc: 0.8303\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2311 - acc: 0.8308\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2309 - acc: 0.8311\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2306 - acc: 0.8313\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2303 - acc: 0.8314\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2301 - acc: 0.8312\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2298 - acc: 0.8314\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2296 - acc: 0.8315\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2294 - acc: 0.8314\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2292 - acc: 0.8317\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2290 - acc: 0.8318\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2288 - acc: 0.8321\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2286 - acc: 0.8318\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2285 - acc: 0.8326\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2282 - acc: 0.8322\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2280 - acc: 0.8324\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2278 - acc: 0.8327\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2276 - acc: 0.8328\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2273 - acc: 0.8339\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2269 - acc: 0.8336\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2269 - acc: 0.8347\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2266 - acc: 0.8332\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2265 - acc: 0.8341\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2262 - acc: 0.8338\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2261 - acc: 0.8341\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2259 - acc: 0.8338\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2258 - acc: 0.8342\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2256 - acc: 0.8343\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2254 - acc: 0.8345\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2252 - acc: 0.8345\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2251 - acc: 0.8347\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2249 - acc: 0.8348\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2247 - acc: 0.8350\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2245 - acc: 0.8353\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2243 - acc: 0.8352\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2242 - acc: 0.8354\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2240 - acc: 0.8355\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2238 - acc: 0.8356\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2235 - acc: 0.8361\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2233 - acc: 0.8362\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2230 - acc: 0.8366\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2228 - acc: 0.8368\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2225 - acc: 0.8369\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2223 - acc: 0.8371\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2221 - acc: 0.8371\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2219 - acc: 0.8374\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2217 - acc: 0.8377\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2215 - acc: 0.8377\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2214 - acc: 0.8378\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2212 - acc: 0.8379\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2210 - acc: 0.8379\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2208 - acc: 0.8381\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2206 - acc: 0.8377\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2204 - acc: 0.8382\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2203 - acc: 0.8378\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2201 - acc: 0.8384\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2199 - acc: 0.8381\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2197 - acc: 0.8385\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2196 - acc: 0.8384\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2194 - acc: 0.8389\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2193 - acc: 0.8390\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2191 - acc: 0.8392\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2190 - acc: 0.8391\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2188 - acc: 0.8394\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2187 - acc: 0.8395\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2185 - acc: 0.8396\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2184 - acc: 0.8395\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2183 - acc: 0.8397\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2181 - acc: 0.8396\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2180 - acc: 0.8401\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2179 - acc: 0.8401\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2178 - acc: 0.8402\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2176 - acc: 0.8404\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2175 - acc: 0.8404\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2174 - acc: 0.8405\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2173 - acc: 0.8405\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2172 - acc: 0.8408\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2171 - acc: 0.8408\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2170 - acc: 0.8408\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2169 - acc: 0.8409\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2167 - acc: 0.8410\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2167 - acc: 0.8409\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2165 - acc: 0.8413\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2164 - acc: 0.8412\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2163 - acc: 0.8415\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2162 - acc: 0.8412\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2161 - acc: 0.8419\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2160 - acc: 0.8417\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2159 - acc: 0.8419\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2158 - acc: 0.8421\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2156 - acc: 0.8422\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2155 - acc: 0.8426\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2154 - acc: 0.8425\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2153 - acc: 0.8426\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2152 - acc: 0.8426\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2151 - acc: 0.8428\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2150 - acc: 0.8428\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2149 - acc: 0.8432\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.2148 - acc: 0.8430\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2147 - acc: 0.8432\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2145 - acc: 0.8433\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2144 - acc: 0.8434\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2143 - acc: 0.8436\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2142 - acc: 0.8439\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2141 - acc: 0.8439\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2140 - acc: 0.8439\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2139 - acc: 0.8442\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2138 - acc: 0.8443\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2137 - acc: 0.8444\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2136 - acc: 0.8444\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2135 - acc: 0.8447\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2134 - acc: 0.8446\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2133 - acc: 0.8446\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2132 - acc: 0.8446\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2131 - acc: 0.8448\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2130 - acc: 0.8449\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2129 - acc: 0.8451\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2127 - acc: 0.8459\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2127 - acc: 0.8458\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2126 - acc: 0.8458\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2125 - acc: 0.8459\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2124 - acc: 0.8459\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2123 - acc: 0.8459\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2122 - acc: 0.8459\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2121 - acc: 0.8457\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2120 - acc: 0.8458\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2119 - acc: 0.8458\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2118 - acc: 0.8458\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2117 - acc: 0.8461\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2116 - acc: 0.8460\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2115 - acc: 0.8462\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2115 - acc: 0.8464\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2114 - acc: 0.8465\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2113 - acc: 0.8466\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2112 - acc: 0.8466\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2111 - acc: 0.8468\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2110 - acc: 0.8469\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2109 - acc: 0.8471\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2109 - acc: 0.8472\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2108 - acc: 0.8475\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2107 - acc: 0.8477\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2106 - acc: 0.8478\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2106 - acc: 0.8479\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2105 - acc: 0.8479\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2104 - acc: 0.8479\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2103 - acc: 0.8482\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2102 - acc: 0.8487\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2102 - acc: 0.8488\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2102 - acc: 0.8487\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2101 - acc: 0.8488\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2100 - acc: 0.8488\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2100 - acc: 0.8488\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2099 - acc: 0.8486\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2099 - acc: 0.8488\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2098 - acc: 0.8489\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2097 - acc: 0.8491\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2097 - acc: 0.8493\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2096 - acc: 0.8494\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2096 - acc: 0.8494\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2095 - acc: 0.8495\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2094 - acc: 0.8498\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2094 - acc: 0.8499\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2093 - acc: 0.8501\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2093 - acc: 0.8500\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2092 - acc: 0.8500\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2092 - acc: 0.8500\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2091 - acc: 0.8501\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2091 - acc: 0.8501\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2090 - acc: 0.8501\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2090 - acc: 0.8502\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2089 - acc: 0.8502\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2089 - acc: 0.8502\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2088 - acc: 0.8504\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2088 - acc: 0.8505\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2087 - acc: 0.8507\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2087 - acc: 0.8509\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2086 - acc: 0.8512\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2086 - acc: 0.8512\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2085 - acc: 0.8512\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2085 - acc: 0.8512\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2084 - acc: 0.8514\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2084 - acc: 0.8514\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2084 - acc: 0.8515\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2083 - acc: 0.8516\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2083 - acc: 0.8516\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2082 - acc: 0.8516\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2082 - acc: 0.8518\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2081 - acc: 0.8521\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2081 - acc: 0.8521\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2080 - acc: 0.8520\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2080 - acc: 0.8521\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2080 - acc: 0.8520\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2079 - acc: 0.8520\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2079 - acc: 0.8521\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2078 - acc: 0.8523\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2078 - acc: 0.8524\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2077 - acc: 0.8524\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2077 - acc: 0.8526\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2076 - acc: 0.8527\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2076 - acc: 0.8527\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2075 - acc: 0.8528\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2075 - acc: 0.8526\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2074 - acc: 0.8526\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2074 - acc: 0.8527\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2073 - acc: 0.8527\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2073 - acc: 0.8526\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2073 - acc: 0.8527\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2072 - acc: 0.8526\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2072 - acc: 0.8528\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2071 - acc: 0.8528\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2071 - acc: 0.8530\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2070 - acc: 0.8530\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2070 - acc: 0.8532\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2069 - acc: 0.8532\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2069 - acc: 0.8533\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2069 - acc: 0.8535\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2068 - acc: 0.8535\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2068 - acc: 0.8536\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2067 - acc: 0.8536\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2067 - acc: 0.8539\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2066 - acc: 0.8539\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2064 - acc: 0.8540\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2062 - acc: 0.8542\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2062 - acc: 0.8541\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2061 - acc: 0.8539\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2060 - acc: 0.8540\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2060 - acc: 0.8541\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2059 - acc: 0.8542\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2058 - acc: 0.8542\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2058 - acc: 0.8542\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2057 - acc: 0.8543\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2056 - acc: 0.8544\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2056 - acc: 0.8545\n",
      "Epoch 1/1\n",
      " - 1s - loss: 0.2055 - acc: 0.8545\n"
     ]
    }
   ],
   "source": [
    "lstm_model=fit_lstm(x_vals_train,y_vals_train,batch,500,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4370\n",
      "(4370, 550)\n",
      "4000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(y_vals_test.shape[0])\n",
    "print(x_vals_test.shape)\n",
    "x_vals_test = x_vals_test[:4000]\n",
    "y_vals_test = y_vals_test[:4000]\n",
    "print(y_vals_test.shape[0])\n",
    "print(x_vals_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 50, 11)\n"
     ]
    }
   ],
   "source": [
    "#predictions=list()\n",
    "#for i in range(0,y_vals_test.shape[0]):\n",
    "x_vals_test_reshape=x_vals_test.reshape(x_vals_test.shape[0],seq_length,feature_size)\n",
    "print(x_vals_test_reshape.shape)\n",
    "\n",
    "yhat=lstm_model.predict(x_vals_test_reshape,batch)\n",
    "#predictions.append(yhat)\n",
    "predictions=yhat;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.892122]\n"
     ]
    }
   ],
   "source": [
    "print(yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save_weights('LSTM_SPEED_ACCEL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.40850434  0.04852006 -0.59674086  0.55385672 -0.04297951  0.06113536\n",
      "   0.23944664  0.09723322  0.78661816  0.3917976   0.51083412]\n",
      " [ 0.41319547  0.04617078 -0.59674086  0.55385672 -0.04297951  0.06113536\n",
      "   0.23944664  0.09723322  0.78661816  0.3917976   0.51083412]\n",
      " [ 0.41414104  0.05290029 -0.59674086  0.55385672 -0.04297951  0.06113536\n",
      "   0.23944664  0.09723322  0.78661816  0.3917976   0.51083412]\n",
      " [ 0.40881519  0.05077289 -0.59674086  0.55385672 -0.04297951  0.06113536\n",
      "   0.23944664  0.09723322  0.78661816  0.3917976   0.51083412]\n",
      " [ 0.41162497  0.03681375 -0.06915739  0.58919661 -0.1600317   0.30630068\n",
      "   0.10606599  0.2047431   0.781173    0.39844153  0.51600051]\n",
      " [ 0.4091263   0.02639389 -0.06915739  0.58919661 -0.1600317   0.30630068\n",
      "   0.10606599  0.2047431   0.781173    0.39844153  0.51600051]\n",
      " [ 0.40850434  0.02160961 -0.06915739  0.58919661 -0.1600317   0.30630068\n",
      "   0.10606599  0.2047431   0.781173    0.39844153  0.51600051]\n",
      " [ 0.39749116  0.0150965  -0.06915739  0.58919661 -0.1600317   0.30630068\n",
      "   0.10606599  0.2047431   0.781173    0.39844153  0.51600051]\n",
      " [ 0.3986981   0.00744201 -0.06915739  0.58919661 -0.1600317   0.30630068\n",
      "   0.10606599  0.2047431   0.781173    0.39844153  0.51600051]\n",
      " [ 0.4097493   0.01236747 -0.35500795  0.48390936 -0.03384778  0.27074235\n",
      "   0.17346579  0.17575759  0.78219464  0.39085467  0.52964459]\n",
      " [ 0.41603984  0.02121878 -0.35500795  0.48390936 -0.03384778  0.27074235\n",
      "   0.17346579  0.17575759  0.78219464  0.39085467  0.52964459]\n",
      " [ 0.41099864  0.01797552 -0.35500795  0.48390936 -0.03384778  0.27074235\n",
      "   0.17346579  0.17575759  0.78219464  0.39085467  0.52964459]\n",
      " [ 0.41699291  0.02188182 -0.35500795  0.48390936 -0.03384778  0.27074235\n",
      "   0.17346579  0.17575759  0.78219464  0.39085467  0.52964459]\n",
      " [ 0.41319547  0.02535364 -0.35500795  0.48390936 -0.03384778  0.27074235\n",
      "   0.17346579  0.17575759  0.78219464  0.39085467  0.52964459]\n",
      " [ 0.41667503  0.02490016 -0.14054054  0.57979706 -0.03716841  0.03930131\n",
      "   0.14012062  0.23583664  0.77873632  0.38974803  0.53600565]\n",
      " [ 0.42895818  0.03876831 -0.14054054  0.57979706 -0.03716841  0.03930131\n",
      "   0.14012062  0.23583664  0.77873632  0.38974803  0.53600565]\n",
      " [ 0.42083067  0.0503614  -0.14054054  0.57979706 -0.03716841  0.03930131\n",
      "   0.14012062  0.23583664  0.77873632  0.38974803  0.53600565]\n",
      " [ 0.41890676  0.05018141 -0.14054054  0.57979706 -0.03716841  0.03930131\n",
      "   0.14012062  0.23583664  0.77873632  0.38974803  0.53600565]\n",
      " [ 0.43325658  0.05030458 -0.14054054  0.57979706 -0.03716841  0.03930131\n",
      "   0.14012062  0.23583664  0.77873632  0.38974803  0.53600565]\n",
      " [ 0.44234669  0.05477155  0.05127186  0.22700847 -0.09663786  0.08796006\n",
      "   0.17914155  0.24268776  0.77712498  0.38166303  0.54951298]\n",
      " [ 0.43659748  0.05631999  0.05127186  0.22700847 -0.09663786  0.08796006\n",
      "   0.17914155  0.24268776  0.77712498  0.38166303  0.54951298]\n",
      " [ 0.43861649  0.05289096  0.05127186  0.22700847 -0.09663786  0.08796006\n",
      "   0.17914155  0.24268776  0.77712498  0.38166303  0.54951298]\n",
      " [ 0.45411606  0.0641397   0.05127186  0.22700847 -0.09663786  0.08796006\n",
      "   0.17914155  0.24268776  0.77712498  0.38166303  0.54951298]\n",
      " [ 0.44680343  0.07038367  0.05127186  0.22700847 -0.09663786  0.08796006\n",
      "   0.17914155  0.24268776  0.77712498  0.38166303  0.54951298]\n",
      " [ 0.45623148  0.06036427 -0.14626391  0.4966659  -0.08244972  0.17030567\n",
      "   0.16495213  0.24005272  0.77885422  0.37763137  0.55648957]\n",
      " [ 0.46193058  0.06841921 -0.14626391  0.4966659  -0.08244972  0.17030567\n",
      "   0.16495213  0.24005272  0.77885422  0.37763137  0.55648957]\n",
      " [ 0.47395824  0.08881307 -0.14626391  0.4966659  -0.08244972  0.17030567\n",
      "   0.16495213  0.24005272  0.77885422  0.37763137  0.55648957]\n",
      " [ 0.4761856   0.09015595 -0.14626391  0.4966659  -0.08244972  0.17030567\n",
      "   0.16495213  0.24005272  0.77885422  0.37763137  0.55648957]\n",
      " [ 0.47880032  0.07650199 -0.14626391  0.4966659  -0.08244972  0.17030567\n",
      "   0.16495213  0.24005272  0.77885422  0.37763137  0.55648957]\n",
      " [ 0.48218789  0.07845589 -0.23282989  0.2852369  -0.00388665  0.08421708\n",
      "   0.17417525  0.23214758  0.7828666   0.36660822  0.56878996]\n",
      " [ 0.49447286  0.09270077 -0.23282989  0.2852369  -0.00388665  0.08421708\n",
      "   0.17417525  0.23214758  0.7828666   0.36660822  0.56878996]\n",
      " [ 0.48943624  0.08516069 -0.23282989  0.2852369  -0.00388665  0.08421708\n",
      "   0.17417525  0.23214758  0.7828666   0.36660822  0.56878996]\n",
      " [ 0.50155276  0.08434795 -0.23282989  0.2852369  -0.00388665  0.08421708\n",
      "   0.17417525  0.23214758  0.7828666   0.36660822  0.56878996]\n",
      " [ 0.5039407   0.09344359 -0.23282989  0.2852369  -0.00388665  0.08421708\n",
      "   0.17417525  0.23214758  0.7828666   0.36660822  0.56878996]\n",
      " [ 0.49760417  0.07943878 -0.2772655   0.30952926 -0.0885627   0.06737367\n",
      "   0.13515432  0.13833994  0.77981377  0.37528271  0.57507297]\n",
      " [ 0.49957365  0.0632182  -0.2772655   0.30952926 -0.0885627   0.06737367\n",
      "   0.13515432  0.13833994  0.77981377  0.37528271  0.57507297]\n",
      " [ 0.51200316  0.06332388 -0.2772655   0.30952926 -0.0885627   0.06737367\n",
      "   0.13515432  0.13833994  0.77981377  0.37528271  0.57507297]\n",
      " [ 0.50754907  0.06562428 -0.2772655   0.30952926 -0.0885627   0.06737367\n",
      "   0.13515432  0.13833994  0.77981377  0.37528271  0.57507297]\n",
      " [ 0.51609483  0.06422157 -0.2772655   0.30952926 -0.0885627   0.06737367\n",
      "   0.13515432  0.13833994  0.77981377  0.37528271  0.57507297]\n",
      " [ 0.52566267  0.06601372 -0.33783784  0.42635233  0.00524509  0.15845289\n",
      "   0.13870168  0.22951254  0.77932504  0.38246612  0.58544045]\n",
      " [ 0.52989238  0.07082194 -0.33783784  0.42635233  0.00524509  0.15845289\n",
      "   0.13870168  0.22951254  0.77932504  0.38246612  0.58544045]\n",
      " [ 0.52861892  0.06779448 -0.33783784  0.42635233  0.00524509  0.15845289\n",
      "   0.13870168  0.22951254  0.77932504  0.38246612  0.58544045]\n",
      " [ 0.53502504  0.060914   -0.33783784  0.42635233  0.00524509  0.15845289\n",
      "   0.13870168  0.22951254  0.77932504  0.38246612  0.58544045]\n",
      " [ 0.53545564  0.06883224 -0.33783784  0.42635233  0.00524509  0.15845289\n",
      "   0.13870168  0.22951254  0.77932504  0.38246612  0.58544045]\n",
      " [ 0.53935068  0.07521415 -0.1799682   0.39662776  0.01860307  0.07174048\n",
      "   0.12876908  0.18945983  0.77731418  0.3875401   0.58995018]\n",
      " [ 0.53978571  0.06782186 -0.1799682   0.39662776  0.01860307  0.07174048\n",
      "   0.12876908  0.18945983  0.77731418  0.3875401   0.58995018]\n",
      " [ 0.55080811  0.07037825 -0.1799682   0.39662776  0.01860307  0.07174048\n",
      "   0.12876908  0.18945983  0.77731418  0.3875401   0.58995018]\n",
      " [ 0.54592311  0.07188015 -0.1799682   0.39662776  0.01860307  0.07174048\n",
      "   0.12876908  0.18945983  0.77731418  0.3875401   0.58995018]\n",
      " [ 0.55170237  0.05923826 -0.1799682   0.39662776  0.01860307  0.07174048\n",
      "   0.12876908  0.18945983  0.77731418  0.3875401   0.58995018]\n",
      " [ 0.56349909  0.06201226 -0.26581876  0.34193942 -0.10659975  0.04553961\n",
      "   0.11528913  0.20316207  0.77523251  0.38239568  0.59988222]]\n"
     ]
    }
   ],
   "source": [
    "print(x_vals_test_reshape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 105us/step\n"
     ]
    }
   ],
   "source": [
    "scores = lstm_model.evaluate(x_vals_test_reshape,y_vals_test,batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21533903665840626, 0.8479999974370003]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "push_index_pre=list()\n",
    "for i in range(len(predictions)):\n",
    "    if(predictions[i]>0):\n",
    "        predictions[i]=1\n",
    "        push_index_pre.append(i)\n",
    "    else:\n",
    "        predictions[i]=-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(push_index_pre))\n",
    "#print(push_index_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "predictions=np.squeeze(predictions)\n",
    "print(predictions+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_vals_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93275\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, y_vals_test), tf.float32))\n",
    "print(sess.run(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,)\n"
     ]
    }
   ],
   "source": [
    "match=tf.equal(predictions, y_vals_test)\n",
    "print(match.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'lstm_13/kernel:0' shape=(11, 4) dtype=float32_ref>, <tf.Variable 'lstm_13/recurrent_kernel:0' shape=(1, 4) dtype=float32_ref>, <tf.Variable 'lstm_13/bias:0' shape=(4,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.layers[0].weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-2.467588  , -0.4748822 , -0.29248804,  1.5438935 ],\n",
      "       [ 6.879515  , -0.9053682 , -3.8640919 , -4.058645  ],\n",
      "       [-3.0119777 , -0.16483419, -0.09317629,  0.8482545 ],\n",
      "       [-0.50112706,  0.27462587,  0.20877554, -0.45988902],\n",
      "       [-0.8812889 ,  0.7433692 , -0.04812019, -1.0335091 ],\n",
      "       [ 0.62394816, -0.18716961,  0.05548005, -0.48061693],\n",
      "       [ 2.8513088 ,  0.270967  ,  0.5809678 , -1.3313452 ],\n",
      "       [ 1.8459439 ,  0.23768651,  0.11361132,  0.09316795],\n",
      "       [ 0.3595688 ,  0.6126058 ,  0.34139833, -0.14293793],\n",
      "       [ 0.76729995,  0.5086219 , -0.8453934 , -0.22615564],\n",
      "       [-0.32726464, -0.08386017, -0.04319441,  0.1744854 ]],\n",
      "      dtype=float32), array([[ 1.9057307 , -0.30936152,  0.53360456, -2.9849014 ]],\n",
      "      dtype=float32), array([ 0.22584009,  1.2504009 ,  0.3241909 , -0.3518248 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.layers[0].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-1.6313976]], dtype=float32), array([-0.6648892], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print((lstm_model.layers[1].get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function linear at 0x7f9363cdb6a8>\n"
     ]
    }
   ],
   "source": [
    "print((lstm_model.layers[1].activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'lstm_12/kernel:0' shape=(3, 4) dtype=float32_ref>, <tf.Variable 'lstm_12/recurrent_kernel:0' shape=(1, 4) dtype=float32_ref>, <tf.Variable 'lstm_12/bias:0' shape=(4,) dtype=float32_ref>, <tf.Variable 'dense_12/kernel:0' shape=(1, 1) dtype=float32_ref>, <tf.Variable 'dense_12/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "print((lstm_model.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-2.9086483 , -1.3354431 , -0.41930252,  1.1520714 ],\n",
      "       [10.030381  ,  0.78706133, -6.2370963 , -3.346558  ],\n",
      "       [-0.08319151,  0.01163469,  0.11354639,  0.80962485]],\n",
      "      dtype=float32), array([[ 0.7697514 , -0.68766826,  0.44904068, -1.5737821 ]],\n",
      "      dtype=float32), array([2.1102474 , 2.1775978 , 0.7336147 , 0.22738917], dtype=float32), array([[-1.0524479]], dtype=float32), array([-0.5111496], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'lstm_12/kernel:0' shape=(3, 4) dtype=float32_ref>, <tf.Variable 'lstm_12/recurrent_kernel:0' shape=(1, 4) dtype=float32_ref>, <tf.Variable 'lstm_12/bias:0' shape=(4,) dtype=float32_ref>, <tf.Variable 'dense_12/kernel:0' shape=(1, 1) dtype=float32_ref>, <tf.Variable 'dense_12/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "print((lstm_model.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-2.0519213e-01,  4.5701525e-01,  5.6810164e-01, -6.5351076e-02,\n",
      "         3.2100949e-01,  4.0525311e-01,  3.2218349e-01, -3.3198297e-01,\n",
      "        -5.8441274e-02,  2.5772029e-01,  3.0936098e-01,  3.7396160e-01,\n",
      "         1.2128439e-01,  4.9625224e-01, -6.1145779e-03, -1.6282354e-01,\n",
      "         3.9555740e-02,  2.5088429e-01,  2.0375276e-01, -7.9840146e-02,\n",
      "         1.6427815e-01,  1.7783567e-01,  1.9600633e-01,  3.5709006e-01,\n",
      "        -4.3715473e-02,  2.7845672e-01, -9.3587600e-02, -1.1968474e-01,\n",
      "        -2.2350639e-01,  2.2780266e-01, -2.4385601e-01,  1.2654191e-01,\n",
      "        -2.2941810e-01,  3.6963925e-02,  2.3294114e-01, -7.4179471e-02,\n",
      "        -9.4008744e-03,  2.4523064e-01,  3.8190812e-01, -4.7663590e-01,\n",
      "         2.8878564e-01,  5.7949066e-02,  1.8276794e-01, -1.3898808e-02,\n",
      "         1.6178323e-02,  1.8885452e-01,  2.4988143e-01, -2.3832142e-01,\n",
      "        -2.9681221e-01,  1.0154809e-02, -3.3184800e-02,  5.6644864e-02,\n",
      "         1.5588007e-03,  4.9233124e-02,  3.0181202e-01,  2.3018456e-01,\n",
      "        -3.0841550e-01,  3.2888564e-01,  1.3913992e-01,  1.2259420e-02,\n",
      "        -3.6042356e-01, -1.1819929e-01, -3.2270050e-01,  4.7710072e-02,\n",
      "        -2.7221495e-01, -3.5196424e-01, -3.2150604e-02, -2.6473422e-02,\n",
      "         4.4007376e-01,  3.3281094e-01,  3.4631914e-01,  3.9513993e-01,\n",
      "         3.9691645e-01,  2.5174439e-01, -2.2125304e-01, -3.1580529e-01,\n",
      "         1.4937812e-01,  8.8322796e-02, -3.8273841e-02,  2.9008225e-01,\n",
      "        -8.3687015e-02, -2.4010148e-02,  1.1490471e-01, -1.8419494e-01,\n",
      "        -1.5394577e-01,  7.8433461e-02,  6.7139226e-01, -1.5453376e-02,\n",
      "         7.0302647e-01, -2.4023189e-01,  9.3361333e-02, -1.7667869e-03,\n",
      "        -1.4672922e-01,  9.8199382e-02,  4.3622777e-01,  2.7243504e-01,\n",
      "        -2.9454497e-01,  1.2967907e-01,  4.2111024e-01, -2.2810721e-01,\n",
      "         1.1691584e-01,  4.3468085e-01,  8.2634993e-02, -3.3293176e-01,\n",
      "         1.2830507e-02, -4.6485323e-02,  2.8228641e-01, -1.8131886e-01,\n",
      "         5.9231576e-02,  4.5721403e-01,  4.3894899e-01, -2.9199666e-01,\n",
      "        -1.2811668e-01,  3.5711575e-01,  1.3244422e-01, -1.9069925e-01,\n",
      "         2.8155252e-01, -1.3411132e-01,  1.4845936e-01,  2.8685355e-01,\n",
      "         1.8821351e-01,  3.4112480e-01,  2.0127963e-01,  1.8391056e-02,\n",
      "        -3.5070100e-01,  4.3953960e-03, -3.3392027e-01, -1.7449972e-01],\n",
      "       [-1.8228994e-01,  3.7997764e-01,  3.5674500e-01, -2.5023732e-01,\n",
      "        -1.3161930e-01, -7.7295274e-02, -4.6592134e-01,  2.9098955e-01,\n",
      "         9.1001317e-02,  1.0340503e-01,  3.9753157e-01, -7.1805555e-01,\n",
      "        -1.9313473e-01, -1.2277514e+00, -9.9001028e-02, -5.1394618e-01,\n",
      "        -9.6742147e-01, -5.1367909e-01,  5.6187034e-01, -2.2449939e-01,\n",
      "        -8.5603654e-02, -5.6724902e-02,  5.2226257e-01, -1.2586674e-01,\n",
      "         3.1018320e-01, -3.7086782e-01,  7.8673983e-01, -3.0443537e-01,\n",
      "         1.4745910e-01,  3.5138285e-01,  7.0561504e-01,  7.0198631e-01,\n",
      "        -3.5090408e-01, -9.8825648e-02,  8.6300182e-01, -9.2070395e-01,\n",
      "        -2.9039496e-01,  1.9445594e-01, -9.1241890e-01, -9.7027771e-02,\n",
      "         5.2279317e-01, -7.5269654e-02,  3.4320515e-01, -1.0530165e+00,\n",
      "         3.9055923e-01, -9.6093893e-01,  4.4521335e-01, -7.8690398e-01,\n",
      "        -1.0797299e+00, -1.4629592e-02,  4.6682569e-01, -4.2940986e-01,\n",
      "        -1.6276851e-01,  7.8517802e-02,  9.6773130e-01, -2.5235850e-01,\n",
      "         1.0764971e+00,  3.1643633e-02,  1.1986697e+00, -7.2530258e-01,\n",
      "        -2.9033297e-01,  1.5638548e-01,  4.0673018e-01,  8.0544889e-02,\n",
      "         8.5887772e-01, -4.8651701e-01, -5.8541822e-01, -6.0869491e-01,\n",
      "         1.1004329e+00, -3.9899078e-01, -2.4697959e-01,  1.5443957e-01,\n",
      "         6.8170619e-01,  2.7250251e-01,  5.1053900e-01,  2.8356481e-01,\n",
      "        -1.5496777e-01, -1.0288819e+00, -7.5774664e-01,  5.6528491e-01,\n",
      "         3.9697900e-01, -1.1574873e+00,  3.0038229e-01, -9.6737897e-01,\n",
      "        -8.5665005e-01,  7.3177248e-01, -1.3122104e-01, -9.0738350e-01,\n",
      "        -7.9348199e-02,  6.4388615e-01,  4.5588732e-01,  1.2459666e-01,\n",
      "        -3.3754137e-01, -7.2730523e-01,  2.6668841e-01,  3.2621622e-01,\n",
      "        -4.1073695e-01,  2.8928721e-01,  1.2923957e+00, -4.8987970e-01,\n",
      "        -8.5039169e-02, -7.1446306e-01, -1.4025475e+00,  4.9794286e-01,\n",
      "         5.7396317e-01,  2.8578272e-02,  1.2828757e-01, -1.1888531e+00,\n",
      "         5.7787997e-01, -8.3905959e-01,  8.4535384e-01, -1.0024520e+00,\n",
      "        -1.7361226e+00,  5.0164018e-02,  8.9985001e-01, -2.3643367e-01,\n",
      "         2.3376973e-01, -6.3781247e-02,  1.2400506e+00, -1.1642952e-01,\n",
      "         1.1900150e+00, -3.0547896e-01,  1.8265948e+00, -8.1510651e-01,\n",
      "        -7.5198615e-01,  3.2554236e-01, -3.4414846e-02,  4.1087008e-01]],\n",
      "      dtype=float32), array([[-0.08911429, -0.44501847, -0.091865  , ...,  0.01808339,\n",
      "         0.20286429,  0.38357008],\n",
      "       [ 0.10152645, -0.1477148 , -0.21491997, ..., -0.08633821,\n",
      "         0.20973195, -0.1249599 ],\n",
      "       [ 0.36306465,  0.4520231 ,  0.01162947, ..., -0.2153196 ,\n",
      "        -0.14022772, -0.5496734 ],\n",
      "       ...,\n",
      "       [ 0.00793493, -0.14073546,  0.17247781, ..., -0.10837752,\n",
      "        -0.00871632, -0.08196475],\n",
      "       [ 0.18115215,  0.23443429,  0.16321474, ...,  0.31149137,\n",
      "        -0.16508679, -0.10321772],\n",
      "       [ 0.03305934,  0.322714  , -0.15917473, ...,  0.23251998,\n",
      "        -0.265942  ,  0.0774781 ]], dtype=float32), array([ 0.12002724,  0.15269598,  0.1862855 ,  0.13586135,  0.34903848,\n",
      "        0.22209352,  0.2668411 ,  0.07924236,  0.25235143,  0.01787189,\n",
      "        0.18306126,  0.09006511,  0.06816694,  0.25504676,  0.22349805,\n",
      "        0.17697375,  0.1381    ,  0.252949  ,  0.01167721,  0.1845979 ,\n",
      "        0.24615793,  0.24446876,  0.333067  ,  0.27399954,  0.48019296,\n",
      "        0.10356139,  0.09030973,  0.03025937,  0.06955671,  0.13774401,\n",
      "        0.26096538,  0.2015015 ,  1.0029304 ,  1.0580685 ,  1.0694792 ,\n",
      "        1.1659696 ,  1.0353011 ,  1.1043038 ,  1.1030648 ,  1.0618019 ,\n",
      "        1.1466242 ,  1.0092134 ,  1.0040493 ,  0.96749306,  0.98955333,\n",
      "        1.0319574 ,  1.0621976 ,  1.0745748 ,  1.1188973 ,  1.0068521 ,\n",
      "        0.99427557,  0.98692626,  1.1315702 ,  1.0850878 ,  1.2847165 ,\n",
      "        1.1562577 ,  1.2641424 ,  1.044929  ,  1.0415537 ,  1.0292313 ,\n",
      "        1.0900048 ,  1.0555464 ,  1.081833  ,  0.9717339 ,  0.11333886,\n",
      "       -0.06973902, -0.11383875,  0.10521448,  0.0225257 ,  0.10408434,\n",
      "        0.0771978 , -0.09153319, -0.04457064,  0.07093658, -0.07642117,\n",
      "       -0.0151828 , -0.03927091,  0.05460484,  0.01436964, -0.04367997,\n",
      "       -0.03865514,  0.03744911, -0.01085342,  0.05243345, -0.03390863,\n",
      "       -0.11516776, -0.10117438, -0.03420014, -0.08796186,  0.00321898,\n",
      "       -0.09824008, -0.07749971,  0.08923318,  0.09398856, -0.04834238,\n",
      "        0.01336041, -0.03952974,  0.04023771,  0.1936045 ,  0.0497123 ,\n",
      "        0.33044368,  0.14545459,  0.03181886,  0.0543237 ,  0.19204143,\n",
      "        0.01203756,  0.13327171,  0.00457397, -0.02442384,  0.1581426 ,\n",
      "        0.18839858,  0.13319218,  0.05477616,  0.17887376,  0.0918683 ,\n",
      "        0.09401939,  0.19289929,  0.07393067,  0.38329312,  0.18058403,\n",
      "        0.25260425,  0.01919319,  0.13029228, -0.03607425, -0.00275927,\n",
      "        0.08013426,  0.08857307,  0.1725659 ], dtype=float32), array([[-0.23266067],\n",
      "       [ 0.21392907],\n",
      "       [ 0.07865428],\n",
      "       [-0.5508916 ],\n",
      "       [-0.57903117],\n",
      "       [ 0.01638051],\n",
      "       [-0.36860162],\n",
      "       [ 0.08924131],\n",
      "       [-0.5514988 ],\n",
      "       [ 0.03333083],\n",
      "       [ 0.27300745],\n",
      "       [-0.20837377],\n",
      "       [ 0.34530377],\n",
      "       [-0.30975935],\n",
      "       [ 0.13245425],\n",
      "       [ 0.03083185],\n",
      "       [ 0.47748086],\n",
      "       [ 0.2540837 ],\n",
      "       [-0.36388612],\n",
      "       [-0.41738388],\n",
      "       [ 0.4747389 ],\n",
      "       [ 0.35575706],\n",
      "       [ 0.20289493],\n",
      "       [ 0.29337204],\n",
      "       [ 0.05398067],\n",
      "       [-0.4808728 ],\n",
      "       [ 0.40038723],\n",
      "       [ 0.3086184 ],\n",
      "       [-0.18027851],\n",
      "       [-0.3300686 ],\n",
      "       [ 0.05471107],\n",
      "       [ 0.27268016]], dtype=float32), array([-0.02986862], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'lstm_2/kernel:0' shape=(11, 128) dtype=float32_ref>, <tf.Variable 'lstm_2/recurrent_kernel:0' shape=(32, 128) dtype=float32_ref>, <tf.Variable 'lstm_2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'dense_2/kernel:0' shape=(32, 1) dtype=float32_ref>, <tf.Variable 'dense_2/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.equal((predictions), y_vals_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0255537 ]\n",
      " [-1.0128306 ]\n",
      " [-0.97264886]\n",
      " ...\n",
      " [-0.85350156]\n",
      " [-0.81048137]\n",
      " [-0.96145207]]\n",
      "(4000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(yhat)\n",
    "print(yhat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
