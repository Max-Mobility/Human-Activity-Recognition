{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Conv1D,Activation,MaxPooling1D,Dense,Flatten,UpSampling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model,load_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_model(myinputs,channel=3):\n",
    "    x     = Conv1D(filters =16, kernel_size=5,strides = 1, padding = 'same')(myinputs)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = MaxPooling1D(pool_size=3,strides = 2,padding='same')(x)\n",
    "    #  x shape is 64X48 =3072\n",
    "    x     = Conv1D(filters =24, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = MaxPooling1D(pool_size=2,strides = 2,padding='same')(x)\n",
    "    #  x shape is 32X64 = 2048\n",
    "    x     = Conv1D(filters =32, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = MaxPooling1D(pool_size=2,strides = 2,padding='same')(x)\n",
    "    # x shape is 16*96 = 1536\n",
    "    x     = Conv1D(filters =32, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = MaxPooling1D(pool_size=2,strides = 2,padding='same')(x)\n",
    "    # x shape is 8*128 = 1024\n",
    "    x     = Conv1D(filters =48, kernel_size=3,strides = 2, padding = 'same')(x)\n",
    "    # x shape is 4*128 = 512\n",
    "\n",
    "    latent_vector = Flatten()(x)\n",
    "    # decoder x = 4*128\n",
    "    x     = Conv1D(filters =32, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = UpSampling1D(2)(x)\n",
    "    # x shape is 8*128\n",
    "    x     = Conv1D(filters =32, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = UpSampling1D(2)(x)\n",
    "    # x shape is 16*96\n",
    "    x     = Conv1D(filters =24, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = UpSampling1D(2)(x)\n",
    "    # x shape is 32*64\n",
    "    x     = Conv1D(filters =16, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = UpSampling1D(2)(x)\n",
    "    # x shape is 64*48\n",
    "    x     = Conv1D(filters =16, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = UpSampling1D(2)(x)\n",
    "    # x shape is 128*48\n",
    "    y     = Conv1D(filters =channel, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    return latent_vector,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(name=\"push_detect\",channel=3):\n",
    "    # input shape 128X26 =3382\n",
    "    with tf.name_scope(name):\n",
    "        myInputs = Input(shape=(128,channel))\n",
    "                \n",
    "        LV,Y = get_sub_model(myInputs,channel=channel)\n",
    "        \n",
    "        autoencoder = Model (inputs=myInputs,\n",
    "                             outputs =Y)\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyroModel=build_model()\n",
    "linearAccModel=build_model()\n",
    "gravityModel=build_model()\n",
    "gameVecModel=build_model(channel=4)\n",
    "opt = keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "gyroModel.compile(optimizer=opt,loss='mse',metrics=['accuracy'])\n",
    "opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "linearAccModel.compile(optimizer=opt,loss='mse',metrics=['accuracy'])\n",
    "opt = keras.optimizers.SGD(lr=0.00001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "gravityModel.compile(optimizer=opt,loss='mse',metrics=['accuracy'])\n",
    "opt = keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "gameVecModel.compile(optimizer=opt,loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= np.load('watch.npy')\n",
    "np.random.shuffle(data)\n",
    "p=0.85\n",
    "train_num =int(data.shape[0]*p)\n",
    "gyro_train=data[:train_num,:,13:16]\n",
    "linearAcc_train=data[:train_num,:,16:19]\n",
    "gravity_train=data[:train_num,:,19:22]\n",
    "gameVec_train=data[:train_num,:,22:26]\n",
    "\n",
    "gyro_test =data[train_num:,:,13:16]\n",
    "linearAcc_test =data[train_num:,:,16:19]\n",
    "gravity_test =data[train_num:,:,19:22]\n",
    "gameVec_test =data[train_num:,:,22:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training round 0\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 35.5028 - acc: 0.6913 - val_loss: 33.3562 - val_acc: 0.6760\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 34.4216 - acc: 0.6901 - val_loss: 34.3767 - val_acc: 0.6748\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 35.0050 - acc: 0.6885 - val_loss: 37.4822 - val_acc: 0.6763\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 35.4059 - acc: 0.6849 - val_loss: 34.4512 - val_acc: 0.6776\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 34.2718 - acc: 0.6840 - val_loss: 36.5376 - val_acc: 0.6694\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 35.1953 - acc: 0.6851 - val_loss: 33.4377 - val_acc: 0.6781\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 34.3750 - acc: 0.6804 - val_loss: 40.7827 - val_acc: 0.6777\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 34.9654 - acc: 0.6875 - val_loss: 35.0648 - val_acc: 0.6762\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 35.2829 - acc: 0.6884 - val_loss: 36.1160 - val_acc: 0.6693\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - ETA: 0s - loss: 34.2481 - acc: 0.68 - 3s 381us/step - loss: 34.1924 - acc: 0.6829 - val_loss: 33.6878 - val_acc: 0.6771\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 34.8132 - acc: 0.6804 - val_loss: 34.5190 - val_acc: 0.6746\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 34.9807 - acc: 0.6902 - val_loss: 36.4798 - val_acc: 0.6755\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 34.7014 - acc: 0.6828 - val_loss: 33.4548 - val_acc: 0.6766\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 34.5306 - acc: 0.6796 - val_loss: 37.4516 - val_acc: 0.6678\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 35.2748 - acc: 0.6811 - val_loss: 34.7051 - val_acc: 0.6744\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 34.9295 - acc: 0.6802 - val_loss: 34.3537 - val_acc: 0.6752\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 34.2002 - acc: 0.6815 - val_loss: 35.3646 - val_acc: 0.6699\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 34.4279 - acc: 0.6795 - val_loss: 35.5797 - val_acc: 0.6805\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 35.5901 - acc: 0.6808 - val_loss: 34.9285 - val_acc: 0.7101\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 34.5074 - acc: 0.6931 - val_loss: 35.4534 - val_acc: 0.6850\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 34.1194 - acc: 0.6818 - val_loss: 35.4072 - val_acc: 0.6805\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 34.8430 - acc: 0.6793 - val_loss: 34.3609 - val_acc: 0.6834\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 35.2172 - acc: 0.6814 - val_loss: 36.5325 - val_acc: 0.7102\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 35.0248 - acc: 0.6934 - val_loss: 35.3231 - val_acc: 0.6820\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 34.9497 - acc: 0.6803 - val_loss: 33.9120 - val_acc: 0.6820\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 33.9253 - acc: 0.6797 - val_loss: 32.7098 - val_acc: 0.6749\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 34.9878 - acc: 0.6791 - val_loss: 35.9365 - val_acc: 0.6757\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 34.7562 - acc: 0.6843 - val_loss: 40.5444 - val_acc: 0.6743\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 35.1479 - acc: 0.6849 - val_loss: 35.1320 - val_acc: 0.6714\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 33.9659 - acc: 0.6857 - val_loss: 34.6380 - val_acc: 0.6808\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 34.5169 - acc: 0.6822 - val_loss: 35.2770 - val_acc: 0.6812\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 35.2693 - acc: 0.6816 - val_loss: 34.4521 - val_acc: 0.6838\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 34.2900 - acc: 0.6823 - val_loss: 35.0285 - val_acc: 0.6817\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 34.8384 - acc: 0.6835 - val_loss: 33.0321 - val_acc: 0.6793\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 34.4256 - acc: 0.6798 - val_loss: 34.5131 - val_acc: 0.6755\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 34.8094 - acc: 0.6794 - val_loss: 34.4536 - val_acc: 0.6751\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 34.2800 - acc: 0.6795 - val_loss: 35.1712 - val_acc: 0.6698\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 34.9861 - acc: 0.6798 - val_loss: 34.6393 - val_acc: 0.6787\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 34.5238 - acc: 0.6791 - val_loss: 33.8530 - val_acc: 0.6824\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 34.7565 - acc: 0.6796 - val_loss: 34.2889 - val_acc: 0.6801\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 33.8098 - acc: 0.6789 - val_loss: 34.5941 - val_acc: 0.6719\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 34.8080 - acc: 0.6787 - val_loss: 34.5919 - val_acc: 0.6756\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 34.9356 - acc: 0.6832 - val_loss: 35.9061 - val_acc: 0.6712\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 34.3697 - acc: 0.6797 - val_loss: 34.7268 - val_acc: 0.6704\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 34.5679 - acc: 0.6802 - val_loss: 36.5159 - val_acc: 0.6742\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 34.6406 - acc: 0.6813 - val_loss: 33.6950 - val_acc: 0.6739\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 34.0399 - acc: 0.6813 - val_loss: 33.0467 - val_acc: 0.6774\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 34.5388 - acc: 0.6790 - val_loss: 35.3215 - val_acc: 0.6837\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 34.9293 - acc: 0.6796 - val_loss: 33.9107 - val_acc: 0.6838\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 33.9489 - acc: 0.6835 - val_loss: 37.1352 - val_acc: 0.6840\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 124.0266 - acc: 0.6200 - val_loss: 128.0113 - val_acc: 0.6182\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 125.1307 - acc: 0.6250 - val_loss: 136.3763 - val_acc: 0.6150\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 129.1877 - acc: 0.6258 - val_loss: 126.4978 - val_acc: 0.6197\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 125.1605 - acc: 0.6244 - val_loss: 127.1917 - val_acc: 0.6193\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 125.5833 - acc: 0.6239 - val_loss: 128.6863 - val_acc: 0.6184\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 126.3955 - acc: 0.6250 - val_loss: 125.3050 - val_acc: 0.6181\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 124.6132 - acc: 0.6237 - val_loss: 128.3417 - val_acc: 0.6207\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 380us/step - loss: 126.6363 - acc: 0.6251 - val_loss: 124.5226 - val_acc: 0.6219\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 124.4778 - acc: 0.6234 - val_loss: 127.4210 - val_acc: 0.6163\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 124.7380 - acc: 0.6225 - val_loss: 125.2810 - val_acc: 0.6193\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 125.0964 - acc: 0.6251 - val_loss: 127.4831 - val_acc: 0.6194\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 127.3175 - acc: 0.6248 - val_loss: 128.8018 - val_acc: 0.6191\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 127.5771 - acc: 0.6240 - val_loss: 124.7365 - val_acc: 0.6198\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 124.3771 - acc: 0.6258 - val_loss: 124.5413 - val_acc: 0.6200\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 123.9424 - acc: 0.6248 - val_loss: 131.0303 - val_acc: 0.6152\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 123.5208 - acc: 0.6211 - val_loss: 124.0184 - val_acc: 0.6167\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 122.5079 - acc: 0.6232 - val_loss: 123.5923 - val_acc: 0.6203\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 122.1397 - acc: 0.6250 - val_loss: 123.6688 - val_acc: 0.6200\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 122.8661 - acc: 0.6215 - val_loss: 127.0965 - val_acc: 0.6139\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 123.6411 - acc: 0.6240 - val_loss: 129.1964 - val_acc: 0.6198\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 127.9341 - acc: 0.6255 - val_loss: 130.2467 - val_acc: 0.6201\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 127.1032 - acc: 0.6256 - val_loss: 130.9557 - val_acc: 0.6202\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 125.5640 - acc: 0.6227 - val_loss: 125.1522 - val_acc: 0.6211\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 123.9238 - acc: 0.6259 - val_loss: 127.0506 - val_acc: 0.6180\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 125.1499 - acc: 0.6241 - val_loss: 128.3009 - val_acc: 0.6170\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 124.1292 - acc: 0.6231 - val_loss: 124.9079 - val_acc: 0.6200\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 123.5435 - acc: 0.6261 - val_loss: 130.2195 - val_acc: 0.6186\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 127.8502 - acc: 0.6244 - val_loss: 127.0305 - val_acc: 0.6212\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 127.8906 - acc: 0.6265 - val_loss: 125.7611 - val_acc: 0.6217\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 125.9153 - acc: 0.6246 - val_loss: 129.1802 - val_acc: 0.6216\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 126.3564 - acc: 0.6252 - val_loss: 124.8937 - val_acc: 0.6194\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 122.1265 - acc: 0.6251 - val_loss: 126.9709 - val_acc: 0.6209\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 124.1193 - acc: 0.6251 - val_loss: 129.2846 - val_acc: 0.6181\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 126.3850 - acc: 0.6260 - val_loss: 127.7018 - val_acc: 0.6218\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 360us/step - loss: 126.5722 - acc: 0.6229 - val_loss: 123.5438 - val_acc: 0.6211\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 124.9889 - acc: 0.6250 - val_loss: 124.0295 - val_acc: 0.6195\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 124.4452 - acc: 0.6217 - val_loss: 126.1806 - val_acc: 0.6196\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 125.0394 - acc: 0.6263 - val_loss: 124.2869 - val_acc: 0.6230\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 126.1908 - acc: 0.6264 - val_loss: 123.6014 - val_acc: 0.6221\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 122.9421 - acc: 0.6246 - val_loss: 128.0107 - val_acc: 0.6016\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 122.6138 - acc: 0.6221 - val_loss: 125.5162 - val_acc: 0.6186\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 122.8332 - acc: 0.6249 - val_loss: 125.9217 - val_acc: 0.6182\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 123.3543 - acc: 0.6257 - val_loss: 131.5594 - val_acc: 0.6195\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 125.4160 - acc: 0.6252 - val_loss: 125.2635 - val_acc: 0.6225\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 126.9215 - acc: 0.6268 - val_loss: 129.5344 - val_acc: 0.6218\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 126.0157 - acc: 0.6262 - val_loss: 129.1728 - val_acc: 0.6196\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 123.9427 - acc: 0.6227 - val_loss: 126.5633 - val_acc: 0.6094\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 122.8828 - acc: 0.6221 - val_loss: 123.5796 - val_acc: 0.6189\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 121.5314 - acc: 0.6242 - val_loss: 124.3798 - val_acc: 0.6178\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 122.4511 - acc: 0.6222 - val_loss: 122.5592 - val_acc: 0.6219\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 60.5603 - acc: 0.4261 - val_loss: 56.5730 - val_acc: 0.4308\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 60.5179 - acc: 0.4264 - val_loss: 56.5505 - val_acc: 0.4262\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 60.4923 - acc: 0.4253 - val_loss: 56.5175 - val_acc: 0.4314\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 60.4523 - acc: 0.4264 - val_loss: 56.4699 - val_acc: 0.4277\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 60.4274 - acc: 0.4259 - val_loss: 56.4478 - val_acc: 0.4304\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 60.3890 - acc: 0.4262 - val_loss: 56.4184 - val_acc: 0.4286\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 60.3550 - acc: 0.4257 - val_loss: 56.3949 - val_acc: 0.4319\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 60.3195 - acc: 0.4268 - val_loss: 56.3540 - val_acc: 0.4304\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 60.2932 - acc: 0.4264 - val_loss: 56.3140 - val_acc: 0.4300\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 60.2628 - acc: 0.4266 - val_loss: 56.3181 - val_acc: 0.4313\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 60.2246 - acc: 0.4267 - val_loss: 56.2745 - val_acc: 0.4329\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 60.1874 - acc: 0.4270 - val_loss: 56.2412 - val_acc: 0.4270\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 60.1639 - acc: 0.4260 - val_loss: 56.2058 - val_acc: 0.4320\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 60.1261 - acc: 0.4275 - val_loss: 56.1721 - val_acc: 0.4274\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 60.1045 - acc: 0.4264 - val_loss: 56.1390 - val_acc: 0.4317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 60.0654 - acc: 0.4269 - val_loss: 56.1122 - val_acc: 0.4324\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 60.0334 - acc: 0.4268 - val_loss: 56.1102 - val_acc: 0.4322\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 60.0021 - acc: 0.4266 - val_loss: 56.0656 - val_acc: 0.4317\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 59.9727 - acc: 0.4276 - val_loss: 56.0445 - val_acc: 0.4292\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 362us/step - loss: 59.9432 - acc: 0.4264 - val_loss: 56.0084 - val_acc: 0.4322\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 59.9134 - acc: 0.4270 - val_loss: 55.9724 - val_acc: 0.4317\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 59.8781 - acc: 0.4274 - val_loss: 55.9483 - val_acc: 0.4315\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 59.8471 - acc: 0.4272 - val_loss: 55.9389 - val_acc: 0.4301\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 59.8248 - acc: 0.4264 - val_loss: 55.9318 - val_acc: 0.4340\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 59.7949 - acc: 0.4274 - val_loss: 55.8734 - val_acc: 0.4318\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 59.7655 - acc: 0.4269 - val_loss: 55.8406 - val_acc: 0.4318\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 59.7317 - acc: 0.4270 - val_loss: 55.8045 - val_acc: 0.4326\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 59.7052 - acc: 0.4277 - val_loss: 55.7881 - val_acc: 0.4317\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 59.6770 - acc: 0.4276 - val_loss: 55.7584 - val_acc: 0.4307\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 59.6468 - acc: 0.4270 - val_loss: 55.7344 - val_acc: 0.4337\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 59.6168 - acc: 0.4272 - val_loss: 55.6962 - val_acc: 0.4323\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 59.5883 - acc: 0.4272 - val_loss: 55.7126 - val_acc: 0.4334\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 59.5619 - acc: 0.4274 - val_loss: 55.6507 - val_acc: 0.4312\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 59.5398 - acc: 0.4271 - val_loss: 55.6313 - val_acc: 0.4326\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 59.5041 - acc: 0.4273 - val_loss: 55.6204 - val_acc: 0.4340\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 59.4818 - acc: 0.4281 - val_loss: 55.5649 - val_acc: 0.4314\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 59.4481 - acc: 0.4273 - val_loss: 55.5348 - val_acc: 0.4316\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 59.4215 - acc: 0.4272 - val_loss: 55.5201 - val_acc: 0.4324\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 59.3986 - acc: 0.4277 - val_loss: 55.4844 - val_acc: 0.4310\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 59.3650 - acc: 0.4276 - val_loss: 55.4697 - val_acc: 0.4334\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 59.3463 - acc: 0.4273 - val_loss: 55.4461 - val_acc: 0.4329\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 59.3141 - acc: 0.4279 - val_loss: 55.4130 - val_acc: 0.4309\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 59.2851 - acc: 0.4275 - val_loss: 55.3898 - val_acc: 0.4318\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 59.2589 - acc: 0.4278 - val_loss: 55.3677 - val_acc: 0.4294\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 59.2351 - acc: 0.4275 - val_loss: 55.3387 - val_acc: 0.4320\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 59.2090 - acc: 0.4276 - val_loss: 55.3175 - val_acc: 0.4317\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 59.1820 - acc: 0.4276 - val_loss: 55.2951 - val_acc: 0.4327\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 59.1525 - acc: 0.4281 - val_loss: 55.2634 - val_acc: 0.4330\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 59.1356 - acc: 0.4276 - val_loss: 55.2313 - val_acc: 0.4312\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 59.1056 - acc: 0.4276 - val_loss: 55.2346 - val_acc: 0.4344\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5698 - acc: 0.4325 - val_loss: 0.5325 - val_acc: 0.4324\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.5700 - acc: 0.4324 - val_loss: 0.5350 - val_acc: 0.4321\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5706 - acc: 0.4324 - val_loss: 0.5306 - val_acc: 0.4323\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5694 - acc: 0.4325 - val_loss: 0.5318 - val_acc: 0.4328\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5692 - acc: 0.4326 - val_loss: 0.5307 - val_acc: 0.4323\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5696 - acc: 0.4325 - val_loss: 0.5300 - val_acc: 0.4325\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5691 - acc: 0.4327 - val_loss: 0.5310 - val_acc: 0.4325\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5686 - acc: 0.4327 - val_loss: 0.5298 - val_acc: 0.4325\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.5685 - acc: 0.4327 - val_loss: 0.5301 - val_acc: 0.4327\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5685 - acc: 0.4329 - val_loss: 0.5298 - val_acc: 0.4328\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5686 - acc: 0.4328 - val_loss: 0.5294 - val_acc: 0.4334\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5682 - acc: 0.4329 - val_loss: 0.5325 - val_acc: 0.4332\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5679 - acc: 0.4332 - val_loss: 0.5296 - val_acc: 0.4328\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5683 - acc: 0.4330 - val_loss: 0.5292 - val_acc: 0.4334\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.5674 - acc: 0.4334 - val_loss: 0.5297 - val_acc: 0.4334\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5673 - acc: 0.4332 - val_loss: 0.5314 - val_acc: 0.4333\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5676 - acc: 0.4335 - val_loss: 0.5299 - val_acc: 0.4330\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.5669 - acc: 0.4333 - val_loss: 0.5294 - val_acc: 0.4335\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5666 - acc: 0.4336 - val_loss: 0.5284 - val_acc: 0.4331\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.5664 - acc: 0.4333 - val_loss: 0.5280 - val_acc: 0.4336\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5674 - acc: 0.4335 - val_loss: 0.5291 - val_acc: 0.4331\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5668 - acc: 0.4334 - val_loss: 0.5277 - val_acc: 0.4336\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5660 - acc: 0.4337 - val_loss: 0.5279 - val_acc: 0.4339\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5658 - acc: 0.4337 - val_loss: 0.5279 - val_acc: 0.4344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.5655 - acc: 0.4340 - val_loss: 0.5271 - val_acc: 0.4339\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5653 - acc: 0.4338 - val_loss: 0.5271 - val_acc: 0.4343\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5653 - acc: 0.4340 - val_loss: 0.5273 - val_acc: 0.4339\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5654 - acc: 0.4340 - val_loss: 0.5268 - val_acc: 0.4341\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5648 - acc: 0.4341 - val_loss: 0.5265 - val_acc: 0.4342\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5647 - acc: 0.4344 - val_loss: 0.5266 - val_acc: 0.4343\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5644 - acc: 0.4340 - val_loss: 0.5279 - val_acc: 0.4349\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.5644 - acc: 0.4340 - val_loss: 0.5264 - val_acc: 0.4354\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5642 - acc: 0.4344 - val_loss: 0.5261 - val_acc: 0.4343\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.5640 - acc: 0.4341 - val_loss: 0.5259 - val_acc: 0.4350\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.5639 - acc: 0.4343 - val_loss: 0.5263 - val_acc: 0.4352\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5645 - acc: 0.4340 - val_loss: 0.5256 - val_acc: 0.4348\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5634 - acc: 0.4345 - val_loss: 0.5255 - val_acc: 0.4347\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.5633 - acc: 0.4345 - val_loss: 0.5253 - val_acc: 0.4347\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5638 - acc: 0.4344 - val_loss: 0.5250 - val_acc: 0.4342\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.5630 - acc: 0.4344 - val_loss: 0.5258 - val_acc: 0.4354\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.5628 - acc: 0.4346 - val_loss: 0.5255 - val_acc: 0.4361\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.5626 - acc: 0.4346 - val_loss: 0.5246 - val_acc: 0.4352\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.5624 - acc: 0.4347 - val_loss: 0.5243 - val_acc: 0.4350\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5624 - acc: 0.4346 - val_loss: 0.5243 - val_acc: 0.4352\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5622 - acc: 0.4347 - val_loss: 0.5243 - val_acc: 0.4354\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5626 - acc: 0.4348 - val_loss: 0.5241 - val_acc: 0.4355\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5617 - acc: 0.4347 - val_loss: 0.5247 - val_acc: 0.4357\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5618 - acc: 0.4348 - val_loss: 0.5245 - val_acc: 0.4346\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5614 - acc: 0.4348 - val_loss: 0.5235 - val_acc: 0.4350\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.5613 - acc: 0.4348 - val_loss: 0.5237 - val_acc: 0.4351\n",
      "start training round 1\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 35.1342 - acc: 0.6805 - val_loss: 35.0003 - val_acc: 0.7111\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 34.2114 - acc: 0.6850 - val_loss: 33.0238 - val_acc: 0.6786\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 34.6889 - acc: 0.6794 - val_loss: 34.6672 - val_acc: 0.6816\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 34.6258 - acc: 0.6824 - val_loss: 32.9626 - val_acc: 0.6779\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 34.1483 - acc: 0.6792 - val_loss: 35.5070 - val_acc: 0.6746\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 357us/step - loss: 34.5838 - acc: 0.6794 - val_loss: 33.9882 - val_acc: 0.6742\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 34.8430 - acc: 0.6832 - val_loss: 34.0284 - val_acc: 0.6745\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 34.1420 - acc: 0.6835 - val_loss: 34.3411 - val_acc: 0.6741\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 34.8391 - acc: 0.6806 - val_loss: 34.2930 - val_acc: 0.6735\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 33.7901 - acc: 0.6795 - val_loss: 35.8154 - val_acc: 0.6814\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 34.8029 - acc: 0.6806 - val_loss: 32.6794 - val_acc: 0.6794\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 34.1610 - acc: 0.6792 - val_loss: 32.7597 - val_acc: 0.6793\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 34.4476 - acc: 0.6796 - val_loss: 32.5604 - val_acc: 0.6809\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 33.9110 - acc: 0.6799 - val_loss: 33.4528 - val_acc: 0.6832\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 34.8676 - acc: 0.6803 - val_loss: 33.6015 - val_acc: 0.6820\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 34.4053 - acc: 0.6827 - val_loss: 36.2010 - val_acc: 0.7100\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 34.1690 - acc: 0.6807 - val_loss: 35.0386 - val_acc: 0.6836\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 34.4326 - acc: 0.6796 - val_loss: 32.8514 - val_acc: 0.6799\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 33.7721 - acc: 0.6796 - val_loss: 33.6999 - val_acc: 0.6733\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 33.8739 - acc: 0.6789 - val_loss: 33.1290 - val_acc: 0.6788\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 33.9260 - acc: 0.6795 - val_loss: 32.9553 - val_acc: 0.6794\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 34.3703 - acc: 0.6783 - val_loss: 35.8442 - val_acc: 0.6839\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 34.5362 - acc: 0.6798 - val_loss: 34.6199 - val_acc: 0.6822\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 34.5893 - acc: 0.6809 - val_loss: 33.3291 - val_acc: 0.6805\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 34.0801 - acc: 0.6795 - val_loss: 35.0442 - val_acc: 0.6821\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 34.3537 - acc: 0.6802 - val_loss: 32.5047 - val_acc: 0.6795\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 33.8453 - acc: 0.6793 - val_loss: 33.1301 - val_acc: 0.6799\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 34.2105 - acc: 0.6794 - val_loss: 33.0446 - val_acc: 0.6804\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 34.3581 - acc: 0.6796 - val_loss: 36.5274 - val_acc: 0.6851\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 33.9253 - acc: 0.6805 - val_loss: 33.3031 - val_acc: 0.6796\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 34.2213 - acc: 0.6791 - val_loss: 34.5160 - val_acc: 0.6808\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 35.2821 - acc: 0.6839 - val_loss: 32.3941 - val_acc: 0.6805\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 33.4238 - acc: 0.6799 - val_loss: 34.9786 - val_acc: 0.6761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 34.9784 - acc: 0.6788 - val_loss: 34.6354 - val_acc: 0.6734\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 33.9940 - acc: 0.6798 - val_loss: 34.5166 - val_acc: 0.6716\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 34.2093 - acc: 0.6792 - val_loss: 34.8232 - val_acc: 0.6714\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 33.8918 - acc: 0.6827 - val_loss: 34.4532 - val_acc: 0.6787\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 34.1813 - acc: 0.6792 - val_loss: 33.0153 - val_acc: 0.6802\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 34.1052 - acc: 0.6788 - val_loss: 33.4136 - val_acc: 0.6814\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 34.3554 - acc: 0.6799 - val_loss: 33.7875 - val_acc: 0.6811\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 33.8856 - acc: 0.6796 - val_loss: 33.4080 - val_acc: 0.6806\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 34.6845 - acc: 0.6801 - val_loss: 33.5082 - val_acc: 0.6785\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 34.5376 - acc: 0.6799 - val_loss: 33.0935 - val_acc: 0.6805\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 34.0430 - acc: 0.6795 - val_loss: 32.5520 - val_acc: 0.6801\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 34.1043 - acc: 0.6788 - val_loss: 32.7456 - val_acc: 0.6801\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 34.6097 - acc: 0.6796 - val_loss: 33.2403 - val_acc: 0.6801\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 34.3713 - acc: 0.6829 - val_loss: 33.4074 - val_acc: 0.6762\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 34.1614 - acc: 0.6801 - val_loss: 34.7044 - val_acc: 0.6792\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 34.7047 - acc: 0.6843 - val_loss: 32.5903 - val_acc: 0.6803\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 33.8692 - acc: 0.6830 - val_loss: 32.7252 - val_acc: 0.6804\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 122.4567 - acc: 0.6258 - val_loss: 124.5533 - val_acc: 0.6226\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 127.5060 - acc: 0.6267 - val_loss: 123.6305 - val_acc: 0.6228\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 125.6122 - acc: 0.6256 - val_loss: 123.1063 - val_acc: 0.6220\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 125.2070 - acc: 0.6260 - val_loss: 128.3616 - val_acc: 0.6211\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 125.0763 - acc: 0.6257 - val_loss: 121.6740 - val_acc: 0.6226\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 124.0586 - acc: 0.6233 - val_loss: 121.9797 - val_acc: 0.6218\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 122.7607 - acc: 0.6273 - val_loss: 122.8675 - val_acc: 0.6230\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 123.3385 - acc: 0.6255 - val_loss: 122.5628 - val_acc: 0.6232\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 125.3850 - acc: 0.6259 - val_loss: 124.0949 - val_acc: 0.6186\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 124.1994 - acc: 0.6244 - val_loss: 124.0826 - val_acc: 0.6213\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 122.2035 - acc: 0.6271 - val_loss: 124.2240 - val_acc: 0.6224\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 125.3310 - acc: 0.6267 - val_loss: 131.5078 - val_acc: 0.6219\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 220us/step - loss: 125.9286 - acc: 0.6257 - val_loss: 123.8800 - val_acc: 0.6222\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 125.0386 - acc: 0.6265 - val_loss: 124.5054 - val_acc: 0.6172\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 123.1280 - acc: 0.6247 - val_loss: 121.9220 - val_acc: 0.6215\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 121.7867 - acc: 0.6221 - val_loss: 123.2060 - val_acc: 0.6188\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 121.1926 - acc: 0.6256 - val_loss: 123.0406 - val_acc: 0.6224\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 125.0368 - acc: 0.6253 - val_loss: 128.7832 - val_acc: 0.6222\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 127.3735 - acc: 0.6270 - val_loss: 122.3488 - val_acc: 0.6232\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 220us/step - loss: 123.3998 - acc: 0.6253 - val_loss: 121.8265 - val_acc: 0.6223\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 121.4615 - acc: 0.6239 - val_loss: 122.5663 - val_acc: 0.6189\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 121.0385 - acc: 0.6240 - val_loss: 122.2088 - val_acc: 0.6196\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 220us/step - loss: 121.4146 - acc: 0.6249 - val_loss: 122.3601 - val_acc: 0.6190\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 121.2414 - acc: 0.6258 - val_loss: 128.3487 - val_acc: 0.6181\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 126.3840 - acc: 0.6268 - val_loss: 126.9473 - val_acc: 0.6226\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 127.6264 - acc: 0.6257 - val_loss: 122.2855 - val_acc: 0.6214\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 122.1712 - acc: 0.6260 - val_loss: 123.3770 - val_acc: 0.6216\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 122.1192 - acc: 0.6242 - val_loss: 120.8540 - val_acc: 0.6207\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 123.1700 - acc: 0.6251 - val_loss: 122.3618 - val_acc: 0.6215\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 122.8351 - acc: 0.6251 - val_loss: 128.8392 - val_acc: 0.6226\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 126.1433 - acc: 0.6257 - val_loss: 128.3190 - val_acc: 0.6196\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 123.9954 - acc: 0.6264 - val_loss: 123.9742 - val_acc: 0.6234\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 124.1391 - acc: 0.6252 - val_loss: 127.6666 - val_acc: 0.6055\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 123.4610 - acc: 0.6239 - val_loss: 123.4059 - val_acc: 0.6228\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 124.4770 - acc: 0.6275 - val_loss: 125.5260 - val_acc: 0.6212\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 124.9600 - acc: 0.6254 - val_loss: 125.8624 - val_acc: 0.6155\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 123.6011 - acc: 0.6259 - val_loss: 124.0027 - val_acc: 0.6229\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 125.1488 - acc: 0.6256 - val_loss: 121.6604 - val_acc: 0.6210\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 121.7273 - acc: 0.6277 - val_loss: 123.6096 - val_acc: 0.6232\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 125.0307 - acc: 0.6274 - val_loss: 125.3347 - val_acc: 0.6219\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 122.7293 - acc: 0.6240 - val_loss: 127.5413 - val_acc: 0.6097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 122.4789 - acc: 0.6238 - val_loss: 122.4179 - val_acc: 0.6214\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 121.2147 - acc: 0.6247 - val_loss: 121.5376 - val_acc: 0.6225\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 121.1343 - acc: 0.6259 - val_loss: 122.5025 - val_acc: 0.6211\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 122.2245 - acc: 0.6251 - val_loss: 125.0517 - val_acc: 0.6221\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 124.7725 - acc: 0.6272 - val_loss: 122.5788 - val_acc: 0.6231\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 123.3546 - acc: 0.6272 - val_loss: 125.5214 - val_acc: 0.6205\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 125.7786 - acc: 0.6253 - val_loss: 125.1574 - val_acc: 0.6218\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 124.5905 - acc: 0.6275 - val_loss: 125.5509 - val_acc: 0.6219\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 124.2073 - acc: 0.6237 - val_loss: 122.8505 - val_acc: 0.6201\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 59.0799 - acc: 0.4280 - val_loss: 55.2086 - val_acc: 0.4331\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 59.0520 - acc: 0.4283 - val_loss: 55.1712 - val_acc: 0.4336\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 59.0284 - acc: 0.4282 - val_loss: 55.1634 - val_acc: 0.4342\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 59.0029 - acc: 0.4286 - val_loss: 55.1098 - val_acc: 0.4316\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 58.9739 - acc: 0.4284 - val_loss: 55.1021 - val_acc: 0.4285\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.9559 - acc: 0.4276 - val_loss: 55.1076 - val_acc: 0.4341\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 58.9301 - acc: 0.4288 - val_loss: 55.0402 - val_acc: 0.4316\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 58.9114 - acc: 0.4281 - val_loss: 55.0508 - val_acc: 0.4339\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.8783 - acc: 0.4287 - val_loss: 55.0081 - val_acc: 0.4292\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.8574 - acc: 0.4277 - val_loss: 54.9951 - val_acc: 0.4341\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 58.8271 - acc: 0.4287 - val_loss: 54.9497 - val_acc: 0.4311\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 58.8038 - acc: 0.4280 - val_loss: 54.9355 - val_acc: 0.4335\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 58.7795 - acc: 0.4288 - val_loss: 54.9054 - val_acc: 0.4323\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 58.7517 - acc: 0.4279 - val_loss: 54.9082 - val_acc: 0.4342\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 58.7255 - acc: 0.4288 - val_loss: 54.8668 - val_acc: 0.4329\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 58.7063 - acc: 0.4281 - val_loss: 54.8497 - val_acc: 0.4340\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 58.6827 - acc: 0.4287 - val_loss: 54.8307 - val_acc: 0.4337\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.6602 - acc: 0.4282 - val_loss: 54.7979 - val_acc: 0.4340\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.6351 - acc: 0.4288 - val_loss: 54.7701 - val_acc: 0.4327\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.6092 - acc: 0.4286 - val_loss: 54.7404 - val_acc: 0.4330\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.5861 - acc: 0.4288 - val_loss: 54.7242 - val_acc: 0.4337\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 58.5601 - acc: 0.4287 - val_loss: 54.6986 - val_acc: 0.4334\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 58.5367 - acc: 0.4289 - val_loss: 54.6817 - val_acc: 0.4340\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 58.5138 - acc: 0.4288 - val_loss: 54.6820 - val_acc: 0.4339\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 58.4915 - acc: 0.4291 - val_loss: 54.6367 - val_acc: 0.4334\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.4688 - acc: 0.4287 - val_loss: 54.6200 - val_acc: 0.4334\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 58.4423 - acc: 0.4295 - val_loss: 54.5932 - val_acc: 0.4310\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.4227 - acc: 0.4285 - val_loss: 54.5699 - val_acc: 0.4331\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.4013 - acc: 0.4291 - val_loss: 54.5479 - val_acc: 0.4320\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 58.3755 - acc: 0.4284 - val_loss: 54.5828 - val_acc: 0.4348\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 58.3468 - acc: 0.4294 - val_loss: 54.5213 - val_acc: 0.4295\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 58.3312 - acc: 0.4287 - val_loss: 54.5007 - val_acc: 0.4345\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.3060 - acc: 0.4294 - val_loss: 54.4599 - val_acc: 0.4340\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 58.2826 - acc: 0.4293 - val_loss: 54.4394 - val_acc: 0.4323\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 58.2608 - acc: 0.4293 - val_loss: 54.4101 - val_acc: 0.4315\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 58.2412 - acc: 0.4290 - val_loss: 54.3913 - val_acc: 0.4337\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 220us/step - loss: 58.2157 - acc: 0.4295 - val_loss: 54.3721 - val_acc: 0.4334\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.1934 - acc: 0.4293 - val_loss: 54.3769 - val_acc: 0.4352\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 58.1734 - acc: 0.4294 - val_loss: 54.3338 - val_acc: 0.4321\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.1488 - acc: 0.4286 - val_loss: 54.3620 - val_acc: 0.4347\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 58.1270 - acc: 0.4296 - val_loss: 54.2892 - val_acc: 0.4326\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 58.1053 - acc: 0.4298 - val_loss: 54.2811 - val_acc: 0.4310\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 58.0903 - acc: 0.4289 - val_loss: 54.2694 - val_acc: 0.4354\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 58.0661 - acc: 0.4295 - val_loss: 54.2305 - val_acc: 0.4338\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 58.0419 - acc: 0.4298 - val_loss: 54.1999 - val_acc: 0.4313\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 58.0178 - acc: 0.4292 - val_loss: 54.1897 - val_acc: 0.4326\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 57.9999 - acc: 0.4297 - val_loss: 54.1889 - val_acc: 0.4305\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 57.9754 - acc: 0.4291 - val_loss: 54.1449 - val_acc: 0.4331\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 57.9534 - acc: 0.4295 - val_loss: 54.1319 - val_acc: 0.4347\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 219us/step - loss: 57.9308 - acc: 0.4298 - val_loss: 54.1267 - val_acc: 0.4354\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.5611 - acc: 0.4350 - val_loss: 0.5250 - val_acc: 0.4366\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.5613 - acc: 0.4348 - val_loss: 0.5233 - val_acc: 0.4361\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5607 - acc: 0.4350 - val_loss: 0.5231 - val_acc: 0.4358\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.5605 - acc: 0.4351 - val_loss: 0.5235 - val_acc: 0.4361\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5604 - acc: 0.4350 - val_loss: 0.5227 - val_acc: 0.4355\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5611 - acc: 0.4349 - val_loss: 0.5225 - val_acc: 0.4359\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5605 - acc: 0.4354 - val_loss: 0.5229 - val_acc: 0.4352\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5600 - acc: 0.4352 - val_loss: 0.5223 - val_acc: 0.4359\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5597 - acc: 0.4353 - val_loss: 0.5221 - val_acc: 0.4360\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5595 - acc: 0.4351 - val_loss: 0.5221 - val_acc: 0.4365\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5595 - acc: 0.4352 - val_loss: 0.5219 - val_acc: 0.4361\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5592 - acc: 0.4354 - val_loss: 0.5216 - val_acc: 0.4366\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5590 - acc: 0.4355 - val_loss: 0.5214 - val_acc: 0.4360\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5593 - acc: 0.4354 - val_loss: 0.5221 - val_acc: 0.4357\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5588 - acc: 0.4355 - val_loss: 0.5219 - val_acc: 0.4360\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.5589 - acc: 0.4355 - val_loss: 0.5225 - val_acc: 0.4357\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.5594 - acc: 0.4354 - val_loss: 0.5208 - val_acc: 0.4365\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5582 - acc: 0.4358 - val_loss: 0.5210 - val_acc: 0.4363\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5581 - acc: 0.4357 - val_loss: 0.5207 - val_acc: 0.4365\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5580 - acc: 0.4356 - val_loss: 0.5205 - val_acc: 0.4364\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.5576 - acc: 0.4357 - val_loss: 0.5205 - val_acc: 0.4366\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5576 - acc: 0.4358 - val_loss: 0.5213 - val_acc: 0.4369\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5580 - acc: 0.4358 - val_loss: 0.5213 - val_acc: 0.4368\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5575 - acc: 0.4358 - val_loss: 0.5202 - val_acc: 0.4366\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5571 - acc: 0.4359 - val_loss: 0.5245 - val_acc: 0.4372\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5572 - acc: 0.4360 - val_loss: 0.5196 - val_acc: 0.4367\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.5568 - acc: 0.4359 - val_loss: 0.5201 - val_acc: 0.4360\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.5571 - acc: 0.4360 - val_loss: 0.5203 - val_acc: 0.4356\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5572 - acc: 0.4359 - val_loss: 0.5192 - val_acc: 0.4368\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5567 - acc: 0.4360 - val_loss: 0.5190 - val_acc: 0.4366\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5565 - acc: 0.4363 - val_loss: 0.5193 - val_acc: 0.4363\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5559 - acc: 0.4360 - val_loss: 0.5195 - val_acc: 0.4367\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5560 - acc: 0.4363 - val_loss: 0.5199 - val_acc: 0.4362\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5561 - acc: 0.4362 - val_loss: 0.5203 - val_acc: 0.4360\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5555 - acc: 0.4363 - val_loss: 0.5187 - val_acc: 0.4370\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.5554 - acc: 0.4363 - val_loss: 0.5182 - val_acc: 0.4369\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5552 - acc: 0.4365 - val_loss: 0.5183 - val_acc: 0.4363\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5550 - acc: 0.4364 - val_loss: 0.5180 - val_acc: 0.4368\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5549 - acc: 0.4365 - val_loss: 0.5199 - val_acc: 0.4375\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5552 - acc: 0.4366 - val_loss: 0.5185 - val_acc: 0.4371\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.5545 - acc: 0.4366 - val_loss: 0.5178 - val_acc: 0.4373\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.5545 - acc: 0.4364 - val_loss: 0.5175 - val_acc: 0.4371\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.5542 - acc: 0.4367 - val_loss: 0.5173 - val_acc: 0.4369\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5540 - acc: 0.4367 - val_loss: 0.5171 - val_acc: 0.4372\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5538 - acc: 0.4367 - val_loss: 0.5171 - val_acc: 0.4373\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.5536 - acc: 0.4367 - val_loss: 0.5172 - val_acc: 0.4371\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5540 - acc: 0.4367 - val_loss: 0.5173 - val_acc: 0.4369\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.5536 - acc: 0.4368 - val_loss: 0.5168 - val_acc: 0.4375\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5532 - acc: 0.4367 - val_loss: 0.5168 - val_acc: 0.4374\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5533 - acc: 0.4370 - val_loss: 0.5166 - val_acc: 0.4375\n",
      "start training round 2\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 33.6519 - acc: 0.6797 - val_loss: 33.1457 - val_acc: 0.6803\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 34.0333 - acc: 0.6794 - val_loss: 33.9897 - val_acc: 0.6828\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 34.2869 - acc: 0.6795 - val_loss: 32.9776 - val_acc: 0.6809\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 33.2279 - acc: 0.6792 - val_loss: 34.1216 - val_acc: 0.6811\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 34.8361 - acc: 0.6790 - val_loss: 33.7732 - val_acc: 0.6781\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 34.1475 - acc: 0.6795 - val_loss: 33.5200 - val_acc: 0.6808\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 34.0124 - acc: 0.6792 - val_loss: 32.7866 - val_acc: 0.6813\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 34.4141 - acc: 0.6793 - val_loss: 36.8611 - val_acc: 0.6833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 34.3173 - acc: 0.6799 - val_loss: 32.8104 - val_acc: 0.6815\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 33.9221 - acc: 0.6798 - val_loss: 34.5430 - val_acc: 0.6796\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.9579 - acc: 0.6814 - val_loss: 34.5020 - val_acc: 0.6777\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 34.2649 - acc: 0.6799 - val_loss: 33.5764 - val_acc: 0.6774\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 33.3301 - acc: 0.6802 - val_loss: 33.6875 - val_acc: 0.6804\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 34.4324 - acc: 0.6798 - val_loss: 32.4062 - val_acc: 0.6818\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.9440 - acc: 0.6792 - val_loss: 34.7916 - val_acc: 0.6826\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 33.2310 - acc: 0.6814 - val_loss: 31.9568 - val_acc: 0.6793\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.1370 - acc: 0.6785 - val_loss: 34.3705 - val_acc: 0.6801\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 34.8326 - acc: 0.6790 - val_loss: 34.1198 - val_acc: 0.6822\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 34.2395 - acc: 0.6789 - val_loss: 33.4112 - val_acc: 0.6812\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 33.9736 - acc: 0.6826 - val_loss: 36.7412 - val_acc: 0.7107\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 34.0372 - acc: 0.6813 - val_loss: 34.3269 - val_acc: 0.6806\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.9810 - acc: 0.6799 - val_loss: 35.0111 - val_acc: 0.6811\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 33.2719 - acc: 0.6790 - val_loss: 33.7858 - val_acc: 0.6697\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 34.4914 - acc: 0.6787 - val_loss: 34.2520 - val_acc: 0.6721\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 33.4253 - acc: 0.6792 - val_loss: 32.2701 - val_acc: 0.6751\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 33.8661 - acc: 0.6784 - val_loss: 33.7694 - val_acc: 0.6720\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 34.0266 - acc: 0.6789 - val_loss: 32.2580 - val_acc: 0.6756\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.8764 - acc: 0.6781 - val_loss: 34.4245 - val_acc: 0.6750\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.7688 - acc: 0.6786 - val_loss: 33.6605 - val_acc: 0.6711\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 212us/step - loss: 33.6775 - acc: 0.6790 - val_loss: 34.2325 - val_acc: 0.6719\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 33.9009 - acc: 0.6790 - val_loss: 33.9866 - val_acc: 0.6706\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 34.1510 - acc: 0.6803 - val_loss: 34.5190 - val_acc: 0.6675\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 33.6435 - acc: 0.6835 - val_loss: 33.5681 - val_acc: 0.6728\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.0436 - acc: 0.6791 - val_loss: 32.7012 - val_acc: 0.6745\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.0441 - acc: 0.6781 - val_loss: 32.3279 - val_acc: 0.6778\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 212us/step - loss: 33.9233 - acc: 0.6781 - val_loss: 33.2006 - val_acc: 0.6794\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 34.4228 - acc: 0.6792 - val_loss: 33.2788 - val_acc: 0.6806\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 32.9264 - acc: 0.6795 - val_loss: 33.3341 - val_acc: 0.6752\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 34.3944 - acc: 0.6783 - val_loss: 34.9478 - val_acc: 0.6722\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.5991 - acc: 0.6794 - val_loss: 33.1287 - val_acc: 0.6736\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.8640 - acc: 0.6804 - val_loss: 34.5952 - val_acc: 0.6711\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.8777 - acc: 0.6845 - val_loss: 33.0020 - val_acc: 0.6750\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.7821 - acc: 0.6791 - val_loss: 33.0191 - val_acc: 0.6726\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 33.8866 - acc: 0.6792 - val_loss: 33.7275 - val_acc: 0.6753\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.6401 - acc: 0.6794 - val_loss: 34.4429 - val_acc: 0.6733\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.7356 - acc: 0.6796 - val_loss: 34.2499 - val_acc: 0.6708\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 34.6078 - acc: 0.6816 - val_loss: 33.1299 - val_acc: 0.6723\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.1804 - acc: 0.6859 - val_loss: 35.2001 - val_acc: 0.6674\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 34.1506 - acc: 0.6858 - val_loss: 32.8979 - val_acc: 0.6791\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.5804 - acc: 0.6789 - val_loss: 34.4538 - val_acc: 0.6830\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 121.2986 - acc: 0.6268 - val_loss: 122.4815 - val_acc: 0.6214\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 212us/step - loss: 121.4873 - acc: 0.6276 - val_loss: 126.2207 - val_acc: 0.6219\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 126.0621 - acc: 0.6274 - val_loss: 122.6648 - val_acc: 0.6228\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 122.1395 - acc: 0.6250 - val_loss: 123.4785 - val_acc: 0.6208\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 121.4472 - acc: 0.6272 - val_loss: 125.2738 - val_acc: 0.6209\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 122.5595 - acc: 0.6253 - val_loss: 122.6984 - val_acc: 0.6214\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 120.8195 - acc: 0.6249 - val_loss: 121.1428 - val_acc: 0.6214\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 121.3142 - acc: 0.6272 - val_loss: 135.0202 - val_acc: 0.6179\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 123.3162 - acc: 0.6265 - val_loss: 132.7680 - val_acc: 0.6175\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 125.4045 - acc: 0.6258 - val_loss: 127.3270 - val_acc: 0.6180\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 125.2238 - acc: 0.6266 - val_loss: 121.5934 - val_acc: 0.6228\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 120.5266 - acc: 0.6266 - val_loss: 122.9916 - val_acc: 0.6186\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 121.1423 - acc: 0.6254 - val_loss: 127.8247 - val_acc: 0.6148\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 121.4451 - acc: 0.6264 - val_loss: 121.1684 - val_acc: 0.6222\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 122.8423 - acc: 0.6278 - val_loss: 127.3458 - val_acc: 0.6219\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 123.0591 - acc: 0.6284 - val_loss: 129.7328 - val_acc: 0.6209\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 217us/step - loss: 125.5385 - acc: 0.6273 - val_loss: 127.8603 - val_acc: 0.6200\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 121.7963 - acc: 0.6267 - val_loss: 122.0423 - val_acc: 0.6221\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 121.7139 - acc: 0.6274 - val_loss: 129.0706 - val_acc: 0.6217\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 220us/step - loss: 123.7792 - acc: 0.6252 - val_loss: 123.6122 - val_acc: 0.6220\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 121.1384 - acc: 0.6285 - val_loss: 127.0696 - val_acc: 0.6219\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 123.6311 - acc: 0.6271 - val_loss: 124.5800 - val_acc: 0.6222\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 212us/step - loss: 121.8689 - acc: 0.6269 - val_loss: 122.0786 - val_acc: 0.6179\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 120.4083 - acc: 0.6228 - val_loss: 118.9858 - val_acc: 0.6236\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 119.9010 - acc: 0.6276 - val_loss: 120.9787 - val_acc: 0.6218\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 121.5493 - acc: 0.6257 - val_loss: 121.6581 - val_acc: 0.6205\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 121.7182 - acc: 0.6250 - val_loss: 119.3453 - val_acc: 0.6232\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 121.4313 - acc: 0.6249 - val_loss: 128.9111 - val_acc: 0.6201\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 125.8507 - acc: 0.6286 - val_loss: 128.0535 - val_acc: 0.6247\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 125.2164 - acc: 0.6279 - val_loss: 121.6046 - val_acc: 0.6243\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 212us/step - loss: 121.7279 - acc: 0.6267 - val_loss: 124.0450 - val_acc: 0.6156\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 120.3233 - acc: 0.6235 - val_loss: 121.0469 - val_acc: 0.6225\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 120.0093 - acc: 0.6280 - val_loss: 121.0753 - val_acc: 0.6224\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 120.7050 - acc: 0.6241 - val_loss: 122.0704 - val_acc: 0.6161\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 119.3861 - acc: 0.6268 - val_loss: 122.3965 - val_acc: 0.6247\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 122.8879 - acc: 0.6278 - val_loss: 126.0495 - val_acc: 0.6232\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 124.4563 - acc: 0.6274 - val_loss: 124.1447 - val_acc: 0.6256\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 125.1760 - acc: 0.6284 - val_loss: 122.6024 - val_acc: 0.6235\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 122.1917 - acc: 0.6275 - val_loss: 121.2478 - val_acc: 0.6195\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 120.5963 - acc: 0.6248 - val_loss: 120.0503 - val_acc: 0.6243\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 119.8337 - acc: 0.6252 - val_loss: 120.9359 - val_acc: 0.6215\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 118.9228 - acc: 0.6264 - val_loss: 122.4558 - val_acc: 0.6182\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 120.2396 - acc: 0.6235 - val_loss: 120.1086 - val_acc: 0.6221\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 121.0289 - acc: 0.6280 - val_loss: 126.1921 - val_acc: 0.6231\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 124.6538 - acc: 0.6286 - val_loss: 125.3228 - val_acc: 0.6236\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 123.6583 - acc: 0.6282 - val_loss: 120.6315 - val_acc: 0.6255\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 121.2545 - acc: 0.6251 - val_loss: 121.8409 - val_acc: 0.6181\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 118.7180 - acc: 0.6269 - val_loss: 122.6656 - val_acc: 0.6211\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 120.8356 - acc: 0.6260 - val_loss: 124.7003 - val_acc: 0.6219\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 124.2246 - acc: 0.6284 - val_loss: 125.5342 - val_acc: 0.6224\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 57.9158 - acc: 0.4298 - val_loss: 54.0809 - val_acc: 0.4323\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 57.8882 - acc: 0.4296 - val_loss: 54.0663 - val_acc: 0.4331\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 57.8724 - acc: 0.4301 - val_loss: 54.0388 - val_acc: 0.4334\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 57.8494 - acc: 0.4297 - val_loss: 54.0286 - val_acc: 0.4346\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 57.8266 - acc: 0.4301 - val_loss: 53.9948 - val_acc: 0.4346\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 57.8066 - acc: 0.4293 - val_loss: 54.0042 - val_acc: 0.4362\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 57.7840 - acc: 0.4300 - val_loss: 53.9594 - val_acc: 0.4340\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 57.7641 - acc: 0.4298 - val_loss: 53.9489 - val_acc: 0.4349\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 57.7426 - acc: 0.4299 - val_loss: 53.9209 - val_acc: 0.4333\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 57.7186 - acc: 0.4295 - val_loss: 53.9178 - val_acc: 0.4361\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 57.7017 - acc: 0.4301 - val_loss: 53.8778 - val_acc: 0.4344\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 57.6794 - acc: 0.4300 - val_loss: 53.8625 - val_acc: 0.4339\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 57.6635 - acc: 0.4299 - val_loss: 53.8332 - val_acc: 0.4334\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 57.6409 - acc: 0.4297 - val_loss: 53.8123 - val_acc: 0.4320\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 57.6153 - acc: 0.4299 - val_loss: 53.7986 - val_acc: 0.4332\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 57.5952 - acc: 0.4296 - val_loss: 53.7912 - val_acc: 0.4357\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 57.5792 - acc: 0.4302 - val_loss: 53.7591 - val_acc: 0.4342\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 57.5532 - acc: 0.4299 - val_loss: 53.7644 - val_acc: 0.4343\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 57.5342 - acc: 0.4296 - val_loss: 53.7228 - val_acc: 0.4341\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 57.5134 - acc: 0.4299 - val_loss: 53.7023 - val_acc: 0.4353\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 57.4926 - acc: 0.4301 - val_loss: 53.6871 - val_acc: 0.4350\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 57.4709 - acc: 0.4299 - val_loss: 53.6845 - val_acc: 0.4356\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 57.4540 - acc: 0.4303 - val_loss: 53.6430 - val_acc: 0.4343\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 57.4365 - acc: 0.4300 - val_loss: 53.6564 - val_acc: 0.4303\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 217us/step - loss: 57.4127 - acc: 0.4291 - val_loss: 53.6274 - val_acc: 0.4355\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 57.3952 - acc: 0.4303 - val_loss: 53.6106 - val_acc: 0.4352\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 57.3747 - acc: 0.4298 - val_loss: 53.5646 - val_acc: 0.4327\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 57.3466 - acc: 0.4296 - val_loss: 53.5560 - val_acc: 0.4348\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 57.3308 - acc: 0.4299 - val_loss: 53.5403 - val_acc: 0.4346\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 57.3096 - acc: 0.4297 - val_loss: 53.5194 - val_acc: 0.4347\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 57.2828 - acc: 0.4301 - val_loss: 53.4862 - val_acc: 0.4337\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 218us/step - loss: 57.2641 - acc: 0.4301 - val_loss: 53.4660 - val_acc: 0.4325\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 57.2484 - acc: 0.4300 - val_loss: 53.4607 - val_acc: 0.4347\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 57.2229 - acc: 0.4299 - val_loss: 53.4472 - val_acc: 0.4355\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 57.2003 - acc: 0.4301 - val_loss: 53.4177 - val_acc: 0.4342\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 57.1829 - acc: 0.4301 - val_loss: 53.4098 - val_acc: 0.4353\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 57.1621 - acc: 0.4301 - val_loss: 53.3797 - val_acc: 0.4339\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 57.1537 - acc: 0.4297 - val_loss: 53.3780 - val_acc: 0.4351\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 57.1200 - acc: 0.4301 - val_loss: 53.3420 - val_acc: 0.4332\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 57.1007 - acc: 0.4298 - val_loss: 53.3450 - val_acc: 0.4358\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 57.0755 - acc: 0.4299 - val_loss: 53.3750 - val_acc: 0.4366\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 212us/step - loss: 57.0644 - acc: 0.4304 - val_loss: 53.3062 - val_acc: 0.4360\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 57.0441 - acc: 0.4302 - val_loss: 53.2743 - val_acc: 0.4354\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 57.0172 - acc: 0.4299 - val_loss: 53.2601 - val_acc: 0.4351\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 57.0017 - acc: 0.4298 - val_loss: 53.2390 - val_acc: 0.4355\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 56.9813 - acc: 0.4300 - val_loss: 53.2196 - val_acc: 0.4339\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 56.9614 - acc: 0.4299 - val_loss: 53.2009 - val_acc: 0.4344\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 56.9389 - acc: 0.4302 - val_loss: 53.1827 - val_acc: 0.4346\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 56.9208 - acc: 0.4300 - val_loss: 53.1719 - val_acc: 0.4350\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 56.9038 - acc: 0.4300 - val_loss: 53.1618 - val_acc: 0.4353\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5529 - acc: 0.4370 - val_loss: 0.5161 - val_acc: 0.4373\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5529 - acc: 0.4369 - val_loss: 0.5161 - val_acc: 0.4381\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5528 - acc: 0.4370 - val_loss: 0.5170 - val_acc: 0.4388\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5527 - acc: 0.4371 - val_loss: 0.5169 - val_acc: 0.4372\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5529 - acc: 0.4369 - val_loss: 0.5157 - val_acc: 0.4385\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5524 - acc: 0.4371 - val_loss: 0.5192 - val_acc: 0.4390\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 220us/step - loss: 0.5524 - acc: 0.4370 - val_loss: 0.5156 - val_acc: 0.4388\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5517 - acc: 0.4373 - val_loss: 0.5152 - val_acc: 0.4382\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.5516 - acc: 0.4372 - val_loss: 0.5177 - val_acc: 0.4370\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.5524 - acc: 0.4371 - val_loss: 0.5149 - val_acc: 0.4380\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5516 - acc: 0.4370 - val_loss: 0.5177 - val_acc: 0.4373\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.5514 - acc: 0.4370 - val_loss: 0.5152 - val_acc: 0.4387\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5514 - acc: 0.4373 - val_loss: 0.5148 - val_acc: 0.4383\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5509 - acc: 0.4371 - val_loss: 0.5145 - val_acc: 0.4387\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5506 - acc: 0.4372 - val_loss: 0.5145 - val_acc: 0.4386\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5505 - acc: 0.4372 - val_loss: 0.5142 - val_acc: 0.4386\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5514 - acc: 0.4373 - val_loss: 0.5139 - val_acc: 0.4387\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5502 - acc: 0.4375 - val_loss: 0.5143 - val_acc: 0.4385\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5500 - acc: 0.4374 - val_loss: 0.5137 - val_acc: 0.4387\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.5499 - acc: 0.4374 - val_loss: 0.5137 - val_acc: 0.4382\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5499 - acc: 0.4376 - val_loss: 0.5183 - val_acc: 0.4388\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5501 - acc: 0.4375 - val_loss: 0.5136 - val_acc: 0.4390\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5494 - acc: 0.4375 - val_loss: 0.5132 - val_acc: 0.4390\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.5494 - acc: 0.4377 - val_loss: 0.5134 - val_acc: 0.4385\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.5495 - acc: 0.4375 - val_loss: 0.5131 - val_acc: 0.4388\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5494 - acc: 0.4376 - val_loss: 0.5129 - val_acc: 0.4388\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.5492 - acc: 0.4379 - val_loss: 0.5128 - val_acc: 0.4396\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5487 - acc: 0.4379 - val_loss: 0.5124 - val_acc: 0.4384\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.5485 - acc: 0.4378 - val_loss: 0.5129 - val_acc: 0.4390\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.5489 - acc: 0.4378 - val_loss: 0.5122 - val_acc: 0.4393\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.5488 - acc: 0.4379 - val_loss: 0.5121 - val_acc: 0.4391\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5483 - acc: 0.4381 - val_loss: 0.5125 - val_acc: 0.4388\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5483 - acc: 0.4380 - val_loss: 0.5121 - val_acc: 0.4392\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5477 - acc: 0.4383 - val_loss: 0.5118 - val_acc: 0.4394\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5477 - acc: 0.4380 - val_loss: 0.5116 - val_acc: 0.4394\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5477 - acc: 0.4383 - val_loss: 0.5115 - val_acc: 0.4393\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5473 - acc: 0.4384 - val_loss: 0.5118 - val_acc: 0.4398\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.5471 - acc: 0.4385 - val_loss: 0.5118 - val_acc: 0.4395\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5477 - acc: 0.4387 - val_loss: 0.5111 - val_acc: 0.4393\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.5468 - acc: 0.4385 - val_loss: 0.5112 - val_acc: 0.4393\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5468 - acc: 0.4386 - val_loss: 0.5109 - val_acc: 0.4393\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5474 - acc: 0.4386 - val_loss: 0.5108 - val_acc: 0.4393\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.5467 - acc: 0.4387 - val_loss: 0.5106 - val_acc: 0.4396\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.5463 - acc: 0.4388 - val_loss: 0.5104 - val_acc: 0.4395\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5462 - acc: 0.4389 - val_loss: 0.5105 - val_acc: 0.4398\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.5461 - acc: 0.4389 - val_loss: 0.5103 - val_acc: 0.4399\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.5458 - acc: 0.4390 - val_loss: 0.5105 - val_acc: 0.4395\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5457 - acc: 0.4389 - val_loss: 0.5100 - val_acc: 0.4402\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.5457 - acc: 0.4391 - val_loss: 0.5102 - val_acc: 0.4405\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.5455 - acc: 0.4391 - val_loss: 0.5098 - val_acc: 0.4400\n",
      "start training round 3\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 34.1685 - acc: 0.6816 - val_loss: 35.4162 - val_acc: 0.6808\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.1280 - acc: 0.6803 - val_loss: 36.0466 - val_acc: 0.6851\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.8089 - acc: 0.6793 - val_loss: 33.5952 - val_acc: 0.6796\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.9230 - acc: 0.6823 - val_loss: 32.6249 - val_acc: 0.6828\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.2354 - acc: 0.6798 - val_loss: 33.7645 - val_acc: 0.6829\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 33.4881 - acc: 0.6799 - val_loss: 33.4347 - val_acc: 0.6712\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 34.2485 - acc: 0.6790 - val_loss: 33.1427 - val_acc: 0.6756\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 212us/step - loss: 33.8943 - acc: 0.6797 - val_loss: 32.8259 - val_acc: 0.6765\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.3172 - acc: 0.6796 - val_loss: 33.8841 - val_acc: 0.6773\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 212us/step - loss: 33.5669 - acc: 0.6799 - val_loss: 34.1144 - val_acc: 0.6751\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 33.8962 - acc: 0.6813 - val_loss: 35.4075 - val_acc: 0.6698\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 212us/step - loss: 34.2217 - acc: 0.6888 - val_loss: 32.1003 - val_acc: 0.6762\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.0580 - acc: 0.6790 - val_loss: 33.4726 - val_acc: 0.6741\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.6581 - acc: 0.6788 - val_loss: 33.6402 - val_acc: 0.6740\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 33.2236 - acc: 0.6791 - val_loss: 35.0673 - val_acc: 0.6652\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 211us/step - loss: 33.5061 - acc: 0.6785 - val_loss: 33.4774 - val_acc: 0.6754\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 34.0119 - acc: 0.6821 - val_loss: 33.2222 - val_acc: 0.6750\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 212us/step - loss: 33.2725 - acc: 0.6813 - val_loss: 34.6397 - val_acc: 0.6726\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 33.7959 - acc: 0.6834 - val_loss: 34.1548 - val_acc: 0.6678\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 32.8239 - acc: 0.6791 - val_loss: 32.0919 - val_acc: 0.6731\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.7130 - acc: 0.6779 - val_loss: 34.3070 - val_acc: 0.6722\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 213us/step - loss: 33.1310 - acc: 0.6792 - val_loss: 36.4180 - val_acc: 0.6699\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 216us/step - loss: 33.7204 - acc: 0.6796 - val_loss: 35.6092 - val_acc: 0.6656\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 219us/step - loss: 33.9668 - acc: 0.6798 - val_loss: 33.2492 - val_acc: 0.6766\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 33.6688 - acc: 0.6787 - val_loss: 35.6185 - val_acc: 0.6646\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 214us/step - loss: 33.2749 - acc: 0.6793 - val_loss: 33.9711 - val_acc: 0.6717\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 217us/step - loss: 33.4216 - acc: 0.6816 - val_loss: 34.6715 - val_acc: 0.6736\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 220us/step - loss: 34.0413 - acc: 0.6809 - val_loss: 32.6065 - val_acc: 0.6739\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 33.4741 - acc: 0.6813 - val_loss: 32.4940 - val_acc: 0.6748\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 33.7111 - acc: 0.6818 - val_loss: 34.2089 - val_acc: 0.6761\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 215us/step - loss: 33.4671 - acc: 0.6792 - val_loss: 35.0549 - val_acc: 0.6762\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 33.4058 - acc: 0.6806 - val_loss: 32.6359 - val_acc: 0.6742\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 32.9616 - acc: 0.6797 - val_loss: 33.5812 - val_acc: 0.6724\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 33.1747 - acc: 0.6786 - val_loss: 32.5480 - val_acc: 0.6732\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 33.7410 - acc: 0.6782 - val_loss: 32.3414 - val_acc: 0.6726\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 33.1686 - acc: 0.6793 - val_loss: 36.3189 - val_acc: 0.6705\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 33.4154 - acc: 0.6799 - val_loss: 31.2662 - val_acc: 0.6781\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 33.2603 - acc: 0.6779 - val_loss: 33.0296 - val_acc: 0.6808\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 32.9647 - acc: 0.6794 - val_loss: 33.8801 - val_acc: 0.6817\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 34.0265 - acc: 0.6792 - val_loss: 33.9877 - val_acc: 0.6829\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 33.0918 - acc: 0.6837 - val_loss: 33.6844 - val_acc: 0.6817\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 33.6523 - acc: 0.6797 - val_loss: 32.7558 - val_acc: 0.6821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 33.0735 - acc: 0.6794 - val_loss: 34.1046 - val_acc: 0.6823\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 33.5108 - acc: 0.6793 - val_loss: 36.3314 - val_acc: 0.6832\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 33.6552 - acc: 0.6821 - val_loss: 33.1734 - val_acc: 0.7102\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 32.9066 - acc: 0.6828 - val_loss: 32.2032 - val_acc: 0.6788\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 32.7913 - acc: 0.6794 - val_loss: 34.5951 - val_acc: 0.6830\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 33.6642 - acc: 0.6798 - val_loss: 34.2763 - val_acc: 0.6843\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 34.0729 - acc: 0.6811 - val_loss: 33.3917 - val_acc: 0.7102\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 32.6541 - acc: 0.6807 - val_loss: 33.7317 - val_acc: 0.6842\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 123.2476 - acc: 0.6286 - val_loss: 124.8657 - val_acc: 0.6222\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 122.8705 - acc: 0.6280 - val_loss: 126.5616 - val_acc: 0.6217\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 122.5773 - acc: 0.6277 - val_loss: 125.3685 - val_acc: 0.6183\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 121.2571 - acc: 0.6267 - val_loss: 120.3878 - val_acc: 0.6237\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 122.5261 - acc: 0.6292 - val_loss: 122.6898 - val_acc: 0.6235\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 122.5901 - acc: 0.6284 - val_loss: 121.8417 - val_acc: 0.6226\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 121.9104 - acc: 0.6252 - val_loss: 123.5591 - val_acc: 0.6233\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 122.2828 - acc: 0.6271 - val_loss: 126.7318 - val_acc: 0.6217\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 122.5591 - acc: 0.6287 - val_loss: 128.3044 - val_acc: 0.6218\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 121.7903 - acc: 0.6274 - val_loss: 123.5780 - val_acc: 0.6198\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 360us/step - loss: 123.0304 - acc: 0.6270 - val_loss: 121.5230 - val_acc: 0.6212\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 120.8579 - acc: 0.6247 - val_loss: 123.0396 - val_acc: 0.6201\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 118.8985 - acc: 0.6283 - val_loss: 121.6749 - val_acc: 0.6201\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 119.6030 - acc: 0.6280 - val_loss: 123.9508 - val_acc: 0.6200\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 119.9983 - acc: 0.6277 - val_loss: 122.4220 - val_acc: 0.6210\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 121.8635 - acc: 0.6266 - val_loss: 121.4119 - val_acc: 0.6245\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 122.9538 - acc: 0.6285 - val_loss: 125.8979 - val_acc: 0.6235\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 123.4832 - acc: 0.6290 - val_loss: 123.0659 - val_acc: 0.6225\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 120.9686 - acc: 0.6276 - val_loss: 121.2797 - val_acc: 0.6238\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 119.9090 - acc: 0.6262 - val_loss: 121.3762 - val_acc: 0.6161\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 362us/step - loss: 120.7184 - acc: 0.6249 - val_loss: 122.8059 - val_acc: 0.6237\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 121.9825 - acc: 0.6267 - val_loss: 120.2144 - val_acc: 0.6230\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 120.1022 - acc: 0.6291 - val_loss: 123.1979 - val_acc: 0.6249\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 122.5850 - acc: 0.6275 - val_loss: 122.8976 - val_acc: 0.6236\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 121.7217 - acc: 0.6292 - val_loss: 120.5939 - val_acc: 0.6247\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 121.7637 - acc: 0.6287 - val_loss: 122.8035 - val_acc: 0.6216\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 120.9681 - acc: 0.6276 - val_loss: 120.8629 - val_acc: 0.6248\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 121.9195 - acc: 0.6291 - val_loss: 122.0370 - val_acc: 0.6238\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 122.3619 - acc: 0.6261 - val_loss: 121.3004 - val_acc: 0.6249\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 121.3953 - acc: 0.6288 - val_loss: 121.6999 - val_acc: 0.6239\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 120.2077 - acc: 0.6267 - val_loss: 120.3812 - val_acc: 0.6208\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 119.3887 - acc: 0.6285 - val_loss: 119.1721 - val_acc: 0.6236\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 119.1362 - acc: 0.6254 - val_loss: 120.5110 - val_acc: 0.6241\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 120.7157 - acc: 0.6264 - val_loss: 121.2091 - val_acc: 0.6234\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 121.7676 - acc: 0.6277 - val_loss: 122.6118 - val_acc: 0.6228\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 120.8890 - acc: 0.6268 - val_loss: 121.2211 - val_acc: 0.6226\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 123.2480 - acc: 0.6291 - val_loss: 121.7778 - val_acc: 0.6251\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 121.2538 - acc: 0.6285 - val_loss: 121.0858 - val_acc: 0.6223\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 119.8926 - acc: 0.6288 - val_loss: 121.3331 - val_acc: 0.6214\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 119.1120 - acc: 0.6259 - val_loss: 120.3604 - val_acc: 0.6200\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 119.0034 - acc: 0.6262 - val_loss: 120.2605 - val_acc: 0.6228\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 120.9204 - acc: 0.6294 - val_loss: 120.9416 - val_acc: 0.6246\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 123.1268 - acc: 0.6273 - val_loss: 118.6435 - val_acc: 0.6248\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 119.7319 - acc: 0.6291 - val_loss: 121.4446 - val_acc: 0.6230\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 121.3510 - acc: 0.6286 - val_loss: 125.0823 - val_acc: 0.6209\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 122.4716 - acc: 0.6270 - val_loss: 124.5779 - val_acc: 0.6220\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 120.8597 - acc: 0.6280 - val_loss: 122.7848 - val_acc: 0.6240\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 119.5893 - acc: 0.6277 - val_loss: 119.6679 - val_acc: 0.6242\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 119.7110 - acc: 0.6266 - val_loss: 120.0926 - val_acc: 0.6229\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 117.8536 - acc: 0.6294 - val_loss: 119.7402 - val_acc: 0.6254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 56.8898 - acc: 0.4301 - val_loss: 53.1341 - val_acc: 0.4345\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 56.8693 - acc: 0.4299 - val_loss: 53.1086 - val_acc: 0.4340\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 56.8445 - acc: 0.4302 - val_loss: 53.0944 - val_acc: 0.4350\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 56.8274 - acc: 0.4300 - val_loss: 53.0880 - val_acc: 0.4353\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 56.8070 - acc: 0.4302 - val_loss: 53.0632 - val_acc: 0.4338\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 56.7891 - acc: 0.4300 - val_loss: 53.0509 - val_acc: 0.4349\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 56.7670 - acc: 0.4302 - val_loss: 53.0264 - val_acc: 0.4349\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 56.7513 - acc: 0.4302 - val_loss: 53.0071 - val_acc: 0.4347\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 56.7297 - acc: 0.4301 - val_loss: 52.9844 - val_acc: 0.4343\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 56.7096 - acc: 0.4300 - val_loss: 52.9848 - val_acc: 0.4347\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 56.6928 - acc: 0.4302 - val_loss: 52.9578 - val_acc: 0.4343\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 56.6743 - acc: 0.4300 - val_loss: 52.9445 - val_acc: 0.4330\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 56.6564 - acc: 0.4300 - val_loss: 52.9386 - val_acc: 0.4347\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 56.6346 - acc: 0.4303 - val_loss: 52.9093 - val_acc: 0.4330\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 56.6228 - acc: 0.4299 - val_loss: 52.9101 - val_acc: 0.4350\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 56.6020 - acc: 0.4303 - val_loss: 52.8897 - val_acc: 0.4346\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 56.5827 - acc: 0.4302 - val_loss: 52.8744 - val_acc: 0.4351\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 56.5625 - acc: 0.4301 - val_loss: 52.8939 - val_acc: 0.4361\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 56.5506 - acc: 0.4303 - val_loss: 52.8309 - val_acc: 0.4351\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 56.5284 - acc: 0.4302 - val_loss: 52.8198 - val_acc: 0.4350\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 56.5096 - acc: 0.4299 - val_loss: 52.7973 - val_acc: 0.4349\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 56.4902 - acc: 0.4303 - val_loss: 52.7765 - val_acc: 0.4343\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 56.4749 - acc: 0.4301 - val_loss: 52.7691 - val_acc: 0.4354\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 56.4540 - acc: 0.4303 - val_loss: 52.7747 - val_acc: 0.4355\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 56.4378 - acc: 0.4303 - val_loss: 52.7370 - val_acc: 0.4358\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 56.4242 - acc: 0.4305 - val_loss: 52.7168 - val_acc: 0.4351\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 56.4050 - acc: 0.4303 - val_loss: 52.7004 - val_acc: 0.4344\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 56.3869 - acc: 0.4302 - val_loss: 52.7031 - val_acc: 0.4355\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 56.3709 - acc: 0.4306 - val_loss: 52.6643 - val_acc: 0.4340\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 56.3520 - acc: 0.4301 - val_loss: 52.6625 - val_acc: 0.4354\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 56.3370 - acc: 0.4304 - val_loss: 52.6392 - val_acc: 0.4350\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 56.3196 - acc: 0.4305 - val_loss: 52.6153 - val_acc: 0.4348\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 56.3006 - acc: 0.4304 - val_loss: 52.6135 - val_acc: 0.4337\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 56.2846 - acc: 0.4301 - val_loss: 52.5828 - val_acc: 0.4345\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 56.2646 - acc: 0.4304 - val_loss: 52.5729 - val_acc: 0.4349\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 56.2480 - acc: 0.4302 - val_loss: 52.5736 - val_acc: 0.4357\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 56.2317 - acc: 0.4309 - val_loss: 52.5514 - val_acc: 0.4334\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 56.2166 - acc: 0.4301 - val_loss: 52.5394 - val_acc: 0.4358\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 56.2003 - acc: 0.4305 - val_loss: 52.5359 - val_acc: 0.4357\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 56.1871 - acc: 0.4307 - val_loss: 52.5014 - val_acc: 0.4349\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 56.1656 - acc: 0.4301 - val_loss: 52.4889 - val_acc: 0.4349\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 56.1467 - acc: 0.4303 - val_loss: 52.4707 - val_acc: 0.4354\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 56.1351 - acc: 0.4306 - val_loss: 52.4570 - val_acc: 0.4349\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 56.1181 - acc: 0.4302 - val_loss: 52.4432 - val_acc: 0.4351\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 56.0981 - acc: 0.4306 - val_loss: 52.4289 - val_acc: 0.4351\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 56.0884 - acc: 0.4304 - val_loss: 52.4262 - val_acc: 0.4353\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 56.0692 - acc: 0.4311 - val_loss: 52.3948 - val_acc: 0.4349\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 56.0489 - acc: 0.4305 - val_loss: 52.3828 - val_acc: 0.4344\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 56.0348 - acc: 0.4302 - val_loss: 52.3957 - val_acc: 0.4359\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 56.0207 - acc: 0.4307 - val_loss: 52.3608 - val_acc: 0.4352\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5456 - acc: 0.4391 - val_loss: 0.5109 - val_acc: 0.4407\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5453 - acc: 0.4393 - val_loss: 0.5100 - val_acc: 0.4407\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.5449 - acc: 0.4393 - val_loss: 0.5095 - val_acc: 0.4402\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5449 - acc: 0.4394 - val_loss: 0.5095 - val_acc: 0.4409\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.5447 - acc: 0.4395 - val_loss: 0.5098 - val_acc: 0.4416\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5447 - acc: 0.4395 - val_loss: 0.5090 - val_acc: 0.4405\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5446 - acc: 0.4396 - val_loss: 0.5089 - val_acc: 0.4409\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5443 - acc: 0.4397 - val_loss: 0.5089 - val_acc: 0.4412\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5443 - acc: 0.4396 - val_loss: 0.5087 - val_acc: 0.4406\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5440 - acc: 0.4399 - val_loss: 0.5094 - val_acc: 0.4410\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5444 - acc: 0.4398 - val_loss: 0.5102 - val_acc: 0.4415\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5448 - acc: 0.4398 - val_loss: 0.5088 - val_acc: 0.4411\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5436 - acc: 0.4401 - val_loss: 0.5105 - val_acc: 0.4402\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5436 - acc: 0.4399 - val_loss: 0.5082 - val_acc: 0.4412\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5434 - acc: 0.4399 - val_loss: 0.5079 - val_acc: 0.4416\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5432 - acc: 0.4402 - val_loss: 0.5086 - val_acc: 0.4417\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5434 - acc: 0.4401 - val_loss: 0.5081 - val_acc: 0.4417\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5430 - acc: 0.4403 - val_loss: 0.5075 - val_acc: 0.4413\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5434 - acc: 0.4402 - val_loss: 0.5075 - val_acc: 0.4409\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5426 - acc: 0.4402 - val_loss: 0.5072 - val_acc: 0.4415\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.5429 - acc: 0.4402 - val_loss: 0.5073 - val_acc: 0.4420\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.5422 - acc: 0.4404 - val_loss: 0.5076 - val_acc: 0.4416\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5422 - acc: 0.4404 - val_loss: 0.5071 - val_acc: 0.4411\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5424 - acc: 0.4405 - val_loss: 0.5068 - val_acc: 0.4418\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.5419 - acc: 0.4405 - val_loss: 0.5066 - val_acc: 0.4418\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.5419 - acc: 0.4406 - val_loss: 0.5065 - val_acc: 0.4420\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5415 - acc: 0.4408 - val_loss: 0.5065 - val_acc: 0.4421\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5414 - acc: 0.4410 - val_loss: 0.5066 - val_acc: 0.4425\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5415 - acc: 0.4408 - val_loss: 0.5116 - val_acc: 0.4418\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5420 - acc: 0.4410 - val_loss: 0.5062 - val_acc: 0.4418\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5410 - acc: 0.4408 - val_loss: 0.5065 - val_acc: 0.4423\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5413 - acc: 0.4410 - val_loss: 0.5065 - val_acc: 0.4420\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.5408 - acc: 0.4410 - val_loss: 0.5057 - val_acc: 0.4418\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.5407 - acc: 0.4410 - val_loss: 0.5055 - val_acc: 0.4418\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5409 - acc: 0.4410 - val_loss: 0.5055 - val_acc: 0.4424\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.5403 - acc: 0.4413 - val_loss: 0.5057 - val_acc: 0.4419\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.5402 - acc: 0.4412 - val_loss: 0.5052 - val_acc: 0.4421\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5401 - acc: 0.4415 - val_loss: 0.5070 - val_acc: 0.4429\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5399 - acc: 0.4414 - val_loss: 0.5050 - val_acc: 0.4420\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5401 - acc: 0.4416 - val_loss: 0.5048 - val_acc: 0.4422\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5396 - acc: 0.4417 - val_loss: 0.5062 - val_acc: 0.4431\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5401 - acc: 0.4417 - val_loss: 0.5049 - val_acc: 0.4423\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5400 - acc: 0.4417 - val_loss: 0.5050 - val_acc: 0.4426\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5408 - acc: 0.4418 - val_loss: 0.5045 - val_acc: 0.4426\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5391 - acc: 0.4419 - val_loss: 0.5044 - val_acc: 0.4424\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5396 - acc: 0.4417 - val_loss: 0.5045 - val_acc: 0.4422\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.5393 - acc: 0.4418 - val_loss: 0.5039 - val_acc: 0.4428\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.5390 - acc: 0.4421 - val_loss: 0.5040 - val_acc: 0.4433\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5394 - acc: 0.4419 - val_loss: 0.5065 - val_acc: 0.4420\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5387 - acc: 0.4422 - val_loss: 0.5037 - val_acc: 0.4434\n",
      "start training round 4\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 33.4409 - acc: 0.6798 - val_loss: 34.5359 - val_acc: 0.6826\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 33.4142 - acc: 0.6839 - val_loss: 32.9731 - val_acc: 0.6805\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 33.2033 - acc: 0.6798 - val_loss: 32.3771 - val_acc: 0.6824\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 33.8783 - acc: 0.6852 - val_loss: 33.1517 - val_acc: 0.7103\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 33.4762 - acc: 0.6883 - val_loss: 34.0877 - val_acc: 0.6820\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 33.4745 - acc: 0.6839 - val_loss: 34.4686 - val_acc: 0.6822\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 32.6572 - acc: 0.6802 - val_loss: 31.9648 - val_acc: 0.6810\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 33.5190 - acc: 0.6796 - val_loss: 31.7836 - val_acc: 0.6800\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 33.2693 - acc: 0.6799 - val_loss: 33.3582 - val_acc: 0.6693\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 32.2204 - acc: 0.6796 - val_loss: 32.3584 - val_acc: 0.6746\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 33.8774 - acc: 0.6792 - val_loss: 33.8581 - val_acc: 0.6764\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 33.2597 - acc: 0.6792 - val_loss: 31.8066 - val_acc: 0.6811\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 33.2752 - acc: 0.6829 - val_loss: 31.6670 - val_acc: 0.6799\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 32.5475 - acc: 0.6797 - val_loss: 32.6286 - val_acc: 0.6798\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 33.7443 - acc: 0.6808 - val_loss: 32.8784 - val_acc: 0.6819\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 32.4918 - acc: 0.6804 - val_loss: 32.8860 - val_acc: 0.6833\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 33.5445 - acc: 0.6793 - val_loss: 32.9397 - val_acc: 0.6817\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 368us/step - loss: 33.0666 - acc: 0.6801 - val_loss: 33.2997 - val_acc: 0.6849\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 33.2947 - acc: 0.6809 - val_loss: 32.8982 - val_acc: 0.6808\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 33.0771 - acc: 0.6798 - val_loss: 34.0967 - val_acc: 0.6825\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 361us/step - loss: 32.9412 - acc: 0.6811 - val_loss: 32.4896 - val_acc: 0.6868\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 33.3559 - acc: 0.6806 - val_loss: 32.6520 - val_acc: 0.6841\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 32.7100 - acc: 0.6802 - val_loss: 33.1986 - val_acc: 0.6825\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 33.3898 - acc: 0.6802 - val_loss: 33.5302 - val_acc: 0.6821\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 33.3028 - acc: 0.6808 - val_loss: 32.5134 - val_acc: 0.6848\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 32.4437 - acc: 0.6799 - val_loss: 33.2766 - val_acc: 0.6731\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 33.2816 - acc: 0.6797 - val_loss: 32.1443 - val_acc: 0.6752\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 31.9757 - acc: 0.6802 - val_loss: 31.9777 - val_acc: 0.6758\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 33.6227 - acc: 0.6791 - val_loss: 33.4027 - val_acc: 0.6793\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 33.1448 - acc: 0.6802 - val_loss: 34.6247 - val_acc: 0.6721\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 32.6597 - acc: 0.6806 - val_loss: 33.7160 - val_acc: 0.6722\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 33.6447 - acc: 0.6810 - val_loss: 32.6248 - val_acc: 0.6751\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 32.1962 - acc: 0.6798 - val_loss: 38.7722 - val_acc: 0.6690\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 33.4499 - acc: 0.6800 - val_loss: 33.6506 - val_acc: 0.6748\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 32.8177 - acc: 0.6805 - val_loss: 31.9319 - val_acc: 0.6745\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 33.1950 - acc: 0.6798 - val_loss: 31.5931 - val_acc: 0.6843\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 361us/step - loss: 32.1185 - acc: 0.6803 - val_loss: 35.5563 - val_acc: 0.6845\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 33.3478 - acc: 0.6799 - val_loss: 31.9701 - val_acc: 0.6840\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 32.9162 - acc: 0.6806 - val_loss: 31.9969 - val_acc: 0.6826\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 33.0526 - acc: 0.6815 - val_loss: 31.3576 - val_acc: 0.6833\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 32.5992 - acc: 0.6799 - val_loss: 31.8849 - val_acc: 0.6826\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 33.0980 - acc: 0.6807 - val_loss: 31.9714 - val_acc: 0.6779\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 32.7668 - acc: 0.6792 - val_loss: 35.9370 - val_acc: 0.6678\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 32.8387 - acc: 0.6806 - val_loss: 33.9168 - val_acc: 0.6744\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 32.8024 - acc: 0.6817 - val_loss: 33.2171 - val_acc: 0.6763\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 32.9699 - acc: 0.6808 - val_loss: 32.1074 - val_acc: 0.6797\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 32.1113 - acc: 0.6799 - val_loss: 36.1982 - val_acc: 0.6852\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 33.1874 - acc: 0.6797 - val_loss: 34.2178 - val_acc: 0.6840\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 32.4790 - acc: 0.6798 - val_loss: 33.6205 - val_acc: 0.6813\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 33.2423 - acc: 0.6807 - val_loss: 30.8273 - val_acc: 0.6837\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 120.8844 - acc: 0.6284 - val_loss: 123.7324 - val_acc: 0.6224\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 122.2616 - acc: 0.6264 - val_loss: 120.5449 - val_acc: 0.6239\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 120.2284 - acc: 0.6292 - val_loss: 123.5785 - val_acc: 0.6227\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 121.8143 - acc: 0.6283 - val_loss: 129.0925 - val_acc: 0.6209\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 121.9185 - acc: 0.6277 - val_loss: 121.9979 - val_acc: 0.6182\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 119.1270 - acc: 0.6257 - val_loss: 121.3282 - val_acc: 0.6210\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 120.1870 - acc: 0.6291 - val_loss: 120.6625 - val_acc: 0.6243\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 119.5312 - acc: 0.6271 - val_loss: 121.7600 - val_acc: 0.6209\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 120.7788 - acc: 0.6286 - val_loss: 126.4009 - val_acc: 0.6249\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 123.3201 - acc: 0.6298 - val_loss: 123.7256 - val_acc: 0.6245\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 121.1349 - acc: 0.6297 - val_loss: 122.3255 - val_acc: 0.6230\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 119.6596 - acc: 0.6279 - val_loss: 117.9552 - val_acc: 0.6255\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 119.4023 - acc: 0.6276 - val_loss: 122.3044 - val_acc: 0.6233\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 118.6726 - acc: 0.6242 - val_loss: 118.8379 - val_acc: 0.6211\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 118.0488 - acc: 0.6288 - val_loss: 119.6939 - val_acc: 0.6254\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 120.6212 - acc: 0.6300 - val_loss: 121.8310 - val_acc: 0.6240\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 120.1420 - acc: 0.6295 - val_loss: 120.9261 - val_acc: 0.6228\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 122.1904 - acc: 0.6284 - val_loss: 126.2091 - val_acc: 0.6233\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 119.1540 - acc: 0.6288 - val_loss: 118.6525 - val_acc: 0.6202\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 118.2525 - acc: 0.6274 - val_loss: 117.4311 - val_acc: 0.6254\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 119.2594 - acc: 0.6303 - val_loss: 120.3096 - val_acc: 0.6243\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 122.2150 - acc: 0.6280 - val_loss: 120.2461 - val_acc: 0.6250\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 119.2084 - acc: 0.6290 - val_loss: 119.3822 - val_acc: 0.6248\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 118.4444 - acc: 0.6280 - val_loss: 119.0755 - val_acc: 0.6240\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 118.7270 - acc: 0.6242 - val_loss: 120.8855 - val_acc: 0.6128\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 374us/step - loss: 117.5612 - acc: 0.6273 - val_loss: 118.3946 - val_acc: 0.6247\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 120.8733 - acc: 0.6285 - val_loss: 120.1385 - val_acc: 0.6246\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 122.0783 - acc: 0.6297 - val_loss: 119.4060 - val_acc: 0.6259\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 120.5272 - acc: 0.6297 - val_loss: 123.2873 - val_acc: 0.6244\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 120.7294 - acc: 0.6286 - val_loss: 121.7190 - val_acc: 0.6212\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 120.2862 - acc: 0.6291 - val_loss: 121.4963 - val_acc: 0.6245\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 119.7205 - acc: 0.6298 - val_loss: 120.1396 - val_acc: 0.6215\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 119.4119 - acc: 0.6279 - val_loss: 119.0942 - val_acc: 0.6250\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 118.0937 - acc: 0.6299 - val_loss: 121.1258 - val_acc: 0.6233\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 118.2877 - acc: 0.6257 - val_loss: 117.0700 - val_acc: 0.6225\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 117.3404 - acc: 0.6261 - val_loss: 119.0087 - val_acc: 0.6209\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 117.8038 - acc: 0.6283 - val_loss: 119.0055 - val_acc: 0.6236\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 120.2838 - acc: 0.6295 - val_loss: 121.2281 - val_acc: 0.6262\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 121.7972 - acc: 0.6305 - val_loss: 127.8773 - val_acc: 0.6251\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 124.9377 - acc: 0.6300 - val_loss: 122.2813 - val_acc: 0.6255\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 120.1101 - acc: 0.6295 - val_loss: 122.3906 - val_acc: 0.6219\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 119.7166 - acc: 0.6271 - val_loss: 121.2809 - val_acc: 0.6249\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 117.2745 - acc: 0.6294 - val_loss: 119.2326 - val_acc: 0.6184\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 118.0987 - acc: 0.6260 - val_loss: 120.8142 - val_acc: 0.6222\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 117.0547 - acc: 0.6297 - val_loss: 121.1140 - val_acc: 0.6240\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 121.1027 - acc: 0.6282 - val_loss: 123.3821 - val_acc: 0.6230\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 119.7273 - acc: 0.6293 - val_loss: 129.5867 - val_acc: 0.6212\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 122.4429 - acc: 0.6289 - val_loss: 122.0821 - val_acc: 0.6252\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 121.3621 - acc: 0.6304 - val_loss: 126.6588 - val_acc: 0.6264\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 120.5538 - acc: 0.6302 - val_loss: 121.8513 - val_acc: 0.6230\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 56.0019 - acc: 0.4307 - val_loss: 52.3423 - val_acc: 0.4343\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 55.9921 - acc: 0.4305 - val_loss: 52.3279 - val_acc: 0.4349\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 55.9736 - acc: 0.4304 - val_loss: 52.3190 - val_acc: 0.4353\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 55.9562 - acc: 0.4307 - val_loss: 52.2992 - val_acc: 0.4351\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 55.9405 - acc: 0.4308 - val_loss: 52.2946 - val_acc: 0.4355\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 55.9266 - acc: 0.4306 - val_loss: 52.2811 - val_acc: 0.4348\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 55.9078 - acc: 0.4309 - val_loss: 52.2596 - val_acc: 0.4336\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 55.9032 - acc: 0.4299 - val_loss: 52.2675 - val_acc: 0.4363\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 55.8866 - acc: 0.4306 - val_loss: 52.2457 - val_acc: 0.4358\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 55.8628 - acc: 0.4307 - val_loss: 52.2140 - val_acc: 0.4353\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 55.8485 - acc: 0.4306 - val_loss: 52.2365 - val_acc: 0.4358\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 55.8325 - acc: 0.4307 - val_loss: 52.1843 - val_acc: 0.4352\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 55.8159 - acc: 0.4305 - val_loss: 52.1795 - val_acc: 0.4354\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 55.8074 - acc: 0.4306 - val_loss: 52.1633 - val_acc: 0.4350\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 55.7903 - acc: 0.4305 - val_loss: 52.1469 - val_acc: 0.4349\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 55.7764 - acc: 0.4303 - val_loss: 52.1350 - val_acc: 0.4343\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 55.7577 - acc: 0.4305 - val_loss: 52.1325 - val_acc: 0.4357\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 358us/step - loss: 55.7451 - acc: 0.4307 - val_loss: 52.1019 - val_acc: 0.4350\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 55.7299 - acc: 0.4304 - val_loss: 52.1068 - val_acc: 0.4360\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 55.7226 - acc: 0.4309 - val_loss: 52.0858 - val_acc: 0.4356\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 55.7044 - acc: 0.4305 - val_loss: 52.0573 - val_acc: 0.4354\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 55.6915 - acc: 0.4305 - val_loss: 52.0531 - val_acc: 0.4354\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 55.6785 - acc: 0.4307 - val_loss: 52.0435 - val_acc: 0.4352\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 55.6593 - acc: 0.4307 - val_loss: 52.0616 - val_acc: 0.4364\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 55.6545 - acc: 0.4306 - val_loss: 52.0261 - val_acc: 0.4356\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 55.6314 - acc: 0.4309 - val_loss: 52.0016 - val_acc: 0.4355\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 55.6176 - acc: 0.4308 - val_loss: 51.9883 - val_acc: 0.4359\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 55.6055 - acc: 0.4308 - val_loss: 51.9834 - val_acc: 0.4356\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 55.5945 - acc: 0.4310 - val_loss: 51.9643 - val_acc: 0.4349\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 55.5787 - acc: 0.4306 - val_loss: 51.9586 - val_acc: 0.4359\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 55.5645 - acc: 0.4309 - val_loss: 51.9355 - val_acc: 0.4353\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 55.5447 - acc: 0.4309 - val_loss: 51.9223 - val_acc: 0.4352\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 55.5362 - acc: 0.4308 - val_loss: 51.9184 - val_acc: 0.4354\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 378us/step - loss: 55.5182 - acc: 0.4309 - val_loss: 51.9025 - val_acc: 0.4349\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 55.5082 - acc: 0.4309 - val_loss: 51.8861 - val_acc: 0.4350\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 55.4955 - acc: 0.4307 - val_loss: 51.8919 - val_acc: 0.4365\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 55.4857 - acc: 0.4309 - val_loss: 51.8621 - val_acc: 0.4354\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 55.4610 - acc: 0.4309 - val_loss: 51.8482 - val_acc: 0.4353\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 55.4478 - acc: 0.4304 - val_loss: 51.8711 - val_acc: 0.4368\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 55.4409 - acc: 0.4313 - val_loss: 51.8199 - val_acc: 0.4361\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 55.4278 - acc: 0.4310 - val_loss: 51.8244 - val_acc: 0.4358\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 55.4159 - acc: 0.4309 - val_loss: 51.8226 - val_acc: 0.4355\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 55.3972 - acc: 0.4312 - val_loss: 51.7832 - val_acc: 0.4350\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 55.3864 - acc: 0.4308 - val_loss: 51.7940 - val_acc: 0.4346\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 55.3735 - acc: 0.4305 - val_loss: 51.7636 - val_acc: 0.4359\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 55.3512 - acc: 0.4306 - val_loss: 51.7870 - val_acc: 0.4368\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 55.3469 - acc: 0.4313 - val_loss: 51.7524 - val_acc: 0.4358\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 55.3323 - acc: 0.4310 - val_loss: 51.7297 - val_acc: 0.4353\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 55.3208 - acc: 0.4310 - val_loss: 51.7182 - val_acc: 0.4351\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 55.3038 - acc: 0.4310 - val_loss: 51.7025 - val_acc: 0.4349\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5386 - acc: 0.4423 - val_loss: 0.5044 - val_acc: 0.4433\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5387 - acc: 0.4424 - val_loss: 0.5035 - val_acc: 0.4430\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5389 - acc: 0.4423 - val_loss: 0.5043 - val_acc: 0.4435\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5377 - acc: 0.4427 - val_loss: 0.5031 - val_acc: 0.4432\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5379 - acc: 0.4425 - val_loss: 0.5033 - val_acc: 0.4432\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.5383 - acc: 0.4423 - val_loss: 0.5029 - val_acc: 0.4433\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5377 - acc: 0.4427 - val_loss: 0.5029 - val_acc: 0.4434\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5374 - acc: 0.4428 - val_loss: 0.5031 - val_acc: 0.4430\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5371 - acc: 0.4427 - val_loss: 0.5026 - val_acc: 0.4441\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.5373 - acc: 0.4429 - val_loss: 0.5027 - val_acc: 0.4428\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.5374 - acc: 0.4428 - val_loss: 0.5032 - val_acc: 0.4440\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.5384 - acc: 0.4426 - val_loss: 0.5024 - val_acc: 0.4440\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.5371 - acc: 0.4431 - val_loss: 0.5021 - val_acc: 0.4434\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5367 - acc: 0.4430 - val_loss: 0.5023 - val_acc: 0.4441\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5365 - acc: 0.4432 - val_loss: 0.5045 - val_acc: 0.4440\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5371 - acc: 0.4433 - val_loss: 0.5020 - val_acc: 0.4440\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5362 - acc: 0.4433 - val_loss: 0.5016 - val_acc: 0.4440\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5361 - acc: 0.4432 - val_loss: 0.5022 - val_acc: 0.4435\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.5359 - acc: 0.4433 - val_loss: 0.5016 - val_acc: 0.4443\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5357 - acc: 0.4434 - val_loss: 0.5014 - val_acc: 0.4434\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5382 - acc: 0.4432 - val_loss: 0.5016 - val_acc: 0.4443\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.5362 - acc: 0.4434 - val_loss: 0.5014 - val_acc: 0.4445\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5354 - acc: 0.4437 - val_loss: 0.5008 - val_acc: 0.4442\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5350 - acc: 0.4435 - val_loss: 0.5009 - val_acc: 0.4449\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5350 - acc: 0.4437 - val_loss: 0.5006 - val_acc: 0.4444\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.5350 - acc: 0.4437 - val_loss: 0.5011 - val_acc: 0.4445\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5363 - acc: 0.4437 - val_loss: 0.5006 - val_acc: 0.4450\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.5352 - acc: 0.4436 - val_loss: 0.5009 - val_acc: 0.4452\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.5354 - acc: 0.4437 - val_loss: 0.5001 - val_acc: 0.4450\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5342 - acc: 0.4438 - val_loss: 0.5007 - val_acc: 0.4451\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5351 - acc: 0.4439 - val_loss: 0.5011 - val_acc: 0.4448\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.5341 - acc: 0.4439 - val_loss: 0.5000 - val_acc: 0.4451\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5340 - acc: 0.4441 - val_loss: 0.4998 - val_acc: 0.4453\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.5337 - acc: 0.4442 - val_loss: 0.4997 - val_acc: 0.4455\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5340 - acc: 0.4439 - val_loss: 0.4998 - val_acc: 0.4447\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.5346 - acc: 0.4441 - val_loss: 0.4992 - val_acc: 0.4452\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.5332 - acc: 0.4442 - val_loss: 0.5000 - val_acc: 0.4455\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.5335 - acc: 0.4442 - val_loss: 0.4999 - val_acc: 0.4451\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5331 - acc: 0.4442 - val_loss: 0.4991 - val_acc: 0.4450\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.5332 - acc: 0.4441 - val_loss: 0.4992 - val_acc: 0.4453\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.5330 - acc: 0.4444 - val_loss: 0.4988 - val_acc: 0.4454\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5333 - acc: 0.4444 - val_loss: 0.4988 - val_acc: 0.4457\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5325 - acc: 0.4444 - val_loss: 0.4987 - val_acc: 0.4459\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.5324 - acc: 0.4444 - val_loss: 0.4995 - val_acc: 0.4447\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5324 - acc: 0.4444 - val_loss: 0.5011 - val_acc: 0.4456\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5337 - acc: 0.4446 - val_loss: 0.4994 - val_acc: 0.4448\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5320 - acc: 0.4446 - val_loss: 0.4982 - val_acc: 0.4458\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.5325 - acc: 0.4445 - val_loss: 0.4982 - val_acc: 0.4458\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.5317 - acc: 0.4447 - val_loss: 0.4980 - val_acc: 0.4461\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5317 - acc: 0.4449 - val_loss: 0.4988 - val_acc: 0.4458\n",
      "start training round 5\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 32.3738 - acc: 0.6805 - val_loss: 34.3422 - val_acc: 0.6828\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 33.0072 - acc: 0.6799 - val_loss: 32.4272 - val_acc: 0.6817\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 32.8667 - acc: 0.6802 - val_loss: 33.3777 - val_acc: 0.6843\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 33.1831 - acc: 0.6816 - val_loss: 32.3631 - val_acc: 0.6844\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 32.9006 - acc: 0.6797 - val_loss: 32.4578 - val_acc: 0.6837\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 32.9418 - acc: 0.6808 - val_loss: 32.9322 - val_acc: 0.6864\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 32.9076 - acc: 0.6822 - val_loss: 33.4770 - val_acc: 0.6824\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 32.6621 - acc: 0.6800 - val_loss: 32.4213 - val_acc: 0.6820\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 32.6482 - acc: 0.6807 - val_loss: 33.8015 - val_acc: 0.6848\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 32.8462 - acc: 0.6808 - val_loss: 30.8987 - val_acc: 0.6829\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 32.2297 - acc: 0.6804 - val_loss: 32.1166 - val_acc: 0.6817\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 32.5585 - acc: 0.6795 - val_loss: 31.8941 - val_acc: 0.6799\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 32.8733 - acc: 0.6797 - val_loss: 33.1707 - val_acc: 0.6774\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 32.8213 - acc: 0.6800 - val_loss: 32.0500 - val_acc: 0.6850\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 32.9500 - acc: 0.6818 - val_loss: 30.9430 - val_acc: 0.6828\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 32.5417 - acc: 0.6809 - val_loss: 31.9195 - val_acc: 0.6804\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 33.0133 - acc: 0.6805 - val_loss: 32.2565 - val_acc: 0.6824\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 32.9816 - acc: 0.6804 - val_loss: 32.8708 - val_acc: 0.6854\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 32.3451 - acc: 0.6804 - val_loss: 32.3866 - val_acc: 0.6808\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 32.7752 - acc: 0.6808 - val_loss: 33.2196 - val_acc: 0.6826\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 33.2979 - acc: 0.6806 - val_loss: 31.2265 - val_acc: 0.6841\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 32.5548 - acc: 0.6806 - val_loss: 31.2100 - val_acc: 0.6819\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 32.3113 - acc: 0.6814 - val_loss: 32.0864 - val_acc: 0.6841\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 32.8085 - acc: 0.6802 - val_loss: 30.8757 - val_acc: 0.6834\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 32.7558 - acc: 0.6807 - val_loss: 30.8320 - val_acc: 0.6834\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 31.9725 - acc: 0.6803 - val_loss: 34.1473 - val_acc: 0.6816\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 32.6958 - acc: 0.6798 - val_loss: 31.3863 - val_acc: 0.6850\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 32.5644 - acc: 0.6805 - val_loss: 30.7521 - val_acc: 0.6819\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 31.3616 - acc: 0.6804 - val_loss: 31.6688 - val_acc: 0.6726\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 33.0773 - acc: 0.6780 - val_loss: 31.9217 - val_acc: 0.6776\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 32.7774 - acc: 0.6801 - val_loss: 31.9884 - val_acc: 0.6748\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 32.8859 - acc: 0.6800 - val_loss: 35.6393 - val_acc: 0.6738\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 33.1103 - acc: 0.6805 - val_loss: 35.0183 - val_acc: 0.6654\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 32.5934 - acc: 0.6812 - val_loss: 31.3142 - val_acc: 0.6805\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 32.3315 - acc: 0.6793 - val_loss: 31.7093 - val_acc: 0.6839\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 359us/step - loss: 32.7876 - acc: 0.6810 - val_loss: 31.6994 - val_acc: 0.6857\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 31.7300 - acc: 0.6805 - val_loss: 30.9646 - val_acc: 0.6823\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 33.3599 - acc: 0.6797 - val_loss: 33.1876 - val_acc: 0.6847\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 32.2270 - acc: 0.6807 - val_loss: 31.4679 - val_acc: 0.6813\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 354us/step - loss: 32.0733 - acc: 0.6807 - val_loss: 32.4612 - val_acc: 0.6843\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 362us/step - loss: 32.5419 - acc: 0.6810 - val_loss: 31.2884 - val_acc: 0.6820\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 32.0621 - acc: 0.6794 - val_loss: 31.6833 - val_acc: 0.6819\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 32.6953 - acc: 0.6795 - val_loss: 31.7296 - val_acc: 0.6803\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 32.4002 - acc: 0.6803 - val_loss: 31.8024 - val_acc: 0.6805\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 32.5610 - acc: 0.6793 - val_loss: 32.6539 - val_acc: 0.6805\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 32.3610 - acc: 0.6803 - val_loss: 31.3857 - val_acc: 0.6828\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 32.5431 - acc: 0.6805 - val_loss: 32.4904 - val_acc: 0.6833\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 32.4264 - acc: 0.6804 - val_loss: 33.0982 - val_acc: 0.6793\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 32.8033 - acc: 0.6802 - val_loss: 31.0219 - val_acc: 0.6828\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 31.3319 - acc: 0.6798 - val_loss: 33.1593 - val_acc: 0.6713\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 374us/step - loss: 118.3273 - acc: 0.6277 - val_loss: 121.1745 - val_acc: 0.6222\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 117.9647 - acc: 0.6273 - val_loss: 120.0525 - val_acc: 0.6205\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 117.3931 - acc: 0.6298 - val_loss: 118.8472 - val_acc: 0.6250\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 120.2947 - acc: 0.6302 - val_loss: 122.6902 - val_acc: 0.6261\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 122.0914 - acc: 0.6303 - val_loss: 118.9598 - val_acc: 0.6256\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 119.0851 - acc: 0.6277 - val_loss: 122.3656 - val_acc: 0.6222\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 120.0899 - acc: 0.6286 - val_loss: 118.3751 - val_acc: 0.6268\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 119.3318 - acc: 0.6297 - val_loss: 125.1661 - val_acc: 0.6178\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 118.5505 - acc: 0.6286 - val_loss: 118.2397 - val_acc: 0.6260\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 118.9652 - acc: 0.6284 - val_loss: 119.4536 - val_acc: 0.6232\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 354us/step - loss: 117.7950 - acc: 0.6269 - val_loss: 117.4040 - val_acc: 0.6235\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 117.3824 - acc: 0.6292 - val_loss: 119.7673 - val_acc: 0.6170\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 117.5469 - acc: 0.6277 - val_loss: 119.7794 - val_acc: 0.6237\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 121.8392 - acc: 0.6295 - val_loss: 123.6333 - val_acc: 0.6260\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 357us/step - loss: 121.1468 - acc: 0.6309 - val_loss: 119.4857 - val_acc: 0.6246\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 117.8013 - acc: 0.6302 - val_loss: 117.6654 - val_acc: 0.6247\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 116.7301 - acc: 0.6282 - val_loss: 119.7999 - val_acc: 0.6185\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 347us/step - loss: 117.4966 - acc: 0.6277 - val_loss: 120.5474 - val_acc: 0.6210\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 119.7626 - acc: 0.6280 - val_loss: 120.6565 - val_acc: 0.6258\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 119.5207 - acc: 0.6305 - val_loss: 124.3936 - val_acc: 0.6236\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 119.3885 - acc: 0.6293 - val_loss: 118.9380 - val_acc: 0.6257\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 119.9508 - acc: 0.6298 - val_loss: 122.2932 - val_acc: 0.6230\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 118.1347 - acc: 0.6283 - val_loss: 128.1700 - val_acc: 0.6184\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 119.9412 - acc: 0.6292 - val_loss: 135.7422 - val_acc: 0.6177\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 122.6560 - acc: 0.6300 - val_loss: 118.2533 - val_acc: 0.6269\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 118.9009 - acc: 0.6312 - val_loss: 121.4331 - val_acc: 0.6207\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 118.1614 - acc: 0.6259 - val_loss: 117.0715 - val_acc: 0.6250\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 116.8531 - acc: 0.6292 - val_loss: 118.0777 - val_acc: 0.6259\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 116.8262 - acc: 0.6305 - val_loss: 117.1236 - val_acc: 0.6254\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 116.9798 - acc: 0.6273 - val_loss: 117.3666 - val_acc: 0.6260\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 117.9684 - acc: 0.6297 - val_loss: 118.8868 - val_acc: 0.6256\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 120.9322 - acc: 0.6305 - val_loss: 120.4084 - val_acc: 0.6268\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 357us/step - loss: 120.2545 - acc: 0.6307 - val_loss: 119.9237 - val_acc: 0.6252\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 119.3822 - acc: 0.6298 - val_loss: 117.4338 - val_acc: 0.6265\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 117.4060 - acc: 0.6286 - val_loss: 118.7308 - val_acc: 0.6214\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 118.3249 - acc: 0.6251 - val_loss: 118.5886 - val_acc: 0.6264\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 121.0928 - acc: 0.6305 - val_loss: 118.8870 - val_acc: 0.6272\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 119.4252 - acc: 0.6302 - val_loss: 120.7813 - val_acc: 0.6222\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 119.3547 - acc: 0.6303 - val_loss: 118.7577 - val_acc: 0.6279\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 118.5928 - acc: 0.6316 - val_loss: 118.5385 - val_acc: 0.6267\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 117.1892 - acc: 0.6261 - val_loss: 117.7174 - val_acc: 0.6215\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 117.2281 - acc: 0.6295 - val_loss: 120.8537 - val_acc: 0.6260\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 121.3597 - acc: 0.6314 - val_loss: 123.0212 - val_acc: 0.6262\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 119.5697 - acc: 0.6308 - val_loss: 118.4747 - val_acc: 0.6248\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 118.3854 - acc: 0.6289 - val_loss: 118.0857 - val_acc: 0.6245\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 117.1306 - acc: 0.6279 - val_loss: 117.7219 - val_acc: 0.6249\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 116.2351 - acc: 0.6295 - val_loss: 118.4945 - val_acc: 0.6238\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 118.2181 - acc: 0.6304 - val_loss: 119.0321 - val_acc: 0.6272\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 119.5397 - acc: 0.6306 - val_loss: 124.9825 - val_acc: 0.6263\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 120.4925 - acc: 0.6310 - val_loss: 118.0983 - val_acc: 0.6269\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 55.2917 - acc: 0.4306 - val_loss: 51.7099 - val_acc: 0.4362\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 55.2777 - acc: 0.4310 - val_loss: 51.6929 - val_acc: 0.4358\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 55.2643 - acc: 0.4312 - val_loss: 51.6858 - val_acc: 0.4363\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 55.2542 - acc: 0.4312 - val_loss: 51.6823 - val_acc: 0.4355\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 55.2432 - acc: 0.4309 - val_loss: 51.6584 - val_acc: 0.4361\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 55.2210 - acc: 0.4315 - val_loss: 51.6243 - val_acc: 0.4348\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 55.2093 - acc: 0.4311 - val_loss: 51.6158 - val_acc: 0.4360\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 55.2015 - acc: 0.4310 - val_loss: 51.6338 - val_acc: 0.4368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 55.1842 - acc: 0.4314 - val_loss: 51.5962 - val_acc: 0.4350\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 55.1723 - acc: 0.4311 - val_loss: 51.5922 - val_acc: 0.4364\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 55.1585 - acc: 0.4312 - val_loss: 51.5730 - val_acc: 0.4359\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 55.1468 - acc: 0.4311 - val_loss: 51.5651 - val_acc: 0.4352\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 55.1299 - acc: 0.4313 - val_loss: 51.5445 - val_acc: 0.4350\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 55.1151 - acc: 0.4309 - val_loss: 51.5379 - val_acc: 0.4361\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 55.1020 - acc: 0.4313 - val_loss: 51.5394 - val_acc: 0.4367\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 354us/step - loss: 55.0915 - acc: 0.4313 - val_loss: 51.5096 - val_acc: 0.4354\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 55.0736 - acc: 0.4312 - val_loss: 51.5020 - val_acc: 0.4360\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 55.0692 - acc: 0.4313 - val_loss: 51.4851 - val_acc: 0.4363\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 55.0551 - acc: 0.4311 - val_loss: 51.4850 - val_acc: 0.4369\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 55.0406 - acc: 0.4315 - val_loss: 51.4646 - val_acc: 0.4370\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 55.0262 - acc: 0.4315 - val_loss: 51.4483 - val_acc: 0.4356\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 55.0149 - acc: 0.4313 - val_loss: 51.4426 - val_acc: 0.4364\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 55.0015 - acc: 0.4313 - val_loss: 51.4316 - val_acc: 0.4363\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 54.9916 - acc: 0.4315 - val_loss: 51.4192 - val_acc: 0.4364\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 54.9743 - acc: 0.4313 - val_loss: 51.4188 - val_acc: 0.4372\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 54.9644 - acc: 0.4319 - val_loss: 51.3924 - val_acc: 0.4364\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 54.9505 - acc: 0.4317 - val_loss: 51.3795 - val_acc: 0.4359\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 54.9360 - acc: 0.4312 - val_loss: 51.3770 - val_acc: 0.4368\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 54.9210 - acc: 0.4320 - val_loss: 51.3622 - val_acc: 0.4355\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 54.9123 - acc: 0.4308 - val_loss: 51.3515 - val_acc: 0.4366\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 54.8993 - acc: 0.4315 - val_loss: 51.3374 - val_acc: 0.4362\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 54.8818 - acc: 0.4316 - val_loss: 51.3254 - val_acc: 0.4364\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 54.8710 - acc: 0.4316 - val_loss: 51.3269 - val_acc: 0.4367\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 54.8590 - acc: 0.4316 - val_loss: 51.3013 - val_acc: 0.4366\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 54.8457 - acc: 0.4317 - val_loss: 51.2822 - val_acc: 0.4358\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 54.8333 - acc: 0.4317 - val_loss: 51.2807 - val_acc: 0.4369\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 54.8245 - acc: 0.4317 - val_loss: 51.2554 - val_acc: 0.4358\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 54.8031 - acc: 0.4315 - val_loss: 51.2604 - val_acc: 0.4357\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 54.8030 - acc: 0.4314 - val_loss: 51.2418 - val_acc: 0.4364\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 54.7849 - acc: 0.4318 - val_loss: 51.2234 - val_acc: 0.4364\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 54.7748 - acc: 0.4318 - val_loss: 51.2486 - val_acc: 0.4373\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 54.7607 - acc: 0.4318 - val_loss: 51.2111 - val_acc: 0.4366\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 54.7494 - acc: 0.4317 - val_loss: 51.1954 - val_acc: 0.4360\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 54.7388 - acc: 0.4317 - val_loss: 51.1746 - val_acc: 0.4363\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 54.7273 - acc: 0.4315 - val_loss: 51.1751 - val_acc: 0.4365\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 54.7112 - acc: 0.4318 - val_loss: 51.1700 - val_acc: 0.4365\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 54.7042 - acc: 0.4317 - val_loss: 51.1816 - val_acc: 0.4371\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 54.6915 - acc: 0.4319 - val_loss: 51.1434 - val_acc: 0.4372\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 54.6767 - acc: 0.4317 - val_loss: 51.1360 - val_acc: 0.4370\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 54.6639 - acc: 0.4318 - val_loss: 51.1191 - val_acc: 0.4369\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5324 - acc: 0.4446 - val_loss: 0.4975 - val_acc: 0.4457\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.5319 - acc: 0.4451 - val_loss: 0.5021 - val_acc: 0.4449\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.5324 - acc: 0.4450 - val_loss: 0.5033 - val_acc: 0.4454\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5319 - acc: 0.4449 - val_loss: 0.4974 - val_acc: 0.4464\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5318 - acc: 0.4450 - val_loss: 0.4974 - val_acc: 0.4463\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5308 - acc: 0.4451 - val_loss: 0.4972 - val_acc: 0.4464\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5306 - acc: 0.4452 - val_loss: 0.4976 - val_acc: 0.4459\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5306 - acc: 0.4453 - val_loss: 0.4971 - val_acc: 0.4460\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5304 - acc: 0.4455 - val_loss: 0.4968 - val_acc: 0.4464\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.5306 - acc: 0.4453 - val_loss: 0.4967 - val_acc: 0.4469\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.5324 - acc: 0.4452 - val_loss: 0.4987 - val_acc: 0.4454\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.5307 - acc: 0.4454 - val_loss: 0.4966 - val_acc: 0.4471\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.5302 - acc: 0.4456 - val_loss: 0.4963 - val_acc: 0.4472\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.5301 - acc: 0.4456 - val_loss: 0.4965 - val_acc: 0.4474\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5297 - acc: 0.4458 - val_loss: 0.4967 - val_acc: 0.4462\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5299 - acc: 0.4454 - val_loss: 0.4958 - val_acc: 0.4470\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5295 - acc: 0.4458 - val_loss: 0.5016 - val_acc: 0.4468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.5307 - acc: 0.4456 - val_loss: 0.4956 - val_acc: 0.4472\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.5299 - acc: 0.4457 - val_loss: 0.4961 - val_acc: 0.4466\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5293 - acc: 0.4458 - val_loss: 0.4963 - val_acc: 0.4473\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5296 - acc: 0.4457 - val_loss: 0.4957 - val_acc: 0.4470\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5294 - acc: 0.4459 - val_loss: 0.4952 - val_acc: 0.4469\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5286 - acc: 0.4460 - val_loss: 0.4964 - val_acc: 0.4462\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5306 - acc: 0.4458 - val_loss: 0.4950 - val_acc: 0.4471\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5285 - acc: 0.4462 - val_loss: 0.4955 - val_acc: 0.4473\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.5282 - acc: 0.4461 - val_loss: 0.4953 - val_acc: 0.4477\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5288 - acc: 0.4460 - val_loss: 0.4953 - val_acc: 0.4475\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5279 - acc: 0.4464 - val_loss: 0.4950 - val_acc: 0.4476\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5285 - acc: 0.4463 - val_loss: 0.4946 - val_acc: 0.4474\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5275 - acc: 0.4462 - val_loss: 0.4944 - val_acc: 0.4477\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5278 - acc: 0.4464 - val_loss: 0.4944 - val_acc: 0.4475\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.5276 - acc: 0.4465 - val_loss: 0.4947 - val_acc: 0.4478\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.5272 - acc: 0.4464 - val_loss: 0.4941 - val_acc: 0.4478\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.5271 - acc: 0.4463 - val_loss: 0.4950 - val_acc: 0.4478\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.5270 - acc: 0.4466 - val_loss: 0.4950 - val_acc: 0.4482\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.5278 - acc: 0.4466 - val_loss: 0.4937 - val_acc: 0.4477\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.5266 - acc: 0.4465 - val_loss: 0.4941 - val_acc: 0.4477\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5269 - acc: 0.4465 - val_loss: 0.4936 - val_acc: 0.4482\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5265 - acc: 0.4468 - val_loss: 0.4940 - val_acc: 0.4478\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5263 - acc: 0.4466 - val_loss: 0.4933 - val_acc: 0.4485\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5265 - acc: 0.4466 - val_loss: 0.4944 - val_acc: 0.4483\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5261 - acc: 0.4470 - val_loss: 0.4935 - val_acc: 0.4485\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5258 - acc: 0.4466 - val_loss: 0.4929 - val_acc: 0.4482\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5258 - acc: 0.4469 - val_loss: 0.4929 - val_acc: 0.4483\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5260 - acc: 0.4467 - val_loss: 0.4940 - val_acc: 0.4481\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.5255 - acc: 0.4471 - val_loss: 0.4931 - val_acc: 0.4481\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.5256 - acc: 0.4470 - val_loss: 0.4925 - val_acc: 0.4490\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.5253 - acc: 0.4471 - val_loss: 0.4923 - val_acc: 0.4488\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.5259 - acc: 0.4471 - val_loss: 0.4922 - val_acc: 0.4487\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5253 - acc: 0.4473 - val_loss: 0.4924 - val_acc: 0.4486\n",
      "start training round 6\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 33.0404 - acc: 0.6777 - val_loss: 31.3420 - val_acc: 0.6764\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 360us/step - loss: 31.9915 - acc: 0.6797 - val_loss: 33.9138 - val_acc: 0.6775\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 32.9091 - acc: 0.6793 - val_loss: 30.6104 - val_acc: 0.6773\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 31.5068 - acc: 0.6792 - val_loss: 34.9634 - val_acc: 0.6732\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 32.3641 - acc: 0.6792 - val_loss: 32.3553 - val_acc: 0.6768\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 32.6470 - acc: 0.6798 - val_loss: 32.2373 - val_acc: 0.6783\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 359us/step - loss: 32.4597 - acc: 0.6797 - val_loss: 31.4476 - val_acc: 0.6778\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 31.9148 - acc: 0.6809 - val_loss: 31.5713 - val_acc: 0.6702\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 32.4822 - acc: 0.6786 - val_loss: 33.0670 - val_acc: 0.6849\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 32.4329 - acc: 0.6809 - val_loss: 32.4525 - val_acc: 0.6830\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 32.5780 - acc: 0.6805 - val_loss: 33.5659 - val_acc: 0.6775\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 32.4015 - acc: 0.6800 - val_loss: 34.5086 - val_acc: 0.6841\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 32.5218 - acc: 0.6805 - val_loss: 31.6584 - val_acc: 0.6835\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 32.2218 - acc: 0.6798 - val_loss: 31.7908 - val_acc: 0.6844\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 32.4277 - acc: 0.6806 - val_loss: 34.5677 - val_acc: 0.6799\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 32.5388 - acc: 0.6813 - val_loss: 32.6593 - val_acc: 0.6847\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 32.0542 - acc: 0.6800 - val_loss: 33.2844 - val_acc: 0.6828\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 360us/step - loss: 32.2405 - acc: 0.6795 - val_loss: 31.9290 - val_acc: 0.6842\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 32.6002 - acc: 0.6795 - val_loss: 31.5808 - val_acc: 0.6836\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 32.3932 - acc: 0.6802 - val_loss: 30.7850 - val_acc: 0.6819\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 31.9018 - acc: 0.6793 - val_loss: 32.5515 - val_acc: 0.6711\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 32.4878 - acc: 0.6792 - val_loss: 32.0075 - val_acc: 0.6728\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 32.5459 - acc: 0.6800 - val_loss: 31.5176 - val_acc: 0.6749\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 32.5362 - acc: 0.6788 - val_loss: 34.2085 - val_acc: 0.6763\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 32.5523 - acc: 0.6807 - val_loss: 31.6159 - val_acc: 0.6769\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 32.4815 - acc: 0.6795 - val_loss: 31.4221 - val_acc: 0.6722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 31.1260 - acc: 0.6798 - val_loss: 31.5373 - val_acc: 0.6817\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 32.7655 - acc: 0.6786 - val_loss: 32.0192 - val_acc: 0.6844\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 32.2027 - acc: 0.6798 - val_loss: 32.5541 - val_acc: 0.6833\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 32.4231 - acc: 0.6813 - val_loss: 31.4600 - val_acc: 0.6843\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 31.8906 - acc: 0.6794 - val_loss: 32.0230 - val_acc: 0.6831\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 32.2011 - acc: 0.6793 - val_loss: 31.3991 - val_acc: 0.6794\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 32.1282 - acc: 0.6794 - val_loss: 31.9209 - val_acc: 0.6840\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 32.7119 - acc: 0.6793 - val_loss: 32.2451 - val_acc: 0.6834\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 32.1349 - acc: 0.6810 - val_loss: 31.7875 - val_acc: 0.6825\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 359us/step - loss: 32.4046 - acc: 0.6798 - val_loss: 31.0243 - val_acc: 0.6815\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 31.9475 - acc: 0.6791 - val_loss: 30.4807 - val_acc: 0.6807\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 31.7537 - acc: 0.6785 - val_loss: 32.9373 - val_acc: 0.6841\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 32.3518 - acc: 0.6794 - val_loss: 31.1702 - val_acc: 0.6806\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 32.1653 - acc: 0.6796 - val_loss: 31.1952 - val_acc: 0.6841\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 31.8929 - acc: 0.6805 - val_loss: 30.8083 - val_acc: 0.6764\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 32.3919 - acc: 0.6793 - val_loss: 31.8582 - val_acc: 0.6730\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 32.4799 - acc: 0.6783 - val_loss: 30.3999 - val_acc: 0.6768\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 32.0859 - acc: 0.6793 - val_loss: 31.8847 - val_acc: 0.6827\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 360us/step - loss: 32.0372 - acc: 0.6794 - val_loss: 31.0607 - val_acc: 0.6841\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 356us/step - loss: 32.1105 - acc: 0.6795 - val_loss: 32.4807 - val_acc: 0.6842\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 31.8727 - acc: 0.6796 - val_loss: 32.0540 - val_acc: 0.6819\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 32.5057 - acc: 0.6795 - val_loss: 32.4693 - val_acc: 0.6840\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 32.2091 - acc: 0.6807 - val_loss: 30.2540 - val_acc: 0.6829\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 30.7265 - acc: 0.6795 - val_loss: 31.7712 - val_acc: 0.6757\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 119.0151 - acc: 0.6302 - val_loss: 123.4443 - val_acc: 0.6245\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 118.1710 - acc: 0.6303 - val_loss: 122.1335 - val_acc: 0.6229\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 118.3606 - acc: 0.6293 - val_loss: 117.2101 - val_acc: 0.6251\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 117.1883 - acc: 0.6304 - val_loss: 122.7469 - val_acc: 0.6268\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 118.5335 - acc: 0.6287 - val_loss: 116.9276 - val_acc: 0.6249\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 116.2606 - acc: 0.6288 - val_loss: 117.8989 - val_acc: 0.6260\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 115.8133 - acc: 0.6306 - val_loss: 115.8772 - val_acc: 0.6261\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 116.1848 - acc: 0.6279 - val_loss: 117.9492 - val_acc: 0.6219\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 115.3705 - acc: 0.6310 - val_loss: 117.9383 - val_acc: 0.6264\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 119.7516 - acc: 0.6309 - val_loss: 122.7893 - val_acc: 0.6271\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 121.5205 - acc: 0.6298 - val_loss: 119.3010 - val_acc: 0.6241\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 120.0133 - acc: 0.6305 - val_loss: 121.9364 - val_acc: 0.6253\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 118.9783 - acc: 0.6302 - val_loss: 119.7827 - val_acc: 0.6232\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 116.9291 - acc: 0.6302 - val_loss: 116.6606 - val_acc: 0.6258\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 116.6467 - acc: 0.6296 - val_loss: 122.3747 - val_acc: 0.6216\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 118.2434 - acc: 0.6309 - val_loss: 121.8392 - val_acc: 0.6276\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 120.0324 - acc: 0.6304 - val_loss: 118.8940 - val_acc: 0.6240\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 117.4128 - acc: 0.6294 - val_loss: 120.7851 - val_acc: 0.6244\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 359us/step - loss: 118.3832 - acc: 0.6318 - val_loss: 125.8340 - val_acc: 0.6228\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 120.4171 - acc: 0.6313 - val_loss: 123.0316 - val_acc: 0.6242\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 119.2374 - acc: 0.6313 - val_loss: 128.2544 - val_acc: 0.6220\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 119.1656 - acc: 0.6294 - val_loss: 125.6030 - val_acc: 0.6254\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 119.5007 - acc: 0.6318 - val_loss: 120.1321 - val_acc: 0.6252\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 117.3811 - acc: 0.6300 - val_loss: 118.9040 - val_acc: 0.6272\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 116.8118 - acc: 0.6295 - val_loss: 121.2441 - val_acc: 0.6236\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 116.6236 - acc: 0.6302 - val_loss: 118.9768 - val_acc: 0.6199\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 117.2733 - acc: 0.6289 - val_loss: 118.3416 - val_acc: 0.6272\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 119.4775 - acc: 0.6317 - val_loss: 116.9825 - val_acc: 0.6264\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 115.6376 - acc: 0.6293 - val_loss: 117.7720 - val_acc: 0.6236\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 116.9846 - acc: 0.6302 - val_loss: 115.8337 - val_acc: 0.6276\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 116.1719 - acc: 0.6309 - val_loss: 118.8279 - val_acc: 0.6242\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 116.3149 - acc: 0.6298 - val_loss: 116.0112 - val_acc: 0.6285\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 357us/step - loss: 117.7050 - acc: 0.6327 - val_loss: 124.2503 - val_acc: 0.6259\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 118.2422 - acc: 0.6327 - val_loss: 122.6941 - val_acc: 0.6276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 120.8258 - acc: 0.6315 - val_loss: 119.1139 - val_acc: 0.6266\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 117.8170 - acc: 0.6302 - val_loss: 116.9632 - val_acc: 0.6265\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 116.2754 - acc: 0.6270 - val_loss: 117.7427 - val_acc: 0.6199\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 115.7530 - acc: 0.6302 - val_loss: 115.8669 - val_acc: 0.6283\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 116.0824 - acc: 0.6309 - val_loss: 120.7630 - val_acc: 0.6279\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 119.1568 - acc: 0.6328 - val_loss: 116.0533 - val_acc: 0.6282\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 119.9755 - acc: 0.6326 - val_loss: 118.0078 - val_acc: 0.6281\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 362us/step - loss: 118.7282 - acc: 0.6329 - val_loss: 118.4287 - val_acc: 0.6268\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 117.7564 - acc: 0.6312 - val_loss: 117.4693 - val_acc: 0.6270\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 360us/step - loss: 116.9547 - acc: 0.6312 - val_loss: 116.3559 - val_acc: 0.6266\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 116.9159 - acc: 0.6302 - val_loss: 123.9197 - val_acc: 0.6125\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 117.1321 - acc: 0.6291 - val_loss: 119.8615 - val_acc: 0.6228\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 118.5970 - acc: 0.6306 - val_loss: 120.1438 - val_acc: 0.6270\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 118.7732 - acc: 0.6323 - val_loss: 122.1538 - val_acc: 0.6269\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 117.4423 - acc: 0.6326 - val_loss: 118.0725 - val_acc: 0.6276\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 362us/step - loss: 116.3914 - acc: 0.6319 - val_loss: 116.9408 - val_acc: 0.6282\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 54.6518 - acc: 0.4317 - val_loss: 51.0982 - val_acc: 0.4367\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 54.6475 - acc: 0.4317 - val_loss: 51.1065 - val_acc: 0.4371\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 54.6328 - acc: 0.4315 - val_loss: 51.0740 - val_acc: 0.4362\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 54.6217 - acc: 0.4315 - val_loss: 51.0744 - val_acc: 0.4360\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 54.6055 - acc: 0.4315 - val_loss: 51.0749 - val_acc: 0.4376\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 54.6000 - acc: 0.4318 - val_loss: 51.0610 - val_acc: 0.4371\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 54.5830 - acc: 0.4320 - val_loss: 51.0356 - val_acc: 0.4370\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 54.5758 - acc: 0.4317 - val_loss: 51.0374 - val_acc: 0.4369\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 54.5614 - acc: 0.4315 - val_loss: 51.0226 - val_acc: 0.4370\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 54.5498 - acc: 0.4321 - val_loss: 51.0017 - val_acc: 0.4360\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 54.5355 - acc: 0.4315 - val_loss: 51.0069 - val_acc: 0.4367\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 54.5271 - acc: 0.4315 - val_loss: 50.9951 - val_acc: 0.4365\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 54.5194 - acc: 0.4318 - val_loss: 50.9769 - val_acc: 0.4363\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 54.5013 - acc: 0.4315 - val_loss: 50.9802 - val_acc: 0.4365\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 357us/step - loss: 54.4931 - acc: 0.4316 - val_loss: 50.9650 - val_acc: 0.4367\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 54.4786 - acc: 0.4316 - val_loss: 50.9411 - val_acc: 0.4370\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 54.4695 - acc: 0.4319 - val_loss: 50.9279 - val_acc: 0.4358\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 54.4690 - acc: 0.4315 - val_loss: 50.9362 - val_acc: 0.4375\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 54.4453 - acc: 0.4316 - val_loss: 50.9077 - val_acc: 0.4365\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 54.4345 - acc: 0.4317 - val_loss: 50.9005 - val_acc: 0.4365\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 54.4275 - acc: 0.4316 - val_loss: 50.8866 - val_acc: 0.4369\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 54.4159 - acc: 0.4316 - val_loss: 50.9111 - val_acc: 0.4368\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 54.3980 - acc: 0.4315 - val_loss: 50.8643 - val_acc: 0.4368\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 54.3860 - acc: 0.4319 - val_loss: 50.8505 - val_acc: 0.4361\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 54.3802 - acc: 0.4314 - val_loss: 50.8462 - val_acc: 0.4360\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 54.3677 - acc: 0.4315 - val_loss: 50.8412 - val_acc: 0.4366\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 54.3559 - acc: 0.4315 - val_loss: 50.8309 - val_acc: 0.4361\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 54.3404 - acc: 0.4317 - val_loss: 50.8056 - val_acc: 0.4363\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 54.3352 - acc: 0.4314 - val_loss: 50.8103 - val_acc: 0.4370\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 54.3222 - acc: 0.4316 - val_loss: 50.8053 - val_acc: 0.4373\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 54.3087 - acc: 0.4320 - val_loss: 50.7771 - val_acc: 0.4366\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 54.2976 - acc: 0.4314 - val_loss: 50.7807 - val_acc: 0.4366\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 54.2846 - acc: 0.4320 - val_loss: 50.7642 - val_acc: 0.4365\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 54.2822 - acc: 0.4316 - val_loss: 50.7499 - val_acc: 0.4371\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 54.2631 - acc: 0.4317 - val_loss: 50.7393 - val_acc: 0.4366\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 54.2546 - acc: 0.4316 - val_loss: 50.7378 - val_acc: 0.4367\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 54.2420 - acc: 0.4318 - val_loss: 50.7211 - val_acc: 0.4360\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 54.2358 - acc: 0.4316 - val_loss: 50.7076 - val_acc: 0.4363\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 54.2182 - acc: 0.4314 - val_loss: 50.6959 - val_acc: 0.4367\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 54.2086 - acc: 0.4319 - val_loss: 50.6829 - val_acc: 0.4367\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 54.1991 - acc: 0.4315 - val_loss: 50.6796 - val_acc: 0.4367\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 54.1886 - acc: 0.4318 - val_loss: 50.6962 - val_acc: 0.4366\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 379us/step - loss: 54.1741 - acc: 0.4313 - val_loss: 50.6593 - val_acc: 0.4367\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 54.1637 - acc: 0.4314 - val_loss: 50.6562 - val_acc: 0.4371\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 54.1547 - acc: 0.4320 - val_loss: 50.6352 - val_acc: 0.4367\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 54.1444 - acc: 0.4316 - val_loss: 50.6501 - val_acc: 0.4376\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 54.1361 - acc: 0.4318 - val_loss: 50.6275 - val_acc: 0.4371\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 54.1205 - acc: 0.4316 - val_loss: 50.6170 - val_acc: 0.4373\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 54.1090 - acc: 0.4319 - val_loss: 50.6073 - val_acc: 0.4372\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 54.0989 - acc: 0.4319 - val_loss: 50.5997 - val_acc: 0.4369\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.5250 - acc: 0.4472 - val_loss: 0.4922 - val_acc: 0.4483\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5246 - acc: 0.4471 - val_loss: 0.4919 - val_acc: 0.4488\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.5266 - acc: 0.4470 - val_loss: 0.4919 - val_acc: 0.4486\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.5245 - acc: 0.4474 - val_loss: 0.4917 - val_acc: 0.4482\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5243 - acc: 0.4473 - val_loss: 0.4922 - val_acc: 0.4484\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5244 - acc: 0.4473 - val_loss: 0.4914 - val_acc: 0.4490\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5242 - acc: 0.4474 - val_loss: 0.4913 - val_acc: 0.4492\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5245 - acc: 0.4476 - val_loss: 0.4913 - val_acc: 0.4490\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5237 - acc: 0.4476 - val_loss: 0.4913 - val_acc: 0.4491\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5240 - acc: 0.4478 - val_loss: 0.4911 - val_acc: 0.4492\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.5236 - acc: 0.4478 - val_loss: 0.4914 - val_acc: 0.4494\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.5240 - acc: 0.4478 - val_loss: 0.4933 - val_acc: 0.4498\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5236 - acc: 0.4479 - val_loss: 0.4912 - val_acc: 0.4493\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5234 - acc: 0.4482 - val_loss: 0.4919 - val_acc: 0.4492\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5234 - acc: 0.4477 - val_loss: 0.4910 - val_acc: 0.4499\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5228 - acc: 0.4482 - val_loss: 0.4905 - val_acc: 0.4499\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5229 - acc: 0.4479 - val_loss: 0.4908 - val_acc: 0.4492\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.5244 - acc: 0.4480 - val_loss: 0.4904 - val_acc: 0.4500\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5224 - acc: 0.4484 - val_loss: 0.4903 - val_acc: 0.4499\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.5226 - acc: 0.4483 - val_loss: 0.4916 - val_acc: 0.4494\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.5230 - acc: 0.4484 - val_loss: 0.4899 - val_acc: 0.4497\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5223 - acc: 0.4483 - val_loss: 0.4898 - val_acc: 0.4501\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5226 - acc: 0.4484 - val_loss: 0.4897 - val_acc: 0.4502\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5218 - acc: 0.4485 - val_loss: 0.4908 - val_acc: 0.4505\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5223 - acc: 0.4485 - val_loss: 0.4904 - val_acc: 0.4501\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.5218 - acc: 0.4485 - val_loss: 0.4895 - val_acc: 0.4502\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5218 - acc: 0.4486 - val_loss: 0.4901 - val_acc: 0.4502\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5214 - acc: 0.4487 - val_loss: 0.4897 - val_acc: 0.4505\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5216 - acc: 0.4487 - val_loss: 0.4896 - val_acc: 0.4508\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.5211 - acc: 0.4488 - val_loss: 0.4891 - val_acc: 0.4501\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.5217 - acc: 0.4487 - val_loss: 0.4893 - val_acc: 0.4500\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.5207 - acc: 0.4488 - val_loss: 0.4887 - val_acc: 0.4502\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5212 - acc: 0.4488 - val_loss: 0.4886 - val_acc: 0.4505\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5208 - acc: 0.4489 - val_loss: 0.4890 - val_acc: 0.4506\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5203 - acc: 0.4488 - val_loss: 0.4884 - val_acc: 0.4500\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.5205 - acc: 0.4489 - val_loss: 0.4892 - val_acc: 0.4499\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5212 - acc: 0.4487 - val_loss: 0.4890 - val_acc: 0.4510\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5209 - acc: 0.4491 - val_loss: 0.4885 - val_acc: 0.4507\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5202 - acc: 0.4491 - val_loss: 0.4883 - val_acc: 0.4506\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.5201 - acc: 0.4490 - val_loss: 0.4882 - val_acc: 0.4501\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.5198 - acc: 0.4490 - val_loss: 0.4877 - val_acc: 0.4502\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5192 - acc: 0.4491 - val_loss: 0.4874 - val_acc: 0.4504\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5192 - acc: 0.4493 - val_loss: 0.4884 - val_acc: 0.4501\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5189 - acc: 0.4492 - val_loss: 0.4880 - val_acc: 0.4509\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.5183 - acc: 0.4494 - val_loss: 0.4875 - val_acc: 0.4507\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5182 - acc: 0.4493 - val_loss: 0.4864 - val_acc: 0.4499\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.5190 - acc: 0.4492 - val_loss: 0.4866 - val_acc: 0.4506\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5185 - acc: 0.4493 - val_loss: 0.4864 - val_acc: 0.4505\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.5176 - acc: 0.4492 - val_loss: 0.4863 - val_acc: 0.4507\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.5175 - acc: 0.4494 - val_loss: 0.4861 - val_acc: 0.4503\n",
      "start training round 7\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 365us/step - loss: 32.4342 - acc: 0.6780 - val_loss: 34.1179 - val_acc: 0.6702\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 32.1170 - acc: 0.6800 - val_loss: 35.6864 - val_acc: 0.6671\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 32.2324 - acc: 0.6785 - val_loss: 30.9786 - val_acc: 0.6777\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 31.7911 - acc: 0.6788 - val_loss: 31.3537 - val_acc: 0.6848\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 32.2644 - acc: 0.6797 - val_loss: 31.1849 - val_acc: 0.6805\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 31.8046 - acc: 0.6793 - val_loss: 31.7368 - val_acc: 0.6824\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 32.0355 - acc: 0.6798 - val_loss: 32.4143 - val_acc: 0.6819\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 32.0560 - acc: 0.6780 - val_loss: 31.6755 - val_acc: 0.6817\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 32.4238 - acc: 0.6790 - val_loss: 31.2178 - val_acc: 0.6842\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 31.9284 - acc: 0.6799 - val_loss: 32.6368 - val_acc: 0.6833\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 32.0228 - acc: 0.6800 - val_loss: 30.7373 - val_acc: 0.6819\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 32.2859 - acc: 0.6794 - val_loss: 30.2074 - val_acc: 0.6836\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 31.3359 - acc: 0.6794 - val_loss: 31.1525 - val_acc: 0.6806\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 31.9132 - acc: 0.6794 - val_loss: 31.6730 - val_acc: 0.6816\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 32.0211 - acc: 0.6782 - val_loss: 32.4251 - val_acc: 0.6824\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 32.5272 - acc: 0.6777 - val_loss: 32.0807 - val_acc: 0.6829\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 31.9734 - acc: 0.6801 - val_loss: 32.5352 - val_acc: 0.6808\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 32.1485 - acc: 0.6796 - val_loss: 31.8514 - val_acc: 0.6840\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 32.2007 - acc: 0.6796 - val_loss: 30.7923 - val_acc: 0.6808\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 32.1648 - acc: 0.6787 - val_loss: 32.3728 - val_acc: 0.6834\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 31.4914 - acc: 0.6797 - val_loss: 32.6200 - val_acc: 0.6815\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 31.9713 - acc: 0.6797 - val_loss: 31.5114 - val_acc: 0.6841\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 31.4167 - acc: 0.6791 - val_loss: 33.2253 - val_acc: 0.6693\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 32.0341 - acc: 0.6780 - val_loss: 32.3386 - val_acc: 0.6687\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 31.7866 - acc: 0.6778 - val_loss: 31.6792 - val_acc: 0.6771\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 32.0229 - acc: 0.6784 - val_loss: 30.6904 - val_acc: 0.6769\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 31.3608 - acc: 0.6774 - val_loss: 33.0778 - val_acc: 0.6700\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 31.9024 - acc: 0.6785 - val_loss: 31.7382 - val_acc: 0.6736\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 31.9865 - acc: 0.6771 - val_loss: 34.2163 - val_acc: 0.6719\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 32.1016 - acc: 0.6785 - val_loss: 32.6255 - val_acc: 0.6698\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 31.3798 - acc: 0.6791 - val_loss: 30.5242 - val_acc: 0.6787\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 32.1588 - acc: 0.6778 - val_loss: 32.6941 - val_acc: 0.6858\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 31.9561 - acc: 0.6795 - val_loss: 30.6395 - val_acc: 0.6822\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 31.7907 - acc: 0.6789 - val_loss: 33.2859 - val_acc: 0.6834\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 32.0908 - acc: 0.6788 - val_loss: 31.5264 - val_acc: 0.6814\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 32.0466 - acc: 0.6786 - val_loss: 30.2781 - val_acc: 0.6807\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 361us/step - loss: 30.9683 - acc: 0.6788 - val_loss: 31.9203 - val_acc: 0.6653\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 357us/step - loss: 32.0143 - acc: 0.6763 - val_loss: 35.0675 - val_acc: 0.6686\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 31.7013 - acc: 0.6782 - val_loss: 30.2851 - val_acc: 0.6747\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 31.5482 - acc: 0.6788 - val_loss: 33.0833 - val_acc: 0.6625\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 31.9403 - acc: 0.6773 - val_loss: 34.7793 - val_acc: 0.6594\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 31.9952 - acc: 0.6793 - val_loss: 31.5959 - val_acc: 0.6746\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 30.8833 - acc: 0.6793 - val_loss: 31.3591 - val_acc: 0.6688\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 32.3442 - acc: 0.6767 - val_loss: 31.1197 - val_acc: 0.6747\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 31.9105 - acc: 0.6777 - val_loss: 33.7804 - val_acc: 0.6709\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 31.6490 - acc: 0.6791 - val_loss: 31.9425 - val_acc: 0.6658\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 31.5860 - acc: 0.6794 - val_loss: 33.3581 - val_acc: 0.6686\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 31.8549 - acc: 0.6783 - val_loss: 32.9536 - val_acc: 0.6742\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 31.6005 - acc: 0.6785 - val_loss: 30.4328 - val_acc: 0.6765\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 360us/step - loss: 31.2426 - acc: 0.6782 - val_loss: 31.8410 - val_acc: 0.6731\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 116.1841 - acc: 0.6324 - val_loss: 119.0707 - val_acc: 0.6271\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 116.4713 - acc: 0.6315 - val_loss: 119.9357 - val_acc: 0.6217\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 116.1363 - acc: 0.6308 - val_loss: 115.8060 - val_acc: 0.6291\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 115.5557 - acc: 0.6322 - val_loss: 116.6240 - val_acc: 0.6254\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 116.2821 - acc: 0.6255 - val_loss: 118.3424 - val_acc: 0.6206\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 114.2856 - acc: 0.6317 - val_loss: 115.9037 - val_acc: 0.6291\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 118.0388 - acc: 0.6320 - val_loss: 120.2228 - val_acc: 0.6276\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 119.3186 - acc: 0.6323 - val_loss: 125.3582 - val_acc: 0.6264\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 382us/step - loss: 119.5098 - acc: 0.6321 - val_loss: 119.2835 - val_acc: 0.6282\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 119.0760 - acc: 0.6329 - val_loss: 123.8230 - val_acc: 0.6266\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 117.0204 - acc: 0.6336 - val_loss: 119.1793 - val_acc: 0.6283\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 118.0486 - acc: 0.6323 - val_loss: 117.0998 - val_acc: 0.6275\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 117.1429 - acc: 0.6310 - val_loss: 121.5678 - val_acc: 0.6243\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 119.2214 - acc: 0.6314 - val_loss: 119.7948 - val_acc: 0.6257\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 116.9646 - acc: 0.6293 - val_loss: 114.5417 - val_acc: 0.6285\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 114.7714 - acc: 0.6318 - val_loss: 116.4572 - val_acc: 0.6258\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 117.2995 - acc: 0.6300 - val_loss: 117.2739 - val_acc: 0.6271\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 119.8537 - acc: 0.6308 - val_loss: 116.4613 - val_acc: 0.6283\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 118.5873 - acc: 0.6321 - val_loss: 118.0718 - val_acc: 0.6250\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 116.2971 - acc: 0.6299 - val_loss: 116.3998 - val_acc: 0.6277\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 115.2748 - acc: 0.6316 - val_loss: 119.5483 - val_acc: 0.6236\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 115.6008 - acc: 0.6301 - val_loss: 117.8649 - val_acc: 0.6221\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 117.6171 - acc: 0.6308 - val_loss: 123.8420 - val_acc: 0.6276\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 120.5407 - acc: 0.6333 - val_loss: 117.3942 - val_acc: 0.6295\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 116.2281 - acc: 0.6337 - val_loss: 116.2071 - val_acc: 0.6288\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 117.5999 - acc: 0.6325 - val_loss: 120.0378 - val_acc: 0.6266\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 118.5715 - acc: 0.6302 - val_loss: 117.2748 - val_acc: 0.6280\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 117.1717 - acc: 0.6326 - val_loss: 121.2486 - val_acc: 0.6248\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 119.4231 - acc: 0.6311 - val_loss: 115.4025 - val_acc: 0.6268\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 115.1542 - acc: 0.6326 - val_loss: 118.5095 - val_acc: 0.6251\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 115.3083 - acc: 0.6286 - val_loss: 115.6073 - val_acc: 0.6270\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 113.8685 - acc: 0.6318 - val_loss: 115.4736 - val_acc: 0.6289\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 115.2996 - acc: 0.6306 - val_loss: 118.7961 - val_acc: 0.6250\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 117.5850 - acc: 0.6323 - val_loss: 122.4611 - val_acc: 0.6241\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 116.7618 - acc: 0.6324 - val_loss: 131.6980 - val_acc: 0.6189\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 120.7616 - acc: 0.6327 - val_loss: 117.2979 - val_acc: 0.6305\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 116.7641 - acc: 0.6339 - val_loss: 123.8156 - val_acc: 0.6279\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 118.3923 - acc: 0.6324 - val_loss: 119.1168 - val_acc: 0.6298\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 117.4793 - acc: 0.6323 - val_loss: 116.9179 - val_acc: 0.6280\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 115.0388 - acc: 0.6318 - val_loss: 117.5138 - val_acc: 0.6228\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 113.7159 - acc: 0.6316 - val_loss: 114.4993 - val_acc: 0.6290\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 114.1697 - acc: 0.6291 - val_loss: 118.2287 - val_acc: 0.6163\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 115.8333 - acc: 0.6302 - val_loss: 120.5209 - val_acc: 0.6242\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 115.4662 - acc: 0.6312 - val_loss: 123.8784 - val_acc: 0.6222\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 117.8982 - acc: 0.6331 - val_loss: 116.8003 - val_acc: 0.6291\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 117.2369 - acc: 0.6344 - val_loss: 120.2461 - val_acc: 0.6286\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 118.5269 - acc: 0.6326 - val_loss: 118.1941 - val_acc: 0.6280\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 116.2638 - acc: 0.6339 - val_loss: 119.8496 - val_acc: 0.6278\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 117.3244 - acc: 0.6319 - val_loss: 119.6470 - val_acc: 0.6279\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 116.6708 - acc: 0.6320 - val_loss: 118.5713 - val_acc: 0.6232\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 54.0865 - acc: 0.4316 - val_loss: 50.5879 - val_acc: 0.4373\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 54.0767 - acc: 0.4317 - val_loss: 50.5637 - val_acc: 0.4371\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 54.0692 - acc: 0.4316 - val_loss: 50.5597 - val_acc: 0.4372\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 54.0532 - acc: 0.4319 - val_loss: 50.5456 - val_acc: 0.4373\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 54.0423 - acc: 0.4314 - val_loss: 50.5440 - val_acc: 0.4374\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 54.0323 - acc: 0.4320 - val_loss: 50.5583 - val_acc: 0.4370\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 54.0227 - acc: 0.4315 - val_loss: 50.5523 - val_acc: 0.4382\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 54.0153 - acc: 0.4321 - val_loss: 50.5134 - val_acc: 0.4377\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 53.9934 - acc: 0.4320 - val_loss: 50.4945 - val_acc: 0.4367\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 53.9964 - acc: 0.4318 - val_loss: 50.4887 - val_acc: 0.4378\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 53.9843 - acc: 0.4321 - val_loss: 50.4815 - val_acc: 0.4373\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 53.9708 - acc: 0.4319 - val_loss: 50.4767 - val_acc: 0.4376\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 53.9583 - acc: 0.4321 - val_loss: 50.4564 - val_acc: 0.4367\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 53.9474 - acc: 0.4317 - val_loss: 50.4576 - val_acc: 0.4382\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 361us/step - loss: 53.9387 - acc: 0.4320 - val_loss: 50.4455 - val_acc: 0.4382\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 53.9263 - acc: 0.4321 - val_loss: 50.4577 - val_acc: 0.4377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 53.9216 - acc: 0.4322 - val_loss: 50.4187 - val_acc: 0.4376\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 53.9082 - acc: 0.4320 - val_loss: 50.4248 - val_acc: 0.4386\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 53.8958 - acc: 0.4322 - val_loss: 50.3987 - val_acc: 0.4379\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 53.8845 - acc: 0.4321 - val_loss: 50.3847 - val_acc: 0.4371\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 53.8731 - acc: 0.4321 - val_loss: 50.3880 - val_acc: 0.4372\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 53.8670 - acc: 0.4320 - val_loss: 50.3674 - val_acc: 0.4382\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 53.8539 - acc: 0.4323 - val_loss: 50.3581 - val_acc: 0.4381\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 53.8425 - acc: 0.4320 - val_loss: 50.3553 - val_acc: 0.4374\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 53.8285 - acc: 0.4324 - val_loss: 50.3356 - val_acc: 0.4381\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 53.8188 - acc: 0.4320 - val_loss: 50.3317 - val_acc: 0.4383\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 53.8081 - acc: 0.4324 - val_loss: 50.3167 - val_acc: 0.4374\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 53.8023 - acc: 0.4319 - val_loss: 50.3364 - val_acc: 0.4380\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 53.7911 - acc: 0.4323 - val_loss: 50.2949 - val_acc: 0.4379\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 53.7850 - acc: 0.4321 - val_loss: 50.2861 - val_acc: 0.4377\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 53.7699 - acc: 0.4321 - val_loss: 50.2967 - val_acc: 0.4382\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 53.7617 - acc: 0.4324 - val_loss: 50.2725 - val_acc: 0.4383\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 53.7473 - acc: 0.4323 - val_loss: 50.2893 - val_acc: 0.4374\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 53.7400 - acc: 0.4321 - val_loss: 50.2622 - val_acc: 0.4386\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 53.7306 - acc: 0.4325 - val_loss: 50.2478 - val_acc: 0.4380\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 53.7190 - acc: 0.4321 - val_loss: 50.2311 - val_acc: 0.4380\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 53.7083 - acc: 0.4324 - val_loss: 50.2309 - val_acc: 0.4387\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 53.6959 - acc: 0.4325 - val_loss: 50.2130 - val_acc: 0.4384\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 360us/step - loss: 53.6839 - acc: 0.4326 - val_loss: 50.2266 - val_acc: 0.4383\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 53.6755 - acc: 0.4325 - val_loss: 50.2077 - val_acc: 0.4388\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 53.6660 - acc: 0.4324 - val_loss: 50.1841 - val_acc: 0.4387\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 53.6576 - acc: 0.4324 - val_loss: 50.1830 - val_acc: 0.4385\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 53.6432 - acc: 0.4325 - val_loss: 50.1799 - val_acc: 0.4387\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 53.6353 - acc: 0.4322 - val_loss: 50.1697 - val_acc: 0.4391\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 53.6255 - acc: 0.4326 - val_loss: 50.1537 - val_acc: 0.4391\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 53.6116 - acc: 0.4326 - val_loss: 50.1475 - val_acc: 0.4386\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 53.6060 - acc: 0.4324 - val_loss: 50.1448 - val_acc: 0.4391\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 53.5901 - acc: 0.4326 - val_loss: 50.1284 - val_acc: 0.4386\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 53.5775 - acc: 0.4324 - val_loss: 50.1231 - val_acc: 0.4382\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 53.5748 - acc: 0.4321 - val_loss: 50.1202 - val_acc: 0.4394\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5178 - acc: 0.4496 - val_loss: 0.4858 - val_acc: 0.4506\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5173 - acc: 0.4495 - val_loss: 0.4856 - val_acc: 0.4502\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.5169 - acc: 0.4496 - val_loss: 0.4857 - val_acc: 0.4505\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5171 - acc: 0.4497 - val_loss: 0.4857 - val_acc: 0.4500\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5173 - acc: 0.4497 - val_loss: 0.4851 - val_acc: 0.4505\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5171 - acc: 0.4496 - val_loss: 0.4854 - val_acc: 0.4509\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5171 - acc: 0.4498 - val_loss: 0.4852 - val_acc: 0.4509\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5163 - acc: 0.4499 - val_loss: 0.4850 - val_acc: 0.4509\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 0.5158 - acc: 0.4500 - val_loss: 0.4845 - val_acc: 0.4509\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5157 - acc: 0.4501 - val_loss: 0.4843 - val_acc: 0.4505\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.5158 - acc: 0.4500 - val_loss: 0.4849 - val_acc: 0.4512\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5158 - acc: 0.4501 - val_loss: 0.4850 - val_acc: 0.4506\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5154 - acc: 0.4499 - val_loss: 0.4840 - val_acc: 0.4505\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5152 - acc: 0.4502 - val_loss: 0.4842 - val_acc: 0.4509\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5153 - acc: 0.4502 - val_loss: 0.4856 - val_acc: 0.4502\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5151 - acc: 0.4503 - val_loss: 0.4846 - val_acc: 0.4506\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5149 - acc: 0.4501 - val_loss: 0.4843 - val_acc: 0.4507\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5149 - acc: 0.4505 - val_loss: 0.4835 - val_acc: 0.4499\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5144 - acc: 0.4504 - val_loss: 0.4833 - val_acc: 0.4504\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5154 - acc: 0.4502 - val_loss: 0.4863 - val_acc: 0.4513\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.5147 - acc: 0.4502 - val_loss: 0.4837 - val_acc: 0.4510\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5144 - acc: 0.4504 - val_loss: 0.4836 - val_acc: 0.4518\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5144 - acc: 0.4503 - val_loss: 0.4830 - val_acc: 0.4513\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.5138 - acc: 0.4504 - val_loss: 0.4835 - val_acc: 0.4513\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5144 - acc: 0.4504 - val_loss: 0.4836 - val_acc: 0.4508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5148 - acc: 0.4503 - val_loss: 0.4824 - val_acc: 0.4509\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5135 - acc: 0.4505 - val_loss: 0.4831 - val_acc: 0.4515\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5140 - acc: 0.4504 - val_loss: 0.4826 - val_acc: 0.4510\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5135 - acc: 0.4505 - val_loss: 0.4825 - val_acc: 0.4516\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5129 - acc: 0.4506 - val_loss: 0.4822 - val_acc: 0.4516\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5134 - acc: 0.4504 - val_loss: 0.4826 - val_acc: 0.4510\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.5132 - acc: 0.4505 - val_loss: 0.4820 - val_acc: 0.4517\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5144 - acc: 0.4507 - val_loss: 0.4817 - val_acc: 0.4506\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5123 - acc: 0.4506 - val_loss: 0.4819 - val_acc: 0.4515\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5129 - acc: 0.4508 - val_loss: 0.4815 - val_acc: 0.4513\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5123 - acc: 0.4508 - val_loss: 0.4814 - val_acc: 0.4520\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5120 - acc: 0.4508 - val_loss: 0.4815 - val_acc: 0.4514\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5127 - acc: 0.4506 - val_loss: 0.4813 - val_acc: 0.4514\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5120 - acc: 0.4510 - val_loss: 0.4819 - val_acc: 0.4510\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5117 - acc: 0.4509 - val_loss: 0.4811 - val_acc: 0.4515\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5120 - acc: 0.4506 - val_loss: 0.4813 - val_acc: 0.4521\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5116 - acc: 0.4510 - val_loss: 0.4808 - val_acc: 0.4519\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5116 - acc: 0.4510 - val_loss: 0.4807 - val_acc: 0.4516\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5114 - acc: 0.4509 - val_loss: 0.4810 - val_acc: 0.4516\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5110 - acc: 0.4512 - val_loss: 0.4805 - val_acc: 0.4515\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5108 - acc: 0.4509 - val_loss: 0.4806 - val_acc: 0.4515\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5116 - acc: 0.4510 - val_loss: 0.4822 - val_acc: 0.4516\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5110 - acc: 0.4512 - val_loss: 0.4806 - val_acc: 0.4520\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.5105 - acc: 0.4514 - val_loss: 0.4803 - val_acc: 0.4518\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5120 - acc: 0.4512 - val_loss: 0.4904 - val_acc: 0.4521\n",
      "start training round 8\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 31.8335 - acc: 0.6782 - val_loss: 33.1251 - val_acc: 0.6611\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 31.6124 - acc: 0.6787 - val_loss: 32.7312 - val_acc: 0.6722\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 31.7302 - acc: 0.6778 - val_loss: 34.4281 - val_acc: 0.6595\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 361us/step - loss: 31.5578 - acc: 0.6783 - val_loss: 31.5213 - val_acc: 0.6724\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 31.8681 - acc: 0.6778 - val_loss: 30.1685 - val_acc: 0.6758\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 31.0833 - acc: 0.6787 - val_loss: 31.1914 - val_acc: 0.6813\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 31.8880 - acc: 0.6775 - val_loss: 31.1092 - val_acc: 0.6801\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 31.6797 - acc: 0.6783 - val_loss: 30.0341 - val_acc: 0.6814\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 30.9289 - acc: 0.6781 - val_loss: 31.1203 - val_acc: 0.6831\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 31.4808 - acc: 0.6782 - val_loss: 31.8999 - val_acc: 0.6840\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 31.8904 - acc: 0.6771 - val_loss: 32.4867 - val_acc: 0.6839\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 32.0941 - acc: 0.6793 - val_loss: 31.5516 - val_acc: 0.6846\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 31.6546 - acc: 0.6795 - val_loss: 33.2822 - val_acc: 0.6833\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 31.6456 - acc: 0.6789 - val_loss: 30.6000 - val_acc: 0.6791\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 31.2392 - acc: 0.6777 - val_loss: 31.5908 - val_acc: 0.6846\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 31.9617 - acc: 0.6785 - val_loss: 32.0843 - val_acc: 0.6827\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 31.1186 - acc: 0.6787 - val_loss: 29.7231 - val_acc: 0.6739\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 31.9015 - acc: 0.6781 - val_loss: 29.7726 - val_acc: 0.6766\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 31.1096 - acc: 0.6776 - val_loss: 32.9472 - val_acc: 0.6674\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 32.0665 - acc: 0.6781 - val_loss: 30.6766 - val_acc: 0.6759\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 31.9584 - acc: 0.6777 - val_loss: 30.6412 - val_acc: 0.6748\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 31.0098 - acc: 0.6786 - val_loss: 30.1345 - val_acc: 0.6767\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 31.4811 - acc: 0.6768 - val_loss: 30.9565 - val_acc: 0.6741\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 31.5234 - acc: 0.6766 - val_loss: 34.9238 - val_acc: 0.6644\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 32.0496 - acc: 0.6780 - val_loss: 31.9236 - val_acc: 0.6689\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 31.4890 - acc: 0.6789 - val_loss: 32.6969 - val_acc: 0.6693\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 31.5251 - acc: 0.6782 - val_loss: 29.8926 - val_acc: 0.6787\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 30.6574 - acc: 0.6786 - val_loss: 32.1596 - val_acc: 0.6823\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 31.7667 - acc: 0.6769 - val_loss: 31.5169 - val_acc: 0.6810\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 31.8473 - acc: 0.6775 - val_loss: 32.4480 - val_acc: 0.6824\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 31.3183 - acc: 0.6793 - val_loss: 30.3209 - val_acc: 0.6789\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 31.0620 - acc: 0.6784 - val_loss: 33.1228 - val_acc: 0.6710\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 31.4960 - acc: 0.6766 - val_loss: 32.1807 - val_acc: 0.6707\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 360us/step - loss: 31.5574 - acc: 0.6779 - val_loss: 31.0324 - val_acc: 0.6685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 31.4405 - acc: 0.6783 - val_loss: 33.0848 - val_acc: 0.6697\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 31.9633 - acc: 0.6775 - val_loss: 33.2510 - val_acc: 0.6751\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 31.6919 - acc: 0.6787 - val_loss: 31.2441 - val_acc: 0.6673\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 31.3593 - acc: 0.6778 - val_loss: 31.1147 - val_acc: 0.6769\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 31.0791 - acc: 0.6784 - val_loss: 33.3467 - val_acc: 0.6666\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 31.6750 - acc: 0.6779 - val_loss: 31.4717 - val_acc: 0.6740\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 31.3745 - acc: 0.6774 - val_loss: 33.2153 - val_acc: 0.6601\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 31.4348 - acc: 0.6784 - val_loss: 32.9566 - val_acc: 0.6696\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 31.2997 - acc: 0.6787 - val_loss: 29.6172 - val_acc: 0.6777\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 31.4145 - acc: 0.6779 - val_loss: 31.4899 - val_acc: 0.6696\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.9598 - acc: 0.6778 - val_loss: 31.5093 - val_acc: 0.6788\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 31.6492 - acc: 0.6755 - val_loss: 30.9379 - val_acc: 0.6824\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 30.9297 - acc: 0.6776 - val_loss: 31.0863 - val_acc: 0.6683\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 32.3577 - acc: 0.6762 - val_loss: 31.1361 - val_acc: 0.6718\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 30.9731 - acc: 0.6785 - val_loss: 31.2190 - val_acc: 0.6714\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 31.4117 - acc: 0.6770 - val_loss: 32.1158 - val_acc: 0.6726\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 114.9809 - acc: 0.6293 - val_loss: 114.0327 - val_acc: 0.6283\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 115.5805 - acc: 0.6329 - val_loss: 119.0898 - val_acc: 0.6291\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 117.4320 - acc: 0.6330 - val_loss: 124.6361 - val_acc: 0.6286\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 355us/step - loss: 117.6957 - acc: 0.6337 - val_loss: 116.2883 - val_acc: 0.6280\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 115.9448 - acc: 0.6303 - val_loss: 114.9919 - val_acc: 0.6266\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 114.0029 - acc: 0.6307 - val_loss: 114.1332 - val_acc: 0.6270\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 114.8376 - acc: 0.6286 - val_loss: 116.9648 - val_acc: 0.6255\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 116.4208 - acc: 0.6340 - val_loss: 120.0861 - val_acc: 0.6283\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 118.3480 - acc: 0.6343 - val_loss: 124.5488 - val_acc: 0.6280\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 119.5595 - acc: 0.6333 - val_loss: 116.4379 - val_acc: 0.6276\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 114.8739 - acc: 0.6308 - val_loss: 116.0717 - val_acc: 0.6282\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 113.7403 - acc: 0.6335 - val_loss: 116.7941 - val_acc: 0.6283\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 114.5046 - acc: 0.6291 - val_loss: 115.0468 - val_acc: 0.6242\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 113.8058 - acc: 0.6331 - val_loss: 117.9419 - val_acc: 0.6287\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 117.1198 - acc: 0.6327 - val_loss: 121.0517 - val_acc: 0.6297\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 120.2861 - acc: 0.6334 - val_loss: 115.9661 - val_acc: 0.6303\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 117.5259 - acc: 0.6334 - val_loss: 117.2830 - val_acc: 0.6297\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 355us/step - loss: 117.9620 - acc: 0.6340 - val_loss: 117.0458 - val_acc: 0.6282\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 115.5133 - acc: 0.6324 - val_loss: 115.2642 - val_acc: 0.6272\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 114.3419 - acc: 0.6323 - val_loss: 125.0546 - val_acc: 0.6122\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 116.4045 - acc: 0.6299 - val_loss: 117.6075 - val_acc: 0.6283\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 115.9250 - acc: 0.6341 - val_loss: 115.5489 - val_acc: 0.6300\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 116.3440 - acc: 0.6335 - val_loss: 115.6554 - val_acc: 0.6291\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 358us/step - loss: 115.4450 - acc: 0.6330 - val_loss: 118.2232 - val_acc: 0.6248\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 116.8763 - acc: 0.6328 - val_loss: 120.3680 - val_acc: 0.6260\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 117.4542 - acc: 0.6333 - val_loss: 117.2828 - val_acc: 0.6293\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 117.0684 - acc: 0.6323 - val_loss: 117.6973 - val_acc: 0.6224\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 115.5628 - acc: 0.6310 - val_loss: 117.3027 - val_acc: 0.6279\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 113.5411 - acc: 0.6343 - val_loss: 113.7259 - val_acc: 0.6300\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 113.8265 - acc: 0.6311 - val_loss: 114.8742 - val_acc: 0.6262\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 114.6280 - acc: 0.6286 - val_loss: 119.1963 - val_acc: 0.6277\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 113.5397 - acc: 0.6313 - val_loss: 113.7574 - val_acc: 0.6281\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 113.5366 - acc: 0.6329 - val_loss: 114.2213 - val_acc: 0.6296\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 115.5125 - acc: 0.6336 - val_loss: 119.5494 - val_acc: 0.6298\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 118.3649 - acc: 0.6332 - val_loss: 119.6867 - val_acc: 0.6295\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 116.8943 - acc: 0.6329 - val_loss: 120.7592 - val_acc: 0.6279\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 116.4755 - acc: 0.6328 - val_loss: 118.8206 - val_acc: 0.6251\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 116.5847 - acc: 0.6340 - val_loss: 116.0868 - val_acc: 0.6270\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 114.2524 - acc: 0.6325 - val_loss: 115.8903 - val_acc: 0.6278\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 113.6700 - acc: 0.6326 - val_loss: 115.3613 - val_acc: 0.6288\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 114.0479 - acc: 0.6324 - val_loss: 117.7129 - val_acc: 0.6241\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 115.8817 - acc: 0.6323 - val_loss: 125.7184 - val_acc: 0.6272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 119.5620 - acc: 0.6341 - val_loss: 117.5329 - val_acc: 0.6307\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 116.9617 - acc: 0.6334 - val_loss: 122.8928 - val_acc: 0.6202\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 115.9554 - acc: 0.6311 - val_loss: 118.7147 - val_acc: 0.6289\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 116.8175 - acc: 0.6343 - val_loss: 117.3642 - val_acc: 0.6314\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 114.8965 - acc: 0.6333 - val_loss: 115.7800 - val_acc: 0.6293\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 113.9995 - acc: 0.6343 - val_loss: 116.5570 - val_acc: 0.6277\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 114.4228 - acc: 0.6303 - val_loss: 114.3222 - val_acc: 0.6289\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 114.9958 - acc: 0.6325 - val_loss: 113.4769 - val_acc: 0.6312\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 53.5635 - acc: 0.4324 - val_loss: 50.0936 - val_acc: 0.4390\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 53.5536 - acc: 0.4324 - val_loss: 50.0935 - val_acc: 0.4393\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 53.5438 - acc: 0.4324 - val_loss: 50.0809 - val_acc: 0.4390\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 53.5297 - acc: 0.4325 - val_loss: 50.0713 - val_acc: 0.4394\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 53.5200 - acc: 0.4326 - val_loss: 50.0663 - val_acc: 0.4393\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 53.5109 - acc: 0.4325 - val_loss: 50.0670 - val_acc: 0.4392\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 53.5023 - acc: 0.4327 - val_loss: 50.0872 - val_acc: 0.4395\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 53.4930 - acc: 0.4327 - val_loss: 50.0381 - val_acc: 0.4388\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 53.4804 - acc: 0.4327 - val_loss: 50.0346 - val_acc: 0.4394\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 53.4707 - acc: 0.4324 - val_loss: 50.0160 - val_acc: 0.4397\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 53.4604 - acc: 0.4329 - val_loss: 49.9975 - val_acc: 0.4393\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 53.4490 - acc: 0.4329 - val_loss: 50.0202 - val_acc: 0.4398\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 53.4388 - acc: 0.4328 - val_loss: 49.9817 - val_acc: 0.4389\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 53.4324 - acc: 0.4323 - val_loss: 49.9912 - val_acc: 0.4401\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 53.4225 - acc: 0.4329 - val_loss: 49.9824 - val_acc: 0.4399\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 53.4082 - acc: 0.4331 - val_loss: 49.9559 - val_acc: 0.4391\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 53.4004 - acc: 0.4328 - val_loss: 49.9521 - val_acc: 0.4399\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 53.3883 - acc: 0.4328 - val_loss: 49.9420 - val_acc: 0.4400\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 53.3793 - acc: 0.4328 - val_loss: 49.9248 - val_acc: 0.4400\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 53.3682 - acc: 0.4327 - val_loss: 49.9227 - val_acc: 0.4400\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 53.3586 - acc: 0.4329 - val_loss: 49.9134 - val_acc: 0.4401\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 53.3475 - acc: 0.4327 - val_loss: 49.9041 - val_acc: 0.4400\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 53.3383 - acc: 0.4330 - val_loss: 49.8953 - val_acc: 0.4397\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 53.3270 - acc: 0.4328 - val_loss: 49.8903 - val_acc: 0.4399\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 53.3171 - acc: 0.4329 - val_loss: 49.8809 - val_acc: 0.4402\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 53.3051 - acc: 0.4329 - val_loss: 49.8849 - val_acc: 0.4402\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 53.2950 - acc: 0.4331 - val_loss: 49.8584 - val_acc: 0.4398\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 53.2867 - acc: 0.4331 - val_loss: 49.8734 - val_acc: 0.4399\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 53.2796 - acc: 0.4330 - val_loss: 49.8387 - val_acc: 0.4400\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 53.2648 - acc: 0.4332 - val_loss: 49.8318 - val_acc: 0.4399\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 53.2575 - acc: 0.4333 - val_loss: 49.8226 - val_acc: 0.4400\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 53.2474 - acc: 0.4331 - val_loss: 49.8214 - val_acc: 0.4400\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 53.2355 - acc: 0.4332 - val_loss: 49.8067 - val_acc: 0.4399\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 53.2273 - acc: 0.4333 - val_loss: 49.8016 - val_acc: 0.4398\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 53.2172 - acc: 0.4331 - val_loss: 49.7798 - val_acc: 0.4398\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 53.2030 - acc: 0.4332 - val_loss: 49.7794 - val_acc: 0.4401\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 53.1949 - acc: 0.4330 - val_loss: 49.7621 - val_acc: 0.4399\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 53.1877 - acc: 0.4332 - val_loss: 49.7584 - val_acc: 0.4394\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 53.1740 - acc: 0.4330 - val_loss: 49.7413 - val_acc: 0.4394\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 53.1659 - acc: 0.4331 - val_loss: 49.7232 - val_acc: 0.4397\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 53.1531 - acc: 0.4330 - val_loss: 49.7191 - val_acc: 0.4394\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 53.1444 - acc: 0.4331 - val_loss: 49.7192 - val_acc: 0.4394\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 53.1351 - acc: 0.4333 - val_loss: 49.7013 - val_acc: 0.4394\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 53.1269 - acc: 0.4333 - val_loss: 49.6957 - val_acc: 0.4400\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 53.1150 - acc: 0.4328 - val_loss: 49.6891 - val_acc: 0.4402\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 53.1038 - acc: 0.4333 - val_loss: 49.6775 - val_acc: 0.4399\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 53.0948 - acc: 0.4334 - val_loss: 49.6637 - val_acc: 0.4400\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 53.0837 - acc: 0.4334 - val_loss: 49.6724 - val_acc: 0.4401\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 53.0730 - acc: 0.4332 - val_loss: 49.6436 - val_acc: 0.4394\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 53.0632 - acc: 0.4333 - val_loss: 49.6368 - val_acc: 0.4400\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.5115 - acc: 0.4510 - val_loss: 0.4817 - val_acc: 0.4515\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5101 - acc: 0.4514 - val_loss: 0.4797 - val_acc: 0.4515\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5101 - acc: 0.4513 - val_loss: 0.4797 - val_acc: 0.4519\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5100 - acc: 0.4514 - val_loss: 0.4795 - val_acc: 0.4516\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5103 - acc: 0.4515 - val_loss: 0.4794 - val_acc: 0.4520\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.5094 - acc: 0.4518 - val_loss: 0.4805 - val_acc: 0.4518\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5109 - acc: 0.4513 - val_loss: 0.4796 - val_acc: 0.4519\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5099 - acc: 0.4516 - val_loss: 0.4792 - val_acc: 0.4526\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5092 - acc: 0.4517 - val_loss: 0.4790 - val_acc: 0.4521\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.5090 - acc: 0.4518 - val_loss: 0.4788 - val_acc: 0.4524\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5091 - acc: 0.4518 - val_loss: 0.4790 - val_acc: 0.4523\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.5089 - acc: 0.4518 - val_loss: 0.4785 - val_acc: 0.4526\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5089 - acc: 0.4520 - val_loss: 0.4792 - val_acc: 0.4521\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.5087 - acc: 0.4519 - val_loss: 0.4850 - val_acc: 0.4519\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5095 - acc: 0.4518 - val_loss: 0.4791 - val_acc: 0.4521\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.5084 - acc: 0.4520 - val_loss: 0.4787 - val_acc: 0.4519\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5082 - acc: 0.4520 - val_loss: 0.4829 - val_acc: 0.4531\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5110 - acc: 0.4518 - val_loss: 0.4780 - val_acc: 0.4533\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.5088 - acc: 0.4522 - val_loss: 0.4780 - val_acc: 0.4525\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.5081 - acc: 0.4520 - val_loss: 0.4778 - val_acc: 0.4530\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.5081 - acc: 0.4523 - val_loss: 0.4781 - val_acc: 0.4530\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5075 - acc: 0.4522 - val_loss: 0.4776 - val_acc: 0.4528\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.5075 - acc: 0.4523 - val_loss: 0.4781 - val_acc: 0.4528\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5074 - acc: 0.4525 - val_loss: 0.4777 - val_acc: 0.4528\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5071 - acc: 0.4526 - val_loss: 0.4773 - val_acc: 0.4528\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5069 - acc: 0.4525 - val_loss: 0.4772 - val_acc: 0.4531\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5068 - acc: 0.4524 - val_loss: 0.4772 - val_acc: 0.4531\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5067 - acc: 0.4526 - val_loss: 0.4789 - val_acc: 0.4525\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5075 - acc: 0.4525 - val_loss: 0.4772 - val_acc: 0.4533\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.5072 - acc: 0.4526 - val_loss: 0.4770 - val_acc: 0.4526\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5063 - acc: 0.4528 - val_loss: 0.4766 - val_acc: 0.4528\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5064 - acc: 0.4528 - val_loss: 0.4814 - val_acc: 0.4542\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5069 - acc: 0.4529 - val_loss: 0.4763 - val_acc: 0.4537\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5061 - acc: 0.4527 - val_loss: 0.4764 - val_acc: 0.4530\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.5057 - acc: 0.4531 - val_loss: 0.4765 - val_acc: 0.4537\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.5069 - acc: 0.4529 - val_loss: 0.4762 - val_acc: 0.4538\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.5056 - acc: 0.4530 - val_loss: 0.4769 - val_acc: 0.4533\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.5054 - acc: 0.4531 - val_loss: 0.4757 - val_acc: 0.4543\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.5053 - acc: 0.4532 - val_loss: 0.4756 - val_acc: 0.4533\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5053 - acc: 0.4531 - val_loss: 0.4755 - val_acc: 0.4536\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.5056 - acc: 0.4533 - val_loss: 0.4774 - val_acc: 0.4535\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.5063 - acc: 0.4531 - val_loss: 0.4762 - val_acc: 0.4544\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.5048 - acc: 0.4534 - val_loss: 0.4752 - val_acc: 0.4533\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5045 - acc: 0.4534 - val_loss: 0.4751 - val_acc: 0.4537\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5045 - acc: 0.4534 - val_loss: 0.4751 - val_acc: 0.4538\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5052 - acc: 0.4532 - val_loss: 0.4754 - val_acc: 0.4536\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5064 - acc: 0.4533 - val_loss: 0.4749 - val_acc: 0.4541\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.5044 - acc: 0.4536 - val_loss: 0.4761 - val_acc: 0.4535\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.5042 - acc: 0.4536 - val_loss: 0.4761 - val_acc: 0.4533\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5045 - acc: 0.4536 - val_loss: 0.4744 - val_acc: 0.4539\n",
      "start training round 9\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 31.8061 - acc: 0.6789 - val_loss: 31.2856 - val_acc: 0.6749\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 31.3304 - acc: 0.6786 - val_loss: 30.0906 - val_acc: 0.6698\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 31.2428 - acc: 0.6782 - val_loss: 30.3056 - val_acc: 0.6741\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 30.8814 - acc: 0.6779 - val_loss: 31.5071 - val_acc: 0.6725\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 31.5892 - acc: 0.6789 - val_loss: 29.8905 - val_acc: 0.6762\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 31.3165 - acc: 0.6779 - val_loss: 36.2412 - val_acc: 0.6570\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 30.6364 - acc: 0.6785 - val_loss: 30.7850 - val_acc: 0.6782\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 30.8826 - acc: 0.6762 - val_loss: 33.9219 - val_acc: 0.6608\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 31.9230 - acc: 0.6772 - val_loss: 31.7658 - val_acc: 0.6704\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 376us/step - loss: 31.7854 - acc: 0.6775 - val_loss: 32.2949 - val_acc: 0.6765\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 31.3616 - acc: 0.6787 - val_loss: 30.2767 - val_acc: 0.6750\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 30.3632 - acc: 0.6778 - val_loss: 31.1976 - val_acc: 0.6646\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 32.0336 - acc: 0.6764 - val_loss: 31.0673 - val_acc: 0.6755\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 30.7204 - acc: 0.6777 - val_loss: 33.8225 - val_acc: 0.6573\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 31.8831 - acc: 0.6772 - val_loss: 32.2257 - val_acc: 0.6699\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 30.8533 - acc: 0.6785 - val_loss: 30.4866 - val_acc: 0.6749\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.2458 - acc: 0.6772 - val_loss: 30.2805 - val_acc: 0.6690\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 31.7832 - acc: 0.6759 - val_loss: 30.1560 - val_acc: 0.6773\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 362us/step - loss: 31.2912 - acc: 0.6785 - val_loss: 31.0127 - val_acc: 0.6750\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 31.7037 - acc: 0.6783 - val_loss: 30.9773 - val_acc: 0.6731\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 31.4239 - acc: 0.6770 - val_loss: 33.1513 - val_acc: 0.6714\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 31.2235 - acc: 0.6795 - val_loss: 32.0683 - val_acc: 0.6687\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 355us/step - loss: 31.3746 - acc: 0.6782 - val_loss: 30.6696 - val_acc: 0.6769\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 31.4670 - acc: 0.6780 - val_loss: 31.9587 - val_acc: 0.6688\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 31.0700 - acc: 0.6785 - val_loss: 30.9992 - val_acc: 0.6716\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 31.6712 - acc: 0.6778 - val_loss: 30.9078 - val_acc: 0.6762\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 31.4177 - acc: 0.6786 - val_loss: 31.4674 - val_acc: 0.6703\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 31.0602 - acc: 0.6787 - val_loss: 29.3820 - val_acc: 0.6745\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 31.2484 - acc: 0.6785 - val_loss: 30.7522 - val_acc: 0.6713\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 31.1064 - acc: 0.6779 - val_loss: 30.2642 - val_acc: 0.6724\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 31.3181 - acc: 0.6780 - val_loss: 32.0252 - val_acc: 0.6709\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 30.7830 - acc: 0.6776 - val_loss: 32.5056 - val_acc: 0.6693\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 31.3281 - acc: 0.6781 - val_loss: 30.3981 - val_acc: 0.6756\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 30.6678 - acc: 0.6777 - val_loss: 31.5825 - val_acc: 0.6699\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 31.6562 - acc: 0.6778 - val_loss: 29.9446 - val_acc: 0.6754\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 31.2154 - acc: 0.6775 - val_loss: 31.9143 - val_acc: 0.6686\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 30.8128 - acc: 0.6778 - val_loss: 30.7681 - val_acc: 0.6699\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 31.2788 - acc: 0.6773 - val_loss: 29.8279 - val_acc: 0.6757\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 30.5115 - acc: 0.6768 - val_loss: 29.7958 - val_acc: 0.6734\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 358us/step - loss: 30.8810 - acc: 0.6778 - val_loss: 31.2754 - val_acc: 0.6725\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 31.2507 - acc: 0.6774 - val_loss: 31.1863 - val_acc: 0.6774\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 31.0577 - acc: 0.6778 - val_loss: 31.7444 - val_acc: 0.6696\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 30.5617 - acc: 0.6764 - val_loss: 33.9259 - val_acc: 0.6632\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 31.1008 - acc: 0.6767 - val_loss: 30.8233 - val_acc: 0.6707\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 31.0413 - acc: 0.6785 - val_loss: 30.3703 - val_acc: 0.6752\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 31.2171 - acc: 0.6774 - val_loss: 32.8658 - val_acc: 0.6644\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 31.4037 - acc: 0.6779 - val_loss: 29.8232 - val_acc: 0.6761\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 30.2515 - acc: 0.6774 - val_loss: 30.7873 - val_acc: 0.6787\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 31.1247 - acc: 0.6754 - val_loss: 30.5689 - val_acc: 0.6799\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 30.8928 - acc: 0.6780 - val_loss: 31.2190 - val_acc: 0.6785\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 117.0959 - acc: 0.6332 - val_loss: 117.8748 - val_acc: 0.6304\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 116.3454 - acc: 0.6344 - val_loss: 119.0693 - val_acc: 0.6311\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 116.3491 - acc: 0.6349 - val_loss: 118.7446 - val_acc: 0.6301\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 116.6992 - acc: 0.6336 - val_loss: 115.2707 - val_acc: 0.6293\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 115.5831 - acc: 0.6319 - val_loss: 116.3677 - val_acc: 0.6281\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 115.1880 - acc: 0.6326 - val_loss: 114.8113 - val_acc: 0.6268\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 113.1989 - acc: 0.6314 - val_loss: 115.3507 - val_acc: 0.6256\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 113.3307 - acc: 0.6307 - val_loss: 113.9344 - val_acc: 0.6284\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 349us/step - loss: 112.9436 - acc: 0.6325 - val_loss: 114.7771 - val_acc: 0.6285\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 113.9579 - acc: 0.6321 - val_loss: 118.6880 - val_acc: 0.6298\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 118.5753 - acc: 0.6336 - val_loss: 118.4310 - val_acc: 0.6275\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 114.6410 - acc: 0.6335 - val_loss: 116.7461 - val_acc: 0.6272\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 116.7791 - acc: 0.6316 - val_loss: 117.4005 - val_acc: 0.6284\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 117.0628 - acc: 0.6338 - val_loss: 114.8954 - val_acc: 0.6302\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 113.6476 - acc: 0.6346 - val_loss: 115.5528 - val_acc: 0.6295\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 113.9175 - acc: 0.6342 - val_loss: 115.3173 - val_acc: 0.6283\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 115.9902 - acc: 0.6318 - val_loss: 116.0551 - val_acc: 0.6303\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 377us/step - loss: 116.2936 - acc: 0.6341 - val_loss: 116.1778 - val_acc: 0.6315\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 113.9627 - acc: 0.6335 - val_loss: 114.8260 - val_acc: 0.6301\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 115.6344 - acc: 0.6334 - val_loss: 116.4746 - val_acc: 0.6271\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 115.7455 - acc: 0.6331 - val_loss: 113.6587 - val_acc: 0.6322\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 114.1482 - acc: 0.6312 - val_loss: 112.9388 - val_acc: 0.6285\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 112.8121 - acc: 0.6320 - val_loss: 115.2220 - val_acc: 0.6262\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 115.2568 - acc: 0.6334 - val_loss: 120.8727 - val_acc: 0.6297\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 117.9256 - acc: 0.6345 - val_loss: 125.2729 - val_acc: 0.6200\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 117.7067 - acc: 0.6322 - val_loss: 118.0232 - val_acc: 0.6285\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 114.6772 - acc: 0.6318 - val_loss: 120.5946 - val_acc: 0.6176\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 112.8480 - acc: 0.6332 - val_loss: 114.6314 - val_acc: 0.6315\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 115.4937 - acc: 0.6336 - val_loss: 112.8304 - val_acc: 0.6327\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 113.7605 - acc: 0.6343 - val_loss: 116.6813 - val_acc: 0.6229\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 114.4339 - acc: 0.6319 - val_loss: 114.8934 - val_acc: 0.6294c: 0.6\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 115.8000 - acc: 0.6337 - val_loss: 119.1468 - val_acc: 0.6306\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 117.2721 - acc: 0.6348 - val_loss: 120.0594 - val_acc: 0.6296\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 117.2107 - acc: 0.6345 - val_loss: 118.8229 - val_acc: 0.6278\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 113.9239 - acc: 0.6331 - val_loss: 113.9288 - val_acc: 0.6272\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 112.5115 - acc: 0.6321 - val_loss: 113.1533 - val_acc: 0.6264\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 113.1750 - acc: 0.6332 - val_loss: 113.1135 - val_acc: 0.6303\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 113.8889 - acc: 0.6341 - val_loss: 114.2056 - val_acc: 0.6307\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 114.2370 - acc: 0.6346 - val_loss: 113.3817 - val_acc: 0.6310\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 116.1197 - acc: 0.6333 - val_loss: 116.1706 - val_acc: 0.6302\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 116.3436 - acc: 0.6352 - val_loss: 116.8774 - val_acc: 0.6323\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 116.7423 - acc: 0.6330 - val_loss: 113.7929 - val_acc: 0.6299\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 114.7108 - acc: 0.6323 - val_loss: 116.0559 - val_acc: 0.6281\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 115.0554 - acc: 0.6343 - val_loss: 115.5694 - val_acc: 0.6284\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 115.4511 - acc: 0.6345 - val_loss: 115.5003 - val_acc: 0.6290\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 115.3200 - acc: 0.6349 - val_loss: 116.0484 - val_acc: 0.6300\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 115.0150 - acc: 0.6315 - val_loss: 117.1946 - val_acc: 0.6268\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 114.2255 - acc: 0.6328 - val_loss: 114.9961 - val_acc: 0.6277\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 113.2358 - acc: 0.6338 - val_loss: 112.8940 - val_acc: 0.6289\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 112.4027 - acc: 0.6319 - val_loss: 115.8218 - val_acc: 0.6228\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 53.0555 - acc: 0.4331 - val_loss: 49.6380 - val_acc: 0.4402\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 53.0448 - acc: 0.4330 - val_loss: 49.6169 - val_acc: 0.4398\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 53.0315 - acc: 0.4332 - val_loss: 49.6250 - val_acc: 0.4405\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 53.0267 - acc: 0.4334 - val_loss: 49.6132 - val_acc: 0.4403\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 53.0169 - acc: 0.4332 - val_loss: 49.6111 - val_acc: 0.4397\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 53.0025 - acc: 0.4333 - val_loss: 49.5838 - val_acc: 0.4400\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 52.9940 - acc: 0.4335 - val_loss: 49.5752 - val_acc: 0.4395\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 52.9868 - acc: 0.4330 - val_loss: 49.5668 - val_acc: 0.4407\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 52.9720 - acc: 0.4337 - val_loss: 49.5565 - val_acc: 0.4405\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 52.9629 - acc: 0.4335 - val_loss: 49.5415 - val_acc: 0.4400\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 52.9541 - acc: 0.4335 - val_loss: 49.5413 - val_acc: 0.4402\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 52.9435 - acc: 0.4335 - val_loss: 49.5397 - val_acc: 0.4400\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 52.9367 - acc: 0.4333 - val_loss: 49.5337 - val_acc: 0.4410\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 52.9271 - acc: 0.4334 - val_loss: 49.5136 - val_acc: 0.4407\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 52.9146 - acc: 0.4338 - val_loss: 49.5025 - val_acc: 0.4399\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 52.9051 - acc: 0.4334 - val_loss: 49.5028 - val_acc: 0.4400\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 52.8985 - acc: 0.4336 - val_loss: 49.4798 - val_acc: 0.4407\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 52.8854 - acc: 0.4337 - val_loss: 49.4754 - val_acc: 0.4404\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 52.8752 - acc: 0.4335 - val_loss: 49.4679 - val_acc: 0.4407\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 52.8643 - acc: 0.4336 - val_loss: 49.4546 - val_acc: 0.4399\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 52.8568 - acc: 0.4335 - val_loss: 49.4516 - val_acc: 0.4405\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 52.8482 - acc: 0.4334 - val_loss: 49.4499 - val_acc: 0.4405\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 52.8387 - acc: 0.4336 - val_loss: 49.4268 - val_acc: 0.4408\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 52.8240 - acc: 0.4337 - val_loss: 49.4152 - val_acc: 0.4407\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 52.8189 - acc: 0.4332 - val_loss: 49.4263 - val_acc: 0.4409\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 380us/step - loss: 52.8060 - acc: 0.4337 - val_loss: 49.4089 - val_acc: 0.4404\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 52.7975 - acc: 0.4335 - val_loss: 49.3973 - val_acc: 0.4407\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 52.7878 - acc: 0.4335 - val_loss: 49.3860 - val_acc: 0.4403\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 52.7760 - acc: 0.4337 - val_loss: 49.3768 - val_acc: 0.4401\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 52.7690 - acc: 0.4335 - val_loss: 49.3823 - val_acc: 0.4405\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 52.7565 - acc: 0.4338 - val_loss: 49.3690 - val_acc: 0.4407\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 52.7458 - acc: 0.4336 - val_loss: 49.3534 - val_acc: 0.4408\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 52.7425 - acc: 0.4335 - val_loss: 49.3390 - val_acc: 0.4403\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 52.7264 - acc: 0.4336 - val_loss: 49.3459 - val_acc: 0.4408\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 52.7189 - acc: 0.4336 - val_loss: 49.3295 - val_acc: 0.4408\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 52.7083 - acc: 0.4338 - val_loss: 49.3219 - val_acc: 0.4408\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 52.7054 - acc: 0.4341 - val_loss: 49.3049 - val_acc: 0.4406\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 52.6906 - acc: 0.4336 - val_loss: 49.3000 - val_acc: 0.4410\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 52.6792 - acc: 0.4339 - val_loss: 49.3082 - val_acc: 0.4401\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 52.6728 - acc: 0.4338 - val_loss: 49.2846 - val_acc: 0.4409\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 52.6658 - acc: 0.4335 - val_loss: 49.2872 - val_acc: 0.4410\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 52.6547 - acc: 0.4340 - val_loss: 49.2692 - val_acc: 0.4407\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 52.6463 - acc: 0.4338 - val_loss: 49.2585 - val_acc: 0.4401\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 52.6356 - acc: 0.4337 - val_loss: 49.2517 - val_acc: 0.4398\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 52.6221 - acc: 0.4334 - val_loss: 49.2388 - val_acc: 0.4405\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 52.6149 - acc: 0.4339 - val_loss: 49.2200 - val_acc: 0.4406\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 52.6013 - acc: 0.4338 - val_loss: 49.2214 - val_acc: 0.4407\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 52.5947 - acc: 0.4337 - val_loss: 49.2150 - val_acc: 0.4403\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 52.5878 - acc: 0.4336 - val_loss: 49.2102 - val_acc: 0.4406\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 52.5759 - acc: 0.4337 - val_loss: 49.2016 - val_acc: 0.4405\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5041 - acc: 0.4537 - val_loss: 0.4745 - val_acc: 0.4544\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.5042 - acc: 0.4537 - val_loss: 0.4803 - val_acc: 0.4550\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.5100 - acc: 0.4532 - val_loss: 0.4742 - val_acc: 0.4545\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.5033 - acc: 0.4539 - val_loss: 0.4740 - val_acc: 0.4544\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5035 - acc: 0.4539 - val_loss: 0.4739 - val_acc: 0.4544\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.5030 - acc: 0.4542 - val_loss: 0.4740 - val_acc: 0.4549\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5040 - acc: 0.4541 - val_loss: 0.4737 - val_acc: 0.4545\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5033 - acc: 0.4542 - val_loss: 0.4736 - val_acc: 0.4551\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.5030 - acc: 0.4543 - val_loss: 0.4742 - val_acc: 0.4537\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.5044 - acc: 0.4540 - val_loss: 0.4749 - val_acc: 0.4542\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.5034 - acc: 0.4544 - val_loss: 0.4734 - val_acc: 0.4552\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5025 - acc: 0.4545 - val_loss: 0.4731 - val_acc: 0.4545\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.5023 - acc: 0.4543 - val_loss: 0.4731 - val_acc: 0.4548\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.5033 - acc: 0.4545 - val_loss: 0.4884 - val_acc: 0.4520\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.5051 - acc: 0.4545 - val_loss: 0.4748 - val_acc: 0.4550\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.5023 - acc: 0.4547 - val_loss: 0.4728 - val_acc: 0.4549\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.5021 - acc: 0.4546 - val_loss: 0.4732 - val_acc: 0.4548\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.5016 - acc: 0.4548 - val_loss: 0.4726 - val_acc: 0.4545\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.5025 - acc: 0.4547 - val_loss: 0.4742 - val_acc: 0.4551\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5019 - acc: 0.4545 - val_loss: 0.4729 - val_acc: 0.4548\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.5019 - acc: 0.4548 - val_loss: 0.4725 - val_acc: 0.4545\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.5021 - acc: 0.4549 - val_loss: 0.4727 - val_acc: 0.4551\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5019 - acc: 0.4550 - val_loss: 0.4727 - val_acc: 0.4556\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.5010 - acc: 0.4552 - val_loss: 0.4726 - val_acc: 0.4556\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.5019 - acc: 0.4550 - val_loss: 0.4731 - val_acc: 0.4560\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5007 - acc: 0.4552 - val_loss: 0.4723 - val_acc: 0.4549\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.5015 - acc: 0.4551 - val_loss: 0.4719 - val_acc: 0.4555\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.5005 - acc: 0.4554 - val_loss: 0.4731 - val_acc: 0.4556\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.5010 - acc: 0.4555 - val_loss: 0.4713 - val_acc: 0.4550\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.5004 - acc: 0.4553 - val_loss: 0.4763 - val_acc: 0.4564\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.5005 - acc: 0.4556 - val_loss: 0.4714 - val_acc: 0.4552\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.5001 - acc: 0.4555 - val_loss: 0.4711 - val_acc: 0.4564\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.4998 - acc: 0.4556 - val_loss: 0.4744 - val_acc: 0.4560\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.5010 - acc: 0.4557 - val_loss: 0.4710 - val_acc: 0.4561\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.5005 - acc: 0.4557 - val_loss: 0.4709 - val_acc: 0.4563\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.4995 - acc: 0.4557 - val_loss: 0.4719 - val_acc: 0.4564\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.4999 - acc: 0.4559 - val_loss: 0.4723 - val_acc: 0.4567\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.5003 - acc: 0.4557 - val_loss: 0.4713 - val_acc: 0.4568\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4993 - acc: 0.4560 - val_loss: 0.4703 - val_acc: 0.4560\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4993 - acc: 0.4557 - val_loss: 0.4701 - val_acc: 0.4562\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4989 - acc: 0.4560 - val_loss: 0.4705 - val_acc: 0.4566\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4990 - acc: 0.4562 - val_loss: 0.4704 - val_acc: 0.4566\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4990 - acc: 0.4562 - val_loss: 0.4744 - val_acc: 0.4551\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4995 - acc: 0.4562 - val_loss: 0.4708 - val_acc: 0.4560\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4991 - acc: 0.4562 - val_loss: 0.4724 - val_acc: 0.4577\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4987 - acc: 0.4565 - val_loss: 0.4754 - val_acc: 0.4554\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.4990 - acc: 0.4562 - val_loss: 0.4741 - val_acc: 0.4575\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4983 - acc: 0.4565 - val_loss: 0.4704 - val_acc: 0.4575\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4977 - acc: 0.4566 - val_loss: 0.4692 - val_acc: 0.4568\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4979 - acc: 0.4566 - val_loss: 0.4691 - val_acc: 0.4573\n",
      "start training round 10\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 31.0233 - acc: 0.6772 - val_loss: 30.2220 - val_acc: 0.6791\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 31.1669 - acc: 0.6778 - val_loss: 30.3783 - val_acc: 0.6824\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 31.0340 - acc: 0.6764 - val_loss: 33.9780 - val_acc: 0.6788\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 31.2029 - acc: 0.6783 - val_loss: 29.7846 - val_acc: 0.6799\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 31.2996 - acc: 0.6785 - val_loss: 30.4715 - val_acc: 0.6806\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 30.9459 - acc: 0.6778 - val_loss: 29.9810 - val_acc: 0.6815\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 31.1244 - acc: 0.6776 - val_loss: 29.7224 - val_acc: 0.6817\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 30.8830 - acc: 0.6783 - val_loss: 30.6177 - val_acc: 0.6819\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 30.5339 - acc: 0.6773 - val_loss: 29.1965 - val_acc: 0.6792\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 30.9204 - acc: 0.6770 - val_loss: 32.6161 - val_acc: 0.6660\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 31.3864 - acc: 0.6776 - val_loss: 30.6484 - val_acc: 0.6759\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 31.0425 - acc: 0.6780 - val_loss: 31.7827 - val_acc: 0.6705\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 30.9690 - acc: 0.6781 - val_loss: 30.7166 - val_acc: 0.6750\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.6550 - acc: 0.6782 - val_loss: 30.7642 - val_acc: 0.6735\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 31.2177 - acc: 0.6773 - val_loss: 33.9854 - val_acc: 0.6740\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 31.3926 - acc: 0.6786 - val_loss: 30.0809 - val_acc: 0.6756\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 30.7457 - acc: 0.6781 - val_loss: 29.7513 - val_acc: 0.6763\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 30.4641 - acc: 0.6772 - val_loss: 31.9510 - val_acc: 0.6845\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 31.6203 - acc: 0.6781 - val_loss: 29.0998 - val_acc: 0.6776\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 30.6162 - acc: 0.6773 - val_loss: 31.6427 - val_acc: 0.6827\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 359us/step - loss: 31.2438 - acc: 0.6787 - val_loss: 29.2525 - val_acc: 0.6807\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 30.1399 - acc: 0.6783 - val_loss: 32.8631 - val_acc: 0.6842\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 31.3459 - acc: 0.6790 - val_loss: 30.8361 - val_acc: 0.6780\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 30.3220 - acc: 0.6781 - val_loss: 30.4132 - val_acc: 0.6804\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 30.9677 - acc: 0.6772 - val_loss: 30.3804 - val_acc: 0.6793\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 30.9066 - acc: 0.6780 - val_loss: 30.9284 - val_acc: 0.6793\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 31.0798 - acc: 0.6779 - val_loss: 30.6057 - val_acc: 0.6801\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.6697 - acc: 0.6788 - val_loss: 30.3446 - val_acc: 0.6788\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 30.8800 - acc: 0.6763 - val_loss: 31.2080 - val_acc: 0.6829\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 30.6055 - acc: 0.6787 - val_loss: 29.9381 - val_acc: 0.6809\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 30.6106 - acc: 0.6767 - val_loss: 30.9470 - val_acc: 0.6810\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 30.5978 - acc: 0.6786 - val_loss: 29.4839 - val_acc: 0.6776\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.6500 - acc: 0.6757 - val_loss: 30.5237 - val_acc: 0.6686\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 30.8630 - acc: 0.6783 - val_loss: 30.8746 - val_acc: 0.6762\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 30.9965 - acc: 0.6770 - val_loss: 30.4859 - val_acc: 0.6722\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 31.1285 - acc: 0.6788 - val_loss: 29.4123 - val_acc: 0.6762\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 30.5108 - acc: 0.6787 - val_loss: 32.0662 - val_acc: 0.6585\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 30.8041 - acc: 0.6780 - val_loss: 31.3214 - val_acc: 0.6755\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 30.4294 - acc: 0.6779 - val_loss: 32.7174 - val_acc: 0.6632\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 30.6827 - acc: 0.6776 - val_loss: 33.5733 - val_acc: 0.6717\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 31.0008 - acc: 0.6777 - val_loss: 32.5601 - val_acc: 0.6745\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 30.8360 - acc: 0.6790 - val_loss: 30.2546 - val_acc: 0.6750\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 389us/step - loss: 30.2054 - acc: 0.6787 - val_loss: 31.3583 - val_acc: 0.6717\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 31.2880 - acc: 0.6766 - val_loss: 33.5796 - val_acc: 0.6551\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 30.7050 - acc: 0.6776 - val_loss: 30.9339 - val_acc: 0.6722\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 30.2401 - acc: 0.6781 - val_loss: 29.5336 - val_acc: 0.6818\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 31.1669 - acc: 0.6780 - val_loss: 29.9194 - val_acc: 0.6804\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 30.1118 - acc: 0.6778 - val_loss: 30.3411 - val_acc: 0.6805\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 31.1861 - acc: 0.6782 - val_loss: 30.6848 - val_acc: 0.6758\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 31.1256 - acc: 0.6768 - val_loss: 30.3631 - val_acc: 0.6821\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 113.3443 - acc: 0.6322 - val_loss: 112.8846 - val_acc: 0.6325\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 115.5188 - acc: 0.6349 - val_loss: 118.8496 - val_acc: 0.6292\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 116.3413 - acc: 0.6356 - val_loss: 117.0314 - val_acc: 0.6273\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 114.7379 - acc: 0.6313 - val_loss: 113.4739 - val_acc: 0.6311\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 113.4331 - acc: 0.6335 - val_loss: 112.9328 - val_acc: 0.6301\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 113.5324 - acc: 0.6352 - val_loss: 120.4905 - val_acc: 0.6301\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 117.5355 - acc: 0.6352 - val_loss: 113.1691 - val_acc: 0.6319\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 115.3154 - acc: 0.6352 - val_loss: 119.5568 - val_acc: 0.6292\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 113.8657 - acc: 0.6353 - val_loss: 114.6960 - val_acc: 0.6311\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 114.7268 - acc: 0.6324 - val_loss: 118.3193 - val_acc: 0.6249\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 114.8937 - acc: 0.6343 - val_loss: 119.9118 - val_acc: 0.6283\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 116.2697 - acc: 0.6337 - val_loss: 112.9081 - val_acc: 0.6322\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 344us/step - loss: 112.8652 - acc: 0.6329 - val_loss: 112.6793 - val_acc: 0.6285\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 112.8314 - acc: 0.6315 - val_loss: 115.0249 - val_acc: 0.6290\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 114.6351 - acc: 0.6346 - val_loss: 113.4301 - val_acc: 0.6312\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 115.0248 - acc: 0.6339 - val_loss: 118.2954 - val_acc: 0.6269\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 115.6162 - acc: 0.6349 - val_loss: 116.0021 - val_acc: 0.6282\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 113.2122 - acc: 0.6317 - val_loss: 115.1926 - val_acc: 0.6276\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 112.7897 - acc: 0.6331 - val_loss: 113.8905 - val_acc: 0.6302\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 113.6506 - acc: 0.6340 - val_loss: 119.9058 - val_acc: 0.6259\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 115.2148 - acc: 0.6337 - val_loss: 117.9982 - val_acc: 0.6328\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 115.4117 - acc: 0.6353 - val_loss: 113.0834 - val_acc: 0.6315\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 114.3930 - acc: 0.6349 - val_loss: 118.3223 - val_acc: 0.6286\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 115.6949 - acc: 0.6330 - val_loss: 115.0980 - val_acc: 0.6298\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 112.9679 - acc: 0.6320 - val_loss: 113.6734 - val_acc: 0.6294\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 113.2054 - acc: 0.6306 - val_loss: 114.2362 - val_acc: 0.6276\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 113.2157 - acc: 0.6353 - val_loss: 116.9424 - val_acc: 0.6295\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 115.8992 - acc: 0.6344 - val_loss: 115.9543 - val_acc: 0.6315\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 114.6420 - acc: 0.6359 - val_loss: 122.9534 - val_acc: 0.6293\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 115.4392 - acc: 0.6348 - val_loss: 124.7897 - val_acc: 0.6297\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 116.5999 - acc: 0.6359 - val_loss: 116.2429 - val_acc: 0.6308\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 113.5812 - acc: 0.6341 - val_loss: 119.6725 - val_acc: 0.6166\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 113.0780 - acc: 0.6309 - val_loss: 115.2826 - val_acc: 0.6291\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 113.8660 - acc: 0.6338 - val_loss: 116.8683 - val_acc: 0.6311\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 114.7644 - acc: 0.6359 - val_loss: 119.8127 - val_acc: 0.6328\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 114.6918 - acc: 0.6353 - val_loss: 119.1920 - val_acc: 0.6267\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 114.2825 - acc: 0.6352 - val_loss: 114.2815 - val_acc: 0.6315\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 113.4279 - acc: 0.6301 - val_loss: 120.7024 - val_acc: 0.6158\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 112.8975 - acc: 0.6321 - val_loss: 114.7253 - val_acc: 0.6266\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 113.4492 - acc: 0.6356 - val_loss: 116.5579 - val_acc: 0.6329\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 115.9086 - acc: 0.6347 - val_loss: 117.6547 - val_acc: 0.6298\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 114.1623 - acc: 0.6357 - val_loss: 121.5021 - val_acc: 0.6295\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 114.0008 - acc: 0.6356 - val_loss: 116.7228 - val_acc: 0.6273\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 113.2869 - acc: 0.6333 - val_loss: 115.2520 - val_acc: 0.6291\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 114.3176 - acc: 0.6308 - val_loss: 115.4699 - val_acc: 0.6291\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 114.6937 - acc: 0.6364 - val_loss: 115.6643 - val_acc: 0.6318\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 113.7143 - acc: 0.6337 - val_loss: 121.4297 - val_acc: 0.6181\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 112.3186 - acc: 0.6326 - val_loss: 114.7427 - val_acc: 0.6295\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 112.3817 - acc: 0.6333 - val_loss: 111.6126 - val_acc: 0.6309\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 111.1458 - acc: 0.6356 - val_loss: 114.8661 - val_acc: 0.6273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 52.5685 - acc: 0.4336 - val_loss: 49.1800 - val_acc: 0.4409\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 52.5599 - acc: 0.4336 - val_loss: 49.1731 - val_acc: 0.4405\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 52.5483 - acc: 0.4335 - val_loss: 49.1854 - val_acc: 0.4405\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 52.5374 - acc: 0.4337 - val_loss: 49.1662 - val_acc: 0.4409\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 52.5309 - acc: 0.4336 - val_loss: 49.1580 - val_acc: 0.4404\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 52.5175 - acc: 0.4334 - val_loss: 49.1517 - val_acc: 0.4408\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 52.5148 - acc: 0.4339 - val_loss: 49.1353 - val_acc: 0.4415\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 52.4999 - acc: 0.4337 - val_loss: 49.1396 - val_acc: 0.4415\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 52.4914 - acc: 0.4337 - val_loss: 49.1363 - val_acc: 0.4410\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 52.4804 - acc: 0.4337 - val_loss: 49.1119 - val_acc: 0.4407\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 52.4716 - acc: 0.4337 - val_loss: 49.1086 - val_acc: 0.4407\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 52.4604 - acc: 0.4336 - val_loss: 49.1315 - val_acc: 0.4406\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 52.4598 - acc: 0.4339 - val_loss: 49.0946 - val_acc: 0.4410\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 52.4473 - acc: 0.4338 - val_loss: 49.0769 - val_acc: 0.4405\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 52.4362 - acc: 0.4338 - val_loss: 49.0803 - val_acc: 0.4413\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 52.4236 - acc: 0.4338 - val_loss: 49.0651 - val_acc: 0.4408\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 52.4212 - acc: 0.4339 - val_loss: 49.0539 - val_acc: 0.4405\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 52.4073 - acc: 0.4336 - val_loss: 49.0472 - val_acc: 0.4407\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 52.3994 - acc: 0.4338 - val_loss: 49.0318 - val_acc: 0.4406\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 52.3877 - acc: 0.4338 - val_loss: 49.0397 - val_acc: 0.4408\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 52.3826 - acc: 0.4338 - val_loss: 49.0375 - val_acc: 0.4411\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 52.3705 - acc: 0.4337 - val_loss: 49.0051 - val_acc: 0.4414\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 52.3613 - acc: 0.4339 - val_loss: 48.9943 - val_acc: 0.4409\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 52.3487 - acc: 0.4340 - val_loss: 48.9971 - val_acc: 0.4408\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 52.3428 - acc: 0.4337 - val_loss: 48.9958 - val_acc: 0.4407\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 52.3341 - acc: 0.4337 - val_loss: 48.9779 - val_acc: 0.4415\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 52.3268 - acc: 0.4342 - val_loss: 48.9644 - val_acc: 0.4406\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 52.3220 - acc: 0.4339 - val_loss: 48.9527 - val_acc: 0.4414\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 52.3038 - acc: 0.4340 - val_loss: 48.9491 - val_acc: 0.4417\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 52.2967 - acc: 0.4343 - val_loss: 48.9412 - val_acc: 0.4411\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 52.2858 - acc: 0.4339 - val_loss: 48.9467 - val_acc: 0.4415\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 52.2775 - acc: 0.4342 - val_loss: 48.9279 - val_acc: 0.4409\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 52.2739 - acc: 0.4341 - val_loss: 48.9158 - val_acc: 0.4416\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 52.2628 - acc: 0.4343 - val_loss: 48.9107 - val_acc: 0.4404\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 52.2509 - acc: 0.4334 - val_loss: 48.9059 - val_acc: 0.4415\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 52.2417 - acc: 0.4344 - val_loss: 48.8974 - val_acc: 0.4415\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 52.2287 - acc: 0.4343 - val_loss: 48.8879 - val_acc: 0.4414\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 52.2260 - acc: 0.4341 - val_loss: 48.8754 - val_acc: 0.4412\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 52.2116 - acc: 0.4344 - val_loss: 48.8767 - val_acc: 0.4417\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 52.2071 - acc: 0.4345 - val_loss: 48.8625 - val_acc: 0.4418\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 52.1939 - acc: 0.4342 - val_loss: 48.8627 - val_acc: 0.4422\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 52.1885 - acc: 0.4343 - val_loss: 48.8528 - val_acc: 0.4417\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 52.1771 - acc: 0.4345 - val_loss: 48.8383 - val_acc: 0.4420\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 52.1719 - acc: 0.4345 - val_loss: 48.8282 - val_acc: 0.4418\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 52.1613 - acc: 0.4346 - val_loss: 48.8204 - val_acc: 0.4419\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 52.1527 - acc: 0.4344 - val_loss: 48.8100 - val_acc: 0.4427\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 52.1381 - acc: 0.4348 - val_loss: 48.7943 - val_acc: 0.4421\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 52.1337 - acc: 0.4344 - val_loss: 48.8081 - val_acc: 0.4424\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 52.1229 - acc: 0.4349 - val_loss: 48.7835 - val_acc: 0.4419\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 52.1124 - acc: 0.4348 - val_loss: 48.7765 - val_acc: 0.4416\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4975 - acc: 0.4567 - val_loss: 0.4689 - val_acc: 0.4572\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4975 - acc: 0.4567 - val_loss: 0.4688 - val_acc: 0.4569\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4973 - acc: 0.4568 - val_loss: 0.4688 - val_acc: 0.4576\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.4979 - acc: 0.4568 - val_loss: 0.4692 - val_acc: 0.4572\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4978 - acc: 0.4569 - val_loss: 0.4714 - val_acc: 0.4582\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4976 - acc: 0.4569 - val_loss: 0.4686 - val_acc: 0.4571\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.4970 - acc: 0.4570 - val_loss: 0.4685 - val_acc: 0.4573\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4975 - acc: 0.4571 - val_loss: 0.4731 - val_acc: 0.4582\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.4976 - acc: 0.4571 - val_loss: 0.4689 - val_acc: 0.4569\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4965 - acc: 0.4572 - val_loss: 0.4691 - val_acc: 0.4579\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4969 - acc: 0.4573 - val_loss: 0.4679 - val_acc: 0.4573\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4971 - acc: 0.4572 - val_loss: 0.4680 - val_acc: 0.4576\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4965 - acc: 0.4574 - val_loss: 0.4686 - val_acc: 0.4586\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4968 - acc: 0.4572 - val_loss: 0.4676 - val_acc: 0.4578\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4962 - acc: 0.4576 - val_loss: 0.4687 - val_acc: 0.4573\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.4961 - acc: 0.4574 - val_loss: 0.4706 - val_acc: 0.4570\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4967 - acc: 0.4577 - val_loss: 0.4674 - val_acc: 0.4576\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.4955 - acc: 0.4576 - val_loss: 0.4690 - val_acc: 0.4573\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4969 - acc: 0.4578 - val_loss: 0.4679 - val_acc: 0.4583\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.4955 - acc: 0.4578 - val_loss: 0.4673 - val_acc: 0.4581\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4955 - acc: 0.4576 - val_loss: 0.4672 - val_acc: 0.4587\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4950 - acc: 0.4581 - val_loss: 0.4669 - val_acc: 0.4583\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.4958 - acc: 0.4578 - val_loss: 0.4675 - val_acc: 0.4577\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4948 - acc: 0.4580 - val_loss: 0.4668 - val_acc: 0.4580\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4948 - acc: 0.4581 - val_loss: 0.4665 - val_acc: 0.4585\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4950 - acc: 0.4582 - val_loss: 0.4670 - val_acc: 0.4591\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4947 - acc: 0.4582 - val_loss: 0.4664 - val_acc: 0.4585\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4947 - acc: 0.4581 - val_loss: 0.4673 - val_acc: 0.4591\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4947 - acc: 0.4583 - val_loss: 0.4661 - val_acc: 0.4583\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.4946 - acc: 0.4584 - val_loss: 0.4702 - val_acc: 0.4577\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4960 - acc: 0.4582 - val_loss: 0.4661 - val_acc: 0.4588\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4939 - acc: 0.4585 - val_loss: 0.4668 - val_acc: 0.4591\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4946 - acc: 0.4585 - val_loss: 0.4669 - val_acc: 0.4590\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4947 - acc: 0.4587 - val_loss: 0.4663 - val_acc: 0.4582\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4938 - acc: 0.4587 - val_loss: 0.4658 - val_acc: 0.4590\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4933 - acc: 0.4587 - val_loss: 0.4654 - val_acc: 0.4589\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.4933 - acc: 0.4588 - val_loss: 0.4658 - val_acc: 0.4594\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4934 - acc: 0.4589 - val_loss: 0.4653 - val_acc: 0.4590\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4933 - acc: 0.4589 - val_loss: 0.4679 - val_acc: 0.4583\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4940 - acc: 0.4588 - val_loss: 0.4716 - val_acc: 0.4574\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4936 - acc: 0.4589 - val_loss: 0.4661 - val_acc: 0.4588\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4933 - acc: 0.4591 - val_loss: 0.4655 - val_acc: 0.4586\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4929 - acc: 0.4590 - val_loss: 0.4655 - val_acc: 0.4594\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4925 - acc: 0.4592 - val_loss: 0.4649 - val_acc: 0.4593\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.4922 - acc: 0.4593 - val_loss: 0.4656 - val_acc: 0.4589\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4924 - acc: 0.4592 - val_loss: 0.4651 - val_acc: 0.4594\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4922 - acc: 0.4593 - val_loss: 0.4645 - val_acc: 0.4591\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4949 - acc: 0.4592 - val_loss: 0.4680 - val_acc: 0.4582\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.4924 - acc: 0.4593 - val_loss: 0.4643 - val_acc: 0.4594\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.4919 - acc: 0.4595 - val_loss: 0.4641 - val_acc: 0.4597\n",
      "start training round 11\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 30.6354 - acc: 0.6786 - val_loss: 30.2271 - val_acc: 0.6803\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 30.6201 - acc: 0.6795 - val_loss: 30.2358 - val_acc: 0.6819\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 31.0807 - acc: 0.6776 - val_loss: 32.3699 - val_acc: 0.6854\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 30.8368 - acc: 0.6786 - val_loss: 29.6625 - val_acc: 0.6784\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 30.4172 - acc: 0.6787 - val_loss: 30.6430 - val_acc: 0.6833\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 30.1061 - acc: 0.6780 - val_loss: 29.9632 - val_acc: 0.6749\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 30.6414 - acc: 0.6769 - val_loss: 30.8891 - val_acc: 0.6757\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 31.1390 - acc: 0.6766 - val_loss: 30.4077 - val_acc: 0.6795\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 30.8855 - acc: 0.6797 - val_loss: 30.1850 - val_acc: 0.6801\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 30.2199 - acc: 0.6787 - val_loss: 30.4431 - val_acc: 0.6813\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 30.6115 - acc: 0.6777 - val_loss: 30.6594 - val_acc: 0.6821\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 30.8150 - acc: 0.6786 - val_loss: 29.0000 - val_acc: 0.6749\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 30.1531 - acc: 0.6772 - val_loss: 33.9085 - val_acc: 0.6646\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 31.0376 - acc: 0.6775 - val_loss: 32.2252 - val_acc: 0.6705\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.2903 - acc: 0.6790 - val_loss: 30.4444 - val_acc: 0.6797\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 30.9232 - acc: 0.6767 - val_loss: 29.8814 - val_acc: 0.6809\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 30.2371 - acc: 0.6786 - val_loss: 29.6090 - val_acc: 0.6771\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.9942 - acc: 0.6780 - val_loss: 31.2315 - val_acc: 0.6784\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 29.8221 - acc: 0.6781 - val_loss: 30.7509 - val_acc: 0.6696\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 31.1987 - acc: 0.6758 - val_loss: 29.7542 - val_acc: 0.6716\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 30.8617 - acc: 0.6780 - val_loss: 30.2643 - val_acc: 0.6740\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 30.6369 - acc: 0.6783 - val_loss: 32.9425 - val_acc: 0.6634\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 30.1367 - acc: 0.6776 - val_loss: 28.6579 - val_acc: 0.6745\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 30.4295 - acc: 0.6779 - val_loss: 30.4638 - val_acc: 0.6750\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 30.6248 - acc: 0.6776 - val_loss: 31.0929 - val_acc: 0.6715\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 30.3343 - acc: 0.6791 - val_loss: 30.5291 - val_acc: 0.6701\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 30.2592 - acc: 0.6785 - val_loss: 29.6661 - val_acc: 0.6749\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 30.7583 - acc: 0.6773 - val_loss: 29.9364 - val_acc: 0.6807\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.3833 - acc: 0.6782 - val_loss: 30.9748 - val_acc: 0.6823\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 31.0126 - acc: 0.6781 - val_loss: 30.0672 - val_acc: 0.6767\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 30.3286 - acc: 0.6779 - val_loss: 30.2566 - val_acc: 0.6782\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.6379 - acc: 0.6779 - val_loss: 30.9659 - val_acc: 0.6807\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 30.4322 - acc: 0.6786 - val_loss: 30.2398 - val_acc: 0.6805\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 30.4726 - acc: 0.6786 - val_loss: 30.2126 - val_acc: 0.6813\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.4558 - acc: 0.6786 - val_loss: 29.8623 - val_acc: 0.6792\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 30.4038 - acc: 0.6778 - val_loss: 30.2118 - val_acc: 0.6812\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 30.4075 - acc: 0.6777 - val_loss: 31.2691 - val_acc: 0.6796\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 30.7656 - acc: 0.6785 - val_loss: 30.2356 - val_acc: 0.6820\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 30.0140 - acc: 0.6793 - val_loss: 32.1816 - val_acc: 0.6838\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.5070 - acc: 0.6781 - val_loss: 29.3062 - val_acc: 0.6777\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 30.1261 - acc: 0.6773 - val_loss: 32.3712 - val_acc: 0.6649\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 30.4731 - acc: 0.6779 - val_loss: 30.9376 - val_acc: 0.6752\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 30.1923 - acc: 0.6789 - val_loss: 30.7336 - val_acc: 0.6727\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 30.4711 - acc: 0.6772 - val_loss: 31.4176 - val_acc: 0.6677\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 30.3644 - acc: 0.6781 - val_loss: 30.0354 - val_acc: 0.6710\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 30.3005 - acc: 0.6784 - val_loss: 29.7701 - val_acc: 0.6692\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 30.1279 - acc: 0.6781 - val_loss: 30.1059 - val_acc: 0.6739\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 30.6065 - acc: 0.6784 - val_loss: 30.6197 - val_acc: 0.6679\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 29.9485 - acc: 0.6790 - val_loss: 31.6184 - val_acc: 0.6689\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 30.6702 - acc: 0.6790 - val_loss: 29.8509 - val_acc: 0.6756\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 114.0665 - acc: 0.6328 - val_loss: 119.1069 - val_acc: 0.6296\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 115.6651 - acc: 0.6358 - val_loss: 113.8991 - val_acc: 0.6319\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 112.2026 - acc: 0.6323 - val_loss: 112.4067 - val_acc: 0.6295\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 112.1195 - acc: 0.6334 - val_loss: 111.5094 - val_acc: 0.6311\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 111.5095 - acc: 0.6349 - val_loss: 112.1782 - val_acc: 0.6316\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 113.7880 - acc: 0.6362 - val_loss: 118.8667 - val_acc: 0.6322\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 116.8629 - acc: 0.6361 - val_loss: 116.5554 - val_acc: 0.6319\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 115.6346 - acc: 0.6353 - val_loss: 113.9726 - val_acc: 0.6303\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 111.1348 - acc: 0.6361 - val_loss: 112.6559 - val_acc: 0.6294\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 112.6577 - acc: 0.6286 - val_loss: 113.0903 - val_acc: 0.6301\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 112.3325 - acc: 0.6338 - val_loss: 112.8178 - val_acc: 0.6309\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 113.7193 - acc: 0.6363 - val_loss: 118.3701 - val_acc: 0.6300\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 116.1859 - acc: 0.6356 - val_loss: 114.8290 - val_acc: 0.6329\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 114.7566 - acc: 0.6364 - val_loss: 115.5276 - val_acc: 0.6312\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 114.0907 - acc: 0.6363 - val_loss: 112.8266 - val_acc: 0.6332\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 113.0656 - acc: 0.6349 - val_loss: 115.5825 - val_acc: 0.6253\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 362us/step - loss: 114.0672 - acc: 0.6335 - val_loss: 113.1128 - val_acc: 0.6311\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 114.1595 - acc: 0.6355 - val_loss: 112.6728 - val_acc: 0.6311\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 111.5068 - acc: 0.6331 - val_loss: 119.8209 - val_acc: 0.6132\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 114.1078 - acc: 0.6328 - val_loss: 114.9666 - val_acc: 0.6315\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 115.1329 - acc: 0.6354 - val_loss: 113.3973 - val_acc: 0.6328\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 113.4188 - acc: 0.6343 - val_loss: 115.4513 - val_acc: 0.6304\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 114.2033 - acc: 0.6367 - val_loss: 114.9482 - val_acc: 0.6309\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 114.1327 - acc: 0.6327 - val_loss: 113.6059 - val_acc: 0.6293\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 112.6336 - acc: 0.6358 - val_loss: 116.1932 - val_acc: 0.6290\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 386us/step - loss: 113.6875 - acc: 0.6356 - val_loss: 114.5191 - val_acc: 0.6331\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 113.3743 - acc: 0.6346 - val_loss: 115.4072 - val_acc: 0.6289\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 114.4302 - acc: 0.6353 - val_loss: 114.9562 - val_acc: 0.6317\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 114.2123 - acc: 0.6336 - val_loss: 112.7072 - val_acc: 0.6325\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 111.6102 - acc: 0.6360 - val_loss: 117.1210 - val_acc: 0.6260\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 112.5001 - acc: 0.6336 - val_loss: 119.7478 - val_acc: 0.6272\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 112.8513 - acc: 0.6314 - val_loss: 113.3211 - val_acc: 0.6282\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 113.0648 - acc: 0.6355 - val_loss: 113.7289 - val_acc: 0.6320\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 114.9065 - acc: 0.6359 - val_loss: 116.9977 - val_acc: 0.6316\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 114.4868 - acc: 0.6344 - val_loss: 115.1152 - val_acc: 0.6310\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 111.5222 - acc: 0.6348 - val_loss: 111.8461 - val_acc: 0.6325\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 112.8924 - acc: 0.6334 - val_loss: 110.9826 - val_acc: 0.6327\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 110.9309 - acc: 0.6359 - val_loss: 113.6260 - val_acc: 0.6315\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 114.8133 - acc: 0.6349 - val_loss: 113.8372 - val_acc: 0.6298\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 114.1610 - acc: 0.6324 - val_loss: 114.1267 - val_acc: 0.6314\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 114.8245 - acc: 0.6365 - val_loss: 113.6413 - val_acc: 0.6329\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 113.9570 - acc: 0.6360 - val_loss: 116.7710 - val_acc: 0.6310\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 114.1724 - acc: 0.6358 - val_loss: 123.0241 - val_acc: 0.6254\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 111.9591 - acc: 0.6346 - val_loss: 114.7341 - val_acc: 0.6301\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 111.8598 - acc: 0.6344 - val_loss: 114.4041 - val_acc: 0.6289\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 112.0379 - acc: 0.6317 - val_loss: 112.3420 - val_acc: 0.6289\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 111.1801 - acc: 0.6318 - val_loss: 113.6927 - val_acc: 0.6264\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 114.3531 - acc: 0.6353 - val_loss: 111.5381 - val_acc: 0.6329\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 112.4956 - acc: 0.6360 - val_loss: 112.4399 - val_acc: 0.6306\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 110.7218 - acc: 0.6358 - val_loss: 111.3348 - val_acc: 0.6320\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 52.0990 - acc: 0.4342 - val_loss: 48.8083 - val_acc: 0.4431\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 52.1025 - acc: 0.4349 - val_loss: 48.7663 - val_acc: 0.4420\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 52.0866 - acc: 0.4348 - val_loss: 48.7682 - val_acc: 0.4421\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 52.0806 - acc: 0.4347 - val_loss: 48.7414 - val_acc: 0.4419\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 52.0700 - acc: 0.4347 - val_loss: 48.7281 - val_acc: 0.4421\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 52.0629 - acc: 0.4349 - val_loss: 48.7306 - val_acc: 0.4423\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 52.0483 - acc: 0.4349 - val_loss: 48.7361 - val_acc: 0.4422\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 52.0446 - acc: 0.4350 - val_loss: 48.7369 - val_acc: 0.4411\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 52.0334 - acc: 0.4345 - val_loss: 48.7057 - val_acc: 0.4419\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 52.0280 - acc: 0.4352 - val_loss: 48.6900 - val_acc: 0.4419\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 52.0123 - acc: 0.4349 - val_loss: 48.6912 - val_acc: 0.4420\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 52.0085 - acc: 0.4347 - val_loss: 48.7099 - val_acc: 0.4430\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 51.9987 - acc: 0.4353 - val_loss: 48.6851 - val_acc: 0.4424\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.9846 - acc: 0.4351 - val_loss: 48.6642 - val_acc: 0.4418\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 51.9770 - acc: 0.4349 - val_loss: 48.6558 - val_acc: 0.4420\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 51.9691 - acc: 0.4352 - val_loss: 48.6576 - val_acc: 0.4411\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 51.9631 - acc: 0.4348 - val_loss: 48.6491 - val_acc: 0.4433\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 51.9519 - acc: 0.4352 - val_loss: 48.6352 - val_acc: 0.4426\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.9409 - acc: 0.4351 - val_loss: 48.6284 - val_acc: 0.4426\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 51.9297 - acc: 0.4353 - val_loss: 48.6174 - val_acc: 0.4427\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 51.9226 - acc: 0.4356 - val_loss: 48.6198 - val_acc: 0.4419\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 51.9195 - acc: 0.4349 - val_loss: 48.6112 - val_acc: 0.4426\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 51.9038 - acc: 0.4354 - val_loss: 48.5953 - val_acc: 0.4429\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 51.8980 - acc: 0.4352 - val_loss: 48.5894 - val_acc: 0.4420\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 51.8879 - acc: 0.4354 - val_loss: 48.5775 - val_acc: 0.4424\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.8833 - acc: 0.4350 - val_loss: 48.5651 - val_acc: 0.4430\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 51.8705 - acc: 0.4356 - val_loss: 48.5519 - val_acc: 0.4424\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 51.8657 - acc: 0.4351 - val_loss: 48.5442 - val_acc: 0.4433\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 51.8496 - acc: 0.4355 - val_loss: 48.5441 - val_acc: 0.4433\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 51.8455 - acc: 0.4353 - val_loss: 48.5399 - val_acc: 0.4436\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 51.8358 - acc: 0.4355 - val_loss: 48.5188 - val_acc: 0.4424\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 51.8223 - acc: 0.4351 - val_loss: 48.5355 - val_acc: 0.4435\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.8209 - acc: 0.4354 - val_loss: 48.5381 - val_acc: 0.4428\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.8076 - acc: 0.4356 - val_loss: 48.5113 - val_acc: 0.4425\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 51.7958 - acc: 0.4352 - val_loss: 48.4951 - val_acc: 0.4434\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 51.7951 - acc: 0.4357 - val_loss: 48.4778 - val_acc: 0.4428\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 51.7802 - acc: 0.4355 - val_loss: 48.4820 - val_acc: 0.4439\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 51.7695 - acc: 0.4357 - val_loss: 48.4663 - val_acc: 0.4433\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 51.7647 - acc: 0.4353 - val_loss: 48.4593 - val_acc: 0.4439\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 51.7515 - acc: 0.4357 - val_loss: 48.4534 - val_acc: 0.4437\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 51.7385 - acc: 0.4360 - val_loss: 48.4534 - val_acc: 0.4431\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.7363 - acc: 0.4359 - val_loss: 48.4429 - val_acc: 0.4424\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 51.7277 - acc: 0.4357 - val_loss: 48.4307 - val_acc: 0.4432\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 51.7174 - acc: 0.4360 - val_loss: 48.4204 - val_acc: 0.4430\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 51.7098 - acc: 0.4355 - val_loss: 48.4175 - val_acc: 0.4442\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 51.7020 - acc: 0.4360 - val_loss: 48.4049 - val_acc: 0.4434\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 51.6940 - acc: 0.4358 - val_loss: 48.4074 - val_acc: 0.4435\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 51.6827 - acc: 0.4361 - val_loss: 48.3842 - val_acc: 0.4433\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 51.6681 - acc: 0.4358 - val_loss: 48.4234 - val_acc: 0.4440\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 51.6600 - acc: 0.4360 - val_loss: 48.3731 - val_acc: 0.4441\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4921 - acc: 0.4594 - val_loss: 0.4645 - val_acc: 0.4588\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.4925 - acc: 0.4596 - val_loss: 0.4686 - val_acc: 0.4580\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4930 - acc: 0.4596 - val_loss: 0.4645 - val_acc: 0.4603\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4917 - acc: 0.4597 - val_loss: 0.4653 - val_acc: 0.4588\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4920 - acc: 0.4596 - val_loss: 0.4635 - val_acc: 0.4597\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4916 - acc: 0.4597 - val_loss: 0.4651 - val_acc: 0.4607\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4911 - acc: 0.4597 - val_loss: 0.4657 - val_acc: 0.4588\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4910 - acc: 0.4598 - val_loss: 0.4641 - val_acc: 0.4605\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.4908 - acc: 0.4598 - val_loss: 0.4637 - val_acc: 0.4599\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4911 - acc: 0.4599 - val_loss: 0.4630 - val_acc: 0.4598\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.4908 - acc: 0.4598 - val_loss: 0.4629 - val_acc: 0.4602\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4906 - acc: 0.4599 - val_loss: 0.4669 - val_acc: 0.4609\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.4910 - acc: 0.4600 - val_loss: 0.4629 - val_acc: 0.4602\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4900 - acc: 0.4601 - val_loss: 0.4633 - val_acc: 0.4596\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.4901 - acc: 0.4601 - val_loss: 0.4625 - val_acc: 0.4599\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.4904 - acc: 0.4600 - val_loss: 0.4628 - val_acc: 0.4606\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4903 - acc: 0.4601 - val_loss: 0.4626 - val_acc: 0.4606\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4898 - acc: 0.4602 - val_loss: 0.4627 - val_acc: 0.4605\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 409us/step - loss: 0.4902 - acc: 0.4601 - val_loss: 0.4623 - val_acc: 0.4609\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.4898 - acc: 0.4604 - val_loss: 0.4624 - val_acc: 0.4608\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4894 - acc: 0.4603 - val_loss: 0.4621 - val_acc: 0.4604\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4890 - acc: 0.4604 - val_loss: 0.4620 - val_acc: 0.4606\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4892 - acc: 0.4603 - val_loss: 0.4627 - val_acc: 0.4609\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4895 - acc: 0.4605 - val_loss: 0.4618 - val_acc: 0.4606\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4889 - acc: 0.4605 - val_loss: 0.4621 - val_acc: 0.4605\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.4886 - acc: 0.4606 - val_loss: 0.4615 - val_acc: 0.4608\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4886 - acc: 0.4608 - val_loss: 0.4615 - val_acc: 0.4609\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4883 - acc: 0.4605 - val_loss: 0.4612 - val_acc: 0.4606\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4886 - acc: 0.4606 - val_loss: 0.4612 - val_acc: 0.4609\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4881 - acc: 0.4607 - val_loss: 0.4611 - val_acc: 0.4610\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4882 - acc: 0.4608 - val_loss: 0.4608 - val_acc: 0.4609\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4891 - acc: 0.4606 - val_loss: 0.4610 - val_acc: 0.4608\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4878 - acc: 0.4610 - val_loss: 0.4617 - val_acc: 0.4607\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.4884 - acc: 0.4608 - val_loss: 0.4615 - val_acc: 0.4613\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4879 - acc: 0.4609 - val_loss: 0.4609 - val_acc: 0.4620\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4874 - acc: 0.4610 - val_loss: 0.4607 - val_acc: 0.4619\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4875 - acc: 0.4610 - val_loss: 0.4615 - val_acc: 0.4622\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4874 - acc: 0.4609 - val_loss: 0.4605 - val_acc: 0.4613\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4869 - acc: 0.4613 - val_loss: 0.4602 - val_acc: 0.4619\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4871 - acc: 0.4613 - val_loss: 0.4603 - val_acc: 0.4618\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4872 - acc: 0.4612 - val_loss: 0.4604 - val_acc: 0.4614\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4868 - acc: 0.4611 - val_loss: 0.4614 - val_acc: 0.4622\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4867 - acc: 0.4614 - val_loss: 0.4606 - val_acc: 0.4620\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4874 - acc: 0.4613 - val_loss: 0.4597 - val_acc: 0.4615\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4865 - acc: 0.4614 - val_loss: 0.4597 - val_acc: 0.4616\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4863 - acc: 0.4613 - val_loss: 0.4598 - val_acc: 0.4623\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4870 - acc: 0.4615 - val_loss: 0.4596 - val_acc: 0.4625\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.4862 - acc: 0.4616 - val_loss: 0.4606 - val_acc: 0.4625\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4859 - acc: 0.4616 - val_loss: 0.4593 - val_acc: 0.4621\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4860 - acc: 0.4616 - val_loss: 0.4592 - val_acc: 0.4620\n",
      "start training round 12\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 29.6796 - acc: 0.6787 - val_loss: 29.6181 - val_acc: 0.6747\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.7960 - acc: 0.6762 - val_loss: 29.9354 - val_acc: 0.6787\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 30.4513 - acc: 0.6778 - val_loss: 29.9591 - val_acc: 0.6834\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.9976 - acc: 0.6788 - val_loss: 30.7297 - val_acc: 0.6789\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 29.9024 - acc: 0.6786 - val_loss: 30.7125 - val_acc: 0.6776\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 30.5960 - acc: 0.6784 - val_loss: 28.9398 - val_acc: 0.6788\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 29.9187 - acc: 0.6785 - val_loss: 30.8499 - val_acc: 0.6836\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 31.1479 - acc: 0.6782 - val_loss: 30.8069 - val_acc: 0.6854\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 29.5221 - acc: 0.6793 - val_loss: 29.7452 - val_acc: 0.6751\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 31.1413 - acc: 0.6771 - val_loss: 29.4435 - val_acc: 0.6743\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 30.2814 - acc: 0.6784 - val_loss: 29.5935 - val_acc: 0.6738\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 29.9391 - acc: 0.6787 - val_loss: 31.6564 - val_acc: 0.6744\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 31.0957 - acc: 0.6788 - val_loss: 30.1735 - val_acc: 0.6723\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 30.0207 - acc: 0.6781 - val_loss: 30.4786 - val_acc: 0.6716\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.5387 - acc: 0.6789 - val_loss: 31.2473 - val_acc: 0.6714\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 30.2968 - acc: 0.6783 - val_loss: 29.8117 - val_acc: 0.6736\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 30.3610 - acc: 0.6778 - val_loss: 31.4962 - val_acc: 0.6743\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 30.6771 - acc: 0.6799 - val_loss: 29.8962 - val_acc: 0.6755\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 361us/step - loss: 30.5548 - acc: 0.6789 - val_loss: 31.3556 - val_acc: 0.6715\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 30.0679 - acc: 0.6784 - val_loss: 31.6176 - val_acc: 0.6724\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 30.5469 - acc: 0.6785 - val_loss: 29.7702 - val_acc: 0.6737\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 30.2670 - acc: 0.6789 - val_loss: 29.6069 - val_acc: 0.6780\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.0845 - acc: 0.6782 - val_loss: 32.3144 - val_acc: 0.6724\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 30.4218 - acc: 0.6786 - val_loss: 30.8469 - val_acc: 0.6727\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 30.3729 - acc: 0.6797 - val_loss: 31.1756 - val_acc: 0.6702\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 30.5418 - acc: 0.6786 - val_loss: 29.5496 - val_acc: 0.6757\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.1573 - acc: 0.6788 - val_loss: 29.8763 - val_acc: 0.6780\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 30.0686 - acc: 0.6781 - val_loss: 31.7718 - val_acc: 0.6690\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 30.2277 - acc: 0.6795 - val_loss: 29.1707 - val_acc: 0.6753\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 29.5044 - acc: 0.6777 - val_loss: 31.4523 - val_acc: 0.6827\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 30.7008 - acc: 0.6782 - val_loss: 29.7274 - val_acc: 0.6808\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 30.6677 - acc: 0.6788 - val_loss: 31.2766 - val_acc: 0.6843\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 30.2145 - acc: 0.6794 - val_loss: 31.4525 - val_acc: 0.6816\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 30.1660 - acc: 0.6783 - val_loss: 29.7765 - val_acc: 0.6812\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 30.2316 - acc: 0.6790 - val_loss: 28.9044 - val_acc: 0.6803\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 29.3853 - acc: 0.6787 - val_loss: 31.9453 - val_acc: 0.6721\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 31.5278 - acc: 0.6769 - val_loss: 31.5477 - val_acc: 0.6701\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 30.0814 - acc: 0.6794 - val_loss: 28.6576 - val_acc: 0.6760\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 29.3048 - acc: 0.6778 - val_loss: 30.9856 - val_acc: 0.6810\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 31.0851 - acc: 0.6781 - val_loss: 30.1439 - val_acc: 0.6797\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 29.2549 - acc: 0.6787 - val_loss: 32.6289 - val_acc: 0.6819\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 30.9284 - acc: 0.6773 - val_loss: 29.8768 - val_acc: 0.6834\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.4697 - acc: 0.6788 - val_loss: 28.9462 - val_acc: 0.6852\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 29.6758 - acc: 0.6797 - val_loss: 28.9420 - val_acc: 0.6774\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 358us/step - loss: 29.7554 - acc: 0.6778 - val_loss: 32.5591 - val_acc: 0.6666\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 30.4827 - acc: 0.6781 - val_loss: 29.2795 - val_acc: 0.6753\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 30.3106 - acc: 0.6779 - val_loss: 31.2556 - val_acc: 0.6752\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 30.5432 - acc: 0.6789 - val_loss: 29.6395 - val_acc: 0.6746\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 29.7557 - acc: 0.6789 - val_loss: 30.7187 - val_acc: 0.6714\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 30.2143 - acc: 0.6786 - val_loss: 29.3154 - val_acc: 0.6738\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 380us/step - loss: 111.3696 - acc: 0.6339 - val_loss: 111.6869 - val_acc: 0.6306\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 113.6483 - acc: 0.6350 - val_loss: 114.8264 - val_acc: 0.6324\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 116.6494 - acc: 0.6360 - val_loss: 116.7992 - val_acc: 0.6293\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 114.0511 - acc: 0.6350 - val_loss: 115.1335 - val_acc: 0.6296\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 112.7146 - acc: 0.6360 - val_loss: 112.8014 - val_acc: 0.6312\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 112.8712 - acc: 0.6364 - val_loss: 115.3340 - val_acc: 0.6326\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 114.5334 - acc: 0.6370 - val_loss: 113.1152 - val_acc: 0.6311\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 113.0433 - acc: 0.6355 - val_loss: 117.4153 - val_acc: 0.6315\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 113.2668 - acc: 0.6359 - val_loss: 112.8695 - val_acc: 0.6323\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 113.0919 - acc: 0.6368 - val_loss: 113.2314 - val_acc: 0.6311\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 112.8019 - acc: 0.6317 - val_loss: 110.6314 - val_acc: 0.6293\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 110.4243 - acc: 0.6314 - val_loss: 111.5993 - val_acc: 0.6292\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 110.6816 - acc: 0.6333 - val_loss: 112.9966 - val_acc: 0.6299\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 111.0776 - acc: 0.6346 - val_loss: 113.2568 - val_acc: 0.6315\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 111.2825 - acc: 0.6348 - val_loss: 112.1509 - val_acc: 0.6322\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 111.7546 - acc: 0.6340 - val_loss: 113.9031 - val_acc: 0.6308\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 116.4705 - acc: 0.6363 - val_loss: 113.2719 - val_acc: 0.6325\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 112.6528 - acc: 0.6364 - val_loss: 113.3411 - val_acc: 0.6329\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 113.0034 - acc: 0.6371 - val_loss: 113.8797 - val_acc: 0.6327\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 113.3134 - acc: 0.6355 - val_loss: 112.3420 - val_acc: 0.6318\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 112.0424 - acc: 0.6344 - val_loss: 116.0416 - val_acc: 0.6259\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 110.8918 - acc: 0.6362 - val_loss: 113.6982 - val_acc: 0.6323\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 112.9359 - acc: 0.6368 - val_loss: 113.8343 - val_acc: 0.6327\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 114.2965 - acc: 0.6357 - val_loss: 115.9638 - val_acc: 0.6308\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 114.5685 - acc: 0.6343 - val_loss: 113.3008 - val_acc: 0.6309\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 113.0538 - acc: 0.6343 - val_loss: 113.8253 - val_acc: 0.6308\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 111.2387 - acc: 0.6364 - val_loss: 111.8800 - val_acc: 0.6326\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 112.3378 - acc: 0.6344 - val_loss: 115.7107 - val_acc: 0.6296\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 116.0352 - acc: 0.6349 - val_loss: 111.3181 - val_acc: 0.6321\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 111.9755 - acc: 0.6368 - val_loss: 117.6272 - val_acc: 0.6255\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 110.7556 - acc: 0.6353 - val_loss: 112.1428 - val_acc: 0.6293\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 111.5272 - acc: 0.6334 - val_loss: 112.5899 - val_acc: 0.6331\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 111.7746 - acc: 0.6340 - val_loss: 127.1200 - val_acc: 0.6121\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 114.3669 - acc: 0.6329 - val_loss: 115.4644 - val_acc: 0.6304\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 112.3911 - acc: 0.6352 - val_loss: 112.0977 - val_acc: 0.6302\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 110.0312 - acc: 0.6356 - val_loss: 111.3942 - val_acc: 0.6318\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 110.6714 - acc: 0.6328 - val_loss: 112.0428 - val_acc: 0.6281\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 111.6906 - acc: 0.6315 - val_loss: 115.8155 - val_acc: 0.6302\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 115.7178 - acc: 0.6370 - val_loss: 115.1744 - val_acc: 0.6323\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 113.2403 - acc: 0.6366 - val_loss: 112.9811 - val_acc: 0.6321\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 112.7257 - acc: 0.6361 - val_loss: 113.1695 - val_acc: 0.6326\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 114.3715 - acc: 0.6360 - val_loss: 112.7222 - val_acc: 0.6325\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 112.4121 - acc: 0.6342 - val_loss: 116.1619 - val_acc: 0.6283\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 111.9802 - acc: 0.6352 - val_loss: 113.8754 - val_acc: 0.6290\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 113.4891 - acc: 0.6356 - val_loss: 116.8947 - val_acc: 0.6293\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 115.2200 - acc: 0.6357 - val_loss: 113.4572 - val_acc: 0.6330\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 112.3050 - acc: 0.6358 - val_loss: 113.5397 - val_acc: 0.6290\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 112.2374 - acc: 0.6322 - val_loss: 110.7365 - val_acc: 0.6331\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 109.5620 - acc: 0.6370 - val_loss: 114.9794 - val_acc: 0.6307\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 112.2410 - acc: 0.6362 - val_loss: 116.3998 - val_acc: 0.6302\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 51.6541 - acc: 0.4360 - val_loss: 48.3756 - val_acc: 0.4447\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 51.6434 - acc: 0.4362 - val_loss: 48.3679 - val_acc: 0.4433\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 51.6378 - acc: 0.4363 - val_loss: 48.3486 - val_acc: 0.4430\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 51.6252 - acc: 0.4357 - val_loss: 48.3384 - val_acc: 0.4451\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 51.6165 - acc: 0.4361 - val_loss: 48.3401 - val_acc: 0.4451\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 51.6080 - acc: 0.4365 - val_loss: 48.3172 - val_acc: 0.4440\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.5976 - acc: 0.4360 - val_loss: 48.3078 - val_acc: 0.4449\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 51.5940 - acc: 0.4364 - val_loss: 48.3115 - val_acc: 0.4433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 51.5804 - acc: 0.4362 - val_loss: 48.2974 - val_acc: 0.4438\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 51.5741 - acc: 0.4363 - val_loss: 48.2978 - val_acc: 0.4428\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 51.5675 - acc: 0.4362 - val_loss: 48.2918 - val_acc: 0.4434\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 51.5591 - acc: 0.4361 - val_loss: 48.2738 - val_acc: 0.4444\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 51.5494 - acc: 0.4365 - val_loss: 48.2623 - val_acc: 0.4437\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 51.5400 - acc: 0.4363 - val_loss: 48.2587 - val_acc: 0.4438\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 51.5292 - acc: 0.4361 - val_loss: 48.2485 - val_acc: 0.4454\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 51.5198 - acc: 0.4368 - val_loss: 48.2576 - val_acc: 0.4447\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 51.5082 - acc: 0.4367 - val_loss: 48.2271 - val_acc: 0.4436\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 51.5034 - acc: 0.4363 - val_loss: 48.2429 - val_acc: 0.4436\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 51.4939 - acc: 0.4368 - val_loss: 48.2100 - val_acc: 0.4443\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 51.4851 - acc: 0.4365 - val_loss: 48.2047 - val_acc: 0.4445\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 51.4774 - acc: 0.4368 - val_loss: 48.2108 - val_acc: 0.4436\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 51.4670 - acc: 0.4364 - val_loss: 48.2023 - val_acc: 0.4443\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 51.4602 - acc: 0.4370 - val_loss: 48.1828 - val_acc: 0.4444\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 51.4537 - acc: 0.4365 - val_loss: 48.1840 - val_acc: 0.4450\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 51.4396 - acc: 0.4368 - val_loss: 48.1711 - val_acc: 0.4444\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 51.4359 - acc: 0.4365 - val_loss: 48.1675 - val_acc: 0.4446\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 51.4246 - acc: 0.4368 - val_loss: 48.1722 - val_acc: 0.4441\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.4152 - acc: 0.4368 - val_loss: 48.1487 - val_acc: 0.4445\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 51.4033 - acc: 0.4368 - val_loss: 48.1314 - val_acc: 0.4444\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.3945 - acc: 0.4369 - val_loss: 48.1508 - val_acc: 0.4437\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 51.3929 - acc: 0.4369 - val_loss: 48.1528 - val_acc: 0.4433\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 51.3822 - acc: 0.4365 - val_loss: 48.1124 - val_acc: 0.4449\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 51.3687 - acc: 0.4370 - val_loss: 48.1135 - val_acc: 0.4436\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 51.3643 - acc: 0.4365 - val_loss: 48.1117 - val_acc: 0.4453\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 51.3511 - acc: 0.4372 - val_loss: 48.0930 - val_acc: 0.4451\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.3476 - acc: 0.4371 - val_loss: 48.0774 - val_acc: 0.4437\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 51.3401 - acc: 0.4365 - val_loss: 48.0813 - val_acc: 0.4440\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 51.3262 - acc: 0.4367 - val_loss: 48.0687 - val_acc: 0.4451\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 51.3183 - acc: 0.4373 - val_loss: 48.0566 - val_acc: 0.4439\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 51.3156 - acc: 0.4368 - val_loss: 48.0487 - val_acc: 0.4447\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 51.3042 - acc: 0.4368 - val_loss: 48.0551 - val_acc: 0.4441\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 51.2910 - acc: 0.4370 - val_loss: 48.0389 - val_acc: 0.4448\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 51.2828 - acc: 0.4371 - val_loss: 48.0597 - val_acc: 0.4439\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 51.2781 - acc: 0.4366 - val_loss: 48.0163 - val_acc: 0.4454\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 51.2651 - acc: 0.4371 - val_loss: 48.0199 - val_acc: 0.4443\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 51.2533 - acc: 0.4373 - val_loss: 48.0089 - val_acc: 0.4450\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 51.2476 - acc: 0.4372 - val_loss: 47.9936 - val_acc: 0.4444\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 51.2388 - acc: 0.4373 - val_loss: 47.9862 - val_acc: 0.4441\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 51.2305 - acc: 0.4368 - val_loss: 47.9874 - val_acc: 0.4443\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 51.2186 - acc: 0.4371 - val_loss: 47.9887 - val_acc: 0.4455\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.4863 - acc: 0.4616 - val_loss: 0.4609 - val_acc: 0.4614\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4858 - acc: 0.4619 - val_loss: 0.4589 - val_acc: 0.4626\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4861 - acc: 0.4618 - val_loss: 0.4595 - val_acc: 0.4621\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4860 - acc: 0.4618 - val_loss: 0.4589 - val_acc: 0.4627\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4857 - acc: 0.4618 - val_loss: 0.4587 - val_acc: 0.4622\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4853 - acc: 0.4618 - val_loss: 0.4593 - val_acc: 0.4632\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4856 - acc: 0.4620 - val_loss: 0.4617 - val_acc: 0.4636\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.4853 - acc: 0.4621 - val_loss: 0.4583 - val_acc: 0.4627\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4850 - acc: 0.4621 - val_loss: 0.4585 - val_acc: 0.4620\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4850 - acc: 0.4621 - val_loss: 0.4594 - val_acc: 0.4631\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4848 - acc: 0.4622 - val_loss: 0.4592 - val_acc: 0.4624\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4850 - acc: 0.4620 - val_loss: 0.4591 - val_acc: 0.4621\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4859 - acc: 0.4621 - val_loss: 0.4584 - val_acc: 0.4624\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4842 - acc: 0.4623 - val_loss: 0.4582 - val_acc: 0.4632\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.4840 - acc: 0.4623 - val_loss: 0.4576 - val_acc: 0.4628\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4841 - acc: 0.4623 - val_loss: 0.4580 - val_acc: 0.4625\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4844 - acc: 0.4624 - val_loss: 0.4575 - val_acc: 0.4630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4838 - acc: 0.4623 - val_loss: 0.4574 - val_acc: 0.4633\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4839 - acc: 0.4625 - val_loss: 0.4573 - val_acc: 0.4634\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4835 - acc: 0.4624 - val_loss: 0.4573 - val_acc: 0.4633\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.4835 - acc: 0.4625 - val_loss: 0.4573 - val_acc: 0.4637\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4832 - acc: 0.4626 - val_loss: 0.4577 - val_acc: 0.4633\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4832 - acc: 0.4627 - val_loss: 0.4571 - val_acc: 0.4637\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4829 - acc: 0.4627 - val_loss: 0.4568 - val_acc: 0.4637\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4832 - acc: 0.4626 - val_loss: 0.4570 - val_acc: 0.4637\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4829 - acc: 0.4628 - val_loss: 0.4571 - val_acc: 0.4642\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4827 - acc: 0.4626 - val_loss: 0.4565 - val_acc: 0.4636\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4827 - acc: 0.4628 - val_loss: 0.4563 - val_acc: 0.4635\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.4827 - acc: 0.4628 - val_loss: 0.4581 - val_acc: 0.4630\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4835 - acc: 0.4627 - val_loss: 0.4562 - val_acc: 0.4636\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4821 - acc: 0.4628 - val_loss: 0.4562 - val_acc: 0.4640\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4825 - acc: 0.4627 - val_loss: 0.4559 - val_acc: 0.4638\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.4820 - acc: 0.4627 - val_loss: 0.4559 - val_acc: 0.4635\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4817 - acc: 0.4628 - val_loss: 0.4561 - val_acc: 0.4643\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4820 - acc: 0.4628 - val_loss: 0.4558 - val_acc: 0.4639\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4815 - acc: 0.4628 - val_loss: 0.4557 - val_acc: 0.4639\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4816 - acc: 0.4629 - val_loss: 0.4556 - val_acc: 0.4644\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.4815 - acc: 0.4631 - val_loss: 0.4556 - val_acc: 0.4637\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.4818 - acc: 0.4629 - val_loss: 0.4553 - val_acc: 0.4639\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4814 - acc: 0.4630 - val_loss: 0.4550 - val_acc: 0.4643\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4828 - acc: 0.4630 - val_loss: 0.4551 - val_acc: 0.4641\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4811 - acc: 0.4630 - val_loss: 0.4553 - val_acc: 0.4645\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4813 - acc: 0.4630 - val_loss: 0.4558 - val_acc: 0.4645\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4807 - acc: 0.4630 - val_loss: 0.4549 - val_acc: 0.4637\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4804 - acc: 0.4630 - val_loss: 0.4551 - val_acc: 0.4648\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.4805 - acc: 0.4631 - val_loss: 0.4549 - val_acc: 0.4636\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4808 - acc: 0.4631 - val_loss: 0.4545 - val_acc: 0.4641\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4800 - acc: 0.4631 - val_loss: 0.4545 - val_acc: 0.4636\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4813 - acc: 0.4629 - val_loss: 0.4555 - val_acc: 0.4630\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4802 - acc: 0.4631 - val_loss: 0.4541 - val_acc: 0.4642\n",
      "start training round 13\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 30.1305 - acc: 0.6788 - val_loss: 29.1152 - val_acc: 0.6705\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 29.8300 - acc: 0.6785 - val_loss: 29.4348 - val_acc: 0.6775\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 30.4914 - acc: 0.6766 - val_loss: 31.2889 - val_acc: 0.6834\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 30.0305 - acc: 0.6794 - val_loss: 30.5580 - val_acc: 0.6835\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 30.2586 - acc: 0.6799 - val_loss: 29.3185 - val_acc: 0.6813\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 29.2512 - acc: 0.6791 - val_loss: 28.8789 - val_acc: 0.6779\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 30.1602 - acc: 0.6773 - val_loss: 28.9180 - val_acc: 0.6746\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 30.0185 - acc: 0.6783 - val_loss: 31.0576 - val_acc: 0.6698\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.1174 - acc: 0.6788 - val_loss: 30.7072 - val_acc: 0.6784\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 30.3895 - acc: 0.6781 - val_loss: 29.5429 - val_acc: 0.6748\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.1743 - acc: 0.6792 - val_loss: 30.0861 - val_acc: 0.6772\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.2844 - acc: 0.6799 - val_loss: 29.1380 - val_acc: 0.6750\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 29.9592 - acc: 0.6784 - val_loss: 29.5461 - val_acc: 0.6768\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 30.5580 - acc: 0.6795 - val_loss: 29.3590 - val_acc: 0.6738\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 30.0270 - acc: 0.6795 - val_loss: 30.3030 - val_acc: 0.6759\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 29.6896 - acc: 0.6793 - val_loss: 31.6398 - val_acc: 0.6727\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 30.3211 - acc: 0.6787 - val_loss: 29.1427 - val_acc: 0.6758\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 29.8626 - acc: 0.6787 - val_loss: 30.5063 - val_acc: 0.6733\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 30.3313 - acc: 0.6791 - val_loss: 30.6187 - val_acc: 0.6743\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 29.7985 - acc: 0.6789 - val_loss: 30.1832 - val_acc: 0.6699\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 30.3664 - acc: 0.6789 - val_loss: 30.0649 - val_acc: 0.6714\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 29.3033 - acc: 0.6785 - val_loss: 30.0787 - val_acc: 0.6709\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 29.7512 - acc: 0.6781 - val_loss: 31.4976 - val_acc: 0.6733\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 30.3311 - acc: 0.6781 - val_loss: 30.3095 - val_acc: 0.6705\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 30.2161 - acc: 0.6793 - val_loss: 29.8306 - val_acc: 0.6828\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 30.2842 - acc: 0.6793 - val_loss: 29.8265 - val_acc: 0.6827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 29.9901 - acc: 0.6794 - val_loss: 30.4177 - val_acc: 0.6786\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 29.6037 - acc: 0.6790 - val_loss: 30.0132 - val_acc: 0.6791\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 30.1080 - acc: 0.6787 - val_loss: 29.0154 - val_acc: 0.6805\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 29.7871 - acc: 0.6788 - val_loss: 31.4264 - val_acc: 0.6790\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 30.1643 - acc: 0.6794 - val_loss: 28.8199 - val_acc: 0.6775\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 29.9375 - acc: 0.6789 - val_loss: 31.2740 - val_acc: 0.6729\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.0642 - acc: 0.6785 - val_loss: 30.7532 - val_acc: 0.6764\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 30.1625 - acc: 0.6795 - val_loss: 29.0916 - val_acc: 0.6749\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 29.9328 - acc: 0.6794 - val_loss: 29.0524 - val_acc: 0.6820\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 29.6812 - acc: 0.6786 - val_loss: 30.2202 - val_acc: 0.6813\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 30.3340 - acc: 0.6791 - val_loss: 29.1922 - val_acc: 0.6807\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 30.0886 - acc: 0.6794 - val_loss: 29.0812 - val_acc: 0.6803\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 29.8977 - acc: 0.6790 - val_loss: 29.9451 - val_acc: 0.6796\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 29.9080 - acc: 0.6788 - val_loss: 28.8869 - val_acc: 0.6803\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 29.3406 - acc: 0.6785 - val_loss: 29.5092 - val_acc: 0.6677\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 30.2548 - acc: 0.6785 - val_loss: 29.9120 - val_acc: 0.6728\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 29.5800 - acc: 0.6785 - val_loss: 30.5588 - val_acc: 0.6736\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 29.9492 - acc: 0.6785 - val_loss: 30.8051 - val_acc: 0.6732\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 30.0767 - acc: 0.6793 - val_loss: 29.8543 - val_acc: 0.6748\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 30.0081 - acc: 0.6792 - val_loss: 31.0309 - val_acc: 0.6736\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 29.5420 - acc: 0.6794 - val_loss: 29.6997 - val_acc: 0.6782\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 29.7008 - acc: 0.6775 - val_loss: 28.6122 - val_acc: 0.6807\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 30.0121 - acc: 0.6791 - val_loss: 31.4724 - val_acc: 0.6803\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 29.9085 - acc: 0.6791 - val_loss: 29.8175 - val_acc: 0.6820\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 113.0901 - acc: 0.6357 - val_loss: 124.0283 - val_acc: 0.6296\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 113.4543 - acc: 0.6350 - val_loss: 113.5420 - val_acc: 0.6327\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 112.2869 - acc: 0.6371 - val_loss: 114.5381 - val_acc: 0.6305\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 114.1057 - acc: 0.6335 - val_loss: 111.8505 - val_acc: 0.6305\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 111.0652 - acc: 0.6331 - val_loss: 112.0683 - val_acc: 0.6298\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 112.6250 - acc: 0.6350 - val_loss: 114.5687 - val_acc: 0.6328\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 114.5823 - acc: 0.6363 - val_loss: 110.6117 - val_acc: 0.6334\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 112.7723 - acc: 0.6371 - val_loss: 113.3572 - val_acc: 0.6325\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 111.5427 - acc: 0.6369 - val_loss: 114.6385 - val_acc: 0.6315\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 112.0132 - acc: 0.6334 - val_loss: 112.7802 - val_acc: 0.6270\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 109.5389 - acc: 0.6364 - val_loss: 111.5908 - val_acc: 0.6315\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 111.7467 - acc: 0.6362 - val_loss: 113.7884 - val_acc: 0.6306\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 113.5440 - acc: 0.6356 - val_loss: 116.6142 - val_acc: 0.6301\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 113.9826 - acc: 0.6352 - val_loss: 111.8293 - val_acc: 0.6311\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 110.8290 - acc: 0.6358 - val_loss: 117.0103 - val_acc: 0.6254\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 112.5692 - acc: 0.6339 - val_loss: 112.2253 - val_acc: 0.6342\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 111.8036 - acc: 0.6340 - val_loss: 111.2040 - val_acc: 0.6320\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 111.1097 - acc: 0.6361 - val_loss: 111.2564 - val_acc: 0.6323\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 110.4976 - acc: 0.6336 - val_loss: 111.1405 - val_acc: 0.6287\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 110.5495 - acc: 0.6346 - val_loss: 111.6990 - val_acc: 0.6312\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 111.7946 - acc: 0.6349 - val_loss: 112.2500 - val_acc: 0.6327\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 113.0236 - acc: 0.6371 - val_loss: 118.0673 - val_acc: 0.6329\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 114.2502 - acc: 0.6369 - val_loss: 112.4610 - val_acc: 0.6336\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 113.0353 - acc: 0.6368 - val_loss: 116.9017 - val_acc: 0.6322\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 111.9899 - acc: 0.6332 - val_loss: 113.9241 - val_acc: 0.6213\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 110.7373 - acc: 0.6332 - val_loss: 110.9531 - val_acc: 0.6308\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 110.8424 - acc: 0.6355 - val_loss: 111.3189 - val_acc: 0.6306\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 111.0906 - acc: 0.6350 - val_loss: 113.7425 - val_acc: 0.6317\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 112.1002 - acc: 0.6348 - val_loss: 111.6977 - val_acc: 0.6315\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 113.0459 - acc: 0.6357 - val_loss: 118.2679 - val_acc: 0.6313\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 114.0674 - acc: 0.6359 - val_loss: 111.9362 - val_acc: 0.6311\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 111.3139 - acc: 0.6365 - val_loss: 109.8593 - val_acc: 0.6331\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 110.2926 - acc: 0.6340 - val_loss: 112.1488 - val_acc: 0.6285\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 110.0502 - acc: 0.6342 - val_loss: 110.6403 - val_acc: 0.6311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 110.5277 - acc: 0.6340 - val_loss: 112.8469 - val_acc: 0.6319\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 113.1773 - acc: 0.6360 - val_loss: 113.1856 - val_acc: 0.6317\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 114.3338 - acc: 0.6360 - val_loss: 112.1018 - val_acc: 0.6318\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 109.9113 - acc: 0.6359 - val_loss: 115.5650 - val_acc: 0.6302\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 111.1316 - acc: 0.6351 - val_loss: 109.3655 - val_acc: 0.6334\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 111.6404 - acc: 0.6360 - val_loss: 113.6282 - val_acc: 0.6315\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 112.5604 - acc: 0.6370 - val_loss: 112.3289 - val_acc: 0.6316\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 113.8682 - acc: 0.6344 - val_loss: 113.4481 - val_acc: 0.6324\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 112.0691 - acc: 0.6364 - val_loss: 110.6523 - val_acc: 0.6331\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 110.2751 - acc: 0.6338 - val_loss: 111.0129 - val_acc: 0.6270\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 109.0663 - acc: 0.6357 - val_loss: 112.1162 - val_acc: 0.6299\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 109.1515 - acc: 0.6369 - val_loss: 110.2498 - val_acc: 0.6329\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 110.0479 - acc: 0.6330 - val_loss: 112.8473 - val_acc: 0.6267\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 109.7561 - acc: 0.6361 - val_loss: 114.0127 - val_acc: 0.6278\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 110.4681 - acc: 0.6313 - val_loss: 112.5201 - val_acc: 0.6303\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 111.8669 - acc: 0.6368 - val_loss: 115.5210 - val_acc: 0.6331\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 51.2134 - acc: 0.4374 - val_loss: 47.9619 - val_acc: 0.4446\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 51.2079 - acc: 0.4371 - val_loss: 47.9528 - val_acc: 0.4454\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 51.1942 - acc: 0.4372 - val_loss: 47.9550 - val_acc: 0.4439\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 51.1872 - acc: 0.4371 - val_loss: 47.9383 - val_acc: 0.4444\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 51.1781 - acc: 0.4372 - val_loss: 47.9664 - val_acc: 0.4441\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 51.1683 - acc: 0.4373 - val_loss: 47.9408 - val_acc: 0.4456\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 51.1605 - acc: 0.4373 - val_loss: 47.9132 - val_acc: 0.4457\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 51.1559 - acc: 0.4372 - val_loss: 47.9042 - val_acc: 0.4453\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 51.1421 - acc: 0.4375 - val_loss: 47.9222 - val_acc: 0.4444\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 51.1345 - acc: 0.4372 - val_loss: 47.9085 - val_acc: 0.4456\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 51.1288 - acc: 0.4375 - val_loss: 47.8866 - val_acc: 0.4450\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 51.1172 - acc: 0.4377 - val_loss: 47.8809 - val_acc: 0.4453\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 51.1085 - acc: 0.4373 - val_loss: 47.8661 - val_acc: 0.4454\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 51.1014 - acc: 0.4374 - val_loss: 47.8528 - val_acc: 0.4456\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.0895 - acc: 0.4377 - val_loss: 47.8580 - val_acc: 0.4451\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 51.0855 - acc: 0.4377 - val_loss: 47.8451 - val_acc: 0.4449\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 51.0747 - acc: 0.4374 - val_loss: 47.8282 - val_acc: 0.4451\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 51.0570 - acc: 0.4374 - val_loss: 47.8489 - val_acc: 0.4457\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 51.0584 - acc: 0.4375 - val_loss: 47.8401 - val_acc: 0.4457\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 51.0513 - acc: 0.4376 - val_loss: 47.8264 - val_acc: 0.4454\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 51.0380 - acc: 0.4377 - val_loss: 47.8207 - val_acc: 0.4453\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 51.0311 - acc: 0.4376 - val_loss: 47.7923 - val_acc: 0.4447\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 51.0187 - acc: 0.4376 - val_loss: 47.8030 - val_acc: 0.4456\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 51.0118 - acc: 0.4377 - val_loss: 47.8233 - val_acc: 0.4444\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 51.0042 - acc: 0.4376 - val_loss: 47.7817 - val_acc: 0.4453\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 50.9915 - acc: 0.4378 - val_loss: 47.7753 - val_acc: 0.4445\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 50.9844 - acc: 0.4372 - val_loss: 47.7583 - val_acc: 0.4454\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 50.9771 - acc: 0.4380 - val_loss: 47.7505 - val_acc: 0.4446\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 50.9668 - acc: 0.4376 - val_loss: 47.7483 - val_acc: 0.4449\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 50.9598 - acc: 0.4378 - val_loss: 47.7394 - val_acc: 0.4442\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 50.9521 - acc: 0.4372 - val_loss: 47.7194 - val_acc: 0.4452\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 50.9440 - acc: 0.4377 - val_loss: 47.7162 - val_acc: 0.4455\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 50.9343 - acc: 0.4380 - val_loss: 47.7040 - val_acc: 0.4445\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 50.9215 - acc: 0.4376 - val_loss: 47.7100 - val_acc: 0.4450\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 50.9141 - acc: 0.4379 - val_loss: 47.6996 - val_acc: 0.4444\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 50.9032 - acc: 0.4377 - val_loss: 47.7031 - val_acc: 0.4443\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 50.9017 - acc: 0.4380 - val_loss: 47.6944 - val_acc: 0.4440\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 50.8920 - acc: 0.4375 - val_loss: 47.6809 - val_acc: 0.4442\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 50.8799 - acc: 0.4375 - val_loss: 47.6642 - val_acc: 0.4452\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 50.8667 - acc: 0.4381 - val_loss: 47.6488 - val_acc: 0.4445\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 50.8633 - acc: 0.4378 - val_loss: 47.6579 - val_acc: 0.4457\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 50.8542 - acc: 0.4379 - val_loss: 47.6384 - val_acc: 0.4450\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 387us/step - loss: 50.8422 - acc: 0.4378 - val_loss: 47.6528 - val_acc: 0.4447\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 50.8405 - acc: 0.4375 - val_loss: 47.6291 - val_acc: 0.4460\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 50.8249 - acc: 0.4382 - val_loss: 47.6102 - val_acc: 0.4446\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.8186 - acc: 0.4377 - val_loss: 47.6129 - val_acc: 0.4454\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.8128 - acc: 0.4380 - val_loss: 47.6104 - val_acc: 0.4451\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 50.8046 - acc: 0.4379 - val_loss: 47.6029 - val_acc: 0.4453\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 50.7935 - acc: 0.4378 - val_loss: 47.5843 - val_acc: 0.4461\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 50.7847 - acc: 0.4379 - val_loss: 47.5778 - val_acc: 0.4457\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4799 - acc: 0.4630 - val_loss: 0.4550 - val_acc: 0.4648\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.4800 - acc: 0.4631 - val_loss: 0.4541 - val_acc: 0.4637\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4795 - acc: 0.4632 - val_loss: 0.4542 - val_acc: 0.4639\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4794 - acc: 0.4630 - val_loss: 0.4539 - val_acc: 0.4643\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4794 - acc: 0.4631 - val_loss: 0.4549 - val_acc: 0.4652\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.4794 - acc: 0.4632 - val_loss: 0.4550 - val_acc: 0.4653\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4795 - acc: 0.4632 - val_loss: 0.4537 - val_acc: 0.4643\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4798 - acc: 0.4632 - val_loss: 0.4534 - val_acc: 0.4642\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.4789 - acc: 0.4633 - val_loss: 0.4533 - val_acc: 0.4643\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4788 - acc: 0.4631 - val_loss: 0.4532 - val_acc: 0.4641\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4786 - acc: 0.4633 - val_loss: 0.4532 - val_acc: 0.4647\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4786 - acc: 0.4632 - val_loss: 0.4549 - val_acc: 0.4642\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4791 - acc: 0.4633 - val_loss: 0.4592 - val_acc: 0.4629\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.4788 - acc: 0.4632 - val_loss: 0.4528 - val_acc: 0.4643\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4781 - acc: 0.4632 - val_loss: 0.4526 - val_acc: 0.4641\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4779 - acc: 0.4634 - val_loss: 0.4527 - val_acc: 0.4647\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4779 - acc: 0.4634 - val_loss: 0.4534 - val_acc: 0.4642\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4781 - acc: 0.4634 - val_loss: 0.4526 - val_acc: 0.4640\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4777 - acc: 0.4634 - val_loss: 0.4526 - val_acc: 0.4645\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.4775 - acc: 0.4634 - val_loss: 0.4525 - val_acc: 0.4639\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4780 - acc: 0.4634 - val_loss: 0.4541 - val_acc: 0.4650\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4774 - acc: 0.4635 - val_loss: 0.4523 - val_acc: 0.4650\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.4772 - acc: 0.4634 - val_loss: 0.4519 - val_acc: 0.4647\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4771 - acc: 0.4635 - val_loss: 0.4516 - val_acc: 0.4648\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4769 - acc: 0.4637 - val_loss: 0.4518 - val_acc: 0.4647\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4771 - acc: 0.4635 - val_loss: 0.4527 - val_acc: 0.4652\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4770 - acc: 0.4636 - val_loss: 0.4517 - val_acc: 0.4650\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4769 - acc: 0.4636 - val_loss: 0.4515 - val_acc: 0.4649\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4769 - acc: 0.4639 - val_loss: 0.4517 - val_acc: 0.4651\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.4794 - acc: 0.4632 - val_loss: 0.4514 - val_acc: 0.4648\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4768 - acc: 0.4635 - val_loss: 0.4514 - val_acc: 0.4651\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4763 - acc: 0.4636 - val_loss: 0.4509 - val_acc: 0.4648\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4761 - acc: 0.4637 - val_loss: 0.4514 - val_acc: 0.4655\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.4761 - acc: 0.4638 - val_loss: 0.4508 - val_acc: 0.4644\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4759 - acc: 0.4637 - val_loss: 0.4523 - val_acc: 0.4643\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.4757 - acc: 0.4639 - val_loss: 0.4507 - val_acc: 0.4654\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4756 - acc: 0.4638 - val_loss: 0.4504 - val_acc: 0.4654\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4753 - acc: 0.4639 - val_loss: 0.4505 - val_acc: 0.4654\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4755 - acc: 0.4638 - val_loss: 0.4505 - val_acc: 0.4657\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4760 - acc: 0.4638 - val_loss: 0.4503 - val_acc: 0.4652\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.4751 - acc: 0.4638 - val_loss: 0.4502 - val_acc: 0.4654\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4760 - acc: 0.4637 - val_loss: 0.4501 - val_acc: 0.4651\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4750 - acc: 0.4639 - val_loss: 0.4501 - val_acc: 0.4655\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4751 - acc: 0.4638 - val_loss: 0.4514 - val_acc: 0.4659\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4746 - acc: 0.4640 - val_loss: 0.4498 - val_acc: 0.4658\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4746 - acc: 0.4639 - val_loss: 0.4514 - val_acc: 0.4658\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4746 - acc: 0.4640 - val_loss: 0.4495 - val_acc: 0.4655\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4744 - acc: 0.4639 - val_loss: 0.4496 - val_acc: 0.4660\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4743 - acc: 0.4639 - val_loss: 0.4495 - val_acc: 0.4658\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4744 - acc: 0.4640 - val_loss: 0.4494 - val_acc: 0.4653\n",
      "start training round 14\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 382us/step - loss: 30.2897 - acc: 0.6797 - val_loss: 29.2952 - val_acc: 0.6790\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 29.4712 - acc: 0.6792 - val_loss: 29.9466 - val_acc: 0.6828\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 29.8311 - acc: 0.6796 - val_loss: 30.4472 - val_acc: 0.6833\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 29.6637 - acc: 0.6791 - val_loss: 30.0110 - val_acc: 0.6812\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 29.6656 - acc: 0.6787 - val_loss: 30.8468 - val_acc: 0.6824\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 30.2519 - acc: 0.6791 - val_loss: 29.9915 - val_acc: 0.6816\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 29.8648 - acc: 0.6790 - val_loss: 29.8265 - val_acc: 0.6794\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 29.0221 - acc: 0.6792 - val_loss: 31.6434 - val_acc: 0.6802\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 30.5900 - acc: 0.6792 - val_loss: 30.0281 - val_acc: 0.6810\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.1459 - acc: 0.6786 - val_loss: 30.3739 - val_acc: 0.6821\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 30.2437 - acc: 0.6790 - val_loss: 29.0897 - val_acc: 0.6823\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 29.3402 - acc: 0.6796 - val_loss: 30.2170 - val_acc: 0.6826\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 30.0802 - acc: 0.6784 - val_loss: 29.5930 - val_acc: 0.6814\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 30.1970 - acc: 0.6790 - val_loss: 28.6652 - val_acc: 0.6819\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 29.3852 - acc: 0.6794 - val_loss: 30.1719 - val_acc: 0.6825\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 30.0261 - acc: 0.6799 - val_loss: 28.5940 - val_acc: 0.6790\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 29.6828 - acc: 0.6794 - val_loss: 28.8332 - val_acc: 0.6798\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 29.1812 - acc: 0.6785 - val_loss: 30.7482 - val_acc: 0.6819\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 30.1955 - acc: 0.6797 - val_loss: 28.8004 - val_acc: 0.6802\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 29.6487 - acc: 0.6795 - val_loss: 31.3052 - val_acc: 0.6819\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 29.7686 - acc: 0.6794 - val_loss: 30.6655 - val_acc: 0.6822\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 29.5553 - acc: 0.6793 - val_loss: 29.5067 - val_acc: 0.6747\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 29.8893 - acc: 0.6777 - val_loss: 28.7455 - val_acc: 0.6793\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 29.4509 - acc: 0.6786 - val_loss: 33.0473 - val_acc: 0.6691\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 30.1067 - acc: 0.6793 - val_loss: 31.6596 - val_acc: 0.6686\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 30.1817 - acc: 0.6793 - val_loss: 32.3923 - val_acc: 0.6729\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 29.1080 - acc: 0.6810 - val_loss: 28.2651 - val_acc: 0.6758\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 29.4074 - acc: 0.6790 - val_loss: 31.3519 - val_acc: 0.6690\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 30.4613 - acc: 0.6790 - val_loss: 29.4837 - val_acc: 0.6736\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 28.7451 - acc: 0.6788 - val_loss: 30.1535 - val_acc: 0.6668\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 30.5869 - acc: 0.6779 - val_loss: 28.8203 - val_acc: 0.6732\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 29.7807 - acc: 0.6807 - val_loss: 28.8878 - val_acc: 0.6776\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 29.3392 - acc: 0.6792 - val_loss: 29.4422 - val_acc: 0.6754\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 29.7392 - acc: 0.6787 - val_loss: 29.8800 - val_acc: 0.6746\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 29.7033 - acc: 0.6793 - val_loss: 30.3343 - val_acc: 0.6720\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 29.6769 - acc: 0.6796 - val_loss: 28.5060 - val_acc: 0.6755\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 29.6069 - acc: 0.6794 - val_loss: 30.3151 - val_acc: 0.6827\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 29.5993 - acc: 0.6800 - val_loss: 28.1997 - val_acc: 0.6815\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 29.3151 - acc: 0.6790 - val_loss: 28.5310 - val_acc: 0.6758\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 30.1293 - acc: 0.6790 - val_loss: 30.4450 - val_acc: 0.6707\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 29.6804 - acc: 0.6804 - val_loss: 30.1998 - val_acc: 0.6731\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 29.8371 - acc: 0.6793 - val_loss: 30.2886 - val_acc: 0.6739\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 30.0861 - acc: 0.6793 - val_loss: 29.7280 - val_acc: 0.6751\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 29.4489 - acc: 0.6805 - val_loss: 29.7399 - val_acc: 0.6739\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 29.7608 - acc: 0.6799 - val_loss: 30.3332 - val_acc: 0.6753\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 29.7353 - acc: 0.6804 - val_loss: 30.1559 - val_acc: 0.6768\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 29.5344 - acc: 0.6796 - val_loss: 29.7084 - val_acc: 0.6720\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 29.9164 - acc: 0.6806 - val_loss: 28.3446 - val_acc: 0.6775\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 29.4997 - acc: 0.6790 - val_loss: 29.1666 - val_acc: 0.6752\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 29.4803 - acc: 0.6794 - val_loss: 31.4579 - val_acc: 0.6717\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 111.5577 - acc: 0.6370 - val_loss: 124.0971 - val_acc: 0.6274\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 116.9667 - acc: 0.6359 - val_loss: 114.4152 - val_acc: 0.6333\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 112.6582 - acc: 0.6364 - val_loss: 113.7526 - val_acc: 0.6299\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 110.6749 - acc: 0.6370 - val_loss: 121.5393 - val_acc: 0.6265\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 112.7574 - acc: 0.6355 - val_loss: 111.5692 - val_acc: 0.6323\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 111.6295 - acc: 0.6361 - val_loss: 112.6382 - val_acc: 0.6294\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 111.0520 - acc: 0.6368 - val_loss: 115.1089 - val_acc: 0.6316\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 112.3678 - acc: 0.6354 - val_loss: 112.2999 - val_acc: 0.6319\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 387us/step - loss: 110.6789 - acc: 0.6372 - val_loss: 112.2509 - val_acc: 0.6302\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 110.4591 - acc: 0.6358 - val_loss: 111.2415 - val_acc: 0.6337\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 111.3904 - acc: 0.6356 - val_loss: 118.8217 - val_acc: 0.6268\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 113.9537 - acc: 0.6363 - val_loss: 117.7997 - val_acc: 0.6308\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 111.6281 - acc: 0.6368 - val_loss: 112.8156 - val_acc: 0.6328\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 109.9891 - acc: 0.6358 - val_loss: 110.3964 - val_acc: 0.6348\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 110.0099 - acc: 0.6322 - val_loss: 115.2485 - val_acc: 0.6159\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 109.2847 - acc: 0.6338 - val_loss: 114.2780 - val_acc: 0.6256\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 108.9023 - acc: 0.6357 - val_loss: 109.2756 - val_acc: 0.6334\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 110.2766 - acc: 0.6335 - val_loss: 109.9482 - val_acc: 0.6315\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 111.5216 - acc: 0.6365 - val_loss: 112.7074 - val_acc: 0.6331\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 113.7760 - acc: 0.6374 - val_loss: 116.3961 - val_acc: 0.6295\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 113.0021 - acc: 0.6353 - val_loss: 112.0903 - val_acc: 0.6320\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 112.2793 - acc: 0.6367 - val_loss: 109.1434 - val_acc: 0.6325\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 362us/step - loss: 109.3678 - acc: 0.6350 - val_loss: 110.3166 - val_acc: 0.6281\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 108.9232 - acc: 0.6351 - val_loss: 110.8022 - val_acc: 0.6299\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 110.4910 - acc: 0.6345 - val_loss: 111.1772 - val_acc: 0.6320\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 361us/step - loss: 112.6846 - acc: 0.6369 - val_loss: 111.6882 - val_acc: 0.6341\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 110.3825 - acc: 0.6374 - val_loss: 116.9210 - val_acc: 0.6327\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 113.4371 - acc: 0.6349 - val_loss: 116.9326 - val_acc: 0.6276\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 112.0440 - acc: 0.6362 - val_loss: 111.2690 - val_acc: 0.6330\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 110.5679 - acc: 0.6361 - val_loss: 113.1755 - val_acc: 0.6338\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 110.4813 - acc: 0.6339 - val_loss: 111.8687 - val_acc: 0.6312\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 110.3457 - acc: 0.6342 - val_loss: 110.1092 - val_acc: 0.6299\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 109.8078 - acc: 0.6354 - val_loss: 110.5203 - val_acc: 0.6311\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 109.2126 - acc: 0.6357 - val_loss: 113.6657 - val_acc: 0.6282\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 109.8594 - acc: 0.6366 - val_loss: 113.4547 - val_acc: 0.6314\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 114.4022 - acc: 0.6359 - val_loss: 116.7250 - val_acc: 0.6289\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 112.9592 - acc: 0.6373 - val_loss: 116.4000 - val_acc: 0.6313\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 113.3417 - acc: 0.6371 - val_loss: 110.9617 - val_acc: 0.6332\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 110.0206 - acc: 0.6365 - val_loss: 114.6135 - val_acc: 0.6277\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 111.2124 - acc: 0.6356 - val_loss: 112.1523 - val_acc: 0.6287\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 109.3666 - acc: 0.6360 - val_loss: 112.1254 - val_acc: 0.6322\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 110.1327 - acc: 0.6364 - val_loss: 109.0567 - val_acc: 0.6322\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 109.3299 - acc: 0.6370 - val_loss: 109.1936 - val_acc: 0.6323\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 108.6277 - acc: 0.6337 - val_loss: 109.5067 - val_acc: 0.6281\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 109.7035 - acc: 0.6348 - val_loss: 109.7332 - val_acc: 0.6328\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 111.0996 - acc: 0.6370 - val_loss: 112.6198 - val_acc: 0.6335\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 113.0034 - acc: 0.6355 - val_loss: 110.9068 - val_acc: 0.6323\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 111.1660 - acc: 0.6373 - val_loss: 112.8322 - val_acc: 0.6308\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 112.3324 - acc: 0.6368 - val_loss: 111.2859 - val_acc: 0.6309\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 110.7340 - acc: 0.6355 - val_loss: 111.0549 - val_acc: 0.6323\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 50.7711 - acc: 0.4386 - val_loss: 47.5704 - val_acc: 0.4440\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 50.7639 - acc: 0.4379 - val_loss: 47.5606 - val_acc: 0.4437\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 50.7579 - acc: 0.4378 - val_loss: 47.5793 - val_acc: 0.4451\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 50.7460 - acc: 0.4381 - val_loss: 47.5394 - val_acc: 0.4449\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 50.7420 - acc: 0.4382 - val_loss: 47.5606 - val_acc: 0.4442\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 50.7326 - acc: 0.4379 - val_loss: 47.5279 - val_acc: 0.4443\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 50.7190 - acc: 0.4379 - val_loss: 47.5410 - val_acc: 0.4461\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 50.7086 - acc: 0.4382 - val_loss: 47.5219 - val_acc: 0.4440\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 50.7028 - acc: 0.4380 - val_loss: 47.5028 - val_acc: 0.4451\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 50.6945 - acc: 0.4383 - val_loss: 47.4913 - val_acc: 0.4445\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.6854 - acc: 0.4379 - val_loss: 47.5013 - val_acc: 0.4457\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.6792 - acc: 0.4384 - val_loss: 47.4860 - val_acc: 0.4453\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 50.6722 - acc: 0.4381 - val_loss: 47.4621 - val_acc: 0.4460\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 50.6589 - acc: 0.4384 - val_loss: 47.4861 - val_acc: 0.4450\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 50.6507 - acc: 0.4386 - val_loss: 47.4658 - val_acc: 0.4443\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 50.6424 - acc: 0.4382 - val_loss: 47.4533 - val_acc: 0.4452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 50.6303 - acc: 0.4383 - val_loss: 47.4549 - val_acc: 0.4454\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 50.6249 - acc: 0.4383 - val_loss: 47.4340 - val_acc: 0.4457\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 50.6144 - acc: 0.4384 - val_loss: 47.4373 - val_acc: 0.4452\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.6131 - acc: 0.4383 - val_loss: 47.4292 - val_acc: 0.4450\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 50.5977 - acc: 0.4379 - val_loss: 47.4114 - val_acc: 0.4470\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 50.5872 - acc: 0.4389 - val_loss: 47.4104 - val_acc: 0.4441\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 50.5804 - acc: 0.4387 - val_loss: 47.4065 - val_acc: 0.4454\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 50.5716 - acc: 0.4382 - val_loss: 47.3897 - val_acc: 0.4455\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.5629 - acc: 0.4386 - val_loss: 47.3811 - val_acc: 0.4451\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 50.5533 - acc: 0.4386 - val_loss: 47.3603 - val_acc: 0.4456\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 50.5429 - acc: 0.4384 - val_loss: 47.3668 - val_acc: 0.4460\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 50.5352 - acc: 0.4389 - val_loss: 47.3436 - val_acc: 0.4450\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 50.5270 - acc: 0.4384 - val_loss: 47.3479 - val_acc: 0.4451\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 50.5182 - acc: 0.4389 - val_loss: 47.3329 - val_acc: 0.4445\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 50.5104 - acc: 0.4386 - val_loss: 47.3247 - val_acc: 0.4452\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 50.5016 - acc: 0.4384 - val_loss: 47.3465 - val_acc: 0.4455\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 50.4901 - acc: 0.4385 - val_loss: 47.3198 - val_acc: 0.4467\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 50.4828 - acc: 0.4389 - val_loss: 47.3481 - val_acc: 0.4456\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.4740 - acc: 0.4389 - val_loss: 47.2931 - val_acc: 0.4458\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.4733 - acc: 0.4386 - val_loss: 47.2863 - val_acc: 0.4459\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 50.4569 - acc: 0.4388 - val_loss: 47.2801 - val_acc: 0.4448\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 50.4499 - acc: 0.4383 - val_loss: 47.2820 - val_acc: 0.4466\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 50.4423 - acc: 0.4392 - val_loss: 47.2643 - val_acc: 0.4451\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 50.4288 - acc: 0.4388 - val_loss: 47.2670 - val_acc: 0.4461\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 50.4229 - acc: 0.4388 - val_loss: 47.2642 - val_acc: 0.4464\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 50.4128 - acc: 0.4387 - val_loss: 47.2587 - val_acc: 0.4456\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 50.4070 - acc: 0.4390 - val_loss: 47.2349 - val_acc: 0.4454\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 50.3973 - acc: 0.4388 - val_loss: 47.2420 - val_acc: 0.4447\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 50.3864 - acc: 0.4383 - val_loss: 47.2148 - val_acc: 0.4467\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 50.3813 - acc: 0.4390 - val_loss: 47.2474 - val_acc: 0.4454\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 50.3730 - acc: 0.4383 - val_loss: 47.2045 - val_acc: 0.4457\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 50.3596 - acc: 0.4387 - val_loss: 47.1953 - val_acc: 0.4461\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.3549 - acc: 0.4390 - val_loss: 47.1901 - val_acc: 0.4449\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 50.3397 - acc: 0.4384 - val_loss: 47.1769 - val_acc: 0.4462\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4750 - acc: 0.4639 - val_loss: 0.4495 - val_acc: 0.4658\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4741 - acc: 0.4639 - val_loss: 0.4507 - val_acc: 0.4662\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.4740 - acc: 0.4640 - val_loss: 0.4491 - val_acc: 0.4650\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4736 - acc: 0.4640 - val_loss: 0.4495 - val_acc: 0.4655\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4735 - acc: 0.4640 - val_loss: 0.4491 - val_acc: 0.4653\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4734 - acc: 0.4640 - val_loss: 0.4489 - val_acc: 0.4654\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4735 - acc: 0.4640 - val_loss: 0.4486 - val_acc: 0.4657\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4736 - acc: 0.4641 - val_loss: 0.4490 - val_acc: 0.4655\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4731 - acc: 0.4640 - val_loss: 0.4499 - val_acc: 0.4644\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4740 - acc: 0.4638 - val_loss: 0.4485 - val_acc: 0.4658\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4728 - acc: 0.4642 - val_loss: 0.4483 - val_acc: 0.4655\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4728 - acc: 0.4641 - val_loss: 0.4500 - val_acc: 0.4665\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4730 - acc: 0.4642 - val_loss: 0.4481 - val_acc: 0.4657\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4725 - acc: 0.4641 - val_loss: 0.4480 - val_acc: 0.4663\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4726 - acc: 0.4642 - val_loss: 0.4480 - val_acc: 0.4655\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4724 - acc: 0.4642 - val_loss: 0.4477 - val_acc: 0.4657\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.4724 - acc: 0.4641 - val_loss: 0.4479 - val_acc: 0.4661\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4739 - acc: 0.4640 - val_loss: 0.4489 - val_acc: 0.4647\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4724 - acc: 0.4641 - val_loss: 0.4487 - val_acc: 0.4644\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4728 - acc: 0.4640 - val_loss: 0.4480 - val_acc: 0.4655\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4719 - acc: 0.4642 - val_loss: 0.4484 - val_acc: 0.4660\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4718 - acc: 0.4642 - val_loss: 0.4477 - val_acc: 0.4655\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4718 - acc: 0.4642 - val_loss: 0.4473 - val_acc: 0.4658\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4718 - acc: 0.4642 - val_loss: 0.4471 - val_acc: 0.4662\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4716 - acc: 0.4643 - val_loss: 0.4475 - val_acc: 0.4652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4719 - acc: 0.4642 - val_loss: 0.4471 - val_acc: 0.4657\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4713 - acc: 0.4642 - val_loss: 0.4482 - val_acc: 0.4668\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4717 - acc: 0.4642 - val_loss: 0.4469 - val_acc: 0.4651\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4716 - acc: 0.4641 - val_loss: 0.4466 - val_acc: 0.4658\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4710 - acc: 0.4644 - val_loss: 0.4487 - val_acc: 0.4669\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4712 - acc: 0.4643 - val_loss: 0.4467 - val_acc: 0.4659\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.4710 - acc: 0.4643 - val_loss: 0.4477 - val_acc: 0.4669\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4713 - acc: 0.4642 - val_loss: 0.4465 - val_acc: 0.4659\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4707 - acc: 0.4643 - val_loss: 0.4469 - val_acc: 0.4666\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4709 - acc: 0.4643 - val_loss: 0.4462 - val_acc: 0.4661\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.4703 - acc: 0.4644 - val_loss: 0.4464 - val_acc: 0.4665\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.4703 - acc: 0.4644 - val_loss: 0.4461 - val_acc: 0.4659\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4704 - acc: 0.4644 - val_loss: 0.4466 - val_acc: 0.4662\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.4700 - acc: 0.4643 - val_loss: 0.4460 - val_acc: 0.4660\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4697 - acc: 0.4642 - val_loss: 0.4464 - val_acc: 0.4667\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4699 - acc: 0.4644 - val_loss: 0.4461 - val_acc: 0.4656\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4711 - acc: 0.4644 - val_loss: 0.4485 - val_acc: 0.4674\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4703 - acc: 0.4642 - val_loss: 0.4454 - val_acc: 0.4660\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.4694 - acc: 0.4645 - val_loss: 0.4455 - val_acc: 0.4662\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.4692 - acc: 0.4642 - val_loss: 0.4454 - val_acc: 0.4666\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4692 - acc: 0.4644 - val_loss: 0.4452 - val_acc: 0.4663\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.4693 - acc: 0.4644 - val_loss: 0.4462 - val_acc: 0.4656\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.4692 - acc: 0.4645 - val_loss: 0.4454 - val_acc: 0.4666\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4689 - acc: 0.4645 - val_loss: 0.4450 - val_acc: 0.4661\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4689 - acc: 0.4646 - val_loss: 0.4451 - val_acc: 0.4656\n",
      "start training round 15\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 29.7479 - acc: 0.6796 - val_loss: 28.8070 - val_acc: 0.6762\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 29.3044 - acc: 0.6795 - val_loss: 30.6257 - val_acc: 0.6744\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 29.4455 - acc: 0.6799 - val_loss: 29.9250 - val_acc: 0.6747\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 30.3097 - acc: 0.6794 - val_loss: 28.9822 - val_acc: 0.6739\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 29.1432 - acc: 0.6799 - val_loss: 30.4327 - val_acc: 0.6707\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 29.5986 - acc: 0.6793 - val_loss: 30.1675 - val_acc: 0.6771\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 29.4637 - acc: 0.6796 - val_loss: 31.2594 - val_acc: 0.6681\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 29.4002 - acc: 0.6801 - val_loss: 30.7068 - val_acc: 0.6716\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 29.5351 - acc: 0.6794 - val_loss: 30.4507 - val_acc: 0.6736\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 29.9468 - acc: 0.6801 - val_loss: 29.3462 - val_acc: 0.6726\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 29.2606 - acc: 0.6792 - val_loss: 31.1459 - val_acc: 0.6695\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 29.3290 - acc: 0.6799 - val_loss: 30.6900 - val_acc: 0.6691\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 29.3928 - acc: 0.6790 - val_loss: 31.9640 - val_acc: 0.6727\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 29.7815 - acc: 0.6792 - val_loss: 29.8639 - val_acc: 0.6680\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 29.7236 - acc: 0.6804 - val_loss: 29.7997 - val_acc: 0.6720\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 29.5248 - acc: 0.6795 - val_loss: 28.9224 - val_acc: 0.6770\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 29.5281 - acc: 0.6793 - val_loss: 30.0031 - val_acc: 0.6740\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 28.9452 - acc: 0.6795 - val_loss: 29.8029 - val_acc: 0.6739\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 30.0730 - acc: 0.6789 - val_loss: 28.7682 - val_acc: 0.6743\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 29.4416 - acc: 0.6798 - val_loss: 30.4539 - val_acc: 0.6759\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 29.1150 - acc: 0.6794 - val_loss: 30.4289 - val_acc: 0.6838\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 29.9832 - acc: 0.6792 - val_loss: 28.9411 - val_acc: 0.6773\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 28.9571 - acc: 0.6793 - val_loss: 30.5237 - val_acc: 0.6729\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 30.0728 - acc: 0.6795 - val_loss: 28.3838 - val_acc: 0.6789\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 29.1893 - acc: 0.6792 - val_loss: 29.2282 - val_acc: 0.6739\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 30.2221 - acc: 0.6802 - val_loss: 28.8000 - val_acc: 0.6751\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 28.8239 - acc: 0.6797 - val_loss: 29.2539 - val_acc: 0.6757\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 29.6628 - acc: 0.6790 - val_loss: 30.0163 - val_acc: 0.6847\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 29.3937 - acc: 0.6798 - val_loss: 29.4904 - val_acc: 0.6806\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 29.6020 - acc: 0.6802 - val_loss: 29.9417 - val_acc: 0.6818\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 29.4862 - acc: 0.6804 - val_loss: 29.9097 - val_acc: 0.6820\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 29.4839 - acc: 0.6811 - val_loss: 30.8848 - val_acc: 0.6827\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 29.6178 - acc: 0.6800 - val_loss: 28.7548 - val_acc: 0.6815\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 29.8228 - acc: 0.6806 - val_loss: 28.9312 - val_acc: 0.6831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 28.7672 - acc: 0.6796 - val_loss: 29.1068 - val_acc: 0.6829\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 29.9418 - acc: 0.6798 - val_loss: 29.9705 - val_acc: 0.6854\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 29.1427 - acc: 0.6808 - val_loss: 29.8282 - val_acc: 0.6808\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 29.8569 - acc: 0.6789 - val_loss: 28.7048 - val_acc: 0.6823\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 29.4257 - acc: 0.6806 - val_loss: 29.7009 - val_acc: 0.6852\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 29.1254 - acc: 0.6802 - val_loss: 30.1948 - val_acc: 0.6854\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 30.0279 - acc: 0.6809 - val_loss: 28.4196 - val_acc: 0.6823\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 28.9555 - acc: 0.6796 - val_loss: 28.4277 - val_acc: 0.6826\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 29.9679 - acc: 0.6803 - val_loss: 28.4889 - val_acc: 0.6842\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 29.2741 - acc: 0.6803 - val_loss: 28.6964 - val_acc: 0.6833\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 29.2733 - acc: 0.6803 - val_loss: 30.0861 - val_acc: 0.6857\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 29.2637 - acc: 0.6797 - val_loss: 29.9652 - val_acc: 0.6792\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 29.5507 - acc: 0.6802 - val_loss: 29.6392 - val_acc: 0.6848\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 29.3998 - acc: 0.6808 - val_loss: 29.2205 - val_acc: 0.6834\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 29.3038 - acc: 0.6803 - val_loss: 28.0796 - val_acc: 0.6819\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 28.8934 - acc: 0.6798 - val_loss: 28.8378 - val_acc: 0.6824\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 110.5492 - acc: 0.6378 - val_loss: 112.4521 - val_acc: 0.6327\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 111.0065 - acc: 0.6355 - val_loss: 111.5096 - val_acc: 0.6300\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 110.4706 - acc: 0.6366 - val_loss: 112.5254 - val_acc: 0.6320\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 110.8009 - acc: 0.6380 - val_loss: 112.1131 - val_acc: 0.6338\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 110.7704 - acc: 0.6368 - val_loss: 113.7112 - val_acc: 0.6320\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 110.7614 - acc: 0.6330 - val_loss: 108.8123 - val_acc: 0.6318\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 109.0781 - acc: 0.6372 - val_loss: 111.4373 - val_acc: 0.6332\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 110.4452 - acc: 0.6370 - val_loss: 112.8436 - val_acc: 0.6315\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 112.4339 - acc: 0.6379 - val_loss: 111.7484 - val_acc: 0.6339\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 361us/step - loss: 110.5396 - acc: 0.6367 - val_loss: 113.3519 - val_acc: 0.6299\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 109.4832 - acc: 0.6364 - val_loss: 110.5793 - val_acc: 0.6309\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 110.7776 - acc: 0.6377 - val_loss: 113.0720 - val_acc: 0.6328\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 112.2667 - acc: 0.6380 - val_loss: 110.1687 - val_acc: 0.6315\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 110.3374 - acc: 0.6306 - val_loss: 108.8180 - val_acc: 0.6313\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 108.3514 - acc: 0.6350 - val_loss: 111.5855 - val_acc: 0.6309\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 109.1292 - acc: 0.6362 - val_loss: 110.4805 - val_acc: 0.6290\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 108.9731 - acc: 0.6335 - val_loss: 107.7794 - val_acc: 0.6333\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 110.3789 - acc: 0.6378 - val_loss: 113.7839 - val_acc: 0.6333\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 113.7270 - acc: 0.6375 - val_loss: 112.9039 - val_acc: 0.6329\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 112.4028 - acc: 0.6377 - val_loss: 110.1387 - val_acc: 0.6334\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 109.6236 - acc: 0.6342 - val_loss: 112.3657 - val_acc: 0.6248\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 109.5987 - acc: 0.6358 - val_loss: 110.8000 - val_acc: 0.6309\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 107.8052 - acc: 0.6376 - val_loss: 109.4321 - val_acc: 0.6323\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 110.3688 - acc: 0.6353 - val_loss: 110.4866 - val_acc: 0.6336\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 111.5335 - acc: 0.6381 - val_loss: 112.2216 - val_acc: 0.6325\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 113.3078 - acc: 0.6372 - val_loss: 113.9850 - val_acc: 0.6337\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 112.2687 - acc: 0.6376 - val_loss: 114.7560 - val_acc: 0.6327\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 111.5239 - acc: 0.6367 - val_loss: 113.1132 - val_acc: 0.6307\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 109.4566 - acc: 0.6353 - val_loss: 110.2230 - val_acc: 0.6298\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 110.2340 - acc: 0.6345 - val_loss: 114.6071 - val_acc: 0.6306\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 111.2144 - acc: 0.6374 - val_loss: 111.0410 - val_acc: 0.6329\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 111.5401 - acc: 0.6375 - val_loss: 110.0658 - val_acc: 0.6343\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 110.8901 - acc: 0.6363 - val_loss: 109.3263 - val_acc: 0.6315\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 109.4856 - acc: 0.6367 - val_loss: 108.3753 - val_acc: 0.6319\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 109.1981 - acc: 0.6358 - val_loss: 112.7786 - val_acc: 0.6240\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 109.1699 - acc: 0.6349 - val_loss: 111.5878 - val_acc: 0.6303\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 108.7143 - acc: 0.6368 - val_loss: 110.1494 - val_acc: 0.6325\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 109.2788 - acc: 0.6337 - val_loss: 110.4744 - val_acc: 0.6320\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 110.7314 - acc: 0.6375 - val_loss: 111.0201 - val_acc: 0.6320\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 111.0778 - acc: 0.6377 - val_loss: 114.9559 - val_acc: 0.6324\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 112.6338 - acc: 0.6376 - val_loss: 111.5592 - val_acc: 0.6341\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 110.1101 - acc: 0.6384 - val_loss: 110.1322 - val_acc: 0.6326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 108.7421 - acc: 0.6380 - val_loss: 113.6804 - val_acc: 0.6286\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 111.7634 - acc: 0.6366 - val_loss: 113.0377 - val_acc: 0.6334\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 111.7845 - acc: 0.6384 - val_loss: 110.8675 - val_acc: 0.6310\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 109.4732 - acc: 0.6363 - val_loss: 109.4197 - val_acc: 0.6325\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 108.4056 - acc: 0.6340 - val_loss: 113.6451 - val_acc: 0.6195\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 108.2850 - acc: 0.6346 - val_loss: 110.1876 - val_acc: 0.6328\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 108.1843 - acc: 0.6377 - val_loss: 109.1140 - val_acc: 0.6332\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 109.8958 - acc: 0.6379 - val_loss: 116.6430 - val_acc: 0.6327\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 50.3322 - acc: 0.4389 - val_loss: 47.1783 - val_acc: 0.4459\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 50.3252 - acc: 0.4387 - val_loss: 47.1602 - val_acc: 0.4458\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 50.3135 - acc: 0.4387 - val_loss: 47.1554 - val_acc: 0.4457\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.3043 - acc: 0.4390 - val_loss: 47.1538 - val_acc: 0.4452\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 50.2983 - acc: 0.4385 - val_loss: 47.1561 - val_acc: 0.4465\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 50.2897 - acc: 0.4390 - val_loss: 47.1317 - val_acc: 0.4462\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 50.2838 - acc: 0.4389 - val_loss: 47.1205 - val_acc: 0.4454\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 50.2726 - acc: 0.4386 - val_loss: 47.1139 - val_acc: 0.4456\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 50.2631 - acc: 0.4388 - val_loss: 47.1061 - val_acc: 0.4451\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 50.2553 - acc: 0.4384 - val_loss: 47.1159 - val_acc: 0.4469\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.2472 - acc: 0.4389 - val_loss: 47.0954 - val_acc: 0.4458\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 50.2372 - acc: 0.4387 - val_loss: 47.0930 - val_acc: 0.4455\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 50.2289 - acc: 0.4389 - val_loss: 47.0719 - val_acc: 0.4446\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 50.2236 - acc: 0.4384 - val_loss: 47.0720 - val_acc: 0.4448\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 50.2051 - acc: 0.4384 - val_loss: 47.0705 - val_acc: 0.4462\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 50.2056 - acc: 0.4391 - val_loss: 47.0722 - val_acc: 0.4453\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 50.1961 - acc: 0.4384 - val_loss: 47.0320 - val_acc: 0.4459\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 50.1840 - acc: 0.4391 - val_loss: 47.0341 - val_acc: 0.4446\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.1760 - acc: 0.4384 - val_loss: 47.0316 - val_acc: 0.4460\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 50.1676 - acc: 0.4389 - val_loss: 47.0137 - val_acc: 0.4464\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 50.1570 - acc: 0.4388 - val_loss: 47.0097 - val_acc: 0.4464\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 50.1476 - acc: 0.4390 - val_loss: 47.0141 - val_acc: 0.4458\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 50.1454 - acc: 0.4387 - val_loss: 47.0024 - val_acc: 0.4454\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 50.1316 - acc: 0.4389 - val_loss: 47.0132 - val_acc: 0.4461\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 50.1253 - acc: 0.4387 - val_loss: 47.0019 - val_acc: 0.4455\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 50.1122 - acc: 0.4388 - val_loss: 46.9660 - val_acc: 0.4461\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 50.1061 - acc: 0.4386 - val_loss: 46.9657 - val_acc: 0.4466\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 50.0935 - acc: 0.4390 - val_loss: 46.9534 - val_acc: 0.4460\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 50.0880 - acc: 0.4388 - val_loss: 46.9745 - val_acc: 0.4462\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 50.0835 - acc: 0.4391 - val_loss: 46.9495 - val_acc: 0.4449\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 50.0727 - acc: 0.4386 - val_loss: 46.9462 - val_acc: 0.4450\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 50.0586 - acc: 0.4391 - val_loss: 46.9326 - val_acc: 0.4450\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 50.0554 - acc: 0.4383 - val_loss: 46.9112 - val_acc: 0.4461\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 50.0376 - acc: 0.4389 - val_loss: 46.9093 - val_acc: 0.4457\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 50.0267 - acc: 0.4388 - val_loss: 46.9042 - val_acc: 0.4455\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 50.0222 - acc: 0.4384 - val_loss: 46.8997 - val_acc: 0.4466\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 50.0189 - acc: 0.4393 - val_loss: 46.8762 - val_acc: 0.4454\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 50.0061 - acc: 0.4386 - val_loss: 46.8796 - val_acc: 0.4456\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 49.9983 - acc: 0.4390 - val_loss: 46.8612 - val_acc: 0.4452\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 49.9912 - acc: 0.4386 - val_loss: 46.8573 - val_acc: 0.4462\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 49.9818 - acc: 0.4390 - val_loss: 46.8687 - val_acc: 0.4453\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 49.9716 - acc: 0.4386 - val_loss: 46.8562 - val_acc: 0.4465\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 49.9609 - acc: 0.4393 - val_loss: 46.8378 - val_acc: 0.4456\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 49.9517 - acc: 0.4390 - val_loss: 46.8575 - val_acc: 0.4454\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 49.9487 - acc: 0.4388 - val_loss: 46.8264 - val_acc: 0.4460\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 49.9358 - acc: 0.4387 - val_loss: 46.8152 - val_acc: 0.4463\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 49.9307 - acc: 0.4390 - val_loss: 46.8283 - val_acc: 0.4458\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 49.9207 - acc: 0.4388 - val_loss: 46.8180 - val_acc: 0.4461\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 49.9085 - acc: 0.4391 - val_loss: 46.7867 - val_acc: 0.4456\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 49.8949 - acc: 0.4391 - val_loss: 46.7790 - val_acc: 0.4459\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4698 - acc: 0.4645 - val_loss: 0.4450 - val_acc: 0.4661\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4686 - acc: 0.4645 - val_loss: 0.4453 - val_acc: 0.4660\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4686 - acc: 0.4648 - val_loss: 0.4448 - val_acc: 0.4659\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.4688 - acc: 0.4647 - val_loss: 0.4446 - val_acc: 0.4659\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4686 - acc: 0.4645 - val_loss: 0.4447 - val_acc: 0.4668\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4681 - acc: 0.4645 - val_loss: 0.4447 - val_acc: 0.4664\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4683 - acc: 0.4645 - val_loss: 0.4443 - val_acc: 0.4659\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4686 - acc: 0.4646 - val_loss: 0.4443 - val_acc: 0.4659\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.4693 - acc: 0.4645 - val_loss: 0.4445 - val_acc: 0.4664\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.4679 - acc: 0.4648 - val_loss: 0.4456 - val_acc: 0.4666\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.4682 - acc: 0.4641 - val_loss: 0.4440 - val_acc: 0.4665\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.4681 - acc: 0.4642 - val_loss: 0.4440 - val_acc: 0.4661\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.4676 - acc: 0.4647 - val_loss: 0.4441 - val_acc: 0.4664\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4673 - acc: 0.4644 - val_loss: 0.4438 - val_acc: 0.4658\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4673 - acc: 0.4649 - val_loss: 0.4436 - val_acc: 0.4665\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4678 - acc: 0.4649 - val_loss: 0.4439 - val_acc: 0.4666\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4670 - acc: 0.4646 - val_loss: 0.4434 - val_acc: 0.4661\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.4671 - acc: 0.4647 - val_loss: 0.4437 - val_acc: 0.4659\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4667 - acc: 0.4648 - val_loss: 0.4432 - val_acc: 0.4658\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4672 - acc: 0.4639 - val_loss: 0.4434 - val_acc: 0.4667\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4666 - acc: 0.4648 - val_loss: 0.4437 - val_acc: 0.4672\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4665 - acc: 0.4648 - val_loss: 0.4431 - val_acc: 0.4667\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.4665 - acc: 0.4649 - val_loss: 0.4431 - val_acc: 0.4673\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.4667 - acc: 0.4650 - val_loss: 0.4436 - val_acc: 0.4668\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.4663 - acc: 0.4649 - val_loss: 0.4427 - val_acc: 0.4658\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.4667 - acc: 0.4646 - val_loss: 0.4429 - val_acc: 0.4669\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4661 - acc: 0.4648 - val_loss: 0.4437 - val_acc: 0.4655\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4663 - acc: 0.4649 - val_loss: 0.4432 - val_acc: 0.4673\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4661 - acc: 0.4649 - val_loss: 0.4429 - val_acc: 0.4670\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4658 - acc: 0.4649 - val_loss: 0.4423 - val_acc: 0.4660\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4660 - acc: 0.4644 - val_loss: 0.4423 - val_acc: 0.4665\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 466us/step - loss: 0.4657 - acc: 0.4648 - val_loss: 0.4443 - val_acc: 0.4678\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.4657 - acc: 0.4654 - val_loss: 0.4471 - val_acc: 0.4675\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4658 - acc: 0.4645 - val_loss: 0.4433 - val_acc: 0.4673\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.4658 - acc: 0.4650 - val_loss: 0.4423 - val_acc: 0.4668\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4651 - acc: 0.4647 - val_loss: 0.4419 - val_acc: 0.4666\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4650 - acc: 0.4651 - val_loss: 0.4424 - val_acc: 0.4659\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.4650 - acc: 0.4644 - val_loss: 0.4434 - val_acc: 0.4669\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4650 - acc: 0.4645 - val_loss: 0.4428 - val_acc: 0.4669\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4652 - acc: 0.4649 - val_loss: 0.4424 - val_acc: 0.4657\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.4651 - acc: 0.4652 - val_loss: 0.4429 - val_acc: 0.4652\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.4646 - acc: 0.4642 - val_loss: 0.4413 - val_acc: 0.4664\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.4644 - acc: 0.4649 - val_loss: 0.4411 - val_acc: 0.4668\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 469us/step - loss: 0.4645 - acc: 0.4644 - val_loss: 0.4418 - val_acc: 0.4665\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.4643 - acc: 0.4646 - val_loss: 0.4413 - val_acc: 0.4670\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 476us/step - loss: 0.4651 - acc: 0.4651 - val_loss: 0.4408 - val_acc: 0.4662\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4639 - acc: 0.4648 - val_loss: 0.4413 - val_acc: 0.4668\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4639 - acc: 0.4645 - val_loss: 0.4407 - val_acc: 0.4665\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4640 - acc: 0.4651 - val_loss: 0.4417 - val_acc: 0.4656\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4637 - acc: 0.4648 - val_loss: 0.4413 - val_acc: 0.4659\n",
      "start training round 16\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 29.2093 - acc: 0.6793 - val_loss: 27.8233 - val_acc: 0.6770\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 29.4407 - acc: 0.6793 - val_loss: 30.3226 - val_acc: 0.6719\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 29.3870 - acc: 0.6795 - val_loss: 30.3424 - val_acc: 0.6714\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 29.3559 - acc: 0.6801 - val_loss: 29.8872 - val_acc: 0.6778\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 29.4274 - acc: 0.6790 - val_loss: 30.8640 - val_acc: 0.6737\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 29.1601 - acc: 0.6811 - val_loss: 29.7726 - val_acc: 0.6698\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 29.1464 - acc: 0.6795 - val_loss: 30.2076 - val_acc: 0.6676\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 30.0046 - acc: 0.6805 - val_loss: 28.6409 - val_acc: 0.6756\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 28.7643 - acc: 0.6803 - val_loss: 30.7873 - val_acc: 0.6668\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 414us/step - loss: 29.9501 - acc: 0.6800 - val_loss: 29.6574 - val_acc: 0.6731\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 28.9317 - acc: 0.6799 - val_loss: 28.9590 - val_acc: 0.6745\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 29.3530 - acc: 0.6805 - val_loss: 28.8040 - val_acc: 0.6714\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 29.2988 - acc: 0.6805 - val_loss: 28.9369 - val_acc: 0.6782\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 28.6939 - acc: 0.6799 - val_loss: 28.1460 - val_acc: 0.6795\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 30.0092 - acc: 0.6788 - val_loss: 29.3321 - val_acc: 0.6837\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 28.8635 - acc: 0.6813 - val_loss: 28.4270 - val_acc: 0.6809\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 29.2366 - acc: 0.6789 - val_loss: 29.0317 - val_acc: 0.6809\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 29.8087 - acc: 0.6800 - val_loss: 30.4714 - val_acc: 0.6849\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 29.3601 - acc: 0.6804 - val_loss: 30.2127 - val_acc: 0.6821\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 29.6075 - acc: 0.6810 - val_loss: 28.5166 - val_acc: 0.6823\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 29.1787 - acc: 0.6810 - val_loss: 30.8752 - val_acc: 0.6837\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 30.1204 - acc: 0.6803 - val_loss: 28.1308 - val_acc: 0.6822\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 29.1068 - acc: 0.6810 - val_loss: 30.0329 - val_acc: 0.6846\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 29.3597 - acc: 0.6811 - val_loss: 29.0029 - val_acc: 0.6836\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 29.2243 - acc: 0.6809 - val_loss: 28.5687 - val_acc: 0.6813\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 29.0627 - acc: 0.6807 - val_loss: 27.8771 - val_acc: 0.6831\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 28.5329 - acc: 0.6800 - val_loss: 29.0010 - val_acc: 0.6746\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 29.8354 - acc: 0.6793 - val_loss: 28.7516 - val_acc: 0.6749\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 28.8867 - acc: 0.6796 - val_loss: 29.3659 - val_acc: 0.6704\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 29.5210 - acc: 0.6798 - val_loss: 29.8908 - val_acc: 0.6765\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 29.3128 - acc: 0.6812 - val_loss: 28.3578 - val_acc: 0.6784\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 28.8225 - acc: 0.6801 - val_loss: 29.2129 - val_acc: 0.6739\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 29.4681 - acc: 0.6813 - val_loss: 27.8449 - val_acc: 0.6782\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 28.3617 - acc: 0.6796 - val_loss: 28.7960 - val_acc: 0.6728\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 29.2427 - acc: 0.6795 - val_loss: 31.8453 - val_acc: 0.6687\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 29.8616 - acc: 0.6799 - val_loss: 29.0014 - val_acc: 0.6761\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 29.3627 - acc: 0.6805 - val_loss: 29.8952 - val_acc: 0.6725\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 29.1210 - acc: 0.6809 - val_loss: 28.5929 - val_acc: 0.6773\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 28.9234 - acc: 0.6802 - val_loss: 29.9615 - val_acc: 0.6842\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 29.1561 - acc: 0.6807 - val_loss: 29.5167 - val_acc: 0.6833\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 29.0857 - acc: 0.6804 - val_loss: 29.3385 - val_acc: 0.6841\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 29.0543 - acc: 0.6802 - val_loss: 27.8165 - val_acc: 0.6805\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 29.0285 - acc: 0.6797 - val_loss: 29.0764 - val_acc: 0.6831\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 29.5548 - acc: 0.6804 - val_loss: 30.0561 - val_acc: 0.6842\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 29.4818 - acc: 0.6815 - val_loss: 35.0997 - val_acc: 0.6830\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 29.9046 - acc: 0.6811 - val_loss: 28.7835 - val_acc: 0.6839\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 28.9737 - acc: 0.6814 - val_loss: 28.6933 - val_acc: 0.6817\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 29.1520 - acc: 0.6805 - val_loss: 29.6365 - val_acc: 0.6811\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 28.9984 - acc: 0.6803 - val_loss: 30.6466 - val_acc: 0.6863\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 29.0845 - acc: 0.6810 - val_loss: 29.7871 - val_acc: 0.6845\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 112.5327 - acc: 0.6367 - val_loss: 111.7140 - val_acc: 0.6306\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 111.1980 - acc: 0.6359 - val_loss: 110.2357 - val_acc: 0.6336\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 111.3730 - acc: 0.6381 - val_loss: 115.5120 - val_acc: 0.6312\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 111.2657 - acc: 0.6370 - val_loss: 119.1164 - val_acc: 0.6304\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 112.0553 - acc: 0.6381 - val_loss: 111.3274 - val_acc: 0.6330\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 108.0755 - acc: 0.6376 - val_loss: 112.0688 - val_acc: 0.6310\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 111.2662 - acc: 0.6346 - val_loss: 110.0659 - val_acc: 0.6307\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 109.3817 - acc: 0.6354 - val_loss: 112.2616 - val_acc: 0.6330\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 110.2500 - acc: 0.6383 - val_loss: 113.8620 - val_acc: 0.6317\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 109.6215 - acc: 0.6357 - val_loss: 107.8391 - val_acc: 0.6331\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 107.6666 - acc: 0.6368 - val_loss: 114.6305 - val_acc: 0.6223\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 109.2228 - acc: 0.6347 - val_loss: 109.3372 - val_acc: 0.6331\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 109.7119 - acc: 0.6388 - val_loss: 118.2408 - val_acc: 0.6316\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 115.2196 - acc: 0.6371 - val_loss: 108.9306 - val_acc: 0.6327\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 109.0152 - acc: 0.6356 - val_loss: 109.2875 - val_acc: 0.6331\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 107.8885 - acc: 0.6368 - val_loss: 109.4668 - val_acc: 0.6305\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 108.2485 - acc: 0.6356 - val_loss: 113.1279 - val_acc: 0.6256\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 411us/step - loss: 109.9370 - acc: 0.6366 - val_loss: 111.1713 - val_acc: 0.6319\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 110.6609 - acc: 0.6375 - val_loss: 109.4150 - val_acc: 0.6335\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 109.0921 - acc: 0.6371 - val_loss: 112.0745 - val_acc: 0.6274\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 108.7020 - acc: 0.6357 - val_loss: 111.0244 - val_acc: 0.6319\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 109.2260 - acc: 0.6377 - val_loss: 111.8823 - val_acc: 0.6338\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 110.2673 - acc: 0.6382 - val_loss: 117.7059 - val_acc: 0.6265\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 111.6051 - acc: 0.6364 - val_loss: 115.1749 - val_acc: 0.6318\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 111.9061 - acc: 0.6389 - val_loss: 112.3999 - val_acc: 0.6334\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 110.1509 - acc: 0.6369 - val_loss: 114.5557 - val_acc: 0.6312\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 111.0040 - acc: 0.6374 - val_loss: 107.9687 - val_acc: 0.6334\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 109.9187 - acc: 0.6362 - val_loss: 109.4256 - val_acc: 0.6308\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 108.7195 - acc: 0.6353 - val_loss: 110.2829 - val_acc: 0.6303\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 107.6153 - acc: 0.6380 - val_loss: 107.8998 - val_acc: 0.6334\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 107.6794 - acc: 0.6376 - val_loss: 108.3782 - val_acc: 0.6322\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 108.3594 - acc: 0.6374 - val_loss: 110.9899 - val_acc: 0.6304\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 108.7707 - acc: 0.6358 - val_loss: 109.6461 - val_acc: 0.6262\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 108.0680 - acc: 0.6348 - val_loss: 108.9440 - val_acc: 0.6311\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 109.7209 - acc: 0.6367 - val_loss: 109.6009 - val_acc: 0.6337\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 111.3900 - acc: 0.6371 - val_loss: 115.0461 - val_acc: 0.6332\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 111.8691 - acc: 0.6391 - val_loss: 111.4376 - val_acc: 0.6332\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 109.7566 - acc: 0.6371 - val_loss: 108.6124 - val_acc: 0.6330\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 108.5149 - acc: 0.6381 - val_loss: 109.0634 - val_acc: 0.6338\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 109.7768 - acc: 0.6378 - val_loss: 109.4256 - val_acc: 0.6329\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 108.3551 - acc: 0.6343 - val_loss: 109.2376 - val_acc: 0.6259\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 108.1841 - acc: 0.6360 - val_loss: 110.5467 - val_acc: 0.6338\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 109.8919 - acc: 0.6389 - val_loss: 118.1102 - val_acc: 0.6341\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 113.7024 - acc: 0.6389 - val_loss: 111.7092 - val_acc: 0.6345\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 110.4606 - acc: 0.6387 - val_loss: 114.5218 - val_acc: 0.6333\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 110.7443 - acc: 0.6377 - val_loss: 110.5717 - val_acc: 0.6299\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 110.2753 - acc: 0.6351 - val_loss: 110.2940 - val_acc: 0.6344\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 108.6573 - acc: 0.6387 - val_loss: 112.1148 - val_acc: 0.6299\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 107.6574 - acc: 0.6375 - val_loss: 107.9770 - val_acc: 0.6335\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 108.0347 - acc: 0.6379 - val_loss: 112.0982 - val_acc: 0.6331\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 49.8921 - acc: 0.4385 - val_loss: 46.7809 - val_acc: 0.4471\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 49.8851 - acc: 0.4391 - val_loss: 46.7589 - val_acc: 0.4461\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 49.8717 - acc: 0.4388 - val_loss: 46.7589 - val_acc: 0.4469\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 49.8663 - acc: 0.4389 - val_loss: 46.7598 - val_acc: 0.4459\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 49.8596 - acc: 0.4392 - val_loss: 46.7362 - val_acc: 0.4453\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 49.8464 - acc: 0.4386 - val_loss: 46.7709 - val_acc: 0.4454\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 49.8446 - acc: 0.4387 - val_loss: 46.7417 - val_acc: 0.4454\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 49.8245 - acc: 0.4389 - val_loss: 46.7156 - val_acc: 0.4462\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 49.8319 - acc: 0.4388 - val_loss: 46.7222 - val_acc: 0.4466\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 49.8155 - acc: 0.4390 - val_loss: 46.7084 - val_acc: 0.4457\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 49.8067 - acc: 0.4393 - val_loss: 46.6948 - val_acc: 0.4450\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 49.7961 - acc: 0.4383 - val_loss: 46.6802 - val_acc: 0.4466\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 49.7876 - acc: 0.4389 - val_loss: 46.6717 - val_acc: 0.4460\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 49.7766 - acc: 0.4390 - val_loss: 46.6795 - val_acc: 0.4461\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 49.7679 - acc: 0.4388 - val_loss: 46.6542 - val_acc: 0.4459\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 49.7523 - acc: 0.4394 - val_loss: 46.6818 - val_acc: 0.4454\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 49.7486 - acc: 0.4386 - val_loss: 46.6576 - val_acc: 0.4464\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 49.7353 - acc: 0.4392 - val_loss: 46.6418 - val_acc: 0.4456\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 49.7285 - acc: 0.4392 - val_loss: 46.6441 - val_acc: 0.4454\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 49.7245 - acc: 0.4386 - val_loss: 46.6040 - val_acc: 0.4461\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 49.7168 - acc: 0.4390 - val_loss: 46.6190 - val_acc: 0.4463\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 49.6992 - acc: 0.4392 - val_loss: 46.5957 - val_acc: 0.4456\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 49.6967 - acc: 0.4389 - val_loss: 46.5853 - val_acc: 0.4458\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 49.6840 - acc: 0.4391 - val_loss: 46.6153 - val_acc: 0.4456\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 49.6780 - acc: 0.4389 - val_loss: 46.5778 - val_acc: 0.4454\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 435us/step - loss: 49.6721 - acc: 0.4388 - val_loss: 46.5645 - val_acc: 0.4466\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 49.6631 - acc: 0.4393 - val_loss: 46.5643 - val_acc: 0.4465\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 49.6524 - acc: 0.4390 - val_loss: 46.5684 - val_acc: 0.4463\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 49.6463 - acc: 0.4391 - val_loss: 46.5495 - val_acc: 0.4453\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 49.6319 - acc: 0.4385 - val_loss: 46.5364 - val_acc: 0.4466\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 49.6163 - acc: 0.4394 - val_loss: 46.5297 - val_acc: 0.4461\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 49.6195 - acc: 0.4388 - val_loss: 46.5358 - val_acc: 0.4464\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 49.6017 - acc: 0.4395 - val_loss: 46.5465 - val_acc: 0.4458\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 49.5969 - acc: 0.4386 - val_loss: 46.4929 - val_acc: 0.4464\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 49.5900 - acc: 0.4391 - val_loss: 46.4904 - val_acc: 0.4466\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 49.5714 - acc: 0.4397 - val_loss: 46.5137 - val_acc: 0.4447\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 49.5616 - acc: 0.4388 - val_loss: 46.4988 - val_acc: 0.4461\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 49.5603 - acc: 0.4394 - val_loss: 46.4806 - val_acc: 0.4451\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 49.5531 - acc: 0.4388 - val_loss: 46.4559 - val_acc: 0.4453\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 49.5365 - acc: 0.4387 - val_loss: 46.4792 - val_acc: 0.4464\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 49.5296 - acc: 0.4393 - val_loss: 46.4759 - val_acc: 0.4466\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 49.5250 - acc: 0.4393 - val_loss: 46.4307 - val_acc: 0.4463\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 409us/step - loss: 49.5208 - acc: 0.4394 - val_loss: 46.4436 - val_acc: 0.4468\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 49.5051 - acc: 0.4395 - val_loss: 46.4270 - val_acc: 0.4462\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 49.4903 - acc: 0.4393 - val_loss: 46.4217 - val_acc: 0.4458\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 49.4852 - acc: 0.4391 - val_loss: 46.4200 - val_acc: 0.4464\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 49.4764 - acc: 0.4392 - val_loss: 46.3960 - val_acc: 0.4463\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 49.4646 - acc: 0.4392 - val_loss: 46.3849 - val_acc: 0.4463\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 49.4607 - acc: 0.4396 - val_loss: 46.3684 - val_acc: 0.4453\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 49.4479 - acc: 0.4390 - val_loss: 46.3761 - val_acc: 0.4462\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4636 - acc: 0.4646 - val_loss: 0.4408 - val_acc: 0.4665\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4634 - acc: 0.4651 - val_loss: 0.4404 - val_acc: 0.4667\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4640 - acc: 0.4652 - val_loss: 0.4438 - val_acc: 0.4652\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4638 - acc: 0.4647 - val_loss: 0.4403 - val_acc: 0.4669\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4637 - acc: 0.4651 - val_loss: 0.4400 - val_acc: 0.4664\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4630 - acc: 0.4650 - val_loss: 0.4401 - val_acc: 0.4665\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4633 - acc: 0.4650 - val_loss: 0.4402 - val_acc: 0.4665\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4629 - acc: 0.4644 - val_loss: 0.4402 - val_acc: 0.4667\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4627 - acc: 0.4651 - val_loss: 0.4400 - val_acc: 0.4664\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4626 - acc: 0.4648 - val_loss: 0.4397 - val_acc: 0.4662\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4631 - acc: 0.4650 - val_loss: 0.4399 - val_acc: 0.4661\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.4629 - acc: 0.4651 - val_loss: 0.4396 - val_acc: 0.4659\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.4627 - acc: 0.4646 - val_loss: 0.4398 - val_acc: 0.4671\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.4624 - acc: 0.4650 - val_loss: 0.4397 - val_acc: 0.4670\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4626 - acc: 0.4647 - val_loss: 0.4399 - val_acc: 0.4662\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4621 - acc: 0.4653 - val_loss: 0.4396 - val_acc: 0.4664\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4623 - acc: 0.4649 - val_loss: 0.4396 - val_acc: 0.4669\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4620 - acc: 0.4650 - val_loss: 0.4395 - val_acc: 0.4670\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4621 - acc: 0.4651 - val_loss: 0.4400 - val_acc: 0.4658\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4620 - acc: 0.4651 - val_loss: 0.4393 - val_acc: 0.4671\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4616 - acc: 0.4650 - val_loss: 0.4391 - val_acc: 0.4671\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4620 - acc: 0.4651 - val_loss: 0.4388 - val_acc: 0.4670\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4621 - acc: 0.4648 - val_loss: 0.4406 - val_acc: 0.4674\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4620 - acc: 0.4651 - val_loss: 0.4386 - val_acc: 0.4667\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4615 - acc: 0.4651 - val_loss: 0.4394 - val_acc: 0.4661\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4612 - acc: 0.4654 - val_loss: 0.4393 - val_acc: 0.4660\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.4614 - acc: 0.4650 - val_loss: 0.4385 - val_acc: 0.4670\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4610 - acc: 0.4653 - val_loss: 0.4387 - val_acc: 0.4674\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4617 - acc: 0.4648 - val_loss: 0.4393 - val_acc: 0.4673\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4608 - acc: 0.4656 - val_loss: 0.4382 - val_acc: 0.4669\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4607 - acc: 0.4649 - val_loss: 0.4382 - val_acc: 0.4668\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4606 - acc: 0.4652 - val_loss: 0.4379 - val_acc: 0.4671\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4605 - acc: 0.4652 - val_loss: 0.4388 - val_acc: 0.4666\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.4612 - acc: 0.4650 - val_loss: 0.4386 - val_acc: 0.4680\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4606 - acc: 0.4657 - val_loss: 0.4378 - val_acc: 0.4666\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4601 - acc: 0.4651 - val_loss: 0.4378 - val_acc: 0.4667\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.4601 - acc: 0.4653 - val_loss: 0.4380 - val_acc: 0.4673\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4600 - acc: 0.4645 - val_loss: 0.4382 - val_acc: 0.4677\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4601 - acc: 0.4648 - val_loss: 0.4374 - val_acc: 0.4669\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4599 - acc: 0.4651 - val_loss: 0.4376 - val_acc: 0.4667\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4597 - acc: 0.4649 - val_loss: 0.4373 - val_acc: 0.4672\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4596 - acc: 0.4657 - val_loss: 0.4371 - val_acc: 0.4673\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.4603 - acc: 0.4651 - val_loss: 0.4371 - val_acc: 0.4670\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4595 - acc: 0.4652 - val_loss: 0.4370 - val_acc: 0.4673\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.4593 - acc: 0.4651 - val_loss: 0.4375 - val_acc: 0.4674\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.4592 - acc: 0.4649 - val_loss: 0.4369 - val_acc: 0.4675\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.4590 - acc: 0.4649 - val_loss: 0.4371 - val_acc: 0.4672\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.4593 - acc: 0.4648 - val_loss: 0.4368 - val_acc: 0.4674\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4590 - acc: 0.4650 - val_loss: 0.4385 - val_acc: 0.4668\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4592 - acc: 0.4648 - val_loss: 0.4369 - val_acc: 0.4678\n",
      "start training round 17\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 28.9461 - acc: 0.6804 - val_loss: 29.5134 - val_acc: 0.6807\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 29.4943 - acc: 0.6813 - val_loss: 29.8474 - val_acc: 0.6802\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 28.6523 - acc: 0.6807 - val_loss: 29.1090 - val_acc: 0.6825\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 28.7517 - acc: 0.6806 - val_loss: 29.0344 - val_acc: 0.6724\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 29.5743 - acc: 0.6796 - val_loss: 29.2431 - val_acc: 0.6764\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 29.1344 - acc: 0.6802 - val_loss: 30.3164 - val_acc: 0.6757\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 29.5490 - acc: 0.6808 - val_loss: 29.9387 - val_acc: 0.6726\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 28.3470 - acc: 0.6809 - val_loss: 29.2542 - val_acc: 0.6718\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 29.2371 - acc: 0.6811 - val_loss: 28.2611 - val_acc: 0.6775\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 28.2391 - acc: 0.6801 - val_loss: 28.1938 - val_acc: 0.6807\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 29.7052 - acc: 0.6789 - val_loss: 28.3384 - val_acc: 0.6826\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 29.3015 - acc: 0.6815 - val_loss: 28.7153 - val_acc: 0.6838\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 28.9178 - acc: 0.6816 - val_loss: 30.4623 - val_acc: 0.6836\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 28.7246 - acc: 0.6797 - val_loss: 28.5081 - val_acc: 0.6827\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 28.9212 - acc: 0.6798 - val_loss: 31.6964 - val_acc: 0.6837\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 29.7358 - acc: 0.6808 - val_loss: 28.6190 - val_acc: 0.6819\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 28.8594 - acc: 0.6814 - val_loss: 30.0045 - val_acc: 0.6709\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 28.6798 - acc: 0.6798 - val_loss: 31.1055 - val_acc: 0.6666\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 29.4555 - acc: 0.6809 - val_loss: 28.9630 - val_acc: 0.6806\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 29.3536 - acc: 0.6804 - val_loss: 28.6404 - val_acc: 0.6829\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 29.6552 - acc: 0.6810 - val_loss: 28.8106 - val_acc: 0.6812\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 29.1217 - acc: 0.6809 - val_loss: 28.4546 - val_acc: 0.6803\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.3134 - acc: 0.6809 - val_loss: 28.0648 - val_acc: 0.6764\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 29.2606 - acc: 0.6795 - val_loss: 29.1613 - val_acc: 0.6725\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 29.3845 - acc: 0.6791 - val_loss: 29.9709 - val_acc: 0.6735\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 29.1944 - acc: 0.6813 - val_loss: 32.9419 - val_acc: 0.6743\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 28.9722 - acc: 0.6797 - val_loss: 28.0872 - val_acc: 0.6744\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 29.2157 - acc: 0.6800 - val_loss: 28.4458 - val_acc: 0.6770\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 28.8173 - acc: 0.6814 - val_loss: 28.9556 - val_acc: 0.6721\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 28.9442 - acc: 0.6803 - val_loss: 29.6661 - val_acc: 0.6690\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 28.9578 - acc: 0.6803 - val_loss: 30.0825 - val_acc: 0.6838\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 29.2412 - acc: 0.6813 - val_loss: 31.5739 - val_acc: 0.6836\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 29.4822 - acc: 0.6810 - val_loss: 29.6270 - val_acc: 0.6839\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 29.1849 - acc: 0.6813 - val_loss: 29.7554 - val_acc: 0.6835\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 29.2665 - acc: 0.6813 - val_loss: 28.6765 - val_acc: 0.6811\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 29.1367 - acc: 0.6822 - val_loss: 28.2018 - val_acc: 0.6840\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 28.7881 - acc: 0.6803 - val_loss: 31.5167 - val_acc: 0.6802\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 28.8877 - acc: 0.6799 - val_loss: 28.4683 - val_acc: 0.6833\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 29.4703 - acc: 0.6816 - val_loss: 28.2371 - val_acc: 0.6826\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 28.4742 - acc: 0.6809 - val_loss: 28.0778 - val_acc: 0.6814\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 29.0858 - acc: 0.6793 - val_loss: 31.3080 - val_acc: 0.6845\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 29.4839 - acc: 0.6809 - val_loss: 28.8895 - val_acc: 0.6824\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 389us/step - loss: 29.0386 - acc: 0.6812 - val_loss: 30.6283 - val_acc: 0.6849\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 29.1013 - acc: 0.6813 - val_loss: 28.6682 - val_acc: 0.6822\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 28.8758 - acc: 0.6817 - val_loss: 28.7045 - val_acc: 0.6823\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 28.9942 - acc: 0.6799 - val_loss: 31.8821 - val_acc: 0.6849\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 29.4630 - acc: 0.6810 - val_loss: 28.6509 - val_acc: 0.6829\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.6410 - acc: 0.6801 - val_loss: 28.3544 - val_acc: 0.6824\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.7895 - acc: 0.6817 - val_loss: 29.0911 - val_acc: 0.6827\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 28.8873 - acc: 0.6809 - val_loss: 29.4295 - val_acc: 0.6822\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 110.9103 - acc: 0.6373 - val_loss: 111.3309 - val_acc: 0.6324\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 109.8437 - acc: 0.6379 - val_loss: 110.7011 - val_acc: 0.6317\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 110.4771 - acc: 0.6363 - val_loss: 110.7877 - val_acc: 0.6310\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 109.8307 - acc: 0.6371 - val_loss: 111.4726 - val_acc: 0.6322\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 109.9546 - acc: 0.6363 - val_loss: 109.9512 - val_acc: 0.6318\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 109.0668 - acc: 0.6375 - val_loss: 109.5192 - val_acc: 0.6333\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 110.7730 - acc: 0.6385 - val_loss: 111.1569 - val_acc: 0.6290\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 108.3982 - acc: 0.6367 - val_loss: 111.9714 - val_acc: 0.6276\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 108.1404 - acc: 0.6351 - val_loss: 107.6110 - val_acc: 0.6331\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 107.8025 - acc: 0.6385 - val_loss: 113.3911 - val_acc: 0.6292\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 111.0456 - acc: 0.6369 - val_loss: 112.4635 - val_acc: 0.6324\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 111.9186 - acc: 0.6387 - val_loss: 110.1854 - val_acc: 0.6315\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 107.9900 - acc: 0.6365 - val_loss: 112.7994 - val_acc: 0.6226\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 108.0564 - acc: 0.6340 - val_loss: 109.1630 - val_acc: 0.6297\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 106.6756 - acc: 0.6376 - val_loss: 109.8921 - val_acc: 0.6306\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 109.1317 - acc: 0.6352 - val_loss: 108.9870 - val_acc: 0.6338\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 111.0138 - acc: 0.6394 - val_loss: 112.7344 - val_acc: 0.6334\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 112.0130 - acc: 0.6388 - val_loss: 112.5453 - val_acc: 0.6333\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 111.2167 - acc: 0.6376 - val_loss: 111.0980 - val_acc: 0.6319\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 110.0101 - acc: 0.6383 - val_loss: 111.5200 - val_acc: 0.6303\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 110.8393 - acc: 0.6365 - val_loss: 107.9064 - val_acc: 0.6339\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 108.4714 - acc: 0.6385 - val_loss: 112.9987 - val_acc: 0.6287\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 108.8217 - acc: 0.6372 - val_loss: 108.4340 - val_acc: 0.6315\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 108.4314 - acc: 0.6383 - val_loss: 111.4584 - val_acc: 0.6317\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 108.6125 - acc: 0.6386 - val_loss: 109.2087 - val_acc: 0.6339\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 109.1240 - acc: 0.6375 - val_loss: 108.1311 - val_acc: 0.6315\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 109.1057 - acc: 0.6374 - val_loss: 111.6367 - val_acc: 0.6336\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 108.9855 - acc: 0.6378 - val_loss: 112.6024 - val_acc: 0.6265\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 107.3455 - acc: 0.6378 - val_loss: 107.6577 - val_acc: 0.6336\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 107.5493 - acc: 0.6389 - val_loss: 113.0763 - val_acc: 0.6299\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 110.1918 - acc: 0.6365 - val_loss: 110.3865 - val_acc: 0.6335\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 110.4904 - acc: 0.6387 - val_loss: 110.0172 - val_acc: 0.6344\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 109.4306 - acc: 0.6356 - val_loss: 109.3204 - val_acc: 0.6316\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 109.4814 - acc: 0.6385 - val_loss: 108.7295 - val_acc: 0.6318\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 108.4928 - acc: 0.6366 - val_loss: 108.5611 - val_acc: 0.6316\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 106.6926 - acc: 0.6387 - val_loss: 110.6635 - val_acc: 0.6325\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 108.3379 - acc: 0.6385 - val_loss: 113.3946 - val_acc: 0.6308\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 107.6582 - acc: 0.6377 - val_loss: 107.5467 - val_acc: 0.6331\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 107.9658 - acc: 0.6341 - val_loss: 112.4617 - val_acc: 0.6291\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 110.9490 - acc: 0.6375 - val_loss: 114.8036 - val_acc: 0.6338\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 112.0577 - acc: 0.6384 - val_loss: 115.5136 - val_acc: 0.6312\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 109.6885 - acc: 0.6384 - val_loss: 110.3274 - val_acc: 0.6334\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 110.2743 - acc: 0.6388 - val_loss: 111.3667 - val_acc: 0.6332\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 110.4141 - acc: 0.6354 - val_loss: 107.8627 - val_acc: 0.6321\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 107.4582 - acc: 0.6375 - val_loss: 108.8968 - val_acc: 0.6339\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 108.2191 - acc: 0.6367 - val_loss: 107.9840 - val_acc: 0.6330\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 108.3747 - acc: 0.6380 - val_loss: 116.0258 - val_acc: 0.6281\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 108.7621 - acc: 0.6382 - val_loss: 108.2859 - val_acc: 0.6340\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 107.1361 - acc: 0.6397 - val_loss: 108.6164 - val_acc: 0.6337\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 109.9193 - acc: 0.6381 - val_loss: 118.0138 - val_acc: 0.6274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 49.4407 - acc: 0.4392 - val_loss: 46.3514 - val_acc: 0.4464\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 49.4323 - acc: 0.4395 - val_loss: 46.3478 - val_acc: 0.4458\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 49.4249 - acc: 0.4393 - val_loss: 46.3477 - val_acc: 0.4449\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 49.4169 - acc: 0.4388 - val_loss: 46.3270 - val_acc: 0.4465\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 49.4019 - acc: 0.4396 - val_loss: 46.3145 - val_acc: 0.4456\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 49.3893 - acc: 0.4391 - val_loss: 46.3165 - val_acc: 0.4465\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 49.3836 - acc: 0.4396 - val_loss: 46.2973 - val_acc: 0.4456\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 49.3742 - acc: 0.4395 - val_loss: 46.2979 - val_acc: 0.4462\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 49.3704 - acc: 0.4390 - val_loss: 46.2796 - val_acc: 0.4466\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 49.3643 - acc: 0.4396 - val_loss: 46.2782 - val_acc: 0.4469\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 49.3460 - acc: 0.4398 - val_loss: 46.3194 - val_acc: 0.4457\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 49.3395 - acc: 0.4397 - val_loss: 46.2643 - val_acc: 0.4460\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 49.3257 - acc: 0.4396 - val_loss: 46.2555 - val_acc: 0.4459\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 49.3207 - acc: 0.4393 - val_loss: 46.2334 - val_acc: 0.4458\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 49.3159 - acc: 0.4396 - val_loss: 46.2332 - val_acc: 0.4456\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 49.2986 - acc: 0.4395 - val_loss: 46.2282 - val_acc: 0.4460\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 49.2875 - acc: 0.4399 - val_loss: 46.2272 - val_acc: 0.4460\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 49.2851 - acc: 0.4394 - val_loss: 46.2112 - val_acc: 0.4458\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 49.2729 - acc: 0.4396 - val_loss: 46.1960 - val_acc: 0.4461\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 49.2595 - acc: 0.4397 - val_loss: 46.1944 - val_acc: 0.4470\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 49.2609 - acc: 0.4393 - val_loss: 46.1756 - val_acc: 0.4471\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 49.2435 - acc: 0.4401 - val_loss: 46.2075 - val_acc: 0.4457\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 49.2392 - acc: 0.4397 - val_loss: 46.1676 - val_acc: 0.4460\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 49.2276 - acc: 0.4393 - val_loss: 46.1649 - val_acc: 0.4475\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 49.2138 - acc: 0.4399 - val_loss: 46.1422 - val_acc: 0.4466\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 49.2088 - acc: 0.4398 - val_loss: 46.1457 - val_acc: 0.4461\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 49.2005 - acc: 0.4400 - val_loss: 46.1331 - val_acc: 0.4458\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 49.2046 - acc: 0.4394 - val_loss: 46.1219 - val_acc: 0.4470\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 49.1726 - acc: 0.4399 - val_loss: 46.1336 - val_acc: 0.4472\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 49.1765 - acc: 0.4400 - val_loss: 46.1014 - val_acc: 0.4465\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 49.1559 - acc: 0.4398 - val_loss: 46.1213 - val_acc: 0.4455\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 49.1539 - acc: 0.4397 - val_loss: 46.1108 - val_acc: 0.4460\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 49.1604 - acc: 0.4398 - val_loss: 46.1331 - val_acc: 0.4467\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 49.1419 - acc: 0.4397 - val_loss: 46.0942 - val_acc: 0.4467\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 49.1270 - acc: 0.4400 - val_loss: 46.0647 - val_acc: 0.4467\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 49.1124 - acc: 0.4395 - val_loss: 46.0759 - val_acc: 0.4474\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 49.1151 - acc: 0.4401 - val_loss: 46.0498 - val_acc: 0.4460\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 49.0939 - acc: 0.4398 - val_loss: 46.0337 - val_acc: 0.4463\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 49.0916 - acc: 0.4395 - val_loss: 46.0450 - val_acc: 0.4474\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 49.0739 - acc: 0.4401 - val_loss: 46.0116 - val_acc: 0.4467\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 49.0697 - acc: 0.4401 - val_loss: 46.0045 - val_acc: 0.4472\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 49.0547 - acc: 0.4398 - val_loss: 46.0189 - val_acc: 0.4471\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 49.0459 - acc: 0.4399 - val_loss: 46.0054 - val_acc: 0.4474\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 49.0321 - acc: 0.4405 - val_loss: 45.9977 - val_acc: 0.4459\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 49.0227 - acc: 0.4395 - val_loss: 45.9766 - val_acc: 0.4470\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 49.0152 - acc: 0.4402 - val_loss: 45.9557 - val_acc: 0.4466\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 49.0087 - acc: 0.4401 - val_loss: 45.9568 - val_acc: 0.4468\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 49.0094 - acc: 0.4399 - val_loss: 45.9614 - val_acc: 0.4469\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 48.9886 - acc: 0.4401 - val_loss: 45.9621 - val_acc: 0.4469\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 48.9863 - acc: 0.4404 - val_loss: 45.9322 - val_acc: 0.4461\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4591 - acc: 0.4650 - val_loss: 0.4371 - val_acc: 0.4676\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4586 - acc: 0.4648 - val_loss: 0.4366 - val_acc: 0.4671\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4587 - acc: 0.4655 - val_loss: 0.4362 - val_acc: 0.4679\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.4584 - acc: 0.4660 - val_loss: 0.4365 - val_acc: 0.4675\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4584 - acc: 0.4654 - val_loss: 0.4365 - val_acc: 0.4671\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4588 - acc: 0.4647 - val_loss: 0.4366 - val_acc: 0.4670\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4584 - acc: 0.4657 - val_loss: 0.4359 - val_acc: 0.4678\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4583 - acc: 0.4652 - val_loss: 0.4362 - val_acc: 0.4673\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4582 - acc: 0.4653 - val_loss: 0.4360 - val_acc: 0.4683\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4580 - acc: 0.4656 - val_loss: 0.4370 - val_acc: 0.4668\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4587 - acc: 0.4653 - val_loss: 0.4359 - val_acc: 0.4674\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4575 - acc: 0.4653 - val_loss: 0.4362 - val_acc: 0.4679\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4582 - acc: 0.4653 - val_loss: 0.4372 - val_acc: 0.4670\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.4576 - acc: 0.4649 - val_loss: 0.4358 - val_acc: 0.4672\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.4574 - acc: 0.4653 - val_loss: 0.4359 - val_acc: 0.4678\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4574 - acc: 0.4652 - val_loss: 0.4357 - val_acc: 0.4674\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.4577 - acc: 0.4655 - val_loss: 0.4355 - val_acc: 0.4682\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.4572 - acc: 0.4651 - val_loss: 0.4350 - val_acc: 0.4679\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4574 - acc: 0.4651 - val_loss: 0.4361 - val_acc: 0.4680\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4574 - acc: 0.4653 - val_loss: 0.4356 - val_acc: 0.4680\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4569 - acc: 0.4655 - val_loss: 0.4349 - val_acc: 0.4682\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4567 - acc: 0.4654 - val_loss: 0.4349 - val_acc: 0.4687\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4569 - acc: 0.4654 - val_loss: 0.4347 - val_acc: 0.4685\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4566 - acc: 0.4653 - val_loss: 0.4346 - val_acc: 0.4681\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 409us/step - loss: 0.4565 - acc: 0.4648 - val_loss: 0.4346 - val_acc: 0.4682\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.4568 - acc: 0.4653 - val_loss: 0.4344 - val_acc: 0.4684\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4564 - acc: 0.4653 - val_loss: 0.4346 - val_acc: 0.4687\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4560 - acc: 0.4650 - val_loss: 0.4345 - val_acc: 0.4686\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4560 - acc: 0.4655 - val_loss: 0.4343 - val_acc: 0.4684\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4566 - acc: 0.4650 - val_loss: 0.4345 - val_acc: 0.4677\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4562 - acc: 0.4655 - val_loss: 0.4353 - val_acc: 0.4673\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4559 - acc: 0.4650 - val_loss: 0.4342 - val_acc: 0.4684\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4556 - acc: 0.4657 - val_loss: 0.4342 - val_acc: 0.4685\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4556 - acc: 0.4653 - val_loss: 0.4343 - val_acc: 0.4687\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4558 - acc: 0.4657 - val_loss: 0.4352 - val_acc: 0.4682\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4566 - acc: 0.4654 - val_loss: 0.4342 - val_acc: 0.4686\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4554 - acc: 0.4655 - val_loss: 0.4338 - val_acc: 0.4692\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4554 - acc: 0.4654 - val_loss: 0.4342 - val_acc: 0.4693\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4551 - acc: 0.4654 - val_loss: 0.4334 - val_acc: 0.4686\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4549 - acc: 0.4653 - val_loss: 0.4335 - val_acc: 0.4692\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4550 - acc: 0.4651 - val_loss: 0.4333 - val_acc: 0.4685\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4550 - acc: 0.4652 - val_loss: 0.4334 - val_acc: 0.4694\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4550 - acc: 0.4656 - val_loss: 0.4332 - val_acc: 0.4688\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4548 - acc: 0.4657 - val_loss: 0.4332 - val_acc: 0.4690\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4546 - acc: 0.4654 - val_loss: 0.4335 - val_acc: 0.4697\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4550 - acc: 0.4654 - val_loss: 0.4330 - val_acc: 0.4688\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4543 - acc: 0.4656 - val_loss: 0.4332 - val_acc: 0.4696\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4547 - acc: 0.4657 - val_loss: 0.4330 - val_acc: 0.4690\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.4543 - acc: 0.4651 - val_loss: 0.4326 - val_acc: 0.4690\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.4544 - acc: 0.4654 - val_loss: 0.4325 - val_acc: 0.4692\n",
      "start training round 18\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 28.0694 - acc: 0.6797 - val_loss: 28.8776 - val_acc: 0.6707\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 29.3412 - acc: 0.6789 - val_loss: 29.4747 - val_acc: 0.6728\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 29.0992 - acc: 0.6789 - val_loss: 30.3040 - val_acc: 0.6676\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 29.2766 - acc: 0.6804 - val_loss: 28.3970 - val_acc: 0.6796\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 29.1396 - acc: 0.6809 - val_loss: 30.1552 - val_acc: 0.6752\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.6469 - acc: 0.6812 - val_loss: 28.1062 - val_acc: 0.6756\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 28.3999 - acc: 0.6791 - val_loss: 27.4966 - val_acc: 0.6790\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 29.5291 - acc: 0.6794 - val_loss: 28.9591 - val_acc: 0.6840\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.3738 - acc: 0.6815 - val_loss: 27.6974 - val_acc: 0.6800\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 29.2720 - acc: 0.6793 - val_loss: 28.7166 - val_acc: 0.6811\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 29.2553 - acc: 0.6807 - val_loss: 28.7112 - val_acc: 0.6851\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.8606 - acc: 0.6819 - val_loss: 27.7661 - val_acc: 0.6819\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 28.7941 - acc: 0.6808 - val_loss: 27.9158 - val_acc: 0.6826\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 28.7719 - acc: 0.6809 - val_loss: 30.0127 - val_acc: 0.6830\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 28.5794 - acc: 0.6801 - val_loss: 27.6929 - val_acc: 0.6778\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 29.0326 - acc: 0.6789 - val_loss: 29.7098 - val_acc: 0.6717\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 28.9990 - acc: 0.6804 - val_loss: 28.6324 - val_acc: 0.6702\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 380us/step - loss: 28.8569 - acc: 0.6801 - val_loss: 28.4424 - val_acc: 0.6744\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 29.2391 - acc: 0.6809 - val_loss: 28.8668 - val_acc: 0.6769\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 28.8539 - acc: 0.6803 - val_loss: 28.4947 - val_acc: 0.6741\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 28.9057 - acc: 0.6798 - val_loss: 29.1429 - val_acc: 0.6710\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 28.6587 - acc: 0.6813 - val_loss: 28.2369 - val_acc: 0.6719\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 29.1884 - acc: 0.6793 - val_loss: 29.8752 - val_acc: 0.6757\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 28.7957 - acc: 0.6818 - val_loss: 28.0537 - val_acc: 0.6782\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 29.3784 - acc: 0.6788 - val_loss: 29.3792 - val_acc: 0.6822\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 28.7068 - acc: 0.6812 - val_loss: 28.6658 - val_acc: 0.6815\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 29.3361 - acc: 0.6807 - val_loss: 27.5674 - val_acc: 0.6810\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 28.9203 - acc: 0.6802 - val_loss: 29.7079 - val_acc: 0.6828\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 28.7006 - acc: 0.6816 - val_loss: 28.3886 - val_acc: 0.6809\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 28.4783 - acc: 0.6807 - val_loss: 28.0828 - val_acc: 0.6776\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 28.5766 - acc: 0.6804 - val_loss: 28.7013 - val_acc: 0.6739\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 29.1276 - acc: 0.6791 - val_loss: 27.4277 - val_acc: 0.6777\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 28.7461 - acc: 0.6814 - val_loss: 29.7110 - val_acc: 0.6700\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 28.8207 - acc: 0.6802 - val_loss: 29.7311 - val_acc: 0.6765\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 29.1526 - acc: 0.6811 - val_loss: 29.6994 - val_acc: 0.6651\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 28.4134 - acc: 0.6813 - val_loss: 27.4237 - val_acc: 0.6758\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 29.0876 - acc: 0.6798 - val_loss: 29.1359 - val_acc: 0.6812\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 28.4291 - acc: 0.6805 - val_loss: 27.6265 - val_acc: 0.6797\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 28.2886 - acc: 0.6796 - val_loss: 29.3720 - val_acc: 0.6798\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 29.5126 - acc: 0.6799 - val_loss: 29.8144 - val_acc: 0.6839\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 29.0198 - acc: 0.6807 - val_loss: 28.8858 - val_acc: 0.6840\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 28.7346 - acc: 0.6819 - val_loss: 29.8843 - val_acc: 0.6813\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 29.2971 - acc: 0.6810 - val_loss: 28.0602 - val_acc: 0.6831\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 28.7546 - acc: 0.6817 - val_loss: 30.1502 - val_acc: 0.6826\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 28.1408 - acc: 0.6811 - val_loss: 27.6157 - val_acc: 0.6743\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.8082 - acc: 0.6791 - val_loss: 28.2631 - val_acc: 0.6745\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 28.8765 - acc: 0.6796 - val_loss: 30.1863 - val_acc: 0.6651\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 29.4468 - acc: 0.6799 - val_loss: 28.2798 - val_acc: 0.6746\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.5028 - acc: 0.6819 - val_loss: 27.1395 - val_acc: 0.6764\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 28.5644 - acc: 0.6803 - val_loss: 29.5985 - val_acc: 0.6716\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 112.5299 - acc: 0.6373 - val_loss: 109.0534 - val_acc: 0.6338\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 108.8379 - acc: 0.6391 - val_loss: 113.3335 - val_acc: 0.6328\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 109.5496 - acc: 0.6390 - val_loss: 110.6000 - val_acc: 0.6303\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 110.0968 - acc: 0.6373 - val_loss: 107.1041 - val_acc: 0.6324\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 107.7435 - acc: 0.6375 - val_loss: 107.4126 - val_acc: 0.6329\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 106.8362 - acc: 0.6373 - val_loss: 108.6218 - val_acc: 0.6276\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 107.4095 - acc: 0.6359 - val_loss: 106.9537 - val_acc: 0.6326\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 106.9492 - acc: 0.6360 - val_loss: 108.2802 - val_acc: 0.6320\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 108.1463 - acc: 0.6373 - val_loss: 114.3553 - val_acc: 0.6324\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 110.4743 - acc: 0.6386 - val_loss: 107.6110 - val_acc: 0.6333\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 108.8524 - acc: 0.6382 - val_loss: 110.6458 - val_acc: 0.6319\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 107.5058 - acc: 0.6381 - val_loss: 107.1459 - val_acc: 0.6348\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 108.3192 - acc: 0.6395 - val_loss: 111.5884 - val_acc: 0.6330\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 111.6092 - acc: 0.6357 - val_loss: 106.4075 - val_acc: 0.6344\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 108.0625 - acc: 0.6376 - val_loss: 111.8554 - val_acc: 0.6306\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 108.8347 - acc: 0.6388 - val_loss: 108.6836 - val_acc: 0.6339\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 110.4538 - acc: 0.6374 - val_loss: 108.9114 - val_acc: 0.6337\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 108.1165 - acc: 0.6399 - val_loss: 110.8187 - val_acc: 0.6332\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 110.0709 - acc: 0.6389 - val_loss: 112.3329 - val_acc: 0.6300\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 109.1524 - acc: 0.6352 - val_loss: 107.3814 - val_acc: 0.6330\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 106.6496 - acc: 0.6380 - val_loss: 107.3586 - val_acc: 0.6337\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 108.9703 - acc: 0.6354 - val_loss: 107.7197 - val_acc: 0.6343\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 109.2806 - acc: 0.6379 - val_loss: 108.8581 - val_acc: 0.6333\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 108.7956 - acc: 0.6385 - val_loss: 107.8828 - val_acc: 0.6338\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 107.9841 - acc: 0.6371 - val_loss: 107.3454 - val_acc: 0.6328\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 381us/step - loss: 108.0142 - acc: 0.6383 - val_loss: 110.0155 - val_acc: 0.6330\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 109.9365 - acc: 0.6392 - val_loss: 114.1720 - val_acc: 0.6338\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 110.7819 - acc: 0.6386 - val_loss: 112.1937 - val_acc: 0.6342\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 110.0777 - acc: 0.6385 - val_loss: 110.3890 - val_acc: 0.6332\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 109.1998 - acc: 0.6380 - val_loss: 108.2036 - val_acc: 0.6344\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 109.3487 - acc: 0.6390 - val_loss: 109.0216 - val_acc: 0.6351\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 108.2705 - acc: 0.6396 - val_loss: 111.4221 - val_acc: 0.6316\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 107.9364 - acc: 0.6367 - val_loss: 110.9086 - val_acc: 0.6270\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 107.5572 - acc: 0.6367 - val_loss: 109.5464 - val_acc: 0.6293\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 106.9087 - acc: 0.6366 - val_loss: 115.7024 - val_acc: 0.6290\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 109.3637 - acc: 0.6388 - val_loss: 113.2906 - val_acc: 0.6326\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 110.6311 - acc: 0.6378 - val_loss: 110.8220 - val_acc: 0.6312\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 107.9026 - acc: 0.6375 - val_loss: 110.7583 - val_acc: 0.6296\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 107.8174 - acc: 0.6375 - val_loss: 108.0337 - val_acc: 0.6327\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 106.2771 - acc: 0.6388 - val_loss: 107.8389 - val_acc: 0.6324\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 108.8009 - acc: 0.6384 - val_loss: 108.9772 - val_acc: 0.6337\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 109.5729 - acc: 0.6377 - val_loss: 112.4156 - val_acc: 0.6297\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 108.0374 - acc: 0.6376 - val_loss: 111.1259 - val_acc: 0.6322\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 108.9542 - acc: 0.6379 - val_loss: 113.9086 - val_acc: 0.6330\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 112.2144 - acc: 0.6374 - val_loss: 109.4756 - val_acc: 0.6322\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 108.4054 - acc: 0.6391 - val_loss: 116.6310 - val_acc: 0.6313\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 107.9549 - acc: 0.6389 - val_loss: 115.3852 - val_acc: 0.6280\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 106.5654 - acc: 0.6385 - val_loss: 106.0275 - val_acc: 0.6341\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 107.8889 - acc: 0.6372 - val_loss: 108.0105 - val_acc: 0.6322\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 107.9791 - acc: 0.6390 - val_loss: 107.8562 - val_acc: 0.6349\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 48.9693 - acc: 0.4398 - val_loss: 45.9517 - val_acc: 0.4469\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 48.9646 - acc: 0.4402 - val_loss: 45.9398 - val_acc: 0.4469\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 48.9537 - acc: 0.4404 - val_loss: 45.9315 - val_acc: 0.4461\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 48.9413 - acc: 0.4397 - val_loss: 45.8818 - val_acc: 0.4473\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 48.9296 - acc: 0.4403 - val_loss: 45.8889 - val_acc: 0.4467\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 48.9241 - acc: 0.4398 - val_loss: 45.8677 - val_acc: 0.4478\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 48.9059 - acc: 0.4406 - val_loss: 45.9126 - val_acc: 0.4475\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 48.9035 - acc: 0.4408 - val_loss: 45.8702 - val_acc: 0.4458\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 48.8927 - acc: 0.4397 - val_loss: 45.8399 - val_acc: 0.4471\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 48.8817 - acc: 0.4407 - val_loss: 45.8444 - val_acc: 0.4460\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 48.8857 - acc: 0.4401 - val_loss: 45.8449 - val_acc: 0.4467\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 48.8645 - acc: 0.4402 - val_loss: 45.8444 - val_acc: 0.4471\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 48.8486 - acc: 0.4406 - val_loss: 45.8227 - val_acc: 0.4458\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 48.8448 - acc: 0.4400 - val_loss: 45.7956 - val_acc: 0.4473\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 48.8320 - acc: 0.4400 - val_loss: 45.7883 - val_acc: 0.4469\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 48.8222 - acc: 0.4405 - val_loss: 45.7901 - val_acc: 0.4455\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 48.8157 - acc: 0.4401 - val_loss: 45.7798 - val_acc: 0.4470\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 48.8028 - acc: 0.4405 - val_loss: 45.7649 - val_acc: 0.4469\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 48.7955 - acc: 0.4402 - val_loss: 45.7666 - val_acc: 0.4464\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 48.8088 - acc: 0.4404 - val_loss: 45.7382 - val_acc: 0.4468\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 48.7726 - acc: 0.4403 - val_loss: 45.7479 - val_acc: 0.4477\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 48.7785 - acc: 0.4406 - val_loss: 45.7760 - val_acc: 0.4471\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 48.7619 - acc: 0.4407 - val_loss: 45.7266 - val_acc: 0.4467\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 48.7518 - acc: 0.4405 - val_loss: 45.7104 - val_acc: 0.4467\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 48.7463 - acc: 0.4402 - val_loss: 45.6974 - val_acc: 0.4477\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 48.7410 - acc: 0.4411 - val_loss: 45.7068 - val_acc: 0.4473\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 48.7132 - acc: 0.4409 - val_loss: 45.6893 - val_acc: 0.4460\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 48.7045 - acc: 0.4406 - val_loss: 45.6717 - val_acc: 0.4462\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 48.6983 - acc: 0.4406 - val_loss: 45.6687 - val_acc: 0.4462\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 48.6908 - acc: 0.4406 - val_loss: 45.6743 - val_acc: 0.4463\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 48.6807 - acc: 0.4401 - val_loss: 45.6507 - val_acc: 0.4464\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 48.6751 - acc: 0.4406 - val_loss: 45.6570 - val_acc: 0.4469\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 48.6656 - acc: 0.4406 - val_loss: 45.6391 - val_acc: 0.4476\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 375us/step - loss: 48.6478 - acc: 0.4411 - val_loss: 45.6299 - val_acc: 0.4462\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 48.6452 - acc: 0.4404 - val_loss: 45.6204 - val_acc: 0.4474\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 48.6412 - acc: 0.4408 - val_loss: 45.6070 - val_acc: 0.4478\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 48.6335 - acc: 0.4408 - val_loss: 45.6182 - val_acc: 0.4475\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 48.6091 - acc: 0.4412 - val_loss: 45.6090 - val_acc: 0.4471\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 48.6012 - acc: 0.4409 - val_loss: 45.5743 - val_acc: 0.4464\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 48.5988 - acc: 0.4406 - val_loss: 45.5941 - val_acc: 0.4467\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 48.5877 - acc: 0.4406 - val_loss: 45.5849 - val_acc: 0.4472\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 48.5786 - acc: 0.4408 - val_loss: 45.5988 - val_acc: 0.4469\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 48.5790 - acc: 0.4405 - val_loss: 45.5397 - val_acc: 0.4483\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 48.5677 - acc: 0.4412 - val_loss: 45.5634 - val_acc: 0.4469\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 48.5474 - acc: 0.4411 - val_loss: 45.5445 - val_acc: 0.4464\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 48.5523 - acc: 0.4406 - val_loss: 45.6217 - val_acc: 0.4466\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 48.5353 - acc: 0.4412 - val_loss: 45.5383 - val_acc: 0.4464\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 48.5216 - acc: 0.4404 - val_loss: 45.5228 - val_acc: 0.4475\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 48.5166 - acc: 0.4410 - val_loss: 45.4815 - val_acc: 0.4469\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 48.5376 - acc: 0.4409 - val_loss: 45.5014 - val_acc: 0.4475\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.4539 - acc: 0.4654 - val_loss: 0.4325 - val_acc: 0.4695\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4544 - acc: 0.4658 - val_loss: 0.4325 - val_acc: 0.4688\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4540 - acc: 0.4656 - val_loss: 0.4324 - val_acc: 0.4698\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4536 - acc: 0.4660 - val_loss: 0.4324 - val_acc: 0.4698\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4537 - acc: 0.4655 - val_loss: 0.4322 - val_acc: 0.4693\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4536 - acc: 0.4654 - val_loss: 0.4330 - val_acc: 0.4689\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4540 - acc: 0.4656 - val_loss: 0.4336 - val_acc: 0.4690\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4535 - acc: 0.4654 - val_loss: 0.4322 - val_acc: 0.4689\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4532 - acc: 0.4657 - val_loss: 0.4321 - val_acc: 0.4691\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4534 - acc: 0.4654 - val_loss: 0.4318 - val_acc: 0.4696\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.4530 - acc: 0.4660 - val_loss: 0.4327 - val_acc: 0.4685\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.4547 - acc: 0.4654 - val_loss: 0.4320 - val_acc: 0.4700\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4536 - acc: 0.4655 - val_loss: 0.4315 - val_acc: 0.4696\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.4528 - acc: 0.4654 - val_loss: 0.4315 - val_acc: 0.4700\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4528 - acc: 0.4657 - val_loss: 0.4314 - val_acc: 0.4696\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4526 - acc: 0.4658 - val_loss: 0.4325 - val_acc: 0.4691\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4525 - acc: 0.4659 - val_loss: 0.4326 - val_acc: 0.4689\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.4526 - acc: 0.4655 - val_loss: 0.4314 - val_acc: 0.4700\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4524 - acc: 0.4662 - val_loss: 0.4311 - val_acc: 0.4696\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4522 - acc: 0.4661 - val_loss: 0.4318 - val_acc: 0.4694\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4522 - acc: 0.4654 - val_loss: 0.4311 - val_acc: 0.4697\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4521 - acc: 0.4657 - val_loss: 0.4317 - val_acc: 0.4702\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.4526 - acc: 0.4656 - val_loss: 0.4319 - val_acc: 0.4690\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4520 - acc: 0.4657 - val_loss: 0.4308 - val_acc: 0.4702\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4518 - acc: 0.4656 - val_loss: 0.4306 - val_acc: 0.4696\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4517 - acc: 0.4654 - val_loss: 0.4306 - val_acc: 0.4695\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4516 - acc: 0.4655 - val_loss: 0.4305 - val_acc: 0.4698\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4518 - acc: 0.4663 - val_loss: 0.4308 - val_acc: 0.4701\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4515 - acc: 0.4654 - val_loss: 0.4310 - val_acc: 0.4692\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4514 - acc: 0.4654 - val_loss: 0.4303 - val_acc: 0.4695\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4512 - acc: 0.4659 - val_loss: 0.4302 - val_acc: 0.4700\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4514 - acc: 0.4659 - val_loss: 0.4318 - val_acc: 0.4704\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4512 - acc: 0.4656 - val_loss: 0.4300 - val_acc: 0.4698\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4508 - acc: 0.4658 - val_loss: 0.4307 - val_acc: 0.4705\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4518 - acc: 0.4654 - val_loss: 0.4303 - val_acc: 0.4703\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4508 - acc: 0.4658 - val_loss: 0.4301 - val_acc: 0.4694\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4512 - acc: 0.4654 - val_loss: 0.4298 - val_acc: 0.4700\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4507 - acc: 0.4657 - val_loss: 0.4301 - val_acc: 0.4704\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4505 - acc: 0.4660 - val_loss: 0.4302 - val_acc: 0.4703\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.4504 - acc: 0.4656 - val_loss: 0.4294 - val_acc: 0.4698\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4506 - acc: 0.4663 - val_loss: 0.4317 - val_acc: 0.4705\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4517 - acc: 0.4655 - val_loss: 0.4294 - val_acc: 0.4700\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4501 - acc: 0.4656 - val_loss: 0.4294 - val_acc: 0.4703\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4503 - acc: 0.4660 - val_loss: 0.4292 - val_acc: 0.4699\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.4501 - acc: 0.4656 - val_loss: 0.4313 - val_acc: 0.4687\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4503 - acc: 0.4657 - val_loss: 0.4292 - val_acc: 0.4701\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4504 - acc: 0.4661 - val_loss: 0.4290 - val_acc: 0.4702\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4502 - acc: 0.4657 - val_loss: 0.4290 - val_acc: 0.4703\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4498 - acc: 0.4659 - val_loss: 0.4289 - val_acc: 0.4704\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4494 - acc: 0.4657 - val_loss: 0.4287 - val_acc: 0.4701\n",
      "start training round 19\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 28.3798 - acc: 0.6805 - val_loss: 27.4887 - val_acc: 0.6770\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 28.6034 - acc: 0.6794 - val_loss: 30.7655 - val_acc: 0.6712\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.9744 - acc: 0.6817 - val_loss: 28.2685 - val_acc: 0.6728\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 28.4526 - acc: 0.6794 - val_loss: 31.9097 - val_acc: 0.6674\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.8052 - acc: 0.6813 - val_loss: 28.4907 - val_acc: 0.6769\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 28.7968 - acc: 0.6800 - val_loss: 31.5621 - val_acc: 0.6630\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 28.8155 - acc: 0.6795 - val_loss: 29.3815 - val_acc: 0.6722\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 28.1380 - acc: 0.6809 - val_loss: 27.6705 - val_acc: 0.6735\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 28.9004 - acc: 0.6789 - val_loss: 28.9765 - val_acc: 0.6718\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.4088 - acc: 0.6812 - val_loss: 31.1765 - val_acc: 0.6670\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 29.4265 - acc: 0.6806 - val_loss: 29.6194 - val_acc: 0.6730\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.2874 - acc: 0.6806 - val_loss: 29.5794 - val_acc: 0.6817\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 29.1009 - acc: 0.6803 - val_loss: 28.5443 - val_acc: 0.6795\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 28.5784 - acc: 0.6807 - val_loss: 29.0453 - val_acc: 0.6822\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 29.1352 - acc: 0.6810 - val_loss: 28.5436 - val_acc: 0.6775\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 28.8298 - acc: 0.6801 - val_loss: 30.3505 - val_acc: 0.6693\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 28.6770 - acc: 0.6809 - val_loss: 29.6190 - val_acc: 0.6726\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 29.0983 - acc: 0.6818 - val_loss: 29.0654 - val_acc: 0.6774\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 28.8899 - acc: 0.6815 - val_loss: 29.5962 - val_acc: 0.6696\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.5946 - acc: 0.6807 - val_loss: 31.2438 - val_acc: 0.6677\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 28.6306 - acc: 0.6801 - val_loss: 28.1030 - val_acc: 0.6746\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 29.0231 - acc: 0.6800 - val_loss: 28.0624 - val_acc: 0.6791\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 28.5835 - acc: 0.6818 - val_loss: 31.2023 - val_acc: 0.6647\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 28.4817 - acc: 0.6803 - val_loss: 29.0526 - val_acc: 0.6744\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 28.7682 - acc: 0.6814 - val_loss: 28.5817 - val_acc: 0.6742\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 28.8676 - acc: 0.6804 - val_loss: 29.7799 - val_acc: 0.6709\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 28.8688 - acc: 0.6811 - val_loss: 27.7284 - val_acc: 0.6789\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 28.7991 - acc: 0.6805 - val_loss: 30.7371 - val_acc: 0.6829\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 28.8028 - acc: 0.6809 - val_loss: 27.9369 - val_acc: 0.6821\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.2913 - acc: 0.6803 - val_loss: 27.7421 - val_acc: 0.6784\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.9764 - acc: 0.6804 - val_loss: 28.5542 - val_acc: 0.6735\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 28.7659 - acc: 0.6804 - val_loss: 27.9811 - val_acc: 0.6726\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 28.5749 - acc: 0.6808 - val_loss: 29.2680 - val_acc: 0.6725\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 28.6988 - acc: 0.6805 - val_loss: 31.5110 - val_acc: 0.6645\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 28.7572 - acc: 0.6813 - val_loss: 28.2621 - val_acc: 0.6760\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 28.8852 - acc: 0.6801 - val_loss: 28.7033 - val_acc: 0.6832\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 28.4779 - acc: 0.6813 - val_loss: 27.5626 - val_acc: 0.6806\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 28.4199 - acc: 0.6812 - val_loss: 29.2719 - val_acc: 0.6835\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 28.2379 - acc: 0.6800 - val_loss: 27.9711 - val_acc: 0.6836\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 28.7540 - acc: 0.6801 - val_loss: 27.6716 - val_acc: 0.6798\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 28.9324 - acc: 0.6800 - val_loss: 30.9542 - val_acc: 0.6835\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.8556 - acc: 0.6859 - val_loss: 28.2004 - val_acc: 0.6799\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 27.9896 - acc: 0.6804 - val_loss: 27.6303 - val_acc: 0.6780\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 28.3504 - acc: 0.6790 - val_loss: 29.2460 - val_acc: 0.6678\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 29.3500 - acc: 0.6790 - val_loss: 30.2714 - val_acc: 0.6734\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 28.9133 - acc: 0.6868 - val_loss: 27.9074 - val_acc: 0.6775\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 28.9338 - acc: 0.6811 - val_loss: 28.5639 - val_acc: 0.6782\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 28.5007 - acc: 0.6816 - val_loss: 30.2023 - val_acc: 0.6745\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 28.9591 - acc: 0.6808 - val_loss: 27.2226 - val_acc: 0.6775\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 28.0821 - acc: 0.6807 - val_loss: 29.8396 - val_acc: 0.6712\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 402us/step - loss: 107.4764 - acc: 0.6384 - val_loss: 108.0828 - val_acc: 0.6343\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 107.4647 - acc: 0.6371 - val_loss: 107.4672 - val_acc: 0.6333\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 108.1445 - acc: 0.6392 - val_loss: 115.0395 - val_acc: 0.6314\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 110.5323 - acc: 0.6394 - val_loss: 110.8841 - val_acc: 0.6332\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 109.2022 - acc: 0.6387 - val_loss: 111.1213 - val_acc: 0.6334\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 109.6394 - acc: 0.6388 - val_loss: 111.8221 - val_acc: 0.6311\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 108.6847 - acc: 0.6361 - val_loss: 108.8243 - val_acc: 0.6300\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 107.0457 - acc: 0.6378 - val_loss: 107.5491 - val_acc: 0.6334\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 106.7264 - acc: 0.6381 - val_loss: 108.2242 - val_acc: 0.6304\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 106.9195 - acc: 0.6379 - val_loss: 106.6524 - val_acc: 0.6342\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 107.1577 - acc: 0.6382 - val_loss: 110.8567 - val_acc: 0.6327\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 108.4369 - acc: 0.6395 - val_loss: 111.0234 - val_acc: 0.6330\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 108.6496 - acc: 0.6388 - val_loss: 113.1841 - val_acc: 0.6318\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 111.7368 - acc: 0.6369 - val_loss: 110.6294 - val_acc: 0.6312\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 108.4795 - acc: 0.6384 - val_loss: 110.0447 - val_acc: 0.6330\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 106.2088 - acc: 0.6386 - val_loss: 106.9098 - val_acc: 0.6314\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 106.6207 - acc: 0.6375 - val_loss: 112.0752 - val_acc: 0.6350\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 109.6805 - acc: 0.6397 - val_loss: 108.0375 - val_acc: 0.6340\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 107.6778 - acc: 0.6391 - val_loss: 109.9963 - val_acc: 0.6298\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 108.1464 - acc: 0.6346 - val_loss: 107.7593 - val_acc: 0.6313\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 108.0217 - acc: 0.6384 - val_loss: 108.6755 - val_acc: 0.6322\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 108.8237 - acc: 0.6392 - val_loss: 113.2044 - val_acc: 0.6311\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 107.1996 - acc: 0.6397 - val_loss: 107.7331 - val_acc: 0.6335\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 108.1945 - acc: 0.6380 - val_loss: 114.2647 - val_acc: 0.6303\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 110.3046 - acc: 0.6382 - val_loss: 108.7380 - val_acc: 0.6330\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 108.5357 - acc: 0.6397 - val_loss: 112.1851 - val_acc: 0.6338\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 108.6711 - acc: 0.6387 - val_loss: 105.7624 - val_acc: 0.6348\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 106.4101 - acc: 0.6381 - val_loss: 106.5004 - val_acc: 0.6324\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 105.6475 - acc: 0.6386 - val_loss: 109.1588 - val_acc: 0.6292\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 106.5137 - acc: 0.6350 - val_loss: 106.8632 - val_acc: 0.6340\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 106.3386 - acc: 0.6393 - val_loss: 107.8989 - val_acc: 0.6347\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 106.6819 - acc: 0.6401 - val_loss: 110.8035 - val_acc: 0.6334\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 110.3747 - acc: 0.6383 - val_loss: 109.9939 - val_acc: 0.6315\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 108.6020 - acc: 0.6384 - val_loss: 110.4428 - val_acc: 0.6345\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 109.7813 - acc: 0.6401 - val_loss: 109.9889 - val_acc: 0.6314\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 108.0780 - acc: 0.6398 - val_loss: 107.0681 - val_acc: 0.6347\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 107.2846 - acc: 0.6395 - val_loss: 105.8379 - val_acc: 0.6348\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 107.4321 - acc: 0.6399 - val_loss: 109.2187 - val_acc: 0.6315\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 108.3612 - acc: 0.6373 - val_loss: 109.9428 - val_acc: 0.6335\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 107.2932 - acc: 0.6352 - val_loss: 108.9287 - val_acc: 0.6246\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 105.7002 - acc: 0.6362 - val_loss: 107.8475 - val_acc: 0.6265\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 107.9833 - acc: 0.6386 - val_loss: 114.9948 - val_acc: 0.6322\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 107.9698 - acc: 0.6394 - val_loss: 108.2217 - val_acc: 0.6327\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 105.7770 - acc: 0.6381 - val_loss: 107.5195 - val_acc: 0.6292\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 106.9616 - acc: 0.6368 - val_loss: 106.3674 - val_acc: 0.6356\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 108.9545 - acc: 0.6405 - val_loss: 111.3126 - val_acc: 0.6347\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 110.0745 - acc: 0.6401 - val_loss: 109.0794 - val_acc: 0.6347\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 107.2875 - acc: 0.6377 - val_loss: 107.7554 - val_acc: 0.6320\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 107.4540 - acc: 0.6390 - val_loss: 110.3966 - val_acc: 0.6341\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 107.4165 - acc: 0.6381 - val_loss: 108.8361 - val_acc: 0.6313\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 48.4869 - acc: 0.4409 - val_loss: 45.4955 - val_acc: 0.4478\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 48.4743 - acc: 0.4414 - val_loss: 45.4667 - val_acc: 0.4460\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 48.4720 - acc: 0.4405 - val_loss: 45.5169 - val_acc: 0.4468\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 48.4607 - acc: 0.4410 - val_loss: 45.4397 - val_acc: 0.4474\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 48.4452 - acc: 0.4411 - val_loss: 45.4904 - val_acc: 0.4465\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 48.4454 - acc: 0.4410 - val_loss: 45.5121 - val_acc: 0.4478\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 48.4462 - acc: 0.4409 - val_loss: 45.4400 - val_acc: 0.4474\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 48.4187 - acc: 0.4411 - val_loss: 45.4141 - val_acc: 0.4481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 48.4121 - acc: 0.4414 - val_loss: 45.4064 - val_acc: 0.4469\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 48.4083 - acc: 0.4411 - val_loss: 45.4057 - val_acc: 0.4467\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 48.3954 - acc: 0.4408 - val_loss: 45.5326 - val_acc: 0.4482\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 48.3957 - acc: 0.4415 - val_loss: 45.3765 - val_acc: 0.4473\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 48.3681 - acc: 0.4411 - val_loss: 45.3973 - val_acc: 0.4474\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 48.3595 - acc: 0.4413 - val_loss: 45.3472 - val_acc: 0.4474\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 48.3480 - acc: 0.4411 - val_loss: 45.3593 - val_acc: 0.4471\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 48.3378 - acc: 0.4411 - val_loss: 45.3800 - val_acc: 0.4473\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 48.3350 - acc: 0.4414 - val_loss: 45.3792 - val_acc: 0.4459\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 48.3441 - acc: 0.4410 - val_loss: 45.3539 - val_acc: 0.4464\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 48.3169 - acc: 0.4414 - val_loss: 45.3026 - val_acc: 0.4470\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 48.2949 - acc: 0.4409 - val_loss: 45.3012 - val_acc: 0.4482\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 48.2959 - acc: 0.4417 - val_loss: 45.2905 - val_acc: 0.4473\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 48.3224 - acc: 0.4411 - val_loss: 45.2716 - val_acc: 0.4473\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 48.2738 - acc: 0.4412 - val_loss: 45.2943 - val_acc: 0.4471\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 48.2727 - acc: 0.4414 - val_loss: 45.3231 - val_acc: 0.4479\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 48.2639 - acc: 0.4414 - val_loss: 45.2568 - val_acc: 0.4468\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 48.2581 - acc: 0.4410 - val_loss: 45.2818 - val_acc: 0.4481\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 48.2453 - acc: 0.4414 - val_loss: 45.2516 - val_acc: 0.4478\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 48.2335 - acc: 0.4415 - val_loss: 45.2630 - val_acc: 0.4477\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 48.2517 - acc: 0.4412 - val_loss: 45.2488 - val_acc: 0.4479\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 48.2163 - acc: 0.4413 - val_loss: 45.2276 - val_acc: 0.4472\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 48.2007 - acc: 0.4414 - val_loss: 45.1986 - val_acc: 0.4470\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 48.2249 - acc: 0.4414 - val_loss: 45.2174 - val_acc: 0.4472\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 48.1676 - acc: 0.4415 - val_loss: 45.1840 - val_acc: 0.4471\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 48.2361 - acc: 0.4415 - val_loss: 45.1962 - val_acc: 0.4471\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 48.1789 - acc: 0.4412 - val_loss: 45.1612 - val_acc: 0.4473\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 48.1517 - acc: 0.4413 - val_loss: 45.1869 - val_acc: 0.4477\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 48.1460 - acc: 0.4418 - val_loss: 45.1599 - val_acc: 0.4470\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 48.1360 - acc: 0.4419 - val_loss: 45.1409 - val_acc: 0.4463\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 48.1183 - acc: 0.4412 - val_loss: 45.1474 - val_acc: 0.4476\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 48.1357 - acc: 0.4413 - val_loss: 45.1342 - val_acc: 0.4476\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 48.1210 - acc: 0.4416 - val_loss: 45.1127 - val_acc: 0.4472\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 48.0993 - acc: 0.4418 - val_loss: 45.0989 - val_acc: 0.4473\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 48.1046 - acc: 0.4414 - val_loss: 45.1489 - val_acc: 0.4473\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 48.0770 - acc: 0.4416 - val_loss: 45.1131 - val_acc: 0.4473\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 48.0876 - acc: 0.4416 - val_loss: 45.0873 - val_acc: 0.4480\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 48.0622 - acc: 0.4419 - val_loss: 45.0593 - val_acc: 0.4477\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 48.0719 - acc: 0.4418 - val_loss: 45.0578 - val_acc: 0.4475\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 48.0445 - acc: 0.4416 - val_loss: 45.1043 - val_acc: 0.4483\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 48.0258 - acc: 0.4421 - val_loss: 45.0800 - val_acc: 0.4482\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 48.0507 - acc: 0.4416 - val_loss: 45.0490 - val_acc: 0.4475\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4498 - acc: 0.4661 - val_loss: 0.4316 - val_acc: 0.4693\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4497 - acc: 0.4658 - val_loss: 0.4287 - val_acc: 0.4699\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4492 - acc: 0.4658 - val_loss: 0.4284 - val_acc: 0.4700\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4493 - acc: 0.4657 - val_loss: 0.4293 - val_acc: 0.4710\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.4496 - acc: 0.4659 - val_loss: 0.4284 - val_acc: 0.4701\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4489 - acc: 0.4658 - val_loss: 0.4300 - val_acc: 0.4706\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.4497 - acc: 0.4654 - val_loss: 0.4299 - val_acc: 0.4707\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.4492 - acc: 0.4655 - val_loss: 0.4287 - val_acc: 0.4706\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4486 - acc: 0.4662 - val_loss: 0.4285 - val_acc: 0.4703\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.4490 - acc: 0.4658 - val_loss: 0.4281 - val_acc: 0.4702\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4489 - acc: 0.4657 - val_loss: 0.4281 - val_acc: 0.4704\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4484 - acc: 0.4656 - val_loss: 0.4278 - val_acc: 0.4707\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.4485 - acc: 0.4662 - val_loss: 0.4281 - val_acc: 0.4704\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4484 - acc: 0.4659 - val_loss: 0.4276 - val_acc: 0.4704\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4485 - acc: 0.4658 - val_loss: 0.4277 - val_acc: 0.4707\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4481 - acc: 0.4657 - val_loss: 0.4277 - val_acc: 0.4700\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4481 - acc: 0.4661 - val_loss: 0.4275 - val_acc: 0.4705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 468us/step - loss: 0.4478 - acc: 0.4659 - val_loss: 0.4276 - val_acc: 0.4712\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 468us/step - loss: 0.4481 - acc: 0.4663 - val_loss: 0.4290 - val_acc: 0.4698\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.4477 - acc: 0.4658 - val_loss: 0.4272 - val_acc: 0.4709\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4476 - acc: 0.4665 - val_loss: 0.4272 - val_acc: 0.4705\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4475 - acc: 0.4660 - val_loss: 0.4270 - val_acc: 0.4705\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.4474 - acc: 0.4662 - val_loss: 0.4269 - val_acc: 0.4705\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.4473 - acc: 0.4660 - val_loss: 0.4271 - val_acc: 0.4706\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4475 - acc: 0.4655 - val_loss: 0.4269 - val_acc: 0.4706\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 472us/step - loss: 0.4471 - acc: 0.4660 - val_loss: 0.4268 - val_acc: 0.4701\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.4470 - acc: 0.4659 - val_loss: 0.4267 - val_acc: 0.4703\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.4470 - acc: 0.4661 - val_loss: 0.4265 - val_acc: 0.4706\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4473 - acc: 0.4663 - val_loss: 0.4265 - val_acc: 0.4702\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4482 - acc: 0.4662 - val_loss: 0.4277 - val_acc: 0.4698\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4469 - acc: 0.4660 - val_loss: 0.4263 - val_acc: 0.4703\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 468us/step - loss: 0.4471 - acc: 0.4658 - val_loss: 0.4263 - val_acc: 0.4709\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.4465 - acc: 0.4662 - val_loss: 0.4270 - val_acc: 0.4701\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.4477 - acc: 0.4658 - val_loss: 0.4265 - val_acc: 0.4704\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 0.4466 - acc: 0.4664 - val_loss: 0.4264 - val_acc: 0.4699\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4470 - acc: 0.4661 - val_loss: 0.4265 - val_acc: 0.4710\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.4464 - acc: 0.4659 - val_loss: 0.4264 - val_acc: 0.4701\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4461 - acc: 0.4661 - val_loss: 0.4271 - val_acc: 0.4709\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.4462 - acc: 0.4657 - val_loss: 0.4257 - val_acc: 0.4706\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.4459 - acc: 0.4660 - val_loss: 0.4258 - val_acc: 0.4703\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.4458 - acc: 0.4660 - val_loss: 0.4256 - val_acc: 0.4707\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.4458 - acc: 0.4660 - val_loss: 0.4262 - val_acc: 0.4708\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.4457 - acc: 0.4661 - val_loss: 0.4268 - val_acc: 0.4712\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 461us/step - loss: 0.4459 - acc: 0.4660 - val_loss: 0.4266 - val_acc: 0.4703\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4454 - acc: 0.4661 - val_loss: 0.4254 - val_acc: 0.4709\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.4452 - acc: 0.4662 - val_loss: 0.4255 - val_acc: 0.4706\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4455 - acc: 0.4659 - val_loss: 0.4260 - val_acc: 0.4704\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4454 - acc: 0.4658 - val_loss: 0.4259 - val_acc: 0.4705\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4454 - acc: 0.4662 - val_loss: 0.4255 - val_acc: 0.4713\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.4455 - acc: 0.4658 - val_loss: 0.4250 - val_acc: 0.4711\n",
      "start training round 20\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 29.1421 - acc: 0.6801 - val_loss: 27.8347 - val_acc: 0.6745\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 28.4119 - acc: 0.6801 - val_loss: 27.8618 - val_acc: 0.6740\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 28.5548 - acc: 0.6806 - val_loss: 28.0401 - val_acc: 0.6758\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 27.9633 - acc: 0.6801 - val_loss: 28.5311 - val_acc: 0.6697\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 28.9249 - acc: 0.6805 - val_loss: 27.5303 - val_acc: 0.6752\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 28.3251 - acc: 0.6790 - val_loss: 28.5518 - val_acc: 0.6825\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 29.0742 - acc: 0.6801 - val_loss: 29.5958 - val_acc: 0.6815\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 28.6242 - acc: 0.6814 - val_loss: 27.3423 - val_acc: 0.6814\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 28.5987 - acc: 0.6802 - val_loss: 27.6301 - val_acc: 0.6801\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 28.3308 - acc: 0.6801 - val_loss: 29.4533 - val_acc: 0.6836\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 28.5102 - acc: 0.6803 - val_loss: 28.0911 - val_acc: 0.6778\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 28.2957 - acc: 0.6798 - val_loss: 28.7542 - val_acc: 0.6688\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 28.0516 - acc: 0.6800 - val_loss: 29.1428 - val_acc: 0.6704\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 29.3226 - acc: 0.6804 - val_loss: 27.7315 - val_acc: 0.6785\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 28.5057 - acc: 0.6797 - val_loss: 32.6396 - val_acc: 0.6744\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 28.8421 - acc: 0.6891 - val_loss: 28.2439 - val_acc: 0.6742\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 28.4106 - acc: 0.6800 - val_loss: 27.8158 - val_acc: 0.6739\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 29.1209 - acc: 0.6809 - val_loss: 28.2774 - val_acc: 0.6776\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 27.9556 - acc: 0.6803 - val_loss: 27.9984 - val_acc: 0.6815\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 29.0811 - acc: 0.6794 - val_loss: 28.3355 - val_acc: 0.6825\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 28.4672 - acc: 0.6805 - val_loss: 28.3901 - val_acc: 0.6843\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 28.2774 - acc: 0.6805 - val_loss: 27.7972 - val_acc: 0.6810\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 28.3363 - acc: 0.6796 - val_loss: 28.7566 - val_acc: 0.6718\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 28.7839 - acc: 0.6797 - val_loss: 27.8268 - val_acc: 0.6760\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 28.2720 - acc: 0.6803 - val_loss: 29.5820 - val_acc: 0.6697\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 28.7524 - acc: 0.6816 - val_loss: 27.5307 - val_acc: 0.6756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 28.6540 - acc: 0.6809 - val_loss: 27.7008 - val_acc: 0.6755\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 27.9959 - acc: 0.6801 - val_loss: 27.6966 - val_acc: 0.6809\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 28.2164 - acc: 0.6791 - val_loss: 29.9074 - val_acc: 0.6837\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 28.9752 - acc: 0.6797 - val_loss: 28.4786 - val_acc: 0.6775\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 28.7278 - acc: 0.6798 - val_loss: 27.7033 - val_acc: 0.6830\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 28.6358 - acc: 0.6798 - val_loss: 27.7710 - val_acc: 0.6816\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 28.0885 - acc: 0.6808 - val_loss: 29.0260 - val_acc: 0.6833\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 28.9761 - acc: 0.6834 - val_loss: 27.7302 - val_acc: 0.6821\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 29.0042 - acc: 0.6828 - val_loss: 30.5714 - val_acc: 0.7134\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 28.1390 - acc: 0.6848 - val_loss: 30.0149 - val_acc: 0.6801\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 28.8943 - acc: 0.6798 - val_loss: 28.1280 - val_acc: 0.6809\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 27.7433 - acc: 0.6800 - val_loss: 28.1364 - val_acc: 0.6727\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 28.6893 - acc: 0.6784 - val_loss: 28.8438 - val_acc: 0.6677\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 27.9035 - acc: 0.6795 - val_loss: 27.9263 - val_acc: 0.6759\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 28.6539 - acc: 0.6798 - val_loss: 29.1215 - val_acc: 0.6783\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 28.1712 - acc: 0.6796 - val_loss: 27.7609 - val_acc: 0.6821\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 28.9440 - acc: 0.6829 - val_loss: 28.5556 - val_acc: 0.6833\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 28.4973 - acc: 0.6843 - val_loss: 28.0241 - val_acc: 0.6799\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 27.9728 - acc: 0.6800 - val_loss: 29.2584 - val_acc: 0.6676\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 28.8129 - acc: 0.6791 - val_loss: 30.0677 - val_acc: 0.6700\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 29.0427 - acc: 0.6840 - val_loss: 27.8075 - val_acc: 0.6782\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 28.1487 - acc: 0.6804 - val_loss: 30.5129 - val_acc: 0.6743\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 28.0860 - acc: 0.6793 - val_loss: 28.9352 - val_acc: 0.6693\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 28.8067 - acc: 0.6793 - val_loss: 28.4257 - val_acc: 0.6700\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 105.6799 - acc: 0.6394 - val_loss: 105.6029 - val_acc: 0.6335\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 105.7084 - acc: 0.6394 - val_loss: 109.5921 - val_acc: 0.6317\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 107.1734 - acc: 0.6401 - val_loss: 108.2868 - val_acc: 0.6343\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 107.8650 - acc: 0.6391 - val_loss: 108.8382 - val_acc: 0.6277\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 108.2697 - acc: 0.6387 - val_loss: 109.8405 - val_acc: 0.6346\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 110.6861 - acc: 0.6398 - val_loss: 109.3700 - val_acc: 0.6339\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 108.2974 - acc: 0.6395 - val_loss: 109.5693 - val_acc: 0.6350\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 107.4279 - acc: 0.6391 - val_loss: 112.5103 - val_acc: 0.6318\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 109.1482 - acc: 0.6385 - val_loss: 108.6522 - val_acc: 0.6344\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 109.9154 - acc: 0.6401 - val_loss: 108.1248 - val_acc: 0.6339\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 107.4046 - acc: 0.6369 - val_loss: 110.3011 - val_acc: 0.6301\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 106.8244 - acc: 0.6381 - val_loss: 107.3819 - val_acc: 0.6338\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 108.8293 - acc: 0.6387 - val_loss: 111.1034 - val_acc: 0.6340\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 109.9247 - acc: 0.6373 - val_loss: 109.4022 - val_acc: 0.6338\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 107.7001 - acc: 0.6405 - val_loss: 108.3294 - val_acc: 0.6341\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 108.4852 - acc: 0.6402 - val_loss: 107.3530 - val_acc: 0.6347\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 108.0650 - acc: 0.6401 - val_loss: 108.8676 - val_acc: 0.6334\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 107.7194 - acc: 0.6367 - val_loss: 107.3362 - val_acc: 0.6281\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 105.2818 - acc: 0.6374 - val_loss: 106.5942 - val_acc: 0.6324\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 105.9275 - acc: 0.6380 - val_loss: 107.1205 - val_acc: 0.6340\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 106.8652 - acc: 0.6397 - val_loss: 105.5706 - val_acc: 0.6347\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 105.5916 - acc: 0.6402 - val_loss: 110.5660 - val_acc: 0.6321\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 109.8420 - acc: 0.6386 - val_loss: 108.1399 - val_acc: 0.6345\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 107.4510 - acc: 0.6408 - val_loss: 111.3281 - val_acc: 0.6336\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 109.2427 - acc: 0.6397 - val_loss: 107.6703 - val_acc: 0.6348\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 107.9867 - acc: 0.6398 - val_loss: 107.3267 - val_acc: 0.6331\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 106.4247 - acc: 0.6365 - val_loss: 107.1721 - val_acc: 0.6307\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 105.9735 - acc: 0.6359 - val_loss: 109.2470 - val_acc: 0.6283\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 106.4266 - acc: 0.6382 - val_loss: 108.4435 - val_acc: 0.6331\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 105.5942 - acc: 0.6382 - val_loss: 105.6650 - val_acc: 0.6331\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 104.5155 - acc: 0.6394 - val_loss: 107.4592 - val_acc: 0.6279\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 104.3750 - acc: 0.6394 - val_loss: 112.8458 - val_acc: 0.6248\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 108.1878 - acc: 0.6382 - val_loss: 112.7055 - val_acc: 0.6347\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 111.2024 - acc: 0.6400 - val_loss: 109.0791 - val_acc: 0.6349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 107.5368 - acc: 0.6388 - val_loss: 107.8073 - val_acc: 0.6331\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 105.3466 - acc: 0.6393 - val_loss: 105.7452 - val_acc: 0.6353\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 104.8766 - acc: 0.6391 - val_loss: 109.2695 - val_acc: 0.6301\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 106.0435 - acc: 0.6397 - val_loss: 105.0509 - val_acc: 0.6356\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 105.4026 - acc: 0.6405 - val_loss: 108.8422 - val_acc: 0.6347\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 109.5741 - acc: 0.6383 - val_loss: 109.7619 - val_acc: 0.6300\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 107.9901 - acc: 0.6397 - val_loss: 113.4646 - val_acc: 0.6348\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 108.4343 - acc: 0.6408 - val_loss: 114.8255 - val_acc: 0.6353\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 110.0795 - acc: 0.6406 - val_loss: 108.9816 - val_acc: 0.6361\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 107.5100 - acc: 0.6401 - val_loss: 107.9943 - val_acc: 0.6327\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 106.3670 - acc: 0.6361 - val_loss: 106.1127 - val_acc: 0.6325\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 105.7820 - acc: 0.6372 - val_loss: 105.8034 - val_acc: 0.6346\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 105.8866 - acc: 0.6392 - val_loss: 107.0453 - val_acc: 0.6346\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 107.4949 - acc: 0.6390 - val_loss: 106.9491 - val_acc: 0.6358\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 107.4255 - acc: 0.6401 - val_loss: 107.5870 - val_acc: 0.6352\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 107.5769 - acc: 0.6367 - val_loss: 105.6684 - val_acc: 0.6339\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 47.9998 - acc: 0.4416 - val_loss: 45.0337 - val_acc: 0.4476\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 47.9859 - acc: 0.4416 - val_loss: 45.0116 - val_acc: 0.4474\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 48.0215 - acc: 0.4414 - val_loss: 44.9948 - val_acc: 0.4479\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 47.9780 - acc: 0.4417 - val_loss: 45.0089 - val_acc: 0.4480\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 47.9729 - acc: 0.4419 - val_loss: 44.9770 - val_acc: 0.4475\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 47.9514 - acc: 0.4414 - val_loss: 44.9803 - val_acc: 0.4480\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 47.9768 - acc: 0.4418 - val_loss: 45.1086 - val_acc: 0.4478\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 47.9640 - acc: 0.4416 - val_loss: 44.9592 - val_acc: 0.4474\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 47.9267 - acc: 0.4416 - val_loss: 44.9615 - val_acc: 0.4480\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 47.9290 - acc: 0.4420 - val_loss: 44.9531 - val_acc: 0.4473\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 47.9010 - acc: 0.4414 - val_loss: 44.9383 - val_acc: 0.4472\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 47.9006 - acc: 0.4416 - val_loss: 44.9291 - val_acc: 0.4477\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 47.8753 - acc: 0.4415 - val_loss: 44.9241 - val_acc: 0.4483\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 47.8712 - acc: 0.4420 - val_loss: 44.9141 - val_acc: 0.4469\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 47.8570 - acc: 0.4417 - val_loss: 44.8870 - val_acc: 0.4476\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 47.8554 - acc: 0.4416 - val_loss: 44.9660 - val_acc: 0.4482\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 47.9248 - acc: 0.4420 - val_loss: 44.9704 - val_acc: 0.4473\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 48.0340 - acc: 0.4416 - val_loss: 45.0020 - val_acc: 0.4474\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 48.0164 - acc: 0.4410 - val_loss: 45.0539 - val_acc: 0.4482\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 48.0479 - acc: 0.4419 - val_loss: 44.8434 - val_acc: 0.4476\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 47.8054 - acc: 0.4416 - val_loss: 44.8260 - val_acc: 0.4477\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 47.8093 - acc: 0.4419 - val_loss: 44.8811 - val_acc: 0.4481\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 47.7878 - acc: 0.4417 - val_loss: 44.8273 - val_acc: 0.4482\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 47.8298 - acc: 0.4415 - val_loss: 44.8408 - val_acc: 0.4483\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 47.7714 - acc: 0.4424 - val_loss: 44.7983 - val_acc: 0.4470\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 47.7642 - acc: 0.4415 - val_loss: 44.7984 - val_acc: 0.4475\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 409us/step - loss: 47.7484 - acc: 0.4421 - val_loss: 44.8347 - val_acc: 0.4462\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 47.7699 - acc: 0.4414 - val_loss: 44.8073 - val_acc: 0.4481\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 47.7494 - acc: 0.4418 - val_loss: 44.7617 - val_acc: 0.4476\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 47.7097 - acc: 0.4418 - val_loss: 44.7508 - val_acc: 0.4477\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 47.7026 - acc: 0.4416 - val_loss: 44.7567 - val_acc: 0.4479\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 47.7485 - acc: 0.4422 - val_loss: 44.7323 - val_acc: 0.4475\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 47.6865 - acc: 0.4418 - val_loss: 44.7351 - val_acc: 0.4475\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 47.7897 - acc: 0.4413 - val_loss: 45.1155 - val_acc: 0.4484\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 47.7781 - acc: 0.4418 - val_loss: 44.8631 - val_acc: 0.4481\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 47.6861 - acc: 0.4418 - val_loss: 44.7067 - val_acc: 0.4482\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 47.6649 - acc: 0.4418 - val_loss: 44.7525 - val_acc: 0.4486\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 47.6881 - acc: 0.4417 - val_loss: 44.6925 - val_acc: 0.4484\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 47.6782 - acc: 0.4423 - val_loss: 44.6595 - val_acc: 0.4476\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 47.6512 - acc: 0.4418 - val_loss: 44.6985 - val_acc: 0.4477\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 47.6238 - acc: 0.4415 - val_loss: 44.6477 - val_acc: 0.4481\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 47.6920 - acc: 0.4417 - val_loss: 44.8579 - val_acc: 0.4467\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 435us/step - loss: 47.6892 - acc: 0.4419 - val_loss: 44.6738 - val_acc: 0.4474\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 47.6042 - acc: 0.4421 - val_loss: 44.7322 - val_acc: 0.4486\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 47.6423 - acc: 0.4422 - val_loss: 44.6172 - val_acc: 0.4476\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 47.5843 - acc: 0.4416 - val_loss: 44.7568 - val_acc: 0.4469\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 47.5779 - acc: 0.4421 - val_loss: 44.5826 - val_acc: 0.4478\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 47.5270 - acc: 0.4417 - val_loss: 44.5969 - val_acc: 0.4478\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 47.5897 - acc: 0.4419 - val_loss: 44.7334 - val_acc: 0.4457\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 47.6472 - acc: 0.4414 - val_loss: 44.5623 - val_acc: 0.4475\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4449 - acc: 0.4658 - val_loss: 0.4257 - val_acc: 0.4711\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4452 - acc: 0.4660 - val_loss: 0.4258 - val_acc: 0.4713\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4461 - acc: 0.4658 - val_loss: 0.4245 - val_acc: 0.4709\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4448 - acc: 0.4660 - val_loss: 0.4245 - val_acc: 0.4709\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.4449 - acc: 0.4661 - val_loss: 0.4248 - val_acc: 0.4709\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.4446 - acc: 0.4661 - val_loss: 0.4248 - val_acc: 0.4709\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4454 - acc: 0.4660 - val_loss: 0.4245 - val_acc: 0.4712\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.4445 - acc: 0.4659 - val_loss: 0.4243 - val_acc: 0.4710\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4440 - acc: 0.4664 - val_loss: 0.4241 - val_acc: 0.4710\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4442 - acc: 0.4660 - val_loss: 0.4239 - val_acc: 0.4713\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4442 - acc: 0.4662 - val_loss: 0.4254 - val_acc: 0.4711\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4439 - acc: 0.4662 - val_loss: 0.4239 - val_acc: 0.4714\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4438 - acc: 0.4658 - val_loss: 0.4242 - val_acc: 0.4708\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.4437 - acc: 0.4656 - val_loss: 0.4239 - val_acc: 0.4717\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.4438 - acc: 0.4666 - val_loss: 0.4236 - val_acc: 0.4712\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4438 - acc: 0.4662 - val_loss: 0.4240 - val_acc: 0.4712\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4433 - acc: 0.4658 - val_loss: 0.4237 - val_acc: 0.4709\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.4437 - acc: 0.4657 - val_loss: 0.4234 - val_acc: 0.4713\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.4433 - acc: 0.4665 - val_loss: 0.4233 - val_acc: 0.4713\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4432 - acc: 0.4663 - val_loss: 0.4233 - val_acc: 0.4709\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 470us/step - loss: 0.4430 - acc: 0.4663 - val_loss: 0.4239 - val_acc: 0.4711\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4431 - acc: 0.4663 - val_loss: 0.4230 - val_acc: 0.4710\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 468us/step - loss: 0.4428 - acc: 0.4664 - val_loss: 0.4240 - val_acc: 0.4716\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4433 - acc: 0.4662 - val_loss: 0.4256 - val_acc: 0.4717\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4428 - acc: 0.4662 - val_loss: 0.4228 - val_acc: 0.4713\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.4425 - acc: 0.4663 - val_loss: 0.4236 - val_acc: 0.4715\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.4444 - acc: 0.4661 - val_loss: 0.4234 - val_acc: 0.4715\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.4428 - acc: 0.4665 - val_loss: 0.4228 - val_acc: 0.4716\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4423 - acc: 0.4659 - val_loss: 0.4226 - val_acc: 0.4715\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4427 - acc: 0.4662 - val_loss: 0.4227 - val_acc: 0.4720\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.4426 - acc: 0.4666 - val_loss: 0.4254 - val_acc: 0.4704\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 0.4425 - acc: 0.4665 - val_loss: 0.4239 - val_acc: 0.4713\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.4425 - acc: 0.4661 - val_loss: 0.4221 - val_acc: 0.4716\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4432 - acc: 0.4663 - val_loss: 0.4221 - val_acc: 0.4717\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4420 - acc: 0.4665 - val_loss: 0.4221 - val_acc: 0.4716\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4420 - acc: 0.4665 - val_loss: 0.4222 - val_acc: 0.4719\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4417 - acc: 0.4664 - val_loss: 0.4227 - val_acc: 0.4714\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 0.4418 - acc: 0.4659 - val_loss: 0.4221 - val_acc: 0.4727\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.4417 - acc: 0.4665 - val_loss: 0.4226 - val_acc: 0.4723\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.4414 - acc: 0.4670 - val_loss: 0.4224 - val_acc: 0.4715\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.4416 - acc: 0.4662 - val_loss: 0.4217 - val_acc: 0.4718\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.4412 - acc: 0.4664 - val_loss: 0.4223 - val_acc: 0.4721\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4414 - acc: 0.4667 - val_loss: 0.4217 - val_acc: 0.4718\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4410 - acc: 0.4663 - val_loss: 0.4216 - val_acc: 0.4720\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4410 - acc: 0.4666 - val_loss: 0.4213 - val_acc: 0.4721\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4407 - acc: 0.4662 - val_loss: 0.4214 - val_acc: 0.4720\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.4410 - acc: 0.4663 - val_loss: 0.4213 - val_acc: 0.4724\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4407 - acc: 0.4667 - val_loss: 0.4215 - val_acc: 0.4721\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4405 - acc: 0.4665 - val_loss: 0.4213 - val_acc: 0.4722\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4405 - acc: 0.4668 - val_loss: 0.4209 - val_acc: 0.4721\n",
      "start training round 21\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 430us/step - loss: 28.5187 - acc: 0.6800 - val_loss: 28.9029 - val_acc: 0.6714\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 28.5788 - acc: 0.6807 - val_loss: 28.7481 - val_acc: 0.6755\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 28.7311 - acc: 0.6811 - val_loss: 28.7792 - val_acc: 0.6693\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 27.8734 - acc: 0.6804 - val_loss: 29.5938 - val_acc: 0.6640\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 28.5210 - acc: 0.6804 - val_loss: 27.2693 - val_acc: 0.6752\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 28.5701 - acc: 0.6813 - val_loss: 28.2359 - val_acc: 0.6722\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 28.7575 - acc: 0.6868 - val_loss: 27.0016 - val_acc: 0.6766\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 27.6039 - acc: 0.6795 - val_loss: 28.8979 - val_acc: 0.6678\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 28.9060 - acc: 0.6786 - val_loss: 31.8023 - val_acc: 0.6673\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 28.5915 - acc: 0.6793 - val_loss: 26.9047 - val_acc: 0.6744\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 28.4520 - acc: 0.6790 - val_loss: 29.8782 - val_acc: 0.6710\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 28.2800 - acc: 0.6815 - val_loss: 28.5437 - val_acc: 0.6744\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 28.4886 - acc: 0.6797 - val_loss: 29.4006 - val_acc: 0.6697\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 28.6092 - acc: 0.6798 - val_loss: 28.2912 - val_acc: 0.6750\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 28.3440 - acc: 0.6788 - val_loss: 29.1341 - val_acc: 0.6749\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 28.5929 - acc: 0.6790 - val_loss: 30.1878 - val_acc: 0.6624\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 28.9815 - acc: 0.6829 - val_loss: 29.0074 - val_acc: 0.6762\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 28.4060 - acc: 0.6805 - val_loss: 28.0381 - val_acc: 0.6763\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 28.3552 - acc: 0.6791 - val_loss: 29.4608 - val_acc: 0.6684\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 28.8513 - acc: 0.6861 - val_loss: 28.0621 - val_acc: 0.6751\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 27.2436 - acc: 0.6800 - val_loss: 27.6945 - val_acc: 0.6724\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 28.0119 - acc: 0.6772 - val_loss: 29.5323 - val_acc: 0.6621\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 28.9109 - acc: 0.6781 - val_loss: 31.1417 - val_acc: 0.6691\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 28.7623 - acc: 0.6802 - val_loss: 29.5103 - val_acc: 0.6697\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 28.5044 - acc: 0.6858 - val_loss: 27.7158 - val_acc: 0.6752\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 28.4002 - acc: 0.6839 - val_loss: 28.5950 - val_acc: 0.6731\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 28.2309 - acc: 0.6881 - val_loss: 28.9285 - val_acc: 0.6722\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 28.4428 - acc: 0.6818 - val_loss: 29.2782 - val_acc: 0.6652\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 28.1478 - acc: 0.6783 - val_loss: 28.9251 - val_acc: 0.6667\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 28.4502 - acc: 0.6783 - val_loss: 27.2284 - val_acc: 0.6774\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 28.3776 - acc: 0.6778 - val_loss: 27.5993 - val_acc: 0.6816\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 28.1396 - acc: 0.6797 - val_loss: 28.7038 - val_acc: 0.6821\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 28.3043 - acc: 0.6803 - val_loss: 27.6931 - val_acc: 0.6793\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 27.9908 - acc: 0.6787 - val_loss: 27.5257 - val_acc: 0.6784\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 28.7501 - acc: 0.6774 - val_loss: 29.3536 - val_acc: 0.6821\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 28.3884 - acc: 0.6798 - val_loss: 29.1353 - val_acc: 0.6818\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 28.6454 - acc: 0.6793 - val_loss: 28.1683 - val_acc: 0.6792\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 28.2272 - acc: 0.6783 - val_loss: 27.1414 - val_acc: 0.6766\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 28.2024 - acc: 0.6777 - val_loss: 27.3139 - val_acc: 0.6787\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 28.1526 - acc: 0.6794 - val_loss: 27.4484 - val_acc: 0.6784\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 28.4080 - acc: 0.6787 - val_loss: 28.9258 - val_acc: 0.6815\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 28.4047 - acc: 0.6788 - val_loss: 27.6347 - val_acc: 0.6833\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 28.7622 - acc: 0.6825 - val_loss: 28.6126 - val_acc: 0.7135\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 27.9786 - acc: 0.6880 - val_loss: 28.5351 - val_acc: 0.6766\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 28.6474 - acc: 0.6776 - val_loss: 29.5838 - val_acc: 0.6700\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 28.3695 - acc: 0.6852 - val_loss: 28.0397 - val_acc: 0.6712\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 28.0022 - acc: 0.6853 - val_loss: 27.8840 - val_acc: 0.6746\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 27.6158 - acc: 0.6784 - val_loss: 28.4156 - val_acc: 0.6794\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 29.0166 - acc: 0.6776 - val_loss: 27.3061 - val_acc: 0.6823\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 28.3515 - acc: 0.6832 - val_loss: 27.5867 - val_acc: 0.7130\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 105.8616 - acc: 0.6391 - val_loss: 106.6492 - val_acc: 0.6342\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 105.5652 - acc: 0.6403 - val_loss: 106.0819 - val_acc: 0.6355\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 106.9093 - acc: 0.6411 - val_loss: 109.7587 - val_acc: 0.6331\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 110.3626 - acc: 0.6388 - val_loss: 108.4479 - val_acc: 0.6338\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 110.0317 - acc: 0.6399 - val_loss: 105.4864 - val_acc: 0.6349\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 106.5822 - acc: 0.6390 - val_loss: 111.3842 - val_acc: 0.6313\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 105.9284 - acc: 0.6393 - val_loss: 107.0443 - val_acc: 0.6351\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 105.3341 - acc: 0.6408 - val_loss: 108.4957 - val_acc: 0.6358\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 383us/step - loss: 109.2182 - acc: 0.6412 - val_loss: 106.1469 - val_acc: 0.6345\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 106.9972 - acc: 0.6392 - val_loss: 110.6222 - val_acc: 0.6314\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 107.3499 - acc: 0.6378 - val_loss: 107.1404 - val_acc: 0.6311\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 105.7310 - acc: 0.6396 - val_loss: 108.0184 - val_acc: 0.6334\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 106.7311 - acc: 0.6390 - val_loss: 108.1026 - val_acc: 0.6326\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 107.4610 - acc: 0.6386 - val_loss: 109.0417 - val_acc: 0.6320\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 107.9258 - acc: 0.6384 - val_loss: 105.1935 - val_acc: 0.6362\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 105.8598 - acc: 0.6379 - val_loss: 109.2092 - val_acc: 0.6305\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 106.1207 - acc: 0.6398 - val_loss: 106.1593 - val_acc: 0.6342\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 105.2919 - acc: 0.6380 - val_loss: 106.6019 - val_acc: 0.6307\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 105.6053 - acc: 0.6389 - val_loss: 107.5809 - val_acc: 0.6330\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 106.3267 - acc: 0.6396 - val_loss: 111.7171 - val_acc: 0.6352\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 108.7689 - acc: 0.6408 - val_loss: 112.7298 - val_acc: 0.6327\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 109.0643 - acc: 0.6406 - val_loss: 109.7914 - val_acc: 0.6340\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 105.8534 - acc: 0.6400 - val_loss: 108.0274 - val_acc: 0.6318\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 105.8718 - acc: 0.6361 - val_loss: 104.8799 - val_acc: 0.6342\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 105.6008 - acc: 0.6383 - val_loss: 106.9946 - val_acc: 0.6330\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 105.8611 - acc: 0.6400 - val_loss: 108.8681 - val_acc: 0.6337\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 110.7984 - acc: 0.6402 - val_loss: 106.4499 - val_acc: 0.6349\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 107.1265 - acc: 0.6403 - val_loss: 108.3867 - val_acc: 0.6332\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 106.4507 - acc: 0.6374 - val_loss: 108.6002 - val_acc: 0.6291\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 105.4391 - acc: 0.6366 - val_loss: 106.0644 - val_acc: 0.6341\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 105.0813 - acc: 0.6396 - val_loss: 106.3072 - val_acc: 0.6351\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 107.1545 - acc: 0.6402 - val_loss: 107.5514 - val_acc: 0.6332\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 107.7427 - acc: 0.6396 - val_loss: 109.3414 - val_acc: 0.6337\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 106.7569 - acc: 0.6391 - val_loss: 106.0952 - val_acc: 0.6320\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 104.7549 - acc: 0.6389 - val_loss: 105.8944 - val_acc: 0.6319\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 104.7887 - acc: 0.6390 - val_loss: 108.8049 - val_acc: 0.6296\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 106.5618 - acc: 0.6398 - val_loss: 113.0552 - val_acc: 0.6354\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 108.4974 - acc: 0.6410 - val_loss: 113.4106 - val_acc: 0.6346\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 358us/step - loss: 111.2236 - acc: 0.6401 - val_loss: 109.9256 - val_acc: 0.6354\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 107.8405 - acc: 0.6401 - val_loss: 111.3143 - val_acc: 0.6332\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 104.6973 - acc: 0.6392 - val_loss: 107.3035 - val_acc: 0.6272\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 105.1891 - acc: 0.6375 - val_loss: 104.7454 - val_acc: 0.6346\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 104.9308 - acc: 0.6394 - val_loss: 106.7802 - val_acc: 0.6350\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 105.7787 - acc: 0.6400 - val_loss: 107.1960 - val_acc: 0.6365\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 108.0686 - acc: 0.6409 - val_loss: 110.5335 - val_acc: 0.6343\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 107.7528 - acc: 0.6404 - val_loss: 107.3130 - val_acc: 0.6352\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 109.7867 - acc: 0.6407 - val_loss: 112.1966 - val_acc: 0.6361\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 109.2107 - acc: 0.6408 - val_loss: 112.6682 - val_acc: 0.6337\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 106.5142 - acc: 0.6394 - val_loss: 112.4326 - val_acc: 0.6262\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 106.6875 - acc: 0.6392 - val_loss: 109.3529 - val_acc: 0.6353\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 47.5976 - acc: 0.4419 - val_loss: 44.7056 - val_acc: 0.4457\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 47.6642 - acc: 0.4410 - val_loss: 44.6722 - val_acc: 0.4469\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 47.5157 - acc: 0.4418 - val_loss: 44.5794 - val_acc: 0.4485\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 47.5278 - acc: 0.4418 - val_loss: 44.5124 - val_acc: 0.4472\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 47.4665 - acc: 0.4419 - val_loss: 44.5097 - val_acc: 0.4477\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 47.5168 - acc: 0.4417 - val_loss: 44.6894 - val_acc: 0.4487\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 47.9230 - acc: 0.4416 - val_loss: 44.5504 - val_acc: 0.4476\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 47.5998 - acc: 0.4417 - val_loss: 44.5800 - val_acc: 0.4481\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 47.5331 - acc: 0.4418 - val_loss: 44.5873 - val_acc: 0.4474\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 47.5730 - acc: 0.4417 - val_loss: 44.4844 - val_acc: 0.4479\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 47.4878 - acc: 0.4414 - val_loss: 44.7458 - val_acc: 0.4486\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 48.0825 - acc: 0.4420 - val_loss: 44.4932 - val_acc: 0.4479\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 47.4386 - acc: 0.4416 - val_loss: 44.4255 - val_acc: 0.4476\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 47.5407 - acc: 0.4420 - val_loss: 44.6089 - val_acc: 0.4454\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 47.5227 - acc: 0.4417 - val_loss: 44.4539 - val_acc: 0.4459\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 47.3646 - acc: 0.4414 - val_loss: 44.5674 - val_acc: 0.4484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 47.4937 - acc: 0.4418 - val_loss: 44.4308 - val_acc: 0.4479\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 47.3331 - acc: 0.4421 - val_loss: 44.4288 - val_acc: 0.4473\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 47.3669 - acc: 0.4414 - val_loss: 44.4353 - val_acc: 0.4472\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 47.3035 - acc: 0.4420 - val_loss: 44.3894 - val_acc: 0.4477\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 47.3090 - acc: 0.4421 - val_loss: 44.3892 - val_acc: 0.4463\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 47.2931 - acc: 0.4413 - val_loss: 44.3356 - val_acc: 0.4476\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 47.3265 - acc: 0.4421 - val_loss: 44.7464 - val_acc: 0.4484\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 47.4224 - acc: 0.4415 - val_loss: 44.6496 - val_acc: 0.4480\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 47.3949 - acc: 0.4413 - val_loss: 44.4400 - val_acc: 0.4485\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 47.3723 - acc: 0.4417 - val_loss: 44.6972 - val_acc: 0.4486\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 47.3233 - acc: 0.4415 - val_loss: 44.3467 - val_acc: 0.4482\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 47.5970 - acc: 0.4418 - val_loss: 44.5096 - val_acc: 0.4486\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 47.3400 - acc: 0.4414 - val_loss: 44.2782 - val_acc: 0.4478\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 47.1781 - acc: 0.4424 - val_loss: 44.2794 - val_acc: 0.4471\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 47.2909 - acc: 0.4413 - val_loss: 44.3607 - val_acc: 0.4480\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 47.2058 - acc: 0.4419 - val_loss: 44.3137 - val_acc: 0.4477\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 47.2480 - acc: 0.4417 - val_loss: 44.4003 - val_acc: 0.4482\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 47.4556 - acc: 0.4409 - val_loss: 44.4362 - val_acc: 0.4487\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 47.2475 - acc: 0.4421 - val_loss: 44.2111 - val_acc: 0.4471\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 47.1490 - acc: 0.4416 - val_loss: 44.2682 - val_acc: 0.4476\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 47.1295 - acc: 0.4423 - val_loss: 44.2229 - val_acc: 0.4468\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 47.2179 - acc: 0.4411 - val_loss: 44.2797 - val_acc: 0.4478\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 47.2962 - acc: 0.4413 - val_loss: 44.3116 - val_acc: 0.4483\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 47.3526 - acc: 0.4418 - val_loss: 44.3835 - val_acc: 0.4485\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 47.3721 - acc: 0.4412 - val_loss: 44.5024 - val_acc: 0.4480\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 47.6403 - acc: 0.4415 - val_loss: 44.1612 - val_acc: 0.4478\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 47.1123 - acc: 0.4419 - val_loss: 44.3949 - val_acc: 0.4480\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 47.1599 - acc: 0.4418 - val_loss: 44.1124 - val_acc: 0.4472\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 47.0596 - acc: 0.4413 - val_loss: 44.1861 - val_acc: 0.4476\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 47.7391 - acc: 0.4409 - val_loss: 44.7910 - val_acc: 0.4483\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 47.6129 - acc: 0.4418 - val_loss: 44.1558 - val_acc: 0.4475\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 47.0420 - acc: 0.4418 - val_loss: 44.4530 - val_acc: 0.4483\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 47.3954 - acc: 0.4412 - val_loss: 44.4453 - val_acc: 0.4487\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 47.2562 - acc: 0.4415 - val_loss: 44.2361 - val_acc: 0.4482\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4413 - acc: 0.4664 - val_loss: 0.4211 - val_acc: 0.4720\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4406 - acc: 0.4668 - val_loss: 0.4211 - val_acc: 0.4722\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4403 - acc: 0.4664 - val_loss: 0.4209 - val_acc: 0.4720\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4405 - acc: 0.4667 - val_loss: 0.4213 - val_acc: 0.4722\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4408 - acc: 0.4664 - val_loss: 0.4206 - val_acc: 0.4723\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.4398 - acc: 0.4669 - val_loss: 0.4205 - val_acc: 0.4723\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4399 - acc: 0.4666 - val_loss: 0.4206 - val_acc: 0.4721\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4399 - acc: 0.4669 - val_loss: 0.4208 - val_acc: 0.4724\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4397 - acc: 0.4667 - val_loss: 0.4205 - val_acc: 0.4722\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4406 - acc: 0.4667 - val_loss: 0.4205 - val_acc: 0.4723\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4395 - acc: 0.4668 - val_loss: 0.4202 - val_acc: 0.4724\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4395 - acc: 0.4668 - val_loss: 0.4200 - val_acc: 0.4723\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4396 - acc: 0.4672 - val_loss: 0.4213 - val_acc: 0.4721\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4392 - acc: 0.4666 - val_loss: 0.4200 - val_acc: 0.4727\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4391 - acc: 0.4669 - val_loss: 0.4198 - val_acc: 0.4723\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4391 - acc: 0.4671 - val_loss: 0.4200 - val_acc: 0.4721\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4391 - acc: 0.4668 - val_loss: 0.4201 - val_acc: 0.4723\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4390 - acc: 0.4669 - val_loss: 0.4196 - val_acc: 0.4723\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4392 - acc: 0.4665 - val_loss: 0.4195 - val_acc: 0.4723\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4388 - acc: 0.4668 - val_loss: 0.4222 - val_acc: 0.4728\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4388 - acc: 0.4669 - val_loss: 0.4194 - val_acc: 0.4719\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4386 - acc: 0.4670 - val_loss: 0.4195 - val_acc: 0.4722\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4385 - acc: 0.4670 - val_loss: 0.4194 - val_acc: 0.4725\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4388 - acc: 0.4668 - val_loss: 0.4206 - val_acc: 0.4728\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4387 - acc: 0.4667 - val_loss: 0.4201 - val_acc: 0.4726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4381 - acc: 0.4671 - val_loss: 0.4191 - val_acc: 0.4723\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4395 - acc: 0.4668 - val_loss: 0.4189 - val_acc: 0.4724\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4383 - acc: 0.4670 - val_loss: 0.4191 - val_acc: 0.4725\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4380 - acc: 0.4674 - val_loss: 0.4197 - val_acc: 0.4727\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4383 - acc: 0.4670 - val_loss: 0.4190 - val_acc: 0.4723\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.4378 - acc: 0.4669 - val_loss: 0.4200 - val_acc: 0.4734\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4394 - acc: 0.4669 - val_loss: 0.4186 - val_acc: 0.4730\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4379 - acc: 0.4671 - val_loss: 0.4194 - val_acc: 0.4731\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4390 - acc: 0.4671 - val_loss: 0.4190 - val_acc: 0.4726\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4375 - acc: 0.4674 - val_loss: 0.4190 - val_acc: 0.4724\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.4374 - acc: 0.4676 - val_loss: 0.4188 - val_acc: 0.4728\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4375 - acc: 0.4669 - val_loss: 0.4182 - val_acc: 0.4734\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4371 - acc: 0.4673 - val_loss: 0.4183 - val_acc: 0.4730\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4370 - acc: 0.4673 - val_loss: 0.4181 - val_acc: 0.4730\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4373 - acc: 0.4676 - val_loss: 0.4190 - val_acc: 0.4725\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4376 - acc: 0.4668 - val_loss: 0.4233 - val_acc: 0.4736\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4377 - acc: 0.4674 - val_loss: 0.4180 - val_acc: 0.4731\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.4368 - acc: 0.4674 - val_loss: 0.4184 - val_acc: 0.4724\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.4366 - acc: 0.4673 - val_loss: 0.4178 - val_acc: 0.4728\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4366 - acc: 0.4676 - val_loss: 0.4186 - val_acc: 0.4734\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4366 - acc: 0.4673 - val_loss: 0.4174 - val_acc: 0.4730\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4363 - acc: 0.4672 - val_loss: 0.4177 - val_acc: 0.4733\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.4366 - acc: 0.4673 - val_loss: 0.4190 - val_acc: 0.4723\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.4378 - acc: 0.4675 - val_loss: 0.4174 - val_acc: 0.4728\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4362 - acc: 0.4676 - val_loss: 0.4173 - val_acc: 0.4726\n",
      "start training round 22\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 27.9766 - acc: 0.6866 - val_loss: 28.7102 - val_acc: 0.6813\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 28.4308 - acc: 0.6834 - val_loss: 28.3484 - val_acc: 0.6829\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 28.3822 - acc: 0.6822 - val_loss: 28.1664 - val_acc: 0.6812\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 28.1750 - acc: 0.6787 - val_loss: 27.2522 - val_acc: 0.6773\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 28.3643 - acc: 0.6781 - val_loss: 27.7355 - val_acc: 0.6765\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 28.0073 - acc: 0.6773 - val_loss: 30.7712 - val_acc: 0.6799\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 27.9817 - acc: 0.6778 - val_loss: 28.3557 - val_acc: 0.6815\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 28.8612 - acc: 0.6832 - val_loss: 27.4566 - val_acc: 0.6800\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 28.2751 - acc: 0.6797 - val_loss: 28.2156 - val_acc: 0.6802\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.1473 - acc: 0.6789 - val_loss: 27.4380 - val_acc: 0.6800\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 28.6258 - acc: 0.6800 - val_loss: 29.5891 - val_acc: 0.7136\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 28.7667 - acc: 0.6904 - val_loss: 27.8086 - val_acc: 0.7135\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 27.5339 - acc: 0.6848 - val_loss: 26.7845 - val_acc: 0.6781\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 28.5341 - acc: 0.6782 - val_loss: 27.7459 - val_acc: 0.6802\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 27.6545 - acc: 0.6790 - val_loss: 27.8581 - val_acc: 0.6819\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 28.7950 - acc: 0.6778 - val_loss: 30.0652 - val_acc: 0.7131\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.0067 - acc: 0.6814 - val_loss: 27.7534 - val_acc: 0.6750\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 28.2146 - acc: 0.6768 - val_loss: 28.6286 - val_acc: 0.6657\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 28.0790 - acc: 0.6768 - val_loss: 33.3919 - val_acc: 0.6604\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 29.0601 - acc: 0.6884 - val_loss: 28.3009 - val_acc: 0.6754\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 27.5007 - acc: 0.6828 - val_loss: 28.3466 - val_acc: 0.6737\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 28.3492 - acc: 0.6770 - val_loss: 27.8812 - val_acc: 0.6665\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 27.9479 - acc: 0.6775 - val_loss: 31.5046 - val_acc: 0.6646\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.8014 - acc: 0.6783 - val_loss: 28.7347 - val_acc: 0.6730\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 28.6368 - acc: 0.6873 - val_loss: 29.8158 - val_acc: 0.6700\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 28.5945 - acc: 0.6913 - val_loss: 27.6999 - val_acc: 0.6770\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 28.0669 - acc: 0.6931 - val_loss: 27.8025 - val_acc: 0.6708\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.6418 - acc: 0.6890 - val_loss: 28.0771 - val_acc: 0.6738\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 28.3767 - acc: 0.6925 - val_loss: 28.2786 - val_acc: 0.6742\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 28.0106 - acc: 0.6827 - val_loss: 27.7606 - val_acc: 0.6683\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 27.5779 - acc: 0.6770 - val_loss: 29.7931 - val_acc: 0.6677\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 28.5720 - acc: 0.6779 - val_loss: 28.8194 - val_acc: 0.6684\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 27.9409 - acc: 0.6775 - val_loss: 31.6392 - val_acc: 0.6603\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.5888 - acc: 0.6890 - val_loss: 28.2320 - val_acc: 0.6796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 27.9887 - acc: 0.6808 - val_loss: 29.8362 - val_acc: 0.6800\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 28.2962 - acc: 0.6768 - val_loss: 27.9435 - val_acc: 0.6811\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 28.3031 - acc: 0.6783 - val_loss: 26.8995 - val_acc: 0.6783\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 27.8929 - acc: 0.6805 - val_loss: 27.6380 - val_acc: 0.6795\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 28.2258 - acc: 0.6774 - val_loss: 28.4155 - val_acc: 0.6811\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 28.2856 - acc: 0.6791 - val_loss: 28.4428 - val_acc: 0.7127\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 27.8094 - acc: 0.6790 - val_loss: 29.0345 - val_acc: 0.6823\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 28.6805 - acc: 0.6884 - val_loss: 27.5873 - val_acc: 0.7128\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 28.0952 - acc: 0.6915 - val_loss: 27.5197 - val_acc: 0.6802\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 27.9804 - acc: 0.6776 - val_loss: 27.5860 - val_acc: 0.6770\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 27.8825 - acc: 0.6768 - val_loss: 28.1527 - val_acc: 0.6821\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 27.9568 - acc: 0.6768 - val_loss: 29.7190 - val_acc: 0.7133\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 28.5198 - acc: 0.6920 - val_loss: 28.7746 - val_acc: 0.7134\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 27.8568 - acc: 0.6866 - val_loss: 28.6261 - val_acc: 0.6738\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 28.5132 - acc: 0.6810 - val_loss: 29.2777 - val_acc: 0.6684\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 28.1272 - acc: 0.6877 - val_loss: 28.3499 - val_acc: 0.6709\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 107.4343 - acc: 0.6415 - val_loss: 111.0867 - val_acc: 0.6360\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 108.1372 - acc: 0.6407 - val_loss: 109.5426 - val_acc: 0.6329\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 106.3998 - acc: 0.6373 - val_loss: 104.9833 - val_acc: 0.6356\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 105.5780 - acc: 0.6388 - val_loss: 104.2707 - val_acc: 0.6360\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 103.9028 - acc: 0.6409 - val_loss: 106.3235 - val_acc: 0.6340\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 106.8568 - acc: 0.6406 - val_loss: 107.9697 - val_acc: 0.6360\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 108.0478 - acc: 0.6398 - val_loss: 110.4611 - val_acc: 0.6340\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 107.3379 - acc: 0.6408 - val_loss: 109.7085 - val_acc: 0.6357\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 108.6524 - acc: 0.6411 - val_loss: 106.3399 - val_acc: 0.6360\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 107.4420 - acc: 0.6399 - val_loss: 109.1390 - val_acc: 0.6331\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 107.0737 - acc: 0.6401 - val_loss: 104.5379 - val_acc: 0.6355\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 104.8549 - acc: 0.6396 - val_loss: 105.3423 - val_acc: 0.6340\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 105.3396 - acc: 0.6396 - val_loss: 112.2108 - val_acc: 0.6319\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 108.2388 - acc: 0.6401 - val_loss: 105.2145 - val_acc: 0.6349\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 105.0417 - acc: 0.6399 - val_loss: 107.3560 - val_acc: 0.6333\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 105.5773 - acc: 0.6376 - val_loss: 110.9067 - val_acc: 0.6250\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 106.2825 - acc: 0.6368 - val_loss: 105.6821 - val_acc: 0.6359\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 106.7919 - acc: 0.6417 - val_loss: 109.8572 - val_acc: 0.6352\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 107.9321 - acc: 0.6412 - val_loss: 108.6864 - val_acc: 0.6347\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 106.5062 - acc: 0.6409 - val_loss: 109.7410 - val_acc: 0.6325\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 106.6427 - acc: 0.6402 - val_loss: 112.3555 - val_acc: 0.6325\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 105.5832 - acc: 0.6417 - val_loss: 106.9424 - val_acc: 0.6349\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 106.8508 - acc: 0.6402 - val_loss: 106.2375 - val_acc: 0.6354\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 105.3490 - acc: 0.6390 - val_loss: 108.7977 - val_acc: 0.6272\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 104.6711 - acc: 0.6376 - val_loss: 104.5584 - val_acc: 0.6347\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 104.2575 - acc: 0.6409 - val_loss: 108.0106 - val_acc: 0.6361\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 108.0111 - acc: 0.6404 - val_loss: 110.4107 - val_acc: 0.6347\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 109.3053 - acc: 0.6407 - val_loss: 115.7700 - val_acc: 0.6356\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 110.7771 - acc: 0.6414 - val_loss: 106.2629 - val_acc: 0.6365\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 106.5892 - acc: 0.6410 - val_loss: 107.3250 - val_acc: 0.6312\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 105.2455 - acc: 0.6374 - val_loss: 104.0795 - val_acc: 0.6360\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 104.0573 - acc: 0.6403 - val_loss: 108.5662 - val_acc: 0.6299\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 105.1911 - acc: 0.6388 - val_loss: 111.3124 - val_acc: 0.6274\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 105.6352 - acc: 0.6386 - val_loss: 107.5612 - val_acc: 0.6350\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 106.9752 - acc: 0.6415 - val_loss: 113.1658 - val_acc: 0.6351\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 109.6333 - acc: 0.6402 - val_loss: 109.4044 - val_acc: 0.6347\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 107.7793 - acc: 0.6413 - val_loss: 108.8820 - val_acc: 0.6353\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 106.4371 - acc: 0.6419 - val_loss: 107.2550 - val_acc: 0.6368\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 106.5549 - acc: 0.6379 - val_loss: 107.8092 - val_acc: 0.6303\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 106.5012 - acc: 0.6398 - val_loss: 105.4225 - val_acc: 0.6355\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 104.8954 - acc: 0.6398 - val_loss: 108.5156 - val_acc: 0.6305\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 104.5993 - acc: 0.6402 - val_loss: 105.2356 - val_acc: 0.6338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 104.7453 - acc: 0.6377 - val_loss: 105.3678 - val_acc: 0.6327\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 104.4404 - acc: 0.6398 - val_loss: 104.1370 - val_acc: 0.6360\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 104.1645 - acc: 0.6390 - val_loss: 105.2858 - val_acc: 0.6322\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 104.0890 - acc: 0.6395 - val_loss: 107.7978 - val_acc: 0.6330\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 106.8151 - acc: 0.6417 - val_loss: 108.0388 - val_acc: 0.6349\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 108.3772 - acc: 0.6404 - val_loss: 107.7849 - val_acc: 0.6337\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 107.0853 - acc: 0.6406 - val_loss: 106.1219 - val_acc: 0.6352\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 107.8957 - acc: 0.6408 - val_loss: 106.1819 - val_acc: 0.6348\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 47.1528 - acc: 0.4414 - val_loss: 44.1664 - val_acc: 0.4479\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 47.0279 - acc: 0.4420 - val_loss: 44.0327 - val_acc: 0.4478\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 47.0074 - acc: 0.4418 - val_loss: 44.2917 - val_acc: 0.4458\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 47.0143 - acc: 0.4416 - val_loss: 44.0686 - val_acc: 0.4466\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 46.9661 - acc: 0.4418 - val_loss: 44.4070 - val_acc: 0.4478\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 47.2052 - acc: 0.4415 - val_loss: 44.1085 - val_acc: 0.4483\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 47.0150 - acc: 0.4420 - val_loss: 43.9798 - val_acc: 0.4472\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 46.9184 - acc: 0.4417 - val_loss: 44.0514 - val_acc: 0.4473\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 46.8755 - acc: 0.4420 - val_loss: 43.9396 - val_acc: 0.4460\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 46.8357 - acc: 0.4414 - val_loss: 43.9304 - val_acc: 0.4465\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 46.8372 - acc: 0.4417 - val_loss: 43.9227 - val_acc: 0.4469\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 46.8169 - acc: 0.4421 - val_loss: 43.9138 - val_acc: 0.4467\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 46.8188 - acc: 0.4418 - val_loss: 43.9445 - val_acc: 0.4465\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 46.9541 - acc: 0.4417 - val_loss: 43.9455 - val_acc: 0.4458\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 46.9083 - acc: 0.4419 - val_loss: 43.9234 - val_acc: 0.4460\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 47.0578 - acc: 0.4418 - val_loss: 44.1904 - val_acc: 0.4448\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 47.3899 - acc: 0.4410 - val_loss: 44.3100 - val_acc: 0.4457\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 47.2711 - acc: 0.4418 - val_loss: 44.0702 - val_acc: 0.4456\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 47.2278 - acc: 0.4421 - val_loss: 43.9166 - val_acc: 0.4450\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 46.7685 - acc: 0.4421 - val_loss: 43.8186 - val_acc: 0.4469\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 46.7040 - acc: 0.4418 - val_loss: 43.8231 - val_acc: 0.4478\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 46.7852 - acc: 0.4420 - val_loss: 44.4547 - val_acc: 0.4485\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 46.9635 - acc: 0.4417 - val_loss: 43.8263 - val_acc: 0.4475\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 46.8005 - acc: 0.4416 - val_loss: 43.8432 - val_acc: 0.4471\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 46.6748 - acc: 0.4420 - val_loss: 43.8661 - val_acc: 0.4464\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 46.7650 - acc: 0.4420 - val_loss: 43.7511 - val_acc: 0.4469\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 46.8728 - acc: 0.4415 - val_loss: 43.9312 - val_acc: 0.4463\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 47.0094 - acc: 0.4415 - val_loss: 43.7762 - val_acc: 0.4464\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 47.1899 - acc: 0.4419 - val_loss: 43.8722 - val_acc: 0.4467\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 46.7884 - acc: 0.4423 - val_loss: 44.1459 - val_acc: 0.4447\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 47.0643 - acc: 0.4422 - val_loss: 43.8210 - val_acc: 0.4449\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 46.6031 - acc: 0.4416 - val_loss: 43.8330 - val_acc: 0.4463\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 46.6127 - acc: 0.4420 - val_loss: 43.7817 - val_acc: 0.4462\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 46.6377 - acc: 0.4419 - val_loss: 43.6677 - val_acc: 0.4477\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 46.7099 - acc: 0.4419 - val_loss: 43.7368 - val_acc: 0.4475\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 46.7755 - acc: 0.4423 - val_loss: 43.6966 - val_acc: 0.4464\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 46.5196 - acc: 0.4422 - val_loss: 43.6849 - val_acc: 0.4461\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 46.6573 - acc: 0.4420 - val_loss: 43.6625 - val_acc: 0.4461\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 46.5604 - acc: 0.4424 - val_loss: 43.8749 - val_acc: 0.4451\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 47.2340 - acc: 0.4418 - val_loss: 43.7439 - val_acc: 0.4455\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 46.6446 - acc: 0.4417 - val_loss: 43.7623 - val_acc: 0.4462\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 46.4950 - acc: 0.4422 - val_loss: 43.6383 - val_acc: 0.4474\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 46.4753 - acc: 0.4423 - val_loss: 43.6072 - val_acc: 0.4470\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 46.4273 - acc: 0.4421 - val_loss: 43.6026 - val_acc: 0.4476\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 46.4498 - acc: 0.4422 - val_loss: 43.8447 - val_acc: 0.4488\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 47.1276 - acc: 0.4419 - val_loss: 43.8195 - val_acc: 0.4482\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 46.6781 - acc: 0.4421 - val_loss: 43.7088 - val_acc: 0.4481\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 46.5990 - acc: 0.4423 - val_loss: 43.5151 - val_acc: 0.4472\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 46.5141 - acc: 0.4423 - val_loss: 45.0184 - val_acc: 0.4492\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 46.9552 - acc: 0.4417 - val_loss: 43.9594 - val_acc: 0.4486\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.4361 - acc: 0.4674 - val_loss: 0.4181 - val_acc: 0.4733\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4364 - acc: 0.4675 - val_loss: 0.4187 - val_acc: 0.4725\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.4359 - acc: 0.4672 - val_loss: 0.4191 - val_acc: 0.4725\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4367 - acc: 0.4674 - val_loss: 0.4176 - val_acc: 0.4737\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.4356 - acc: 0.4676 - val_loss: 0.4169 - val_acc: 0.4734\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4357 - acc: 0.4675 - val_loss: 0.4168 - val_acc: 0.4732\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4360 - acc: 0.4677 - val_loss: 0.4181 - val_acc: 0.4723\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.4365 - acc: 0.4675 - val_loss: 0.4169 - val_acc: 0.4733\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.4356 - acc: 0.4675 - val_loss: 0.4256 - val_acc: 0.4712\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4372 - acc: 0.4672 - val_loss: 0.4167 - val_acc: 0.4734\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4352 - acc: 0.4677 - val_loss: 0.4168 - val_acc: 0.4731\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.4354 - acc: 0.4678 - val_loss: 0.4168 - val_acc: 0.4736\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4370 - acc: 0.4675 - val_loss: 0.4164 - val_acc: 0.4732\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4351 - acc: 0.4678 - val_loss: 0.4162 - val_acc: 0.4736\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4350 - acc: 0.4676 - val_loss: 0.4168 - val_acc: 0.4735\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4354 - acc: 0.4677 - val_loss: 0.4171 - val_acc: 0.4726\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4347 - acc: 0.4677 - val_loss: 0.4159 - val_acc: 0.4734\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.4349 - acc: 0.4675 - val_loss: 0.4168 - val_acc: 0.4740\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4349 - acc: 0.4678 - val_loss: 0.4195 - val_acc: 0.4724\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4366 - acc: 0.4674 - val_loss: 0.4160 - val_acc: 0.4736\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4349 - acc: 0.4678 - val_loss: 0.4157 - val_acc: 0.4736\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4345 - acc: 0.4677 - val_loss: 0.4156 - val_acc: 0.4737\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.4357 - acc: 0.4678 - val_loss: 0.4182 - val_acc: 0.4729\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4348 - acc: 0.4677 - val_loss: 0.4157 - val_acc: 0.4741\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4339 - acc: 0.4681 - val_loss: 0.4156 - val_acc: 0.4730\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.4339 - acc: 0.4677 - val_loss: 0.4155 - val_acc: 0.4734\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4345 - acc: 0.4675 - val_loss: 0.4151 - val_acc: 0.4733\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4340 - acc: 0.4679 - val_loss: 0.4172 - val_acc: 0.4723\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4349 - acc: 0.4676 - val_loss: 0.4155 - val_acc: 0.4742\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4339 - acc: 0.4678 - val_loss: 0.4152 - val_acc: 0.4734\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4341 - acc: 0.4680 - val_loss: 0.4200 - val_acc: 0.4724\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4346 - acc: 0.4678 - val_loss: 0.4157 - val_acc: 0.4741\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4337 - acc: 0.4678 - val_loss: 0.4156 - val_acc: 0.4742\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4345 - acc: 0.4679 - val_loss: 0.4147 - val_acc: 0.4736\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4336 - acc: 0.4679 - val_loss: 0.4166 - val_acc: 0.4740\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4337 - acc: 0.4681 - val_loss: 0.4146 - val_acc: 0.4738\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.4332 - acc: 0.4680 - val_loss: 0.4153 - val_acc: 0.4739\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4334 - acc: 0.4677 - val_loss: 0.4155 - val_acc: 0.4743\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.4330 - acc: 0.4680 - val_loss: 0.4149 - val_acc: 0.4735\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.4330 - acc: 0.4680 - val_loss: 0.4158 - val_acc: 0.4740\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4339 - acc: 0.4679 - val_loss: 0.4145 - val_acc: 0.4738\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4329 - acc: 0.4682 - val_loss: 0.4148 - val_acc: 0.4731\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4332 - acc: 0.4681 - val_loss: 0.4158 - val_acc: 0.4739\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.4326 - acc: 0.4680 - val_loss: 0.4183 - val_acc: 0.4725\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4328 - acc: 0.4678 - val_loss: 0.4140 - val_acc: 0.4737\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4326 - acc: 0.4679 - val_loss: 0.4144 - val_acc: 0.4743\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4325 - acc: 0.4678 - val_loss: 0.4139 - val_acc: 0.4739\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.4327 - acc: 0.4681 - val_loss: 0.4137 - val_acc: 0.4739\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4319 - acc: 0.4677 - val_loss: 0.4142 - val_acc: 0.4737\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4326 - acc: 0.4679 - val_loss: 0.4138 - val_acc: 0.4737\n",
      "start training round 23\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 28.3369 - acc: 0.6919 - val_loss: 26.8571 - val_acc: 0.6767\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 26.9576 - acc: 0.6778 - val_loss: 27.5051 - val_acc: 0.6785\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 28.1766 - acc: 0.6760 - val_loss: 28.6438 - val_acc: 0.6793\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 28.5492 - acc: 0.6803 - val_loss: 28.6241 - val_acc: 0.7129\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 28.1821 - acc: 0.6931 - val_loss: 28.7595 - val_acc: 0.7120\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 28.1082 - acc: 0.6797 - val_loss: 27.9486 - val_acc: 0.7134\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 28.3438 - acc: 0.6869 - val_loss: 29.4025 - val_acc: 0.6775\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 28.2008 - acc: 0.6921 - val_loss: 27.5524 - val_acc: 0.6786\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 28.1269 - acc: 0.6923 - val_loss: 27.9521 - val_acc: 0.6766\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 388us/step - loss: 28.0782 - acc: 0.6774 - val_loss: 28.5026 - val_acc: 0.7130\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 28.4278 - acc: 0.6884 - val_loss: 27.7408 - val_acc: 0.7122\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 28.0344 - acc: 0.6832 - val_loss: 29.0577 - val_acc: 0.7129\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 28.4390 - acc: 0.6923 - val_loss: 27.1087 - val_acc: 0.6805\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 27.5666 - acc: 0.6876 - val_loss: 27.6403 - val_acc: 0.6736\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 28.6007 - acc: 0.6762 - val_loss: 28.4106 - val_acc: 0.6690\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 28.3565 - acc: 0.6810 - val_loss: 28.3640 - val_acc: 0.6695\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 27.8772 - acc: 0.6850 - val_loss: 28.8460 - val_acc: 0.6740\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.1067 - acc: 0.6767 - val_loss: 27.3530 - val_acc: 0.6793\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 27.9274 - acc: 0.6774 - val_loss: 28.0257 - val_acc: 0.6821\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 27.9776 - acc: 0.6799 - val_loss: 27.9557 - val_acc: 0.6817\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 28.2208 - acc: 0.6873 - val_loss: 27.1417 - val_acc: 0.6796\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 27.4980 - acc: 0.6778 - val_loss: 27.1008 - val_acc: 0.6752\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 27.5044 - acc: 0.6764 - val_loss: 28.1737 - val_acc: 0.6824\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 28.3784 - acc: 0.6794 - val_loss: 27.8930 - val_acc: 0.6796\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 28.3981 - acc: 0.6846 - val_loss: 27.5108 - val_acc: 0.7133\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 27.9511 - acc: 0.6930 - val_loss: 27.8870 - val_acc: 0.6808\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 28.0310 - acc: 0.6816 - val_loss: 28.7415 - val_acc: 0.6800\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 28.4065 - acc: 0.6889 - val_loss: 26.9864 - val_acc: 0.7125\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 28.1461 - acc: 0.6913 - val_loss: 27.5928 - val_acc: 0.7128\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 27.9726 - acc: 0.6920 - val_loss: 29.6420 - val_acc: 0.7130\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 27.8381 - acc: 0.6869 - val_loss: 28.2469 - val_acc: 0.6799\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.7777 - acc: 0.6893 - val_loss: 28.0339 - val_acc: 0.7132\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 28.2060 - acc: 0.6906 - val_loss: 28.6033 - val_acc: 0.7122\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 27.9583 - acc: 0.6946 - val_loss: 28.4895 - val_acc: 0.7128\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 27.6767 - acc: 0.6844 - val_loss: 29.5090 - val_acc: 0.6810\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 28.3321 - acc: 0.6764 - val_loss: 27.5224 - val_acc: 0.6785\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 28.4429 - acc: 0.6887 - val_loss: 29.0903 - val_acc: 0.7122\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 28.0465 - acc: 0.6911 - val_loss: 26.9046 - val_acc: 0.7131\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 27.3792 - acc: 0.6800 - val_loss: 29.9748 - val_acc: 0.6822\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.3033 - acc: 0.6887 - val_loss: 27.8247 - val_acc: 0.6787\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 27.8402 - acc: 0.6779 - val_loss: 27.1959 - val_acc: 0.6806\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 28.0458 - acc: 0.6814 - val_loss: 28.3071 - val_acc: 0.7129\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 28.2099 - acc: 0.6945 - val_loss: 27.2457 - val_acc: 0.6790\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 27.9966 - acc: 0.6775 - val_loss: 27.3975 - val_acc: 0.6732\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 27.7676 - acc: 0.6852 - val_loss: 27.9983 - val_acc: 0.6695\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 27.1583 - acc: 0.6763 - val_loss: 27.9034 - val_acc: 0.6763\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 28.4382 - acc: 0.6745 - val_loss: 28.4859 - val_acc: 0.6787\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 28.0735 - acc: 0.6898 - val_loss: 27.8285 - val_acc: 0.7130\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 28.0137 - acc: 0.6896 - val_loss: 28.0488 - val_acc: 0.7126\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 28.0423 - acc: 0.6817 - val_loss: 28.6704 - val_acc: 0.7136\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 106.6909 - acc: 0.6410 - val_loss: 108.3129 - val_acc: 0.6334\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 104.9688 - acc: 0.6417 - val_loss: 107.0583 - val_acc: 0.6353\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 106.0467 - acc: 0.6412 - val_loss: 105.9153 - val_acc: 0.6351\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 106.1198 - acc: 0.6416 - val_loss: 107.4436 - val_acc: 0.6354\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 106.1436 - acc: 0.6413 - val_loss: 109.4063 - val_acc: 0.6333\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 107.3085 - acc: 0.6383 - val_loss: 104.6436 - val_acc: 0.6343\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 104.5172 - acc: 0.6405 - val_loss: 106.5097 - val_acc: 0.6335\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 104.9529 - acc: 0.6398 - val_loss: 106.1756 - val_acc: 0.6348\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 105.8405 - acc: 0.6405 - val_loss: 106.1785 - val_acc: 0.6351\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 107.4407 - acc: 0.6412 - val_loss: 108.1664 - val_acc: 0.6361\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 107.0718 - acc: 0.6410 - val_loss: 105.9446 - val_acc: 0.6341\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 105.3005 - acc: 0.6388 - val_loss: 104.3787 - val_acc: 0.6347\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 104.0907 - acc: 0.6393 - val_loss: 107.0187 - val_acc: 0.6297\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 104.5715 - acc: 0.6394 - val_loss: 105.4227 - val_acc: 0.6361\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 104.9406 - acc: 0.6395 - val_loss: 106.0717 - val_acc: 0.6326\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 104.7270 - acc: 0.6399 - val_loss: 104.5971 - val_acc: 0.6366\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 107.1430 - acc: 0.6420 - val_loss: 113.2768 - val_acc: 0.6325\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 390us/step - loss: 107.5197 - acc: 0.6416 - val_loss: 117.0339 - val_acc: 0.6329\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 108.3982 - acc: 0.6409 - val_loss: 105.7248 - val_acc: 0.6361\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 107.1166 - acc: 0.6401 - val_loss: 104.3623 - val_acc: 0.6355\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 104.2783 - acc: 0.6382 - val_loss: 104.2044 - val_acc: 0.6350\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 103.0772 - acc: 0.6416 - val_loss: 103.9555 - val_acc: 0.6357\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 104.8438 - acc: 0.6385 - val_loss: 108.6632 - val_acc: 0.6346\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 105.9006 - acc: 0.6415 - val_loss: 111.3211 - val_acc: 0.6352\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 108.2300 - acc: 0.6419 - val_loss: 108.1377 - val_acc: 0.6366\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 108.0048 - acc: 0.6412 - val_loss: 106.6489 - val_acc: 0.6360\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 106.6689 - acc: 0.6403 - val_loss: 107.7960 - val_acc: 0.6308\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 103.7861 - acc: 0.6394 - val_loss: 106.3917 - val_acc: 0.6330\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 104.6381 - acc: 0.6407 - val_loss: 104.8728 - val_acc: 0.6355\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 104.4452 - acc: 0.6419 - val_loss: 105.2044 - val_acc: 0.6360\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 106.9208 - acc: 0.6392 - val_loss: 112.2876 - val_acc: 0.6350\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 109.4431 - acc: 0.6418 - val_loss: 105.0020 - val_acc: 0.6375\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 106.5307 - acc: 0.6420 - val_loss: 108.4684 - val_acc: 0.6346\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 106.6550 - acc: 0.6405 - val_loss: 107.0850 - val_acc: 0.6337\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 104.3118 - acc: 0.6408 - val_loss: 104.5930 - val_acc: 0.6332\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 105.2593 - acc: 0.6375 - val_loss: 104.2453 - val_acc: 0.6361\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 104.1548 - acc: 0.6407 - val_loss: 106.2895 - val_acc: 0.6357\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 104.4725 - acc: 0.6400 - val_loss: 107.7324 - val_acc: 0.6294\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 107.2078 - acc: 0.6405 - val_loss: 107.1291 - val_acc: 0.6362\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 106.3786 - acc: 0.6404 - val_loss: 105.5455 - val_acc: 0.6359\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 107.4395 - acc: 0.6404 - val_loss: 106.9547 - val_acc: 0.6335\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 105.8505 - acc: 0.6408 - val_loss: 106.9150 - val_acc: 0.6353\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 105.0127 - acc: 0.6415 - val_loss: 106.0022 - val_acc: 0.6357\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 105.2709 - acc: 0.6416 - val_loss: 115.5522 - val_acc: 0.6347\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 108.6132 - acc: 0.6400 - val_loss: 109.6710 - val_acc: 0.6349\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 107.3910 - acc: 0.6413 - val_loss: 105.6805 - val_acc: 0.6358\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 105.0034 - acc: 0.6400 - val_loss: 106.1949 - val_acc: 0.6345\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 104.4353 - acc: 0.6401 - val_loss: 106.8612 - val_acc: 0.6319\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 104.8898 - acc: 0.6380 - val_loss: 106.4331 - val_acc: 0.6301\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 103.6807 - acc: 0.6403 - val_loss: 105.2805 - val_acc: 0.6354\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 46.5832 - acc: 0.4423 - val_loss: 43.6935 - val_acc: 0.4477\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 46.6315 - acc: 0.4425 - val_loss: 43.5188 - val_acc: 0.4474\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 46.4632 - acc: 0.4418 - val_loss: 43.4655 - val_acc: 0.4475\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 46.3617 - acc: 0.4423 - val_loss: 43.5339 - val_acc: 0.4473\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 46.3049 - acc: 0.4424 - val_loss: 43.6342 - val_acc: 0.4480\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 46.6506 - acc: 0.4421 - val_loss: 43.4266 - val_acc: 0.4475\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 46.3195 - acc: 0.4427 - val_loss: 43.4600 - val_acc: 0.4466\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 46.2644 - acc: 0.4424 - val_loss: 43.3883 - val_acc: 0.4469\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 46.2359 - acc: 0.4428 - val_loss: 43.4171 - val_acc: 0.4465\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 46.3829 - acc: 0.4424 - val_loss: 43.7279 - val_acc: 0.4458\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 46.6926 - acc: 0.4419 - val_loss: 43.4939 - val_acc: 0.4461\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 46.4145 - acc: 0.4425 - val_loss: 43.6594 - val_acc: 0.4457\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 46.5066 - acc: 0.4425 - val_loss: 43.3322 - val_acc: 0.4472\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 46.2197 - acc: 0.4428 - val_loss: 43.3019 - val_acc: 0.4470\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 46.2432 - acc: 0.4427 - val_loss: 43.3707 - val_acc: 0.4478\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 46.2306 - acc: 0.4425 - val_loss: 43.2667 - val_acc: 0.4471\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 46.2118 - acc: 0.4428 - val_loss: 43.9515 - val_acc: 0.4481\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 46.5784 - acc: 0.4423 - val_loss: 43.5624 - val_acc: 0.4481\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 46.2048 - acc: 0.4425 - val_loss: 43.2627 - val_acc: 0.4477\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 46.1084 - acc: 0.4425 - val_loss: 43.2225 - val_acc: 0.4474\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 46.0635 - acc: 0.4430 - val_loss: 43.3351 - val_acc: 0.4469\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 46.1856 - acc: 0.4430 - val_loss: 43.3465 - val_acc: 0.4468\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 46.2279 - acc: 0.4425 - val_loss: 43.1752 - val_acc: 0.4461\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 46.0595 - acc: 0.4427 - val_loss: 43.1673 - val_acc: 0.4465\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 46.1212 - acc: 0.4431 - val_loss: 43.6329 - val_acc: 0.4459\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 393us/step - loss: 46.8017 - acc: 0.4424 - val_loss: 43.7947 - val_acc: 0.4453\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 46.4150 - acc: 0.4428 - val_loss: 43.1595 - val_acc: 0.4473\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 45.9568 - acc: 0.4429 - val_loss: 43.1082 - val_acc: 0.4477\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 45.9805 - acc: 0.4433 - val_loss: 43.1090 - val_acc: 0.4471\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 45.9845 - acc: 0.4433 - val_loss: 43.0692 - val_acc: 0.4468\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 45.9267 - acc: 0.4430 - val_loss: 43.1568 - val_acc: 0.4479\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 45.9189 - acc: 0.4431 - val_loss: 43.1159 - val_acc: 0.4480\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 45.9847 - acc: 0.4429 - val_loss: 43.1461 - val_acc: 0.4469\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 45.9347 - acc: 0.4432 - val_loss: 43.1230 - val_acc: 0.4482\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 46.0363 - acc: 0.4432 - val_loss: 43.3155 - val_acc: 0.4482\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 45.9007 - acc: 0.4429 - val_loss: 43.0833 - val_acc: 0.4482\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 46.4321 - acc: 0.4425 - val_loss: 43.6750 - val_acc: 0.4488\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 46.2604 - acc: 0.4426 - val_loss: 43.2478 - val_acc: 0.4490\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 46.0974 - acc: 0.4435 - val_loss: 43.0128 - val_acc: 0.4474\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 45.7964 - acc: 0.4431 - val_loss: 43.0007 - val_acc: 0.4467\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 45.8682 - acc: 0.4432 - val_loss: 42.9896 - val_acc: 0.4471\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 45.9978 - acc: 0.4429 - val_loss: 43.0079 - val_acc: 0.4469\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 45.7457 - acc: 0.4436 - val_loss: 42.8946 - val_acc: 0.4469\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 45.7866 - acc: 0.4428 - val_loss: 42.9888 - val_acc: 0.4473\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 45.7418 - acc: 0.4431 - val_loss: 42.9016 - val_acc: 0.4478\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 45.7061 - acc: 0.4436 - val_loss: 43.0809 - val_acc: 0.4465\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 46.0007 - acc: 0.4428 - val_loss: 42.8380 - val_acc: 0.4469\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 45.6958 - acc: 0.4432 - val_loss: 43.1603 - val_acc: 0.4472\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 45.9922 - acc: 0.4434 - val_loss: 42.8416 - val_acc: 0.4466\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 45.7444 - acc: 0.4435 - val_loss: 42.8798 - val_acc: 0.4463\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4321 - acc: 0.4680 - val_loss: 0.4135 - val_acc: 0.4738\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4318 - acc: 0.4678 - val_loss: 0.4135 - val_acc: 0.4739\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.4316 - acc: 0.4681 - val_loss: 0.4135 - val_acc: 0.4739\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4317 - acc: 0.4682 - val_loss: 0.4132 - val_acc: 0.4735\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4315 - acc: 0.4684 - val_loss: 0.4132 - val_acc: 0.4737\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.4317 - acc: 0.4678 - val_loss: 0.4132 - val_acc: 0.4737\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.4317 - acc: 0.4682 - val_loss: 0.4135 - val_acc: 0.4741\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4313 - acc: 0.4682 - val_loss: 0.4132 - val_acc: 0.4736\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.4313 - acc: 0.4680 - val_loss: 0.4131 - val_acc: 0.4739\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4319 - acc: 0.4682 - val_loss: 0.4148 - val_acc: 0.4741\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.4326 - acc: 0.4679 - val_loss: 0.4136 - val_acc: 0.4736\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.4311 - acc: 0.4679 - val_loss: 0.4136 - val_acc: 0.4740\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4323 - acc: 0.4682 - val_loss: 0.4319 - val_acc: 0.4712\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4340 - acc: 0.4678 - val_loss: 0.4131 - val_acc: 0.4735\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.4308 - acc: 0.4681 - val_loss: 0.4126 - val_acc: 0.4738\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.4310 - acc: 0.4681 - val_loss: 0.4124 - val_acc: 0.4739\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4308 - acc: 0.4680 - val_loss: 0.4123 - val_acc: 0.4741\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.4312 - acc: 0.4682 - val_loss: 0.4124 - val_acc: 0.4737\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.4305 - acc: 0.4684 - val_loss: 0.4126 - val_acc: 0.4737\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.4307 - acc: 0.4678 - val_loss: 0.4128 - val_acc: 0.4738\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4311 - acc: 0.4681 - val_loss: 0.4130 - val_acc: 0.4734\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4308 - acc: 0.4681 - val_loss: 0.4123 - val_acc: 0.4739\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.4302 - acc: 0.4684 - val_loss: 0.4121 - val_acc: 0.4739\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.4300 - acc: 0.4680 - val_loss: 0.4120 - val_acc: 0.4741\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4301 - acc: 0.4682 - val_loss: 0.4118 - val_acc: 0.4741\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4299 - acc: 0.4684 - val_loss: 0.4120 - val_acc: 0.4740\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.4297 - acc: 0.4680 - val_loss: 0.4119 - val_acc: 0.4740\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4298 - acc: 0.4682 - val_loss: 0.4116 - val_acc: 0.4741\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.4298 - acc: 0.4682 - val_loss: 0.4119 - val_acc: 0.4741\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.4299 - acc: 0.4681 - val_loss: 0.4118 - val_acc: 0.4742\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.4298 - acc: 0.4681 - val_loss: 0.4116 - val_acc: 0.4741\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4294 - acc: 0.4679 - val_loss: 0.4115 - val_acc: 0.4739\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4293 - acc: 0.4684 - val_loss: 0.4114 - val_acc: 0.4744\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.4303 - acc: 0.4678 - val_loss: 0.4113 - val_acc: 0.4742\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4302 - acc: 0.4682 - val_loss: 0.4112 - val_acc: 0.4742\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4292 - acc: 0.4683 - val_loss: 0.4117 - val_acc: 0.4742\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.4296 - acc: 0.4683 - val_loss: 0.4116 - val_acc: 0.4744\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.4293 - acc: 0.4680 - val_loss: 0.4113 - val_acc: 0.4740\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.4290 - acc: 0.4680 - val_loss: 0.4110 - val_acc: 0.4743\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.4291 - acc: 0.4684 - val_loss: 0.4107 - val_acc: 0.4742\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.4289 - acc: 0.4684 - val_loss: 0.4111 - val_acc: 0.4737\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.4292 - acc: 0.4683 - val_loss: 0.4106 - val_acc: 0.4742\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.4284 - acc: 0.4683 - val_loss: 0.4106 - val_acc: 0.4745\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.4284 - acc: 0.4683 - val_loss: 0.4105 - val_acc: 0.4743\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.4289 - acc: 0.4683 - val_loss: 0.4104 - val_acc: 0.4742\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.4285 - acc: 0.4683 - val_loss: 0.4111 - val_acc: 0.4750\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.4283 - acc: 0.4682 - val_loss: 0.4105 - val_acc: 0.4744\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4289 - acc: 0.4682 - val_loss: 0.4104 - val_acc: 0.4744\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.4279 - acc: 0.4683 - val_loss: 0.4100 - val_acc: 0.4743\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.4281 - acc: 0.4685 - val_loss: 0.4101 - val_acc: 0.4741\n",
      "start training round 24\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 27.9052 - acc: 0.6934 - val_loss: 28.3777 - val_acc: 0.7133\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 27.6044 - acc: 0.6865 - val_loss: 28.8115 - val_acc: 0.6711\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 28.2975 - acc: 0.6771 - val_loss: 28.0117 - val_acc: 0.6658\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 27.9747 - acc: 0.6848 - val_loss: 28.3583 - val_acc: 0.6672\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 28.0769 - acc: 0.6925 - val_loss: 27.8307 - val_acc: 0.6702\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 27.3601 - acc: 0.6837 - val_loss: 28.9573 - val_acc: 0.6678\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 28.4560 - acc: 0.6887 - val_loss: 28.0095 - val_acc: 0.6697\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 27.8726 - acc: 0.6816 - val_loss: 28.6039 - val_acc: 0.6795\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 27.8767 - acc: 0.6902 - val_loss: 27.7032 - val_acc: 0.7134\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.2438 - acc: 0.6995 - val_loss: 27.3095 - val_acc: 0.7122\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 28.1951 - acc: 0.6919 - val_loss: 27.3473 - val_acc: 0.7128\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 27.0618 - acc: 0.6826 - val_loss: 28.1431 - val_acc: 0.6714\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 28.4493 - acc: 0.6869 - val_loss: 29.6593 - val_acc: 0.6682\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 28.1528 - acc: 0.7006 - val_loss: 26.9685 - val_acc: 0.6803\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.1672 - acc: 0.6812 - val_loss: 27.3151 - val_acc: 0.7126\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 27.5629 - acc: 0.6919 - val_loss: 28.7631 - val_acc: 0.7123\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 27.9042 - acc: 0.6933 - val_loss: 27.5613 - val_acc: 0.7127\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 28.3269 - acc: 0.6920 - val_loss: 27.6062 - val_acc: 0.7131\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 28.0541 - acc: 0.6935 - val_loss: 28.8163 - val_acc: 0.7136\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 27.6890 - acc: 0.7036 - val_loss: 27.2978 - val_acc: 0.7131\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 27.6902 - acc: 0.6931 - val_loss: 27.4269 - val_acc: 0.7134\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 28.0400 - acc: 0.6881 - val_loss: 29.1967 - val_acc: 0.6701\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 28.3852 - acc: 0.6865 - val_loss: 28.7893 - val_acc: 0.6700\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 27.7489 - acc: 0.6925 - val_loss: 29.4984 - val_acc: 0.6707\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 27.8399 - acc: 0.6913 - val_loss: 28.5991 - val_acc: 0.6708\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 27.2140 - acc: 0.6774 - val_loss: 28.5802 - val_acc: 0.6672\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 28.5601 - acc: 0.6789 - val_loss: 27.0357 - val_acc: 0.6725\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 27.9737 - acc: 0.6919 - val_loss: 26.7593 - val_acc: 0.6746\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 27.1608 - acc: 0.6826 - val_loss: 30.1543 - val_acc: 0.6650\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 28.4178 - acc: 0.6847 - val_loss: 27.9403 - val_acc: 0.6690\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 28.1303 - acc: 0.6933 - val_loss: 28.0185 - val_acc: 0.6710\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 27.7390 - acc: 0.6964 - val_loss: 27.8142 - val_acc: 0.6662\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 27.3925 - acc: 0.6852 - val_loss: 29.2099 - val_acc: 0.6667\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 28.5609 - acc: 0.6940 - val_loss: 27.9883 - val_acc: 0.6699\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 27.6772 - acc: 0.6919 - val_loss: 28.2468 - val_acc: 0.6691\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 27.7991 - acc: 0.6841 - val_loss: 27.0131 - val_acc: 0.6734\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 28.0225 - acc: 0.6834 - val_loss: 27.2328 - val_acc: 0.6703\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 27.9299 - acc: 0.6885 - val_loss: 29.1484 - val_acc: 0.7122\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 28.4328 - acc: 0.7007 - val_loss: 27.6067 - val_acc: 0.7122\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 27.4836 - acc: 0.7004 - val_loss: 28.2204 - val_acc: 0.6726\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 27.8250 - acc: 0.6992 - val_loss: 27.5038 - val_acc: 0.6734\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 28.1954 - acc: 0.6850 - val_loss: 28.3320 - val_acc: 0.6696\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 388us/step - loss: 27.7712 - acc: 0.7036 - val_loss: 28.3724 - val_acc: 0.6682\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 28.0927 - acc: 0.7026 - val_loss: 27.5106 - val_acc: 0.7120\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 27.5480 - acc: 0.6861 - val_loss: 29.9611 - val_acc: 0.6642\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 28.0787 - acc: 0.6921 - val_loss: 27.4715 - val_acc: 0.6719\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 27.7356 - acc: 0.6909 - val_loss: 26.9281 - val_acc: 0.6704\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 27.9365 - acc: 0.6950 - val_loss: 28.9314 - val_acc: 0.6712\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 27.5142 - acc: 0.6891 - val_loss: 28.1104 - val_acc: 0.6642\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 28.1246 - acc: 0.6873 - val_loss: 28.2446 - val_acc: 0.6739\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 104.1790 - acc: 0.6396 - val_loss: 107.0510 - val_acc: 0.6334\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 105.3605 - acc: 0.6416 - val_loss: 109.1621 - val_acc: 0.6351\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 108.2290 - acc: 0.6419 - val_loss: 108.3616 - val_acc: 0.6367\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 107.6224 - acc: 0.6410 - val_loss: 106.5115 - val_acc: 0.6344\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 104.9434 - acc: 0.6374 - val_loss: 105.1392 - val_acc: 0.6317\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 103.9889 - acc: 0.6402 - val_loss: 105.9619 - val_acc: 0.6315\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 103.7890 - acc: 0.6402 - val_loss: 111.0358 - val_acc: 0.6231\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 104.4043 - acc: 0.6383 - val_loss: 105.0082 - val_acc: 0.6343\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 104.5845 - acc: 0.6393 - val_loss: 109.8536 - val_acc: 0.6351\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 109.6157 - acc: 0.6417 - val_loss: 107.1873 - val_acc: 0.6357\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 107.6123 - acc: 0.6411 - val_loss: 109.7230 - val_acc: 0.6343\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 106.9587 - acc: 0.6422 - val_loss: 108.4777 - val_acc: 0.6361\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 106.5069 - acc: 0.6398 - val_loss: 105.0465 - val_acc: 0.6352\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 105.8592 - acc: 0.6414 - val_loss: 104.7666 - val_acc: 0.6355\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 105.3456 - acc: 0.6414 - val_loss: 104.6919 - val_acc: 0.6356\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 104.8433 - acc: 0.6392 - val_loss: 104.3413 - val_acc: 0.6362\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 103.5240 - acc: 0.6412 - val_loss: 104.7298 - val_acc: 0.6353\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 104.0979 - acc: 0.6406 - val_loss: 109.1321 - val_acc: 0.6327\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 105.9425 - acc: 0.6394 - val_loss: 106.9815 - val_acc: 0.6345\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 106.2616 - acc: 0.6422 - val_loss: 107.9588 - val_acc: 0.6375\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 107.3595 - acc: 0.6415 - val_loss: 108.0137 - val_acc: 0.6324\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 104.6617 - acc: 0.6395 - val_loss: 108.4272 - val_acc: 0.6330\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 105.4697 - acc: 0.6404 - val_loss: 104.7427 - val_acc: 0.6374\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 106.0767 - acc: 0.6422 - val_loss: 107.9257 - val_acc: 0.6366\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 105.7638 - acc: 0.6417 - val_loss: 110.7655 - val_acc: 0.6343\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 106.6493 - acc: 0.6414 - val_loss: 105.6456 - val_acc: 0.6371\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 106.1297 - acc: 0.6398 - val_loss: 106.2988 - val_acc: 0.6319\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 104.1832 - acc: 0.6389 - val_loss: 107.5783 - val_acc: 0.6301\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 103.6580 - acc: 0.6411 - val_loss: 105.1750 - val_acc: 0.6355\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 105.3685 - acc: 0.6413 - val_loss: 104.8413 - val_acc: 0.6353\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 104.5604 - acc: 0.6414 - val_loss: 103.9384 - val_acc: 0.6365\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 104.2805 - acc: 0.6415 - val_loss: 107.6417 - val_acc: 0.6339\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 108.3208 - acc: 0.6407 - val_loss: 108.9858 - val_acc: 0.6343\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 106.1558 - acc: 0.6414 - val_loss: 106.6974 - val_acc: 0.6344\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 106.5375 - acc: 0.6396 - val_loss: 104.5586 - val_acc: 0.6354\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 104.6909 - acc: 0.6420 - val_loss: 104.9781 - val_acc: 0.6368\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 105.6145 - acc: 0.6400 - val_loss: 103.6500 - val_acc: 0.6370\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 103.1842 - acc: 0.6405 - val_loss: 106.5949 - val_acc: 0.6295\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 103.7483 - acc: 0.6384 - val_loss: 104.9733 - val_acc: 0.6320\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 105.5891 - acc: 0.6403 - val_loss: 104.6818 - val_acc: 0.6353\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 105.5369 - acc: 0.6419 - val_loss: 109.9927 - val_acc: 0.6342\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 107.9941 - acc: 0.6401 - val_loss: 104.6457 - val_acc: 0.6355\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 104.0109 - acc: 0.6418 - val_loss: 105.1580 - val_acc: 0.6362\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 104.6024 - acc: 0.6416 - val_loss: 105.1419 - val_acc: 0.6357\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 104.2617 - acc: 0.6405 - val_loss: 109.1268 - val_acc: 0.6295\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 107.6879 - acc: 0.6393 - val_loss: 104.9997 - val_acc: 0.6350\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 104.3397 - acc: 0.6403 - val_loss: 104.3093 - val_acc: 0.6347\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 103.3583 - acc: 0.6415 - val_loss: 105.6510 - val_acc: 0.6355\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 104.4529 - acc: 0.6410 - val_loss: 103.2077 - val_acc: 0.6368\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 104.8578 - acc: 0.6428 - val_loss: 107.1367 - val_acc: 0.6365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 45.8825 - acc: 0.4431 - val_loss: 43.0648 - val_acc: 0.4469\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 45.7477 - acc: 0.4435 - val_loss: 42.8941 - val_acc: 0.4469\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 45.5917 - acc: 0.4437 - val_loss: 42.7502 - val_acc: 0.4468\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 45.6873 - acc: 0.4429 - val_loss: 42.8303 - val_acc: 0.4476\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 45.7638 - acc: 0.4433 - val_loss: 42.8080 - val_acc: 0.4484\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 45.5657 - acc: 0.4435 - val_loss: 42.7341 - val_acc: 0.4468\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 45.5678 - acc: 0.4432 - val_loss: 42.6863 - val_acc: 0.4473\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 45.5759 - acc: 0.4436 - val_loss: 42.6942 - val_acc: 0.4473\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 45.4929 - acc: 0.4436 - val_loss: 42.6811 - val_acc: 0.4471\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 45.5142 - acc: 0.4431 - val_loss: 42.7440 - val_acc: 0.4477\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 45.5974 - acc: 0.4436 - val_loss: 43.0563 - val_acc: 0.4495\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 45.7092 - acc: 0.4435 - val_loss: 42.6884 - val_acc: 0.4485\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 45.5869 - acc: 0.4439 - val_loss: 42.6626 - val_acc: 0.4481\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 45.4579 - acc: 0.4439 - val_loss: 42.8161 - val_acc: 0.4486\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 45.4415 - acc: 0.4434 - val_loss: 42.8036 - val_acc: 0.4488\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 45.4320 - acc: 0.4440 - val_loss: 42.6719 - val_acc: 0.4482\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 45.5257 - acc: 0.4437 - val_loss: 42.6041 - val_acc: 0.4483\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 45.3792 - acc: 0.4437 - val_loss: 42.6727 - val_acc: 0.4484\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 45.4898 - acc: 0.4437 - val_loss: 42.9071 - val_acc: 0.4492\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 45.8706 - acc: 0.4430 - val_loss: 42.6683 - val_acc: 0.4482\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 45.3756 - acc: 0.4440 - val_loss: 42.7404 - val_acc: 0.4476\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 45.3506 - acc: 0.4438 - val_loss: 42.4818 - val_acc: 0.4475\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 45.4330 - acc: 0.4437 - val_loss: 42.6041 - val_acc: 0.4489\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 45.5621 - acc: 0.4442 - val_loss: 42.5400 - val_acc: 0.4486\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 45.3714 - acc: 0.4438 - val_loss: 42.4272 - val_acc: 0.4479\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 45.2266 - acc: 0.4443 - val_loss: 42.4696 - val_acc: 0.4481\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 45.2114 - acc: 0.4439 - val_loss: 42.4044 - val_acc: 0.4482\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 45.1911 - acc: 0.4439 - val_loss: 42.3985 - val_acc: 0.4474\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 45.1803 - acc: 0.4438 - val_loss: 42.4836 - val_acc: 0.4486\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 45.2190 - acc: 0.4444 - val_loss: 42.9191 - val_acc: 0.4486\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 46.0753 - acc: 0.4433 - val_loss: 42.7332 - val_acc: 0.4494\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 45.2490 - acc: 0.4442 - val_loss: 42.3548 - val_acc: 0.4471\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 45.1492 - acc: 0.4439 - val_loss: 42.3603 - val_acc: 0.4469\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 45.0881 - acc: 0.4442 - val_loss: 42.3146 - val_acc: 0.4478\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 45.1418 - acc: 0.4443 - val_loss: 42.2849 - val_acc: 0.4473\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 45.0802 - acc: 0.4441 - val_loss: 42.2980 - val_acc: 0.4480\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 45.0461 - acc: 0.4442 - val_loss: 42.2836 - val_acc: 0.4480\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 45.2981 - acc: 0.4439 - val_loss: 42.8577 - val_acc: 0.4490\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 45.2391 - acc: 0.4442 - val_loss: 42.2180 - val_acc: 0.4475\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 45.0088 - acc: 0.4445 - val_loss: 42.2449 - val_acc: 0.4484\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 45.0178 - acc: 0.4445 - val_loss: 42.2928 - val_acc: 0.4489\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 45.1494 - acc: 0.4445 - val_loss: 42.2392 - val_acc: 0.4484\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 44.9610 - acc: 0.4442 - val_loss: 42.2978 - val_acc: 0.4485\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 44.9250 - acc: 0.4443 - val_loss: 42.1227 - val_acc: 0.4475\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 44.8922 - acc: 0.4442 - val_loss: 42.1408 - val_acc: 0.4474\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 44.9108 - acc: 0.4446 - val_loss: 42.1596 - val_acc: 0.4475\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 44.8984 - acc: 0.4440 - val_loss: 42.0723 - val_acc: 0.4479\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 45.0026 - acc: 0.4445 - val_loss: 42.8201 - val_acc: 0.4492\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 45.1257 - acc: 0.4446 - val_loss: 42.1947 - val_acc: 0.4481\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 44.8139 - acc: 0.4445 - val_loss: 42.2843 - val_acc: 0.4489\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4285 - acc: 0.4684 - val_loss: 0.4100 - val_acc: 0.4744\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.4288 - acc: 0.4683 - val_loss: 0.4100 - val_acc: 0.4739\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4279 - acc: 0.4684 - val_loss: 0.4107 - val_acc: 0.4747\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4285 - acc: 0.4683 - val_loss: 0.4103 - val_acc: 0.4747\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.4279 - acc: 0.4684 - val_loss: 0.4117 - val_acc: 0.4737\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4281 - acc: 0.4685 - val_loss: 0.4099 - val_acc: 0.4741\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4278 - acc: 0.4684 - val_loss: 0.4098 - val_acc: 0.4743\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.4273 - acc: 0.4683 - val_loss: 0.4098 - val_acc: 0.4746\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.4276 - acc: 0.4684 - val_loss: 0.4100 - val_acc: 0.4737\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4271 - acc: 0.4683 - val_loss: 0.4105 - val_acc: 0.4749\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.4279 - acc: 0.4685 - val_loss: 0.4101 - val_acc: 0.4738\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4284 - acc: 0.4685 - val_loss: 0.4101 - val_acc: 0.4745\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 470us/step - loss: 0.4274 - acc: 0.4682 - val_loss: 0.4093 - val_acc: 0.4742\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.4267 - acc: 0.4684 - val_loss: 0.4094 - val_acc: 0.4740\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.4274 - acc: 0.4685 - val_loss: 0.4132 - val_acc: 0.4734\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4279 - acc: 0.4684 - val_loss: 0.4091 - val_acc: 0.4744\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4265 - acc: 0.4684 - val_loss: 0.4089 - val_acc: 0.4747\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 468us/step - loss: 0.4266 - acc: 0.4687 - val_loss: 0.4093 - val_acc: 0.4741\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4268 - acc: 0.4682 - val_loss: 0.4088 - val_acc: 0.4747\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4262 - acc: 0.4687 - val_loss: 0.4093 - val_acc: 0.4747\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.4277 - acc: 0.4683 - val_loss: 0.4111 - val_acc: 0.4736\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4267 - acc: 0.4686 - val_loss: 0.4094 - val_acc: 0.4742\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.4277 - acc: 0.4683 - val_loss: 0.4094 - val_acc: 0.4751\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4266 - acc: 0.4684 - val_loss: 0.4086 - val_acc: 0.4748\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.4278 - acc: 0.4686 - val_loss: 0.4152 - val_acc: 0.4734\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4273 - acc: 0.4684 - val_loss: 0.4126 - val_acc: 0.4748\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.4274 - acc: 0.4685 - val_loss: 0.4101 - val_acc: 0.4749\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.4264 - acc: 0.4685 - val_loss: 0.4086 - val_acc: 0.4749\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.4268 - acc: 0.4684 - val_loss: 0.4081 - val_acc: 0.4747\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.4256 - acc: 0.4686 - val_loss: 0.4080 - val_acc: 0.4748\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.4260 - acc: 0.4686 - val_loss: 0.4085 - val_acc: 0.4744\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.4254 - acc: 0.4685 - val_loss: 0.4084 - val_acc: 0.4747\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4256 - acc: 0.4686 - val_loss: 0.4086 - val_acc: 0.4748\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4258 - acc: 0.4684 - val_loss: 0.4080 - val_acc: 0.4750\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4251 - acc: 0.4685 - val_loss: 0.4076 - val_acc: 0.4742\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 470us/step - loss: 0.4256 - acc: 0.4684 - val_loss: 0.4077 - val_acc: 0.4745\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4250 - acc: 0.4685 - val_loss: 0.4083 - val_acc: 0.4749\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.4250 - acc: 0.4686 - val_loss: 0.4076 - val_acc: 0.4745\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.4250 - acc: 0.4684 - val_loss: 0.4091 - val_acc: 0.4741\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.4253 - acc: 0.4684 - val_loss: 0.4074 - val_acc: 0.4747\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4256 - acc: 0.4684 - val_loss: 0.4084 - val_acc: 0.4746\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4249 - acc: 0.4686 - val_loss: 0.4072 - val_acc: 0.4745\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4245 - acc: 0.4685 - val_loss: 0.4078 - val_acc: 0.4749\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4243 - acc: 0.4685 - val_loss: 0.4071 - val_acc: 0.4743\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4249 - acc: 0.4686 - val_loss: 0.4075 - val_acc: 0.4751\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4247 - acc: 0.4686 - val_loss: 0.4087 - val_acc: 0.4741\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4252 - acc: 0.4685 - val_loss: 0.4073 - val_acc: 0.4743\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.4249 - acc: 0.4686 - val_loss: 0.4069 - val_acc: 0.4749\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 470us/step - loss: 0.4244 - acc: 0.4687 - val_loss: 0.4075 - val_acc: 0.4747\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4244 - acc: 0.4685 - val_loss: 0.4075 - val_acc: 0.4746\n",
      "start training round 25\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 27.8836 - acc: 0.6884 - val_loss: 28.1236 - val_acc: 0.6631\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 27.7525 - acc: 0.6918 - val_loss: 28.1264 - val_acc: 0.6703\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 28.2597 - acc: 0.6848 - val_loss: 29.4533 - val_acc: 0.6633\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 27.7623 - acc: 0.6958 - val_loss: 27.3184 - val_acc: 0.7120\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 27.9643 - acc: 0.6977 - val_loss: 27.7929 - val_acc: 0.6714\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 27.7348 - acc: 0.6917 - val_loss: 27.6153 - val_acc: 0.6733\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 27.8576 - acc: 0.6928 - val_loss: 30.3189 - val_acc: 0.6659\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 28.0614 - acc: 0.7021 - val_loss: 29.3355 - val_acc: 0.6601\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 27.5392 - acc: 0.6885 - val_loss: 27.6777 - val_acc: 0.6826\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 27.9952 - acc: 0.6823 - val_loss: 27.6492 - val_acc: 0.7132\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 28.1376 - acc: 0.6993 - val_loss: 28.2706 - val_acc: 0.7124\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 27.5750 - acc: 0.6975 - val_loss: 27.4755 - val_acc: 0.7130\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 27.9905 - acc: 0.6923 - val_loss: 27.0160 - val_acc: 0.7129\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 27.6423 - acc: 0.6916 - val_loss: 27.3133 - val_acc: 0.7124\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 26.9009 - acc: 0.6783 - val_loss: 27.0842 - val_acc: 0.6744\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 27.8555 - acc: 0.6736 - val_loss: 28.6081 - val_acc: 0.6636\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 28.1304 - acc: 0.6904 - val_loss: 28.8023 - val_acc: 0.7103\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 437us/step - loss: 27.7876 - acc: 0.7065 - val_loss: 29.0672 - val_acc: 0.6613\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 27.3143 - acc: 0.6859 - val_loss: 27.5823 - val_acc: 0.6705\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 28.1680 - acc: 0.6843 - val_loss: 28.0461 - val_acc: 0.6737\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 27.9951 - acc: 0.6974 - val_loss: 27.8741 - val_acc: 0.6711\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 27.9156 - acc: 0.6919 - val_loss: 27.3310 - val_acc: 0.7121\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 27.5659 - acc: 0.7032 - val_loss: 27.3458 - val_acc: 0.6727\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 27.6397 - acc: 0.6864 - val_loss: 28.4829 - val_acc: 0.7125\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 28.0077 - acc: 0.6907 - val_loss: 27.9036 - val_acc: 0.7126\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 27.3218 - acc: 0.6834 - val_loss: 28.4604 - val_acc: 0.6683\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 27.7785 - acc: 0.6910 - val_loss: 29.8035 - val_acc: 0.6628\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 28.0081 - acc: 0.7010 - val_loss: 27.7548 - val_acc: 0.6694\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 27.5000 - acc: 0.6907 - val_loss: 27.6442 - val_acc: 0.6663\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 28.2579 - acc: 0.6983 - val_loss: 27.9010 - val_acc: 0.6672\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 27.4641 - acc: 0.6963 - val_loss: 27.2241 - val_acc: 0.6703\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 27.7151 - acc: 0.6908 - val_loss: 29.4208 - val_acc: 0.6694\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 27.6172 - acc: 0.6954 - val_loss: 26.8282 - val_acc: 0.6664\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 27.7191 - acc: 0.6876 - val_loss: 27.3439 - val_acc: 0.7119\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 27.1972 - acc: 0.6933 - val_loss: 26.7821 - val_acc: 0.6708\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 27.2867 - acc: 0.6795 - val_loss: 32.3005 - val_acc: 0.6604\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 27.6644 - acc: 0.6912 - val_loss: 29.0946 - val_acc: 0.6628\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 28.0336 - acc: 0.6934 - val_loss: 27.7835 - val_acc: 0.7124\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 27.1817 - acc: 0.6914 - val_loss: 26.7947 - val_acc: 0.6727\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 27.8983 - acc: 0.6796 - val_loss: 27.4904 - val_acc: 0.7129\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 27.9325 - acc: 0.6976 - val_loss: 27.6087 - val_acc: 0.7117\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 27.4828 - acc: 0.6808 - val_loss: 28.6132 - val_acc: 0.6608\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 28.0048 - acc: 0.6999 - val_loss: 27.4540 - val_acc: 0.7113\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 27.1187 - acc: 0.6985 - val_loss: 28.4215 - val_acc: 0.6706\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 28.4849 - acc: 0.6921 - val_loss: 28.2276 - val_acc: 0.7116\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 27.5443 - acc: 0.7080 - val_loss: 28.4447 - val_acc: 0.6674\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 27.7703 - acc: 0.6913 - val_loss: 28.7951 - val_acc: 0.6663\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 27.6541 - acc: 0.7077 - val_loss: 31.3128 - val_acc: 0.6603\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 27.8791 - acc: 0.6917 - val_loss: 29.9672 - val_acc: 0.6717\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 27.9938 - acc: 0.6950 - val_loss: 32.5604 - val_acc: 0.6586\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 105.9989 - acc: 0.6390 - val_loss: 105.9963 - val_acc: 0.6365\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 106.8226 - acc: 0.6416 - val_loss: 104.8188 - val_acc: 0.6370\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 104.9552 - acc: 0.6418 - val_loss: 107.4744 - val_acc: 0.6351\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 104.5581 - acc: 0.6414 - val_loss: 103.7591 - val_acc: 0.6370\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 104.7508 - acc: 0.6415 - val_loss: 108.8830 - val_acc: 0.6321\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 107.7210 - acc: 0.6402 - val_loss: 105.4939 - val_acc: 0.6359\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 105.0839 - acc: 0.6417 - val_loss: 103.5763 - val_acc: 0.6372\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 106.6105 - acc: 0.6416 - val_loss: 107.5586 - val_acc: 0.6320\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 106.5162 - acc: 0.6389 - val_loss: 104.3111 - val_acc: 0.6368\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 104.6975 - acc: 0.6409 - val_loss: 104.8474 - val_acc: 0.6340\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 102.7850 - acc: 0.6416 - val_loss: 103.1786 - val_acc: 0.6361\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 104.1275 - acc: 0.6402 - val_loss: 104.9088 - val_acc: 0.6348\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 103.5139 - acc: 0.6414 - val_loss: 105.7934 - val_acc: 0.6335\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 104.2183 - acc: 0.6403 - val_loss: 103.6294 - val_acc: 0.6368\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 105.4782 - acc: 0.6404 - val_loss: 106.4498 - val_acc: 0.6360\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 107.7540 - acc: 0.6403 - val_loss: 104.3263 - val_acc: 0.6378\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 104.8289 - acc: 0.6420 - val_loss: 106.1282 - val_acc: 0.6357\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 105.7198 - acc: 0.6423 - val_loss: 107.0224 - val_acc: 0.6370\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 106.0431 - acc: 0.6420 - val_loss: 107.8617 - val_acc: 0.6346\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 104.2724 - acc: 0.6415 - val_loss: 106.7785 - val_acc: 0.6350\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 105.9734 - acc: 0.6402 - val_loss: 108.3618 - val_acc: 0.6328\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 104.8542 - acc: 0.6414 - val_loss: 103.4035 - val_acc: 0.6376\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 104.7656 - acc: 0.6417 - val_loss: 106.0028 - val_acc: 0.6328\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 105.9421 - acc: 0.6379 - val_loss: 105.1669 - val_acc: 0.6342\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 103.9908 - acc: 0.6402 - val_loss: 105.5036 - val_acc: 0.6353\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 430us/step - loss: 104.5945 - acc: 0.6414 - val_loss: 104.2331 - val_acc: 0.6355\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 105.1234 - acc: 0.6421 - val_loss: 106.3477 - val_acc: 0.6348\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 105.0610 - acc: 0.6420 - val_loss: 103.7237 - val_acc: 0.6367\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 104.7725 - acc: 0.6397 - val_loss: 104.6996 - val_acc: 0.6345\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 104.6097 - acc: 0.6384 - val_loss: 106.4522 - val_acc: 0.6342\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 104.4329 - acc: 0.6412 - val_loss: 103.0738 - val_acc: 0.6373\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 104.3543 - acc: 0.6418 - val_loss: 105.9982 - val_acc: 0.6335\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 104.0067 - acc: 0.6399 - val_loss: 104.8614 - val_acc: 0.6367\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 105.1905 - acc: 0.6412 - val_loss: 104.6225 - val_acc: 0.6347\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 103.6847 - acc: 0.6406 - val_loss: 104.9275 - val_acc: 0.6352\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 103.9664 - acc: 0.6408 - val_loss: 111.6525 - val_acc: 0.6315\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 107.9314 - acc: 0.6411 - val_loss: 109.3321 - val_acc: 0.6370\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 106.0544 - acc: 0.6427 - val_loss: 107.0221 - val_acc: 0.6344\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 104.9987 - acc: 0.6401 - val_loss: 103.9092 - val_acc: 0.6358\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 103.8903 - acc: 0.6416 - val_loss: 104.2144 - val_acc: 0.6356\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 103.4894 - acc: 0.6422 - val_loss: 105.2719 - val_acc: 0.6366\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 105.8063 - acc: 0.6410 - val_loss: 113.9964 - val_acc: 0.6300\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 107.0688 - acc: 0.6419 - val_loss: 108.7342 - val_acc: 0.6349\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 105.8475 - acc: 0.6411 - val_loss: 106.5038 - val_acc: 0.6339\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 105.4644 - acc: 0.6402 - val_loss: 105.1858 - val_acc: 0.6345\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 461us/step - loss: 104.2202 - acc: 0.6394 - val_loss: 104.4049 - val_acc: 0.6336\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 102.7955 - acc: 0.6406 - val_loss: 102.7063 - val_acc: 0.6361\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 102.8650 - acc: 0.6388 - val_loss: 104.7280 - val_acc: 0.6316\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 102.9432 - acc: 0.6408 - val_loss: 104.1392 - val_acc: 0.6374\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 102.6920 - acc: 0.6423 - val_loss: 104.6461 - val_acc: 0.6371\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 44.8793 - acc: 0.4447 - val_loss: 42.0317 - val_acc: 0.4485\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 44.7884 - acc: 0.4447 - val_loss: 42.0135 - val_acc: 0.4488\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 44.8035 - acc: 0.4451 - val_loss: 42.0815 - val_acc: 0.4478\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 44.7384 - acc: 0.4441 - val_loss: 41.9677 - val_acc: 0.4479\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 44.8070 - acc: 0.4445 - val_loss: 42.8392 - val_acc: 0.4457\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 45.0429 - acc: 0.4444 - val_loss: 41.9437 - val_acc: 0.4489\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 44.7086 - acc: 0.4448 - val_loss: 41.9454 - val_acc: 0.4488\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 44.6914 - acc: 0.4447 - val_loss: 41.8941 - val_acc: 0.4486\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 44.7396 - acc: 0.4450 - val_loss: 42.0306 - val_acc: 0.4492\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 44.7115 - acc: 0.4447 - val_loss: 41.8618 - val_acc: 0.4479\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 44.6073 - acc: 0.4447 - val_loss: 41.8603 - val_acc: 0.4484\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 44.6056 - acc: 0.4451 - val_loss: 41.8416 - val_acc: 0.4490\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 44.6268 - acc: 0.4446 - val_loss: 41.8414 - val_acc: 0.4483\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 44.5821 - acc: 0.4451 - val_loss: 41.7973 - val_acc: 0.4487\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 44.6037 - acc: 0.4445 - val_loss: 41.9690 - val_acc: 0.4489\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 44.8137 - acc: 0.4448 - val_loss: 42.5416 - val_acc: 0.4498\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 44.7405 - acc: 0.4445 - val_loss: 41.7598 - val_acc: 0.4494\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 44.4871 - acc: 0.4452 - val_loss: 41.7636 - val_acc: 0.4478\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 44.5227 - acc: 0.4447 - val_loss: 41.7050 - val_acc: 0.4494\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 44.4797 - acc: 0.4449 - val_loss: 41.7932 - val_acc: 0.4492\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 44.4503 - acc: 0.4450 - val_loss: 41.7903 - val_acc: 0.4497\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 44.5194 - acc: 0.4450 - val_loss: 41.6525 - val_acc: 0.4484\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 44.3857 - acc: 0.4448 - val_loss: 41.6414 - val_acc: 0.4484\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 44.3782 - acc: 0.4448 - val_loss: 41.6191 - val_acc: 0.4488\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 44.3382 - acc: 0.4448 - val_loss: 41.5951 - val_acc: 0.4490\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 44.3184 - acc: 0.4450 - val_loss: 41.5770 - val_acc: 0.4489\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 44.3206 - acc: 0.4448 - val_loss: 41.5832 - val_acc: 0.4492\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 44.4219 - acc: 0.4446 - val_loss: 41.6386 - val_acc: 0.4496\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 44.3048 - acc: 0.4450 - val_loss: 41.5147 - val_acc: 0.4486\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 44.3640 - acc: 0.4448 - val_loss: 41.5231 - val_acc: 0.4484\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 44.2270 - acc: 0.4451 - val_loss: 41.5434 - val_acc: 0.4478\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 44.2744 - acc: 0.4448 - val_loss: 41.5181 - val_acc: 0.4483\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 44.3234 - acc: 0.4451 - val_loss: 41.4932 - val_acc: 0.4478\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 420us/step - loss: 44.2415 - acc: 0.4448 - val_loss: 41.7364 - val_acc: 0.4475\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 44.3067 - acc: 0.4453 - val_loss: 41.4656 - val_acc: 0.4484\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 44.1276 - acc: 0.4448 - val_loss: 41.4145 - val_acc: 0.4490\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 44.2867 - acc: 0.4452 - val_loss: 41.6865 - val_acc: 0.4500\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 44.1932 - acc: 0.4452 - val_loss: 41.3715 - val_acc: 0.4495\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 44.0654 - acc: 0.4454 - val_loss: 41.4970 - val_acc: 0.4491\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 44.0859 - acc: 0.4448 - val_loss: 41.3480 - val_acc: 0.4486\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 44.0445 - acc: 0.4454 - val_loss: 41.3381 - val_acc: 0.4481\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 44.0249 - acc: 0.4448 - val_loss: 41.2736 - val_acc: 0.4501\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 43.9817 - acc: 0.4453 - val_loss: 41.2780 - val_acc: 0.4491\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 44.3740 - acc: 0.4451 - val_loss: 41.6969 - val_acc: 0.4479\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 44.1123 - acc: 0.4457 - val_loss: 41.2757 - val_acc: 0.4486\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 43.9593 - acc: 0.4453 - val_loss: 41.2227 - val_acc: 0.4493\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 43.9808 - acc: 0.4458 - val_loss: 41.3429 - val_acc: 0.4484\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 43.9542 - acc: 0.4451 - val_loss: 41.1903 - val_acc: 0.4496\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 44.1206 - acc: 0.4458 - val_loss: 41.4777 - val_acc: 0.4504\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 44.1143 - acc: 0.4457 - val_loss: 41.2000 - val_acc: 0.4492\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4266 - acc: 0.4684 - val_loss: 0.4073 - val_acc: 0.4745\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.4239 - acc: 0.4685 - val_loss: 0.4065 - val_acc: 0.4745\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.4248 - acc: 0.4685 - val_loss: 0.4071 - val_acc: 0.4745\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4238 - acc: 0.4685 - val_loss: 0.4086 - val_acc: 0.4747\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 466us/step - loss: 0.4237 - acc: 0.4685 - val_loss: 0.4079 - val_acc: 0.4748\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4243 - acc: 0.4682 - val_loss: 0.4100 - val_acc: 0.4747\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.4257 - acc: 0.4684 - val_loss: 0.4061 - val_acc: 0.4749\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4236 - acc: 0.4685 - val_loss: 0.4098 - val_acc: 0.4747\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 0.4245 - acc: 0.4683 - val_loss: 0.4060 - val_acc: 0.4747\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4243 - acc: 0.4684 - val_loss: 0.4063 - val_acc: 0.4745\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.4233 - acc: 0.4686 - val_loss: 0.4061 - val_acc: 0.4745\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4229 - acc: 0.4684 - val_loss: 0.4058 - val_acc: 0.4748\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.4236 - acc: 0.4684 - val_loss: 0.4072 - val_acc: 0.4750\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.4235 - acc: 0.4682 - val_loss: 0.4073 - val_acc: 0.4741\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.4229 - acc: 0.4685 - val_loss: 0.4077 - val_acc: 0.4748\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.4232 - acc: 0.4684 - val_loss: 0.4058 - val_acc: 0.4748\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4228 - acc: 0.4682 - val_loss: 0.4062 - val_acc: 0.4750\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.4232 - acc: 0.4683 - val_loss: 0.4116 - val_acc: 0.4739\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.4234 - acc: 0.4682 - val_loss: 0.4054 - val_acc: 0.4746\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.4228 - acc: 0.4684 - val_loss: 0.4054 - val_acc: 0.4744\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.4237 - acc: 0.4682 - val_loss: 0.4096 - val_acc: 0.4739\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4231 - acc: 0.4684 - val_loss: 0.4055 - val_acc: 0.4748\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 461us/step - loss: 0.4235 - acc: 0.4685 - val_loss: 0.4061 - val_acc: 0.4754\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.4238 - acc: 0.4682 - val_loss: 0.4052 - val_acc: 0.4748\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4219 - acc: 0.4685 - val_loss: 0.4050 - val_acc: 0.4749\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.4218 - acc: 0.4684 - val_loss: 0.4051 - val_acc: 0.4744\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4222 - acc: 0.4683 - val_loss: 0.4079 - val_acc: 0.4740\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4229 - acc: 0.4682 - val_loss: 0.4047 - val_acc: 0.4749\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4218 - acc: 0.4683 - val_loss: 0.4061 - val_acc: 0.4739\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.4224 - acc: 0.4684 - val_loss: 0.4049 - val_acc: 0.4742\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.4214 - acc: 0.4684 - val_loss: 0.4048 - val_acc: 0.4744\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.4213 - acc: 0.4684 - val_loss: 0.4044 - val_acc: 0.4743\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4216 - acc: 0.4684 - val_loss: 0.4045 - val_acc: 0.4747\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.4221 - acc: 0.4684 - val_loss: 0.4049 - val_acc: 0.4739\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4213 - acc: 0.4683 - val_loss: 0.4044 - val_acc: 0.4746\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.4216 - acc: 0.4683 - val_loss: 0.4049 - val_acc: 0.4744\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.4238 - acc: 0.4684 - val_loss: 0.4096 - val_acc: 0.4753\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 474us/step - loss: 0.4257 - acc: 0.4683 - val_loss: 0.4041 - val_acc: 0.4750\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.4208 - acc: 0.4684 - val_loss: 0.4039 - val_acc: 0.4746\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.4209 - acc: 0.4685 - val_loss: 0.4049 - val_acc: 0.4749\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4215 - acc: 0.4683 - val_loss: 0.4038 - val_acc: 0.4745\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 480us/step - loss: 0.4206 - acc: 0.4684 - val_loss: 0.4038 - val_acc: 0.4747\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.4220 - acc: 0.4684 - val_loss: 0.4040 - val_acc: 0.4742\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.4208 - acc: 0.4684 - val_loss: 0.4044 - val_acc: 0.4751\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.4203 - acc: 0.4683 - val_loss: 0.4038 - val_acc: 0.4745\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4208 - acc: 0.4683 - val_loss: 0.4034 - val_acc: 0.4743\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 476us/step - loss: 0.4201 - acc: 0.4684 - val_loss: 0.4037 - val_acc: 0.4752\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 461us/step - loss: 0.4203 - acc: 0.4681 - val_loss: 0.4045 - val_acc: 0.4745\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.4203 - acc: 0.4683 - val_loss: 0.4045 - val_acc: 0.4740\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.4200 - acc: 0.4682 - val_loss: 0.4041 - val_acc: 0.4742\n",
      "start training round 26\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 28.0131 - acc: 0.7060 - val_loss: 27.4241 - val_acc: 0.7095\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 27.4850 - acc: 0.6923 - val_loss: 29.3239 - val_acc: 0.6646\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 28.1810 - acc: 0.7086 - val_loss: 28.0989 - val_acc: 0.7112\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 28.0731 - acc: 0.7061 - val_loss: 27.2496 - val_acc: 0.7109\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 26.5518 - acc: 0.6911 - val_loss: 27.6895 - val_acc: 0.6760\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 28.2708 - acc: 0.6880 - val_loss: 28.0869 - val_acc: 0.7113\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 27.5710 - acc: 0.6969 - val_loss: 28.0234 - val_acc: 0.6675\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 26.8233 - acc: 0.6795 - val_loss: 28.0169 - val_acc: 0.6761\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 28.2338 - acc: 0.6812 - val_loss: 27.8359 - val_acc: 0.7129\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 28.0265 - acc: 0.6926 - val_loss: 29.3175 - val_acc: 0.7133\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 27.8352 - acc: 0.7095 - val_loss: 27.1413 - val_acc: 0.7126\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 27.3982 - acc: 0.6973 - val_loss: 27.9900 - val_acc: 0.6768\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 27.7714 - acc: 0.6860 - val_loss: 27.6151 - val_acc: 0.7127\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 27.9067 - acc: 0.7024 - val_loss: 27.1600 - val_acc: 0.7124\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 27.5123 - acc: 0.6917 - val_loss: 27.0640 - val_acc: 0.6694\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 27.6119 - acc: 0.6913 - val_loss: 27.8069 - val_acc: 0.6676\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 27.7291 - acc: 0.7020 - val_loss: 27.0549 - val_acc: 0.7103\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 27.4304 - acc: 0.7087 - val_loss: 27.2422 - val_acc: 0.6734\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 27.9170 - acc: 0.6965 - val_loss: 28.5925 - val_acc: 0.7100\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 27.5007 - acc: 0.7124 - val_loss: 27.1159 - val_acc: 0.6632\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 27.8231 - acc: 0.6951 - val_loss: 27.8750 - val_acc: 0.7119\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 27.3695 - acc: 0.6958 - val_loss: 29.7662 - val_acc: 0.6588\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 28.1454 - acc: 0.7037 - val_loss: 27.1049 - val_acc: 0.7119\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 27.6196 - acc: 0.7079 - val_loss: 27.5059 - val_acc: 0.6681\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 27.2560 - acc: 0.7053 - val_loss: 28.2276 - val_acc: 0.7109\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 27.4915 - acc: 0.6981 - val_loss: 27.2482 - val_acc: 0.6672\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 26.5616 - acc: 0.6748 - val_loss: 27.4492 - val_acc: 0.6714\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 28.1385 - acc: 0.6856 - val_loss: 28.2284 - val_acc: 0.7130\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 28.0748 - acc: 0.7001 - val_loss: 26.6243 - val_acc: 0.7129\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 28.4649 - acc: 0.7123 - val_loss: 26.3753 - val_acc: 0.7128\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 26.2589 - acc: 0.7053 - val_loss: 27.9632 - val_acc: 0.6800\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 27.6394 - acc: 0.6877 - val_loss: 27.5345 - val_acc: 0.7127\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 27.2374 - acc: 0.6846 - val_loss: 29.1830 - val_acc: 0.7136\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 27.8775 - acc: 0.7095 - val_loss: 26.6792 - val_acc: 0.7118\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 27.1125 - acc: 0.6801 - val_loss: 27.0865 - val_acc: 0.7134\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 27.4744 - acc: 0.7018 - val_loss: 27.1520 - val_acc: 0.7116\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 27.6900 - acc: 0.6912 - val_loss: 28.0453 - val_acc: 0.7132\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 27.5801 - acc: 0.7030 - val_loss: 27.1885 - val_acc: 0.7130\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 26.9678 - acc: 0.6985 - val_loss: 28.8464 - val_acc: 0.7137\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 27.8279 - acc: 0.6999 - val_loss: 27.4178 - val_acc: 0.7127\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 27.8491 - acc: 0.7020 - val_loss: 26.5066 - val_acc: 0.7126\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 27.1780 - acc: 0.7046 - val_loss: 28.6996 - val_acc: 0.7125\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 28.1590 - acc: 0.7103 - val_loss: 27.1588 - val_acc: 0.7132\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 26.6893 - acc: 0.7040 - val_loss: 27.6543 - val_acc: 0.7123\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 27.6797 - acc: 0.6925 - val_loss: 27.0038 - val_acc: 0.7125\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 27.8346 - acc: 0.7090 - val_loss: 28.8637 - val_acc: 0.7135\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 27.3539 - acc: 0.7067 - val_loss: 26.9107 - val_acc: 0.7120\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 27.5350 - acc: 0.6858 - val_loss: 26.6568 - val_acc: 0.7129\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 27.9138 - acc: 0.6946 - val_loss: 28.5383 - val_acc: 0.7131\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 27.9348 - acc: 0.7125 - val_loss: 27.4086 - val_acc: 0.7133\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 432us/step - loss: 107.3022 - acc: 0.6424 - val_loss: 108.4391 - val_acc: 0.6325\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 104.9446 - acc: 0.6403 - val_loss: 104.5459 - val_acc: 0.6325\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 102.9323 - acc: 0.6411 - val_loss: 105.0923 - val_acc: 0.6336\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 103.2931 - acc: 0.6416 - val_loss: 105.9541 - val_acc: 0.6359\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 105.4145 - acc: 0.6422 - val_loss: 106.0504 - val_acc: 0.6377\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 105.5161 - acc: 0.6425 - val_loss: 109.0532 - val_acc: 0.6366\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 107.2031 - acc: 0.6394 - val_loss: 105.2344 - val_acc: 0.6373\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 104.0191 - acc: 0.6426 - val_loss: 106.7887 - val_acc: 0.6351\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 104.9663 - acc: 0.6415 - val_loss: 107.7742 - val_acc: 0.6360\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 105.6051 - acc: 0.6424 - val_loss: 106.8470 - val_acc: 0.6370\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 105.2128 - acc: 0.6409 - val_loss: 105.7222 - val_acc: 0.6342\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 104.6233 - acc: 0.6414 - val_loss: 104.8888 - val_acc: 0.6372\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 105.2135 - acc: 0.6426 - val_loss: 102.8097 - val_acc: 0.6369\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 104.3829 - acc: 0.6411 - val_loss: 104.9711 - val_acc: 0.6348\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 102.5365 - acc: 0.6422 - val_loss: 103.2118 - val_acc: 0.6367\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 103.7101 - acc: 0.6379 - val_loss: 103.4148 - val_acc: 0.6330\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 102.3176 - acc: 0.6393 - val_loss: 103.9233 - val_acc: 0.6312\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 103.1893 - acc: 0.6414 - val_loss: 111.2644 - val_acc: 0.6333\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 107.2524 - acc: 0.6415 - val_loss: 111.1458 - val_acc: 0.6371\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 107.0629 - acc: 0.6421 - val_loss: 106.3848 - val_acc: 0.6369\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 104.5203 - acc: 0.6425 - val_loss: 108.0299 - val_acc: 0.6360\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 104.7644 - acc: 0.6411 - val_loss: 105.3833 - val_acc: 0.6342\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 103.7136 - acc: 0.6392 - val_loss: 104.8743 - val_acc: 0.6337\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 103.1686 - acc: 0.6388 - val_loss: 106.4315 - val_acc: 0.6339\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 102.6192 - acc: 0.6406 - val_loss: 103.1430 - val_acc: 0.6354\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 101.9932 - acc: 0.6420 - val_loss: 103.6167 - val_acc: 0.6356\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 102.0379 - acc: 0.6401 - val_loss: 104.8261 - val_acc: 0.6289\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 103.0154 - acc: 0.6390 - val_loss: 104.3771 - val_acc: 0.6349\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 107.3662 - acc: 0.6423 - val_loss: 104.1922 - val_acc: 0.6364\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 106.1600 - acc: 0.6423 - val_loss: 109.9072 - val_acc: 0.6344\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 106.5268 - acc: 0.6418 - val_loss: 107.7570 - val_acc: 0.6361\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 105.8734 - acc: 0.6420 - val_loss: 107.1695 - val_acc: 0.6352\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 106.0678 - acc: 0.6413 - val_loss: 104.4781 - val_acc: 0.6359\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 103.2089 - acc: 0.6419 - val_loss: 103.8231 - val_acc: 0.6361\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 102.9184 - acc: 0.6415 - val_loss: 103.5408 - val_acc: 0.6359\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 101.8686 - acc: 0.6414 - val_loss: 104.1831 - val_acc: 0.6348\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 103.2721 - acc: 0.6395 - val_loss: 102.7668 - val_acc: 0.6348\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 103.0391 - acc: 0.6409 - val_loss: 106.1478 - val_acc: 0.6345\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 106.4078 - acc: 0.6425 - val_loss: 106.4360 - val_acc: 0.6366\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 109.1766 - acc: 0.6420 - val_loss: 103.2509 - val_acc: 0.6359\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 103.7761 - acc: 0.6403 - val_loss: 106.2651 - val_acc: 0.6302\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 102.8872 - acc: 0.6400 - val_loss: 105.3972 - val_acc: 0.6341\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 102.6301 - acc: 0.6403 - val_loss: 104.2043 - val_acc: 0.6369\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 104.1226 - acc: 0.6415 - val_loss: 106.1649 - val_acc: 0.6378\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 104.8197 - acc: 0.6414 - val_loss: 104.5623 - val_acc: 0.6369\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 103.9697 - acc: 0.6428 - val_loss: 104.9616 - val_acc: 0.6364\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 105.1842 - acc: 0.6413 - val_loss: 108.2902 - val_acc: 0.6364\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 106.8554 - acc: 0.6418 - val_loss: 105.3698 - val_acc: 0.6358\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 103.8215 - acc: 0.6419 - val_loss: 107.0165 - val_acc: 0.6345\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 105.5933 - acc: 0.6423 - val_loss: 108.8311 - val_acc: 0.6356\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 43.8512 - acc: 0.4451 - val_loss: 41.1368 - val_acc: 0.4499\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 43.8609 - acc: 0.4458 - val_loss: 41.1423 - val_acc: 0.4492\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 43.8433 - acc: 0.4460 - val_loss: 41.1523 - val_acc: 0.4505\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 43.8400 - acc: 0.4459 - val_loss: 41.0903 - val_acc: 0.4498\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 43.7868 - acc: 0.4457 - val_loss: 41.0570 - val_acc: 0.4507\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 43.7633 - acc: 0.4457 - val_loss: 41.0466 - val_acc: 0.4507\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 43.7362 - acc: 0.4462 - val_loss: 41.0462 - val_acc: 0.4502\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 43.7640 - acc: 0.4469 - val_loss: 41.0134 - val_acc: 0.4495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 43.7230 - acc: 0.4459 - val_loss: 41.0503 - val_acc: 0.4508\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 43.7992 - acc: 0.4456 - val_loss: 41.0548 - val_acc: 0.4513\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 43.7117 - acc: 0.4464 - val_loss: 40.9652 - val_acc: 0.4500\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 43.6923 - acc: 0.4466 - val_loss: 40.9693 - val_acc: 0.4500\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 43.6511 - acc: 0.4463 - val_loss: 40.9223 - val_acc: 0.4504\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 43.6875 - acc: 0.4463 - val_loss: 40.9656 - val_acc: 0.4500\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 43.6482 - acc: 0.4465 - val_loss: 40.9167 - val_acc: 0.4510\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 43.6083 - acc: 0.4466 - val_loss: 40.9756 - val_acc: 0.4495\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 43.6204 - acc: 0.4465 - val_loss: 40.9712 - val_acc: 0.4497\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 43.5948 - acc: 0.4469 - val_loss: 40.8515 - val_acc: 0.4495\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 43.5910 - acc: 0.4462 - val_loss: 40.8348 - val_acc: 0.4511\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 43.6491 - acc: 0.4462 - val_loss: 40.9809 - val_acc: 0.4526\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 43.6108 - acc: 0.4468 - val_loss: 40.8163 - val_acc: 0.4512\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 43.5410 - acc: 0.4469 - val_loss: 40.8188 - val_acc: 0.4509\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 43.5781 - acc: 0.4470 - val_loss: 41.0061 - val_acc: 0.4515\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 43.6017 - acc: 0.4468 - val_loss: 40.7905 - val_acc: 0.4518\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 43.5167 - acc: 0.4467 - val_loss: 40.8307 - val_acc: 0.4515\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 43.4602 - acc: 0.4470 - val_loss: 40.7749 - val_acc: 0.4514\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 43.4114 - acc: 0.4471 - val_loss: 40.7079 - val_acc: 0.4506\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 43.4129 - acc: 0.4470 - val_loss: 40.8274 - val_acc: 0.4497\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 43.5131 - acc: 0.4474 - val_loss: 41.1814 - val_acc: 0.4488\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 43.5621 - acc: 0.4472 - val_loss: 40.6764 - val_acc: 0.4512\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 43.3985 - acc: 0.4474 - val_loss: 40.7200 - val_acc: 0.4512\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 43.3711 - acc: 0.4474 - val_loss: 40.6526 - val_acc: 0.4502\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 43.4647 - acc: 0.4472 - val_loss: 40.7328 - val_acc: 0.4500\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 43.3928 - acc: 0.4471 - val_loss: 40.6729 - val_acc: 0.4503\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 43.3315 - acc: 0.4477 - val_loss: 40.6509 - val_acc: 0.4510\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 43.3754 - acc: 0.4475 - val_loss: 40.5741 - val_acc: 0.4510\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 43.3190 - acc: 0.4475 - val_loss: 40.5955 - val_acc: 0.4509\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 43.2459 - acc: 0.4476 - val_loss: 40.5414 - val_acc: 0.4513\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 43.2322 - acc: 0.4477 - val_loss: 40.6376 - val_acc: 0.4506\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 43.2666 - acc: 0.4478 - val_loss: 40.6914 - val_acc: 0.4504\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 43.2834 - acc: 0.4477 - val_loss: 40.5629 - val_acc: 0.4519\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 43.2791 - acc: 0.4479 - val_loss: 40.6684 - val_acc: 0.4528\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 43.1941 - acc: 0.4481 - val_loss: 40.4984 - val_acc: 0.4521\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 43.1688 - acc: 0.4482 - val_loss: 40.4664 - val_acc: 0.4527\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 43.1354 - acc: 0.4477 - val_loss: 40.4790 - val_acc: 0.4525\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 43.1608 - acc: 0.4485 - val_loss: 40.4593 - val_acc: 0.4525\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 43.1104 - acc: 0.4485 - val_loss: 40.4234 - val_acc: 0.4523\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 43.1757 - acc: 0.4480 - val_loss: 40.6085 - val_acc: 0.4509\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 43.1585 - acc: 0.4483 - val_loss: 40.4275 - val_acc: 0.4526\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 43.0615 - acc: 0.4485 - val_loss: 40.3717 - val_acc: 0.4513\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4211 - acc: 0.4683 - val_loss: 0.4033 - val_acc: 0.4744\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.4198 - acc: 0.4682 - val_loss: 0.4034 - val_acc: 0.4750\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4196 - acc: 0.4682 - val_loss: 0.4045 - val_acc: 0.4745\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.4227 - acc: 0.4680 - val_loss: 0.4034 - val_acc: 0.4751\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4200 - acc: 0.4683 - val_loss: 0.4062 - val_acc: 0.4753\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.4224 - acc: 0.4682 - val_loss: 0.4036 - val_acc: 0.4751\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 0.4205 - acc: 0.4683 - val_loss: 0.4073 - val_acc: 0.4737\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.4202 - acc: 0.4683 - val_loss: 0.4030 - val_acc: 0.4752\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.4193 - acc: 0.4683 - val_loss: 0.4028 - val_acc: 0.4754\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4205 - acc: 0.4683 - val_loss: 0.4034 - val_acc: 0.4754\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4190 - acc: 0.4683 - val_loss: 0.4029 - val_acc: 0.4744\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.4191 - acc: 0.4681 - val_loss: 0.4027 - val_acc: 0.4749\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4191 - acc: 0.4684 - val_loss: 0.4028 - val_acc: 0.4742\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4196 - acc: 0.4682 - val_loss: 0.4025 - val_acc: 0.4743\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4195 - acc: 0.4682 - val_loss: 0.4022 - val_acc: 0.4746\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.4192 - acc: 0.4681 - val_loss: 0.4055 - val_acc: 0.4754\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.4202 - acc: 0.4682 - val_loss: 0.4021 - val_acc: 0.4751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.4186 - acc: 0.4682 - val_loss: 0.4029 - val_acc: 0.4754\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.4200 - acc: 0.4683 - val_loss: 0.4021 - val_acc: 0.4745\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.4186 - acc: 0.4682 - val_loss: 0.4022 - val_acc: 0.4747\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4185 - acc: 0.4681 - val_loss: 0.4034 - val_acc: 0.4752\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.4192 - acc: 0.4680 - val_loss: 0.4017 - val_acc: 0.4748\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4182 - acc: 0.4681 - val_loss: 0.4020 - val_acc: 0.4750\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.4181 - acc: 0.4682 - val_loss: 0.4016 - val_acc: 0.4751\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4190 - acc: 0.4682 - val_loss: 0.4018 - val_acc: 0.4740\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4178 - acc: 0.4682 - val_loss: 0.4015 - val_acc: 0.4743\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4178 - acc: 0.4682 - val_loss: 0.4015 - val_acc: 0.4748\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4182 - acc: 0.4681 - val_loss: 0.4016 - val_acc: 0.4745\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4178 - acc: 0.4682 - val_loss: 0.4011 - val_acc: 0.4743\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4175 - acc: 0.4681 - val_loss: 0.4014 - val_acc: 0.4754\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 475us/step - loss: 0.4174 - acc: 0.4683 - val_loss: 0.4010 - val_acc: 0.4748\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4178 - acc: 0.4680 - val_loss: 0.4012 - val_acc: 0.4755\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4176 - acc: 0.4683 - val_loss: 0.4010 - val_acc: 0.4747\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.4208 - acc: 0.4682 - val_loss: 0.4096 - val_acc: 0.4733\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.4190 - acc: 0.4681 - val_loss: 0.4015 - val_acc: 0.4744\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4179 - acc: 0.4682 - val_loss: 0.4042 - val_acc: 0.4742\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4180 - acc: 0.4681 - val_loss: 0.4007 - val_acc: 0.4745\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4174 - acc: 0.4682 - val_loss: 0.4050 - val_acc: 0.4742\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.4197 - acc: 0.4680 - val_loss: 0.4011 - val_acc: 0.4744\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.4168 - acc: 0.4682 - val_loss: 0.4006 - val_acc: 0.4751\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4167 - acc: 0.4682 - val_loss: 0.4009 - val_acc: 0.4750\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4165 - acc: 0.4682 - val_loss: 0.4003 - val_acc: 0.4746\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 469us/step - loss: 0.4166 - acc: 0.4682 - val_loss: 0.4007 - val_acc: 0.4747\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4164 - acc: 0.4681 - val_loss: 0.4002 - val_acc: 0.4746\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.4174 - acc: 0.4681 - val_loss: 0.4059 - val_acc: 0.4738\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.4176 - acc: 0.4681 - val_loss: 0.4005 - val_acc: 0.4747\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.4161 - acc: 0.4682 - val_loss: 0.4001 - val_acc: 0.4747\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.4162 - acc: 0.4682 - val_loss: 0.3998 - val_acc: 0.4747\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4169 - acc: 0.4681 - val_loss: 0.4006 - val_acc: 0.4748\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.4182 - acc: 0.4682 - val_loss: 0.3998 - val_acc: 0.4748\n",
      "start training round 27\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 27.5765 - acc: 0.7093 - val_loss: 27.6334 - val_acc: 0.7136\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 27.6684 - acc: 0.7110 - val_loss: 27.0123 - val_acc: 0.7122\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 27.3337 - acc: 0.6962 - val_loss: 27.8931 - val_acc: 0.7128\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 27.9702 - acc: 0.7097 - val_loss: 27.8968 - val_acc: 0.7123\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 26.8954 - acc: 0.7072 - val_loss: 27.6724 - val_acc: 0.6656\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 28.0910 - acc: 0.7020 - val_loss: 26.9625 - val_acc: 0.7105\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 27.0413 - acc: 0.7092 - val_loss: 28.1659 - val_acc: 0.7106\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 27.8347 - acc: 0.7106 - val_loss: 28.7299 - val_acc: 0.7112\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 27.6275 - acc: 0.7113 - val_loss: 27.9882 - val_acc: 0.6655\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 27.4942 - acc: 0.6990 - val_loss: 29.0369 - val_acc: 0.6646\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 28.0935 - acc: 0.7096 - val_loss: 28.5503 - val_acc: 0.7087\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 27.4283 - acc: 0.7105 - val_loss: 28.8367 - val_acc: 0.7099\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 27.3382 - acc: 0.7089 - val_loss: 27.5293 - val_acc: 0.6623\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 27.5295 - acc: 0.6986 - val_loss: 29.2102 - val_acc: 0.6625\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 27.8255 - acc: 0.7046 - val_loss: 26.7807 - val_acc: 0.7110\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 26.4391 - acc: 0.6808 - val_loss: 27.6926 - val_acc: 0.6728\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 27.8109 - acc: 0.6784 - val_loss: 27.7638 - val_acc: 0.7130\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 28.2332 - acc: 0.6953 - val_loss: 26.7070 - val_acc: 0.7126\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 27.1179 - acc: 0.7125 - val_loss: 27.2998 - val_acc: 0.7124\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 27.4008 - acc: 0.7042 - val_loss: 26.7790 - val_acc: 0.7132\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 27.4568 - acc: 0.7125 - val_loss: 26.9831 - val_acc: 0.7126\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 27.6973 - acc: 0.7057 - val_loss: 27.7889 - val_acc: 0.7130\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 26.8180 - acc: 0.6954 - val_loss: 27.9477 - val_acc: 0.6762\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 28.0485 - acc: 0.6867 - val_loss: 28.1542 - val_acc: 0.7127\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 27.2347 - acc: 0.6987 - val_loss: 27.4007 - val_acc: 0.7121\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 27.9708 - acc: 0.6980 - val_loss: 27.1467 - val_acc: 0.7132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 27.2118 - acc: 0.7102 - val_loss: 29.8988 - val_acc: 0.7118\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 27.9666 - acc: 0.7095 - val_loss: 27.1559 - val_acc: 0.7134\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 26.4231 - acc: 0.7008 - val_loss: 27.9387 - val_acc: 0.7128\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 28.2555 - acc: 0.7003 - val_loss: 27.4914 - val_acc: 0.7130\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 27.2709 - acc: 0.7123 - val_loss: 27.4308 - val_acc: 0.7123\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 27.7522 - acc: 0.7078 - val_loss: 26.5070 - val_acc: 0.7128\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 27.1470 - acc: 0.7008 - val_loss: 28.6123 - val_acc: 0.7096\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 27.6826 - acc: 0.7123 - val_loss: 26.9966 - val_acc: 0.7121\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 26.7296 - acc: 0.6959 - val_loss: 27.6417 - val_acc: 0.6703\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 27.0180 - acc: 0.6743 - val_loss: 28.3824 - val_acc: 0.7141\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 27.9240 - acc: 0.7033 - val_loss: 27.7452 - val_acc: 0.7120\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 27.1569 - acc: 0.7022 - val_loss: 33.0558 - val_acc: 0.6447\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 28.3107 - acc: 0.7074 - val_loss: 27.8324 - val_acc: 0.7117\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 26.9700 - acc: 0.7062 - val_loss: 29.8502 - val_acc: 0.6625\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 27.4646 - acc: 0.6984 - val_loss: 28.0420 - val_acc: 0.6620\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 27.2721 - acc: 0.7039 - val_loss: 26.9212 - val_acc: 0.7110\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 26.8625 - acc: 0.6865 - val_loss: 27.1066 - val_acc: 0.6635\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 27.8674 - acc: 0.7002 - val_loss: 27.9660 - val_acc: 0.6649\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 27.0281 - acc: 0.6955 - val_loss: 28.2514 - val_acc: 0.6580\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 28.2085 - acc: 0.7054 - val_loss: 29.1542 - val_acc: 0.7103\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 27.2409 - acc: 0.7121 - val_loss: 27.5586 - val_acc: 0.7114\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 27.3512 - acc: 0.7102 - val_loss: 26.4105 - val_acc: 0.7118\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 27.1543 - acc: 0.7072 - val_loss: 28.6935 - val_acc: 0.6634\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 27.6811 - acc: 0.6931 - val_loss: 28.0180 - val_acc: 0.7117\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 104.5370 - acc: 0.6415 - val_loss: 107.3100 - val_acc: 0.6351\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 105.6428 - acc: 0.6424 - val_loss: 105.9916 - val_acc: 0.6364\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 104.5741 - acc: 0.6419 - val_loss: 106.4905 - val_acc: 0.6358\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 104.0563 - acc: 0.6397 - val_loss: 102.5075 - val_acc: 0.6358\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 101.8952 - acc: 0.6413 - val_loss: 108.4444 - val_acc: 0.6293\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 103.8976 - acc: 0.6397 - val_loss: 107.5295 - val_acc: 0.6358\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 104.3026 - acc: 0.6423 - val_loss: 108.3110 - val_acc: 0.6351\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 103.9300 - acc: 0.6421 - val_loss: 113.5860 - val_acc: 0.6315\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 104.8409 - acc: 0.6419 - val_loss: 105.3616 - val_acc: 0.6374\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 104.5551 - acc: 0.6424 - val_loss: 103.7993 - val_acc: 0.6379\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 103.8430 - acc: 0.6429 - val_loss: 108.7807 - val_acc: 0.6343\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 106.7308 - acc: 0.6397 - val_loss: 105.2919 - val_acc: 0.6342\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 103.6068 - acc: 0.6417 - val_loss: 104.3845 - val_acc: 0.6363\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 104.3952 - acc: 0.6403 - val_loss: 102.3843 - val_acc: 0.6375\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 103.4064 - acc: 0.6409 - val_loss: 104.1961 - val_acc: 0.6351\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 103.6333 - acc: 0.6415 - val_loss: 102.6308 - val_acc: 0.6374\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 102.5915 - acc: 0.6427 - val_loss: 105.9463 - val_acc: 0.6359\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 104.4240 - acc: 0.6418 - val_loss: 109.1404 - val_acc: 0.6321\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 105.7462 - acc: 0.6415 - val_loss: 107.8153 - val_acc: 0.6368\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 107.0716 - acc: 0.6425 - val_loss: 109.6017 - val_acc: 0.6349\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 106.0307 - acc: 0.6386 - val_loss: 105.6234 - val_acc: 0.6369\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 103.9748 - acc: 0.6427 - val_loss: 107.4316 - val_acc: 0.6356\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 103.2793 - acc: 0.6428 - val_loss: 107.0216 - val_acc: 0.6361\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 103.5970 - acc: 0.6404 - val_loss: 107.6641 - val_acc: 0.6288\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 102.2424 - acc: 0.6413 - val_loss: 102.0042 - val_acc: 0.6369\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 102.8076 - acc: 0.6391 - val_loss: 105.3972 - val_acc: 0.6295\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 101.9854 - acc: 0.6411 - val_loss: 102.7131 - val_acc: 0.6362\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 102.8720 - acc: 0.6411 - val_loss: 103.8950 - val_acc: 0.6376\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 104.0637 - acc: 0.6428 - val_loss: 109.3014 - val_acc: 0.6367\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 106.6256 - acc: 0.6427 - val_loss: 105.2890 - val_acc: 0.6358\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 103.8278 - acc: 0.6410 - val_loss: 102.9457 - val_acc: 0.6382\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 103.8491 - acc: 0.6431 - val_loss: 109.8547 - val_acc: 0.6367\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 106.2959 - acc: 0.6418 - val_loss: 104.5531 - val_acc: 0.6369\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 103.8302 - acc: 0.6417 - val_loss: 104.0250 - val_acc: 0.6376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 103.9542 - acc: 0.6410 - val_loss: 106.9439 - val_acc: 0.6355\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 103.0045 - acc: 0.6417 - val_loss: 102.9677 - val_acc: 0.6357\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 103.5427 - acc: 0.6384 - val_loss: 103.5613 - val_acc: 0.6359\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 103.6938 - acc: 0.6407 - val_loss: 105.2446 - val_acc: 0.6373\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 105.8251 - acc: 0.6422 - val_loss: 106.4315 - val_acc: 0.6366\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 104.7167 - acc: 0.6419 - val_loss: 106.1600 - val_acc: 0.6350\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 102.7931 - acc: 0.6425 - val_loss: 104.5980 - val_acc: 0.6355\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 104.0683 - acc: 0.6401 - val_loss: 104.4899 - val_acc: 0.6334\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 101.9641 - acc: 0.6418 - val_loss: 104.5302 - val_acc: 0.6355\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 102.8895 - acc: 0.6421 - val_loss: 114.4852 - val_acc: 0.6336\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 103.5568 - acc: 0.6419 - val_loss: 103.1897 - val_acc: 0.6354\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 103.7730 - acc: 0.6412 - val_loss: 103.8601 - val_acc: 0.6340\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 103.8162 - acc: 0.6402 - val_loss: 103.7964 - val_acc: 0.6363\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 103.9128 - acc: 0.6423 - val_loss: 109.5170 - val_acc: 0.6339\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 105.8284 - acc: 0.6423 - val_loss: 106.4571 - val_acc: 0.6338\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 105.0219 - acc: 0.6420 - val_loss: 104.9081 - val_acc: 0.6373\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 43.0612 - acc: 0.4485 - val_loss: 40.3593 - val_acc: 0.4520\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 43.0432 - acc: 0.4485 - val_loss: 40.4106 - val_acc: 0.4535\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 43.0420 - acc: 0.4487 - val_loss: 40.3655 - val_acc: 0.4517\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 43.0201 - acc: 0.4485 - val_loss: 40.3181 - val_acc: 0.4526\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 42.9777 - acc: 0.4490 - val_loss: 40.3085 - val_acc: 0.4525\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 42.9834 - acc: 0.4488 - val_loss: 40.3227 - val_acc: 0.4527\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 42.9637 - acc: 0.4484 - val_loss: 40.2781 - val_acc: 0.4535\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 42.9692 - acc: 0.4487 - val_loss: 40.3148 - val_acc: 0.4544\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 42.9697 - acc: 0.4492 - val_loss: 40.2561 - val_acc: 0.4520\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 42.9372 - acc: 0.4489 - val_loss: 40.2357 - val_acc: 0.4533\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 42.9031 - acc: 0.4489 - val_loss: 40.2809 - val_acc: 0.4535\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 42.8969 - acc: 0.4492 - val_loss: 40.2102 - val_acc: 0.4525\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 42.9524 - acc: 0.4489 - val_loss: 40.2179 - val_acc: 0.4531\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 42.9078 - acc: 0.4492 - val_loss: 40.1698 - val_acc: 0.4531\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 42.8585 - acc: 0.4491 - val_loss: 40.1880 - val_acc: 0.4519\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 42.8370 - acc: 0.4492 - val_loss: 40.1535 - val_acc: 0.4536\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 42.8501 - acc: 0.4492 - val_loss: 40.2161 - val_acc: 0.4538\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 42.8198 - acc: 0.4496 - val_loss: 40.2219 - val_acc: 0.4529\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 42.9189 - acc: 0.4489 - val_loss: 40.6749 - val_acc: 0.4551\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 42.9838 - acc: 0.4494 - val_loss: 40.0833 - val_acc: 0.4531\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 42.8223 - acc: 0.4496 - val_loss: 40.0794 - val_acc: 0.4529\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 42.7553 - acc: 0.4494 - val_loss: 40.1855 - val_acc: 0.4534\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 42.7838 - acc: 0.4493 - val_loss: 40.0809 - val_acc: 0.4536\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 42.7572 - acc: 0.4493 - val_loss: 40.1050 - val_acc: 0.4537\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 42.7528 - acc: 0.4498 - val_loss: 40.1775 - val_acc: 0.4524\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 42.7025 - acc: 0.4496 - val_loss: 40.0203 - val_acc: 0.4530\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 42.6774 - acc: 0.4495 - val_loss: 40.0526 - val_acc: 0.4529\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 42.6842 - acc: 0.4495 - val_loss: 40.0808 - val_acc: 0.4531\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 42.7403 - acc: 0.4496 - val_loss: 39.9773 - val_acc: 0.4532\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 42.6206 - acc: 0.4493 - val_loss: 39.9666 - val_acc: 0.4542\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 42.6339 - acc: 0.4501 - val_loss: 40.0558 - val_acc: 0.4543\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 42.6237 - acc: 0.4498 - val_loss: 39.9591 - val_acc: 0.4538\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 42.6373 - acc: 0.4497 - val_loss: 40.1056 - val_acc: 0.4546\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 42.6465 - acc: 0.4501 - val_loss: 40.1323 - val_acc: 0.4543\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 42.5765 - acc: 0.4502 - val_loss: 39.9286 - val_acc: 0.4522\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 42.5832 - acc: 0.4495 - val_loss: 39.9507 - val_acc: 0.4553\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 42.5688 - acc: 0.4503 - val_loss: 40.1704 - val_acc: 0.4532\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 42.7529 - acc: 0.4499 - val_loss: 39.8489 - val_acc: 0.4533\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 42.6005 - acc: 0.4498 - val_loss: 39.8632 - val_acc: 0.4540\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 42.4943 - acc: 0.4506 - val_loss: 39.8299 - val_acc: 0.4540\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 42.4707 - acc: 0.4500 - val_loss: 39.8768 - val_acc: 0.4544\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 42.4889 - acc: 0.4499 - val_loss: 39.8464 - val_acc: 0.4546\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 431us/step - loss: 42.4376 - acc: 0.4502 - val_loss: 39.7857 - val_acc: 0.4543\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 42.4194 - acc: 0.4502 - val_loss: 39.7988 - val_acc: 0.4542\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 42.4114 - acc: 0.4504 - val_loss: 39.8199 - val_acc: 0.4545\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 42.4283 - acc: 0.4508 - val_loss: 39.9383 - val_acc: 0.4531\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 42.4725 - acc: 0.4501 - val_loss: 39.7726 - val_acc: 0.4543\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 42.3726 - acc: 0.4505 - val_loss: 39.7637 - val_acc: 0.4549\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 42.4120 - acc: 0.4506 - val_loss: 39.7428 - val_acc: 0.4543\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 42.3644 - acc: 0.4507 - val_loss: 39.9416 - val_acc: 0.4547\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4156 - acc: 0.4683 - val_loss: 0.3994 - val_acc: 0.4746\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4176 - acc: 0.4683 - val_loss: 0.3997 - val_acc: 0.4748\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 469us/step - loss: 0.4151 - acc: 0.4684 - val_loss: 0.3989 - val_acc: 0.4748\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 468us/step - loss: 0.4159 - acc: 0.4685 - val_loss: 0.4002 - val_acc: 0.4743\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.4157 - acc: 0.4683 - val_loss: 0.3992 - val_acc: 0.4745\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.4158 - acc: 0.4685 - val_loss: 0.3993 - val_acc: 0.4744\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4157 - acc: 0.4683 - val_loss: 0.4022 - val_acc: 0.4751\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.4148 - acc: 0.4684 - val_loss: 0.3984 - val_acc: 0.4748\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.4143 - acc: 0.4683 - val_loss: 0.3984 - val_acc: 0.4747\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.4143 - acc: 0.4684 - val_loss: 0.3984 - val_acc: 0.4743\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4144 - acc: 0.4684 - val_loss: 0.3982 - val_acc: 0.4747\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.4145 - acc: 0.4684 - val_loss: 0.3992 - val_acc: 0.4753\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.4155 - acc: 0.4683 - val_loss: 0.3985 - val_acc: 0.4749\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.4138 - acc: 0.4684 - val_loss: 0.3983 - val_acc: 0.4741\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4140 - acc: 0.4682 - val_loss: 0.3977 - val_acc: 0.4749\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.4135 - acc: 0.4684 - val_loss: 0.3988 - val_acc: 0.4752\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.4156 - acc: 0.4685 - val_loss: 0.3993 - val_acc: 0.4749\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.4133 - acc: 0.4682 - val_loss: 0.3982 - val_acc: 0.4754\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.4131 - acc: 0.4685 - val_loss: 0.3975 - val_acc: 0.4745\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4138 - acc: 0.4683 - val_loss: 0.3982 - val_acc: 0.4752\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4144 - acc: 0.4683 - val_loss: 0.3975 - val_acc: 0.4751\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.4131 - acc: 0.4683 - val_loss: 0.3990 - val_acc: 0.4745\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4131 - acc: 0.4684 - val_loss: 0.3973 - val_acc: 0.4750\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4135 - acc: 0.4685 - val_loss: 0.3972 - val_acc: 0.4748\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.4144 - acc: 0.4682 - val_loss: 0.3971 - val_acc: 0.4748\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.4144 - acc: 0.4683 - val_loss: 0.3972 - val_acc: 0.4748\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4128 - acc: 0.4684 - val_loss: 0.4023 - val_acc: 0.4737\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.4135 - acc: 0.4682 - val_loss: 0.3969 - val_acc: 0.4758\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.4139 - acc: 0.4684 - val_loss: 0.3967 - val_acc: 0.4749\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4124 - acc: 0.4686 - val_loss: 0.3998 - val_acc: 0.4757\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4134 - acc: 0.4681 - val_loss: 0.3966 - val_acc: 0.4752\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4131 - acc: 0.4684 - val_loss: 0.3982 - val_acc: 0.4756\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4141 - acc: 0.4684 - val_loss: 0.3961 - val_acc: 0.4749\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.4123 - acc: 0.4682 - val_loss: 0.3964 - val_acc: 0.4749\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.4114 - acc: 0.4684 - val_loss: 0.3964 - val_acc: 0.4752\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4118 - acc: 0.4682 - val_loss: 0.4005 - val_acc: 0.4756\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4181 - acc: 0.4680 - val_loss: 0.3959 - val_acc: 0.4748\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 468us/step - loss: 0.4122 - acc: 0.4685 - val_loss: 0.3957 - val_acc: 0.4750\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4123 - acc: 0.4684 - val_loss: 0.3988 - val_acc: 0.4739\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4142 - acc: 0.4682 - val_loss: 0.3984 - val_acc: 0.4743\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4119 - acc: 0.4686 - val_loss: 0.3956 - val_acc: 0.4750\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.4111 - acc: 0.4684 - val_loss: 0.3990 - val_acc: 0.4741\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.4142 - acc: 0.4682 - val_loss: 0.3957 - val_acc: 0.4744\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.4121 - acc: 0.4685 - val_loss: 0.3975 - val_acc: 0.4742\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4121 - acc: 0.4683 - val_loss: 0.3952 - val_acc: 0.4752\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4109 - acc: 0.4685 - val_loss: 0.3962 - val_acc: 0.4753\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4114 - acc: 0.4683 - val_loss: 0.3949 - val_acc: 0.4750\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4109 - acc: 0.4684 - val_loss: 0.3947 - val_acc: 0.4750\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.4103 - acc: 0.4684 - val_loss: 0.3952 - val_acc: 0.4754\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.4102 - acc: 0.4685 - val_loss: 0.3946 - val_acc: 0.4746\n",
      "start training round 28\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 437us/step - loss: 27.7252 - acc: 0.7065 - val_loss: 28.8106 - val_acc: 0.7085\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 27.5788 - acc: 0.7103 - val_loss: 29.4131 - val_acc: 0.7103\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 27.4583 - acc: 0.7120 - val_loss: 26.9758 - val_acc: 0.7101\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 27.0140 - acc: 0.7053 - val_loss: 27.8789 - val_acc: 0.6633\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 27.9068 - acc: 0.7096 - val_loss: 28.3983 - val_acc: 0.6610\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 27.6892 - acc: 0.7072 - val_loss: 26.4895 - val_acc: 0.7109\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 27.1940 - acc: 0.7078 - val_loss: 27.4945 - val_acc: 0.7102\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 27.3763 - acc: 0.7081 - val_loss: 27.9658 - val_acc: 0.7113\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 27.5084 - acc: 0.7120 - val_loss: 26.5172 - val_acc: 0.7122\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 27.2673 - acc: 0.6812 - val_loss: 31.0164 - val_acc: 0.7126\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 27.9167 - acc: 0.7083 - val_loss: 26.8508 - val_acc: 0.7121\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 27.0807 - acc: 0.7103 - val_loss: 26.7812 - val_acc: 0.7131\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 27.8282 - acc: 0.6977 - val_loss: 28.3021 - val_acc: 0.7133\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 27.2264 - acc: 0.7121 - val_loss: 28.9380 - val_acc: 0.7126\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 27.4163 - acc: 0.7126 - val_loss: 28.4822 - val_acc: 0.7129\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 27.3794 - acc: 0.7107 - val_loss: 26.8602 - val_acc: 0.7128\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 26.8566 - acc: 0.6975 - val_loss: 27.7049 - val_acc: 0.7119\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 27.7030 - acc: 0.7050 - val_loss: 30.2994 - val_acc: 0.7117\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 28.1996 - acc: 0.7057 - val_loss: 27.5078 - val_acc: 0.7125\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 27.4290 - acc: 0.7109 - val_loss: 29.1523 - val_acc: 0.7129\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 27.2980 - acc: 0.7120 - val_loss: 27.0278 - val_acc: 0.7125\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 26.5685 - acc: 0.6962 - val_loss: 28.8010 - val_acc: 0.6654\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 27.7639 - acc: 0.6883 - val_loss: 26.8441 - val_acc: 0.7101\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 27.2679 - acc: 0.7082 - val_loss: 29.6368 - val_acc: 0.6597\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 27.3463 - acc: 0.7088 - val_loss: 27.0677 - val_acc: 0.7115\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 27.3526 - acc: 0.7118 - val_loss: 26.3024 - val_acc: 0.7109\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 26.3625 - acc: 0.6985 - val_loss: 27.0739 - val_acc: 0.6603\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 27.5735 - acc: 0.6980 - val_loss: 30.0664 - val_acc: 0.7097\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 27.4699 - acc: 0.7104 - val_loss: 25.9405 - val_acc: 0.7118\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 26.5351 - acc: 0.6961 - val_loss: 28.6587 - val_acc: 0.6566\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 27.4381 - acc: 0.6991 - val_loss: 27.4515 - val_acc: 0.6695\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 27.2565 - acc: 0.6897 - val_loss: 27.8031 - val_acc: 0.6630\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 28.2582 - acc: 0.7054 - val_loss: 27.8474 - val_acc: 0.7106\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 27.6198 - acc: 0.7124 - val_loss: 26.9381 - val_acc: 0.7116\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 466us/step - loss: 27.0103 - acc: 0.7010 - val_loss: 27.9020 - val_acc: 0.7129\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 27.6223 - acc: 0.7096 - val_loss: 27.1055 - val_acc: 0.7133\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 466us/step - loss: 26.7536 - acc: 0.7121 - val_loss: 27.5440 - val_acc: 0.7128\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 27.4746 - acc: 0.7107 - val_loss: 26.7763 - val_acc: 0.7132\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 27.2899 - acc: 0.7123 - val_loss: 26.5266 - val_acc: 0.7130\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 26.6863 - acc: 0.6996 - val_loss: 26.6284 - val_acc: 0.7127\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 27.8160 - acc: 0.6996 - val_loss: 27.4367 - val_acc: 0.7129\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 27.0283 - acc: 0.7121 - val_loss: 27.2935 - val_acc: 0.7127\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 27.3207 - acc: 0.7104 - val_loss: 28.4931 - val_acc: 0.7129\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 27.6902 - acc: 0.7125 - val_loss: 27.0087 - val_acc: 0.7117\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 26.8522 - acc: 0.7095 - val_loss: 27.0053 - val_acc: 0.7134\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 27.4744 - acc: 0.7028 - val_loss: 28.9769 - val_acc: 0.7122\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 28.0577 - acc: 0.7100 - val_loss: 27.2721 - val_acc: 0.7125\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 27.4290 - acc: 0.7120 - val_loss: 26.3330 - val_acc: 0.7128\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 27.3013 - acc: 0.7124 - val_loss: 26.7141 - val_acc: 0.7133\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 27.1371 - acc: 0.7119 - val_loss: 27.4367 - val_acc: 0.7133\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 104.1616 - acc: 0.6415 - val_loss: 103.6266 - val_acc: 0.6353\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 102.0058 - acc: 0.6417 - val_loss: 103.4749 - val_acc: 0.6355\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 102.5112 - acc: 0.6384 - val_loss: 101.9767 - val_acc: 0.6369\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 102.2694 - acc: 0.6405 - val_loss: 102.2797 - val_acc: 0.6363\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 102.3793 - acc: 0.6409 - val_loss: 107.2255 - val_acc: 0.6295\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 101.7571 - acc: 0.6416 - val_loss: 101.6744 - val_acc: 0.6379\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 101.8009 - acc: 0.6427 - val_loss: 105.9559 - val_acc: 0.6347\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 105.3578 - acc: 0.6406 - val_loss: 112.1914 - val_acc: 0.6359\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 414us/step - loss: 107.8878 - acc: 0.6429 - val_loss: 106.7485 - val_acc: 0.6373\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 104.4303 - acc: 0.6424 - val_loss: 107.7329 - val_acc: 0.6379\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 106.3164 - acc: 0.6422 - val_loss: 105.2822 - val_acc: 0.6379\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 105.5785 - acc: 0.6423 - val_loss: 103.1573 - val_acc: 0.6364\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 102.1937 - acc: 0.6425 - val_loss: 102.4291 - val_acc: 0.6349\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 102.7705 - acc: 0.6389 - val_loss: 108.2599 - val_acc: 0.6316\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 103.3201 - acc: 0.6412 - val_loss: 106.3702 - val_acc: 0.6358\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 105.0351 - acc: 0.6421 - val_loss: 106.4466 - val_acc: 0.6344\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 104.8376 - acc: 0.6417 - val_loss: 104.3581 - val_acc: 0.6380\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 104.1095 - acc: 0.6431 - val_loss: 108.2930 - val_acc: 0.6367\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 105.0072 - acc: 0.6423 - val_loss: 109.6651 - val_acc: 0.6370\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 105.9624 - acc: 0.6406 - val_loss: 108.2039 - val_acc: 0.6360\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 104.1756 - acc: 0.6426 - val_loss: 103.7181 - val_acc: 0.6358\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 101.7440 - acc: 0.6420 - val_loss: 110.0892 - val_acc: 0.6315\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 102.9848 - acc: 0.6409 - val_loss: 110.5790 - val_acc: 0.6300\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 104.7815 - acc: 0.6387 - val_loss: 105.7867 - val_acc: 0.6340\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 103.0247 - acc: 0.6412 - val_loss: 105.7751 - val_acc: 0.6340\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 102.6719 - acc: 0.6424 - val_loss: 107.2329 - val_acc: 0.6358\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 106.0885 - acc: 0.6430 - val_loss: 108.3128 - val_acc: 0.6377\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 105.3347 - acc: 0.6425 - val_loss: 115.6385 - val_acc: 0.6361\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 105.8488 - acc: 0.6428 - val_loss: 105.8218 - val_acc: 0.6365\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 103.0927 - acc: 0.6420 - val_loss: 103.6906 - val_acc: 0.6354\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 102.7615 - acc: 0.6415 - val_loss: 108.0775 - val_acc: 0.6330\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 103.4008 - acc: 0.6424 - val_loss: 105.1261 - val_acc: 0.6366\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 103.0920 - acc: 0.6423 - val_loss: 106.1377 - val_acc: 0.6343\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 103.0354 - acc: 0.6392 - val_loss: 104.6728 - val_acc: 0.6358\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 101.6244 - acc: 0.6403 - val_loss: 103.4551 - val_acc: 0.6333\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 102.0703 - acc: 0.6406 - val_loss: 101.5552 - val_acc: 0.6369\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 102.2913 - acc: 0.6402 - val_loss: 105.5509 - val_acc: 0.6337\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 101.5727 - acc: 0.6421 - val_loss: 101.8172 - val_acc: 0.6380\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 102.0403 - acc: 0.6432 - val_loss: 102.9697 - val_acc: 0.6366\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 105.0736 - acc: 0.6418 - val_loss: 103.9556 - val_acc: 0.6378\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 106.1178 - acc: 0.6421 - val_loss: 106.0098 - val_acc: 0.6363\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 105.6290 - acc: 0.6422 - val_loss: 103.5393 - val_acc: 0.6371\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 103.2110 - acc: 0.6425 - val_loss: 102.7310 - val_acc: 0.6379\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 102.2033 - acc: 0.6404 - val_loss: 105.4641 - val_acc: 0.6325\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 103.7861 - acc: 0.6399 - val_loss: 103.5364 - val_acc: 0.6357\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 104.2690 - acc: 0.6422 - val_loss: 104.6957 - val_acc: 0.6374\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 105.2914 - acc: 0.6427 - val_loss: 105.6317 - val_acc: 0.6378\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 103.8746 - acc: 0.6426 - val_loss: 105.9132 - val_acc: 0.6374\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 105.1425 - acc: 0.6425 - val_loss: 105.5740 - val_acc: 0.6339\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 103.4125 - acc: 0.6410 - val_loss: 104.0799 - val_acc: 0.6375\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 42.3803 - acc: 0.4505 - val_loss: 39.7232 - val_acc: 0.4539\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 42.3454 - acc: 0.4503 - val_loss: 39.8497 - val_acc: 0.4558\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 42.4607 - acc: 0.4514 - val_loss: 39.7432 - val_acc: 0.4546\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 42.2898 - acc: 0.4506 - val_loss: 39.6935 - val_acc: 0.4551\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 42.2772 - acc: 0.4511 - val_loss: 39.6677 - val_acc: 0.4556\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 42.3242 - acc: 0.4509 - val_loss: 39.7971 - val_acc: 0.4564\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 42.3619 - acc: 0.4507 - val_loss: 39.7020 - val_acc: 0.4558\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 42.2862 - acc: 0.4515 - val_loss: 39.5887 - val_acc: 0.4549\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 42.2635 - acc: 0.4509 - val_loss: 39.5905 - val_acc: 0.4546\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 42.3588 - acc: 0.4508 - val_loss: 39.7091 - val_acc: 0.4539\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 42.2691 - acc: 0.4506 - val_loss: 39.5610 - val_acc: 0.4558\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 42.1903 - acc: 0.4512 - val_loss: 39.5692 - val_acc: 0.4550\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 42.1628 - acc: 0.4518 - val_loss: 39.5314 - val_acc: 0.4554\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 42.1808 - acc: 0.4515 - val_loss: 39.5302 - val_acc: 0.4557\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 42.1450 - acc: 0.4513 - val_loss: 39.5505 - val_acc: 0.4560\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 42.2273 - acc: 0.4514 - val_loss: 39.8073 - val_acc: 0.4564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 42.1875 - acc: 0.4513 - val_loss: 39.5206 - val_acc: 0.4553\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 42.2896 - acc: 0.4515 - val_loss: 39.4952 - val_acc: 0.4557\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 42.1091 - acc: 0.4518 - val_loss: 39.4479 - val_acc: 0.4561\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 42.1017 - acc: 0.4520 - val_loss: 39.6916 - val_acc: 0.4548\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 42.2098 - acc: 0.4516 - val_loss: 39.4759 - val_acc: 0.4552\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 42.1481 - acc: 0.4515 - val_loss: 39.4398 - val_acc: 0.4562\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 42.0754 - acc: 0.4519 - val_loss: 39.5338 - val_acc: 0.4567\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 42.0506 - acc: 0.4519 - val_loss: 39.4138 - val_acc: 0.4560\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 42.0450 - acc: 0.4518 - val_loss: 39.4389 - val_acc: 0.4564\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 42.0374 - acc: 0.4522 - val_loss: 39.4656 - val_acc: 0.4558\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 42.0720 - acc: 0.4518 - val_loss: 39.3942 - val_acc: 0.4563\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 42.0309 - acc: 0.4519 - val_loss: 39.4410 - val_acc: 0.4564\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 41.9653 - acc: 0.4522 - val_loss: 39.3683 - val_acc: 0.4561\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 465us/step - loss: 41.9660 - acc: 0.4524 - val_loss: 39.3456 - val_acc: 0.4570\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 41.9454 - acc: 0.4524 - val_loss: 39.4381 - val_acc: 0.4564\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 41.9432 - acc: 0.4519 - val_loss: 39.3056 - val_acc: 0.4563\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 41.9284 - acc: 0.4523 - val_loss: 39.3725 - val_acc: 0.4570\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 41.9499 - acc: 0.4524 - val_loss: 39.3502 - val_acc: 0.4556\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 41.8860 - acc: 0.4520 - val_loss: 39.2631 - val_acc: 0.4568\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 41.8986 - acc: 0.4527 - val_loss: 39.2597 - val_acc: 0.4559\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 41.9794 - acc: 0.4522 - val_loss: 39.3711 - val_acc: 0.4571\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 42.0313 - acc: 0.4522 - val_loss: 39.2679 - val_acc: 0.4575\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 41.8357 - acc: 0.4525 - val_loss: 39.2244 - val_acc: 0.4570\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 41.8238 - acc: 0.4524 - val_loss: 39.2458 - val_acc: 0.4573\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 41.8859 - acc: 0.4525 - val_loss: 39.1974 - val_acc: 0.4570\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 41.8271 - acc: 0.4529 - val_loss: 39.2182 - val_acc: 0.4559\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 41.8825 - acc: 0.4523 - val_loss: 39.1810 - val_acc: 0.4578\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 41.8564 - acc: 0.4527 - val_loss: 39.2714 - val_acc: 0.4563\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 41.8714 - acc: 0.4528 - val_loss: 39.1694 - val_acc: 0.4574\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 41.8083 - acc: 0.4529 - val_loss: 39.1443 - val_acc: 0.4571\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 41.7697 - acc: 0.4529 - val_loss: 39.1128 - val_acc: 0.4572\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 41.7261 - acc: 0.4527 - val_loss: 39.1500 - val_acc: 0.4580\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 41.8096 - acc: 0.4531 - val_loss: 39.1670 - val_acc: 0.4581\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 41.7306 - acc: 0.4532 - val_loss: 39.1071 - val_acc: 0.4568\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.4106 - acc: 0.4685 - val_loss: 0.3983 - val_acc: 0.4741\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.4119 - acc: 0.4685 - val_loss: 0.3947 - val_acc: 0.4745\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.4115 - acc: 0.4684 - val_loss: 0.4030 - val_acc: 0.4758\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 474us/step - loss: 0.4123 - acc: 0.4684 - val_loss: 0.3966 - val_acc: 0.4741\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.4108 - acc: 0.4682 - val_loss: 0.3948 - val_acc: 0.4747\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.4099 - acc: 0.4685 - val_loss: 0.3942 - val_acc: 0.4753\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 484us/step - loss: 0.4100 - acc: 0.4685 - val_loss: 0.3946 - val_acc: 0.4753\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.4099 - acc: 0.4684 - val_loss: 0.3962 - val_acc: 0.4758\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4128 - acc: 0.4684 - val_loss: 0.3954 - val_acc: 0.4752\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 476us/step - loss: 0.4099 - acc: 0.4684 - val_loss: 0.3939 - val_acc: 0.4748\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.4096 - acc: 0.4683 - val_loss: 0.3942 - val_acc: 0.4753\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.4102 - acc: 0.4685 - val_loss: 0.3937 - val_acc: 0.4745\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4094 - acc: 0.4684 - val_loss: 0.3976 - val_acc: 0.4738\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.4105 - acc: 0.4685 - val_loss: 0.3939 - val_acc: 0.4747\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.4116 - acc: 0.4685 - val_loss: 0.3938 - val_acc: 0.4755\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4095 - acc: 0.4686 - val_loss: 0.3944 - val_acc: 0.4758\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.4090 - acc: 0.4684 - val_loss: 0.3937 - val_acc: 0.4749\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 468us/step - loss: 0.4090 - acc: 0.4684 - val_loss: 0.3937 - val_acc: 0.4748\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.4105 - acc: 0.4683 - val_loss: 0.3933 - val_acc: 0.4753\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.4091 - acc: 0.4684 - val_loss: 0.3979 - val_acc: 0.4738\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.4130 - acc: 0.4682 - val_loss: 0.3933 - val_acc: 0.4748\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 469us/step - loss: 0.4082 - acc: 0.4685 - val_loss: 0.3930 - val_acc: 0.4750\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4080 - acc: 0.4685 - val_loss: 0.3929 - val_acc: 0.4750\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4084 - acc: 0.4685 - val_loss: 0.3936 - val_acc: 0.4751\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.4082 - acc: 0.4685 - val_loss: 0.3926 - val_acc: 0.4750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4078 - acc: 0.4684 - val_loss: 0.3930 - val_acc: 0.4749\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4077 - acc: 0.4686 - val_loss: 0.3926 - val_acc: 0.4749\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4076 - acc: 0.4686 - val_loss: 0.3927 - val_acc: 0.4747\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.4088 - acc: 0.4686 - val_loss: 0.3937 - val_acc: 0.4742\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.4082 - acc: 0.4684 - val_loss: 0.3928 - val_acc: 0.4745\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.4080 - acc: 0.4685 - val_loss: 0.3936 - val_acc: 0.4743\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.4123 - acc: 0.4682 - val_loss: 0.3972 - val_acc: 0.4739 1s - loss: 0.4014 \n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.4101 - acc: 0.4682 - val_loss: 0.3923 - val_acc: 0.4752\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 465us/step - loss: 0.4076 - acc: 0.4685 - val_loss: 0.3923 - val_acc: 0.4754\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4070 - acc: 0.4684 - val_loss: 0.3924 - val_acc: 0.4748\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4092 - acc: 0.4683 - val_loss: 0.3920 - val_acc: 0.4749\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.4070 - acc: 0.4685 - val_loss: 0.3924 - val_acc: 0.4748\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 465us/step - loss: 0.4073 - acc: 0.4685 - val_loss: 0.3924 - val_acc: 0.4752\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4068 - acc: 0.4685 - val_loss: 0.3931 - val_acc: 0.4747\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4073 - acc: 0.4684 - val_loss: 0.3931 - val_acc: 0.4756\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.4105 - acc: 0.4682 - val_loss: 0.3917 - val_acc: 0.4749\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.4070 - acc: 0.4684 - val_loss: 0.3915 - val_acc: 0.4753\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4071 - acc: 0.4686 - val_loss: 0.3927 - val_acc: 0.4753\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.4092 - acc: 0.4684 - val_loss: 0.3923 - val_acc: 0.4752\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.4069 - acc: 0.4686 - val_loss: 0.3915 - val_acc: 0.4750\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4069 - acc: 0.4685 - val_loss: 0.3920 - val_acc: 0.4751\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 466us/step - loss: 0.4062 - acc: 0.4686 - val_loss: 0.3918 - val_acc: 0.4753\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.4064 - acc: 0.4685 - val_loss: 0.3947 - val_acc: 0.4753\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4070 - acc: 0.4685 - val_loss: 0.3920 - val_acc: 0.4748\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4073 - acc: 0.4687 - val_loss: 0.3915 - val_acc: 0.4750\n",
      "start training round 29\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 27.2274 - acc: 0.7124 - val_loss: 28.6706 - val_acc: 0.7137\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 27.1827 - acc: 0.7123 - val_loss: 27.3650 - val_acc: 0.7124\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 27.6135 - acc: 0.7122 - val_loss: 27.8842 - val_acc: 0.7117\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 27.1361 - acc: 0.7083 - val_loss: 28.9212 - val_acc: 0.6619\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 27.7909 - acc: 0.7108 - val_loss: 28.4980 - val_acc: 0.7108\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 27.3131 - acc: 0.7120 - val_loss: 26.8757 - val_acc: 0.7110\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 27.1059 - acc: 0.7124 - val_loss: 27.7982 - val_acc: 0.7094\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 27.0827 - acc: 0.7104 - val_loss: 27.0525 - val_acc: 0.7105\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 27.0150 - acc: 0.7108 - val_loss: 27.1272 - val_acc: 0.7117\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 27.0737 - acc: 0.7056 - val_loss: 27.6289 - val_acc: 0.7102\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 27.0265 - acc: 0.6917 - val_loss: 28.6738 - val_acc: 0.6593\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 27.1280 - acc: 0.6934 - val_loss: 27.6215 - val_acc: 0.6652\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 27.0309 - acc: 0.6998 - val_loss: 29.9582 - val_acc: 0.7100\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 27.7317 - acc: 0.7123 - val_loss: 28.5060 - val_acc: 0.7093\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 26.9199 - acc: 0.7119 - val_loss: 26.9158 - val_acc: 0.6657\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 27.3038 - acc: 0.7018 - val_loss: 27.9456 - val_acc: 0.7098\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 27.6057 - acc: 0.7123 - val_loss: 27.3352 - val_acc: 0.7115\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 27.2162 - acc: 0.7091 - val_loss: 26.1712 - val_acc: 0.7117\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 469us/step - loss: 27.1570 - acc: 0.7122 - val_loss: 28.7255 - val_acc: 0.7104\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 27.0513 - acc: 0.7122 - val_loss: 28.3213 - val_acc: 0.7107\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 27.6845 - acc: 0.7103 - val_loss: 27.5001 - val_acc: 0.7097\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 26.7518 - acc: 0.7100 - val_loss: 26.9648 - val_acc: 0.7124\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 27.6367 - acc: 0.6992 - val_loss: 26.5642 - val_acc: 0.7127\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 27.0760 - acc: 0.7123 - val_loss: 27.1028 - val_acc: 0.7128\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 26.8841 - acc: 0.7102 - val_loss: 26.7899 - val_acc: 0.7127\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 26.5414 - acc: 0.6976 - val_loss: 26.1415 - val_acc: 0.7118\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 27.6411 - acc: 0.6978 - val_loss: 26.9284 - val_acc: 0.7127\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 27.2388 - acc: 0.7070 - val_loss: 27.2655 - val_acc: 0.7120\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 27.5134 - acc: 0.7122 - val_loss: 28.2217 - val_acc: 0.7132\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 27.2616 - acc: 0.7122 - val_loss: 27.3212 - val_acc: 0.7126\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 26.9593 - acc: 0.7123 - val_loss: 26.5799 - val_acc: 0.7125\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 27.4204 - acc: 0.7108 - val_loss: 27.5537 - val_acc: 0.7127\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 26.6026 - acc: 0.7121 - val_loss: 28.2774 - val_acc: 0.7135\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 416us/step - loss: 27.2119 - acc: 0.7111 - val_loss: 26.1887 - val_acc: 0.7121\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 27.3144 - acc: 0.7088 - val_loss: 26.1963 - val_acc: 0.7130\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 27.0767 - acc: 0.7123 - val_loss: 27.1614 - val_acc: 0.7120\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 26.9596 - acc: 0.7077 - val_loss: 26.3799 - val_acc: 0.6682\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 27.3857 - acc: 0.6922 - val_loss: 28.2627 - val_acc: 0.7098\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 27.6165 - acc: 0.7126 - val_loss: 26.1380 - val_acc: 0.7116\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 26.9255 - acc: 0.7069 - val_loss: 27.5036 - val_acc: 0.7103\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 27.0243 - acc: 0.7092 - val_loss: 27.0838 - val_acc: 0.7119\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 27.0473 - acc: 0.7124 - val_loss: 27.4626 - val_acc: 0.7100\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 27.1384 - acc: 0.7092 - val_loss: 28.1312 - val_acc: 0.7095\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 27.4058 - acc: 0.7124 - val_loss: 27.5652 - val_acc: 0.7111\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 26.9675 - acc: 0.7120 - val_loss: 26.6177 - val_acc: 0.7109\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 27.1233 - acc: 0.7103 - val_loss: 27.8060 - val_acc: 0.7097\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 27.4222 - acc: 0.7125 - val_loss: 26.3975 - val_acc: 0.7113\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 27.1006 - acc: 0.7066 - val_loss: 27.2730 - val_acc: 0.7095\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 26.2593 - acc: 0.7063 - val_loss: 25.7836 - val_acc: 0.6713\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 26.7016 - acc: 0.6782 - val_loss: 26.5527 - val_acc: 0.6652\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 102.8668 - acc: 0.6422 - val_loss: 105.2048 - val_acc: 0.6340\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 101.2167 - acc: 0.6404 - val_loss: 107.5758 - val_acc: 0.6272\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 102.0934 - acc: 0.6388 - val_loss: 103.3381 - val_acc: 0.6351\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 102.0182 - acc: 0.6406 - val_loss: 102.9314 - val_acc: 0.6365\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 102.0846 - acc: 0.6429 - val_loss: 104.7933 - val_acc: 0.6385\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 106.0372 - acc: 0.6427 - val_loss: 107.1169 - val_acc: 0.6323\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 106.2681 - acc: 0.6412 - val_loss: 104.6623 - val_acc: 0.6375\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 103.5221 - acc: 0.6417 - val_loss: 101.9530 - val_acc: 0.6365\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 102.1042 - acc: 0.6426 - val_loss: 103.0884 - val_acc: 0.6368\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 103.3431 - acc: 0.6421 - val_loss: 102.5076 - val_acc: 0.6377\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 101.8268 - acc: 0.6418 - val_loss: 104.1747 - val_acc: 0.6340\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 102.1422 - acc: 0.6392 - val_loss: 107.3023 - val_acc: 0.6311\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 103.7932 - acc: 0.6413 - val_loss: 102.7455 - val_acc: 0.6353\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 101.1237 - acc: 0.6426 - val_loss: 105.6712 - val_acc: 0.6355\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 105.5592 - acc: 0.6416 - val_loss: 105.3801 - val_acc: 0.6360\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 105.2082 - acc: 0.6421 - val_loss: 105.8550 - val_acc: 0.6365\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 104.3167 - acc: 0.6421 - val_loss: 104.6232 - val_acc: 0.6358\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 102.8964 - acc: 0.6416 - val_loss: 106.9920 - val_acc: 0.6331\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 103.5947 - acc: 0.6415 - val_loss: 103.1822 - val_acc: 0.6351\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 409us/step - loss: 101.7592 - acc: 0.6419 - val_loss: 100.9433 - val_acc: 0.6378\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 101.2349 - acc: 0.6424 - val_loss: 108.0801 - val_acc: 0.6317\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 102.7634 - acc: 0.6419 - val_loss: 111.3189 - val_acc: 0.6354\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 105.7449 - acc: 0.6420 - val_loss: 106.4400 - val_acc: 0.6328\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 103.6336 - acc: 0.6414 - val_loss: 110.0185 - val_acc: 0.6368\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 104.5038 - acc: 0.6427 - val_loss: 103.8077 - val_acc: 0.6368\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 103.5666 - acc: 0.6425 - val_loss: 106.3484 - val_acc: 0.6345\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 103.4726 - acc: 0.6414 - val_loss: 112.3840 - val_acc: 0.6297\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 105.2067 - acc: 0.6409 - val_loss: 103.6940 - val_acc: 0.6357\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 102.4592 - acc: 0.6423 - val_loss: 107.5936 - val_acc: 0.6325\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 104.5885 - acc: 0.6414 - val_loss: 107.2286 - val_acc: 0.6365\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 104.7405 - acc: 0.6425 - val_loss: 102.0930 - val_acc: 0.6375\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 103.0969 - acc: 0.6429 - val_loss: 107.1286 - val_acc: 0.6369\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 103.6778 - acc: 0.6420 - val_loss: 103.2136 - val_acc: 0.6376\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 102.0724 - acc: 0.6419 - val_loss: 102.5890 - val_acc: 0.6351\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 102.6160 - acc: 0.6393 - val_loss: 101.8089 - val_acc: 0.6369\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 101.4903 - acc: 0.6393 - val_loss: 101.8654 - val_acc: 0.6345\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 101.3622 - acc: 0.6414 - val_loss: 103.8323 - val_acc: 0.6356\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 104.8484 - acc: 0.6415 - val_loss: 108.9008 - val_acc: 0.6346\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 104.2425 - acc: 0.6428 - val_loss: 106.3251 - val_acc: 0.6367\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 103.8049 - acc: 0.6421 - val_loss: 108.0338 - val_acc: 0.6356\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 104.6073 - acc: 0.6417 - val_loss: 104.0051 - val_acc: 0.6380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 102.8876 - acc: 0.6431 - val_loss: 102.0653 - val_acc: 0.6360\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 102.8042 - acc: 0.6410 - val_loss: 103.5060 - val_acc: 0.6361\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 102.8987 - acc: 0.6421 - val_loss: 104.3012 - val_acc: 0.6355\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 102.8220 - acc: 0.6410 - val_loss: 102.3634 - val_acc: 0.6350\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 101.2153 - acc: 0.6399 - val_loss: 101.5784 - val_acc: 0.6361\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 101.8846 - acc: 0.6424 - val_loss: 101.9542 - val_acc: 0.6370\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 101.0650 - acc: 0.6422 - val_loss: 101.0516 - val_acc: 0.6374\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 102.3745 - acc: 0.6410 - val_loss: 102.3980 - val_acc: 0.6383\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 103.0985 - acc: 0.6421 - val_loss: 104.4608 - val_acc: 0.6365\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 41.6942 - acc: 0.4530 - val_loss: 39.1123 - val_acc: 0.4571\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 41.8064 - acc: 0.4532 - val_loss: 40.1522 - val_acc: 0.4578\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 42.2162 - acc: 0.4526 - val_loss: 39.0874 - val_acc: 0.4576\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 41.6879 - acc: 0.4534 - val_loss: 39.0333 - val_acc: 0.4566\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 41.8089 - acc: 0.4532 - val_loss: 39.2074 - val_acc: 0.4560\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 41.8346 - acc: 0.4526 - val_loss: 39.0432 - val_acc: 0.4572\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 41.6147 - acc: 0.4532 - val_loss: 39.0277 - val_acc: 0.4580\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 41.6191 - acc: 0.4534 - val_loss: 38.9892 - val_acc: 0.4576\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 41.6036 - acc: 0.4534 - val_loss: 39.0043 - val_acc: 0.4580\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 41.5896 - acc: 0.4536 - val_loss: 39.0426 - val_acc: 0.4577\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 41.5725 - acc: 0.4535 - val_loss: 38.9680 - val_acc: 0.4574\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 41.5835 - acc: 0.4534 - val_loss: 39.0507 - val_acc: 0.4577\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 41.7715 - acc: 0.4536 - val_loss: 39.0726 - val_acc: 0.4575\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 41.6129 - acc: 0.4535 - val_loss: 38.9571 - val_acc: 0.4573\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 41.5368 - acc: 0.4535 - val_loss: 38.9189 - val_acc: 0.4577\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 41.5510 - acc: 0.4538 - val_loss: 38.9357 - val_acc: 0.4575\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 41.5144 - acc: 0.4539 - val_loss: 38.9038 - val_acc: 0.4574\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 41.5621 - acc: 0.4539 - val_loss: 38.8945 - val_acc: 0.4580\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 41.6436 - acc: 0.4535 - val_loss: 39.0667 - val_acc: 0.4585\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 41.7456 - acc: 0.4537 - val_loss: 38.8950 - val_acc: 0.4574\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 41.4793 - acc: 0.4540 - val_loss: 38.8421 - val_acc: 0.4585\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 41.4902 - acc: 0.4540 - val_loss: 38.9020 - val_acc: 0.4577\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 41.4383 - acc: 0.4539 - val_loss: 38.8583 - val_acc: 0.4584\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 41.4599 - acc: 0.4541 - val_loss: 38.8657 - val_acc: 0.4586\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 41.4172 - acc: 0.4540 - val_loss: 38.8583 - val_acc: 0.4584\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 41.3894 - acc: 0.4544 - val_loss: 38.8347 - val_acc: 0.4580\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 41.4075 - acc: 0.4542 - val_loss: 38.9123 - val_acc: 0.4569\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 41.4385 - acc: 0.4540 - val_loss: 38.7703 - val_acc: 0.4585\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 41.4191 - acc: 0.4545 - val_loss: 39.6039 - val_acc: 0.4584\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 42.0752 - acc: 0.4540 - val_loss: 39.1589 - val_acc: 0.4593\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 41.5897 - acc: 0.4541 - val_loss: 38.9525 - val_acc: 0.4591\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 41.3890 - acc: 0.4543 - val_loss: 38.7423 - val_acc: 0.4595\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 41.3217 - acc: 0.4547 - val_loss: 38.8355 - val_acc: 0.4577\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 41.6616 - acc: 0.4545 - val_loss: 38.8708 - val_acc: 0.4576\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 41.3343 - acc: 0.4547 - val_loss: 38.7122 - val_acc: 0.4588\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 41.2668 - acc: 0.4544 - val_loss: 38.7106 - val_acc: 0.4590\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 41.2765 - acc: 0.4548 - val_loss: 38.6633 - val_acc: 0.4581\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 41.2736 - acc: 0.4549 - val_loss: 38.6631 - val_acc: 0.4592\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 41.2452 - acc: 0.4553 - val_loss: 38.7432 - val_acc: 0.4581\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 41.3999 - acc: 0.4548 - val_loss: 38.7874 - val_acc: 0.4571\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 41.2503 - acc: 0.4549 - val_loss: 38.6307 - val_acc: 0.4589\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 41.2143 - acc: 0.4550 - val_loss: 38.6064 - val_acc: 0.4596\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 41.2643 - acc: 0.4550 - val_loss: 38.6311 - val_acc: 0.4604\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 41.4013 - acc: 0.4554 - val_loss: 38.9418 - val_acc: 0.4597\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 41.3067 - acc: 0.4555 - val_loss: 38.6442 - val_acc: 0.4594\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 41.2767 - acc: 0.4551 - val_loss: 39.1899 - val_acc: 0.4601\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 41.2658 - acc: 0.4550 - val_loss: 38.5522 - val_acc: 0.4597\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 41.1729 - acc: 0.4552 - val_loss: 38.6994 - val_acc: 0.4604\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 41.6051 - acc: 0.4551 - val_loss: 38.7135 - val_acc: 0.4606\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 444us/step - loss: 41.1936 - acc: 0.4553 - val_loss: 38.6832 - val_acc: 0.4585\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4068 - acc: 0.4685 - val_loss: 0.3919 - val_acc: 0.4746\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.4061 - acc: 0.4686 - val_loss: 0.3931 - val_acc: 0.4759\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4077 - acc: 0.4685 - val_loss: 0.3907 - val_acc: 0.4749\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 472us/step - loss: 0.4055 - acc: 0.4686 - val_loss: 0.3914 - val_acc: 0.4748\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4064 - acc: 0.4686 - val_loss: 0.3904 - val_acc: 0.4752\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.4060 - acc: 0.4687 - val_loss: 0.3904 - val_acc: 0.4748\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 461us/step - loss: 0.4052 - acc: 0.4686 - val_loss: 0.3903 - val_acc: 0.4751\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.4063 - acc: 0.4687 - val_loss: 0.3922 - val_acc: 0.4755\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.4067 - acc: 0.4688 - val_loss: 0.3961 - val_acc: 0.4764\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.4065 - acc: 0.4686 - val_loss: 0.3903 - val_acc: 0.4752\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.4075 - acc: 0.4687 - val_loss: 0.3942 - val_acc: 0.4746\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.4062 - acc: 0.4686 - val_loss: 0.3903 - val_acc: 0.4749\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4051 - acc: 0.4688 - val_loss: 0.3902 - val_acc: 0.4749\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.4046 - acc: 0.4687 - val_loss: 0.3899 - val_acc: 0.4755\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.4049 - acc: 0.4687 - val_loss: 0.3898 - val_acc: 0.4748\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.4045 - acc: 0.4688 - val_loss: 0.3896 - val_acc: 0.4751\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.4053 - acc: 0.4688 - val_loss: 0.3903 - val_acc: 0.4754\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4045 - acc: 0.4687 - val_loss: 0.3898 - val_acc: 0.4750\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.4045 - acc: 0.4688 - val_loss: 0.3895 - val_acc: 0.4757\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4044 - acc: 0.4686 - val_loss: 0.3899 - val_acc: 0.4753\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.4059 - acc: 0.4688 - val_loss: 0.3928 - val_acc: 0.4742\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.4055 - acc: 0.4688 - val_loss: 0.3893 - val_acc: 0.4751\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.4059 - acc: 0.4686 - val_loss: 0.3893 - val_acc: 0.4754\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.4040 - acc: 0.4689 - val_loss: 0.3893 - val_acc: 0.4753\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.4052 - acc: 0.4686 - val_loss: 0.3904 - val_acc: 0.4749\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4039 - acc: 0.4691 - val_loss: 0.3888 - val_acc: 0.4755\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.4046 - acc: 0.4688 - val_loss: 0.3960 - val_acc: 0.4741\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 461us/step - loss: 0.4107 - acc: 0.4683 - val_loss: 0.3906 - val_acc: 0.4748\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.4049 - acc: 0.4688 - val_loss: 0.3887 - val_acc: 0.4750\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.4034 - acc: 0.4688 - val_loss: 0.3887 - val_acc: 0.4751\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.4067 - acc: 0.4687 - val_loss: 0.3886 - val_acc: 0.4752\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.4035 - acc: 0.4689 - val_loss: 0.3886 - val_acc: 0.4758\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.4063 - acc: 0.4687 - val_loss: 0.3889 - val_acc: 0.4758\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4036 - acc: 0.4688 - val_loss: 0.3889 - val_acc: 0.4748\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.4046 - acc: 0.4687 - val_loss: 0.3890 - val_acc: 0.4754\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.4066 - acc: 0.4687 - val_loss: 0.3889 - val_acc: 0.4758\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4034 - acc: 0.4688 - val_loss: 0.3880 - val_acc: 0.4757\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.4027 - acc: 0.4688 - val_loss: 0.3887 - val_acc: 0.4755\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.4050 - acc: 0.4687 - val_loss: 0.3926 - val_acc: 0.4749\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.4045 - acc: 0.4689 - val_loss: 0.3881 - val_acc: 0.4760\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.4037 - acc: 0.4689 - val_loss: 0.3945 - val_acc: 0.4746\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.4038 - acc: 0.4689 - val_loss: 0.3947 - val_acc: 0.4762\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.4052 - acc: 0.4687 - val_loss: 0.3880 - val_acc: 0.4758\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4045 - acc: 0.4687 - val_loss: 0.3908 - val_acc: 0.4763\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.4023 - acc: 0.4688 - val_loss: 0.3881 - val_acc: 0.4752\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.4021 - acc: 0.4689 - val_loss: 0.3878 - val_acc: 0.4752\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.4032 - acc: 0.4688 - val_loss: 0.3958 - val_acc: 0.4739\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.4078 - acc: 0.4687 - val_loss: 0.3879 - val_acc: 0.4758\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.4024 - acc: 0.4690 - val_loss: 0.3872 - val_acc: 0.4756\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.4036 - acc: 0.4689 - val_loss: 0.3936 - val_acc: 0.4739\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print('start training round '+str(i))\n",
    "    print('training gyro model')\n",
    "    gyroModel.fit(gyro_train,gyro_train,batch_size=256,epochs=50,validation_split=0.1)\n",
    "    print('training linearAcc model')\n",
    "    linearAccModel.fit(linearAcc_train,linearAcc_train,batch_size=256,epochs=50,validation_split=0.1)\n",
    "    print('training gravity model')\n",
    "    gravityModel.fit(gravity_train,gravity_train,batch_size=256,epochs=50,validation_split=0.1)\n",
    "    print('training gameVec model')\n",
    "    gameVecModel.fit(gameVec_train,gameVec_train,batch_size=256,epochs=50,validation_split=0.1)\n",
    "    gyroModel.save('gyroModelFFT.h5')\n",
    "    linearAccModel.save('linearAccModelFFT.h5')\n",
    "    gravityModel.save('gravityModelFFT.h5')\n",
    "    gameVecModel.save('gameVecModelFFT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = 32\n",
    "gyroy = gyroModel.predict(gyro_train[sample].reshape(1,128,3))\n",
    "fig=plt.figure(figsize=(20,7))\n",
    "for channel in range(3):\n",
    "    plt.subplot(1,3,channel+1)\n",
    "    plot(gyro_train[sample,:,channel],'b')\n",
    "    plot(gyroy[0,:,channel],'r')\n",
    "linearAccy = linearAccModel.predict(linearAcc_train[sample].reshape(1,128,3))\n",
    "fig=plt.figure(figsize=(20,7))\n",
    "for channel in range(3):\n",
    "    plt.subplot(1,3,channel+1)\n",
    "    plot(linearAcc_train[sample,:,channel],'b')\n",
    "    plot(linearAccy[0,:,channel],'r')\n",
    "gravityy = gravityModel.predict(gravity_train[sample].reshape(1,128,3))\n",
    "fig=plt.figure(figsize=(20,7))\n",
    "for channel in range(3):\n",
    "    plt.subplot(1,3,channel+1)\n",
    "    plot(gravity_train[sample,:,channel],'b')\n",
    "    plot(gravityy[0,:,channel],'r')\n",
    "gameVecy = gameVecModel.predict(gameVec_train[sample].reshape(1,128,4))\n",
    "fig=plt.figure(figsize=(20,7))\n",
    "for channel in range(4):\n",
    "    plt.subplot(1,4,channel+1)\n",
    "    plot(gameVec_train[sample,:,channel],'b')\n",
    "    plot(gameVecy[0,:,channel],'r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
