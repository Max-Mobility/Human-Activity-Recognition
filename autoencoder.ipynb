{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Conv1D,Activation,MaxPooling1D,Dense,Flatten,UpSampling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model,load_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_model(myinputs,channel=3):\n",
    "    x     = Conv1D(filters =16, kernel_size=5,strides = 1, padding = 'same')(myinputs)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = MaxPooling1D(pool_size=3,strides = 2,padding='same')(x)\n",
    "    #  x shape is 64X48 =3072\n",
    "    x     = Conv1D(filters =24, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = MaxPooling1D(pool_size=2,strides = 2,padding='same')(x)\n",
    "    #  x shape is 32X64 = 2048\n",
    "    x     = Conv1D(filters =32, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = MaxPooling1D(pool_size=2,strides = 2,padding='same')(x)\n",
    "    # x shape is 16*96 = 1536\n",
    "    x     = Conv1D(filters =32, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = MaxPooling1D(pool_size=2,strides = 2,padding='same')(x)\n",
    "    # x shape is 8*128 = 1024\n",
    "    x     = Conv1D(filters =48, kernel_size=3,strides = 2, padding = 'same')(x)\n",
    "    # x shape is 4*128 = 512\n",
    "\n",
    "    latent_vector = Flatten()(x)\n",
    "    # decoder x = 4*128\n",
    "    x     = Conv1D(filters =32, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = UpSampling1D(2)(x)\n",
    "    # x shape is 8*128\n",
    "    x     = Conv1D(filters =32, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = UpSampling1D(2)(x)\n",
    "    # x shape is 16*96\n",
    "    x     = Conv1D(filters =24, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = UpSampling1D(2)(x)\n",
    "    # x shape is 32*64\n",
    "    x     = Conv1D(filters =16, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = UpSampling1D(2)(x)\n",
    "    # x shape is 64*48\n",
    "    x     = Conv1D(filters =16, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    #x     = BatchNormalization()(x) \n",
    "    x     = Activation('relu')(x)\n",
    "    x     = UpSampling1D(2)(x)\n",
    "    # x shape is 128*48\n",
    "    y     = Conv1D(filters =channel, kernel_size=3,strides = 1, padding = 'same')(x)\n",
    "    return latent_vector,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(name=\"push_detect\",channel=3):\n",
    "    # input shape 128X26 =3382\n",
    "    with tf.name_scope(name):\n",
    "        myInputs = Input(shape=(128,channel))\n",
    "                \n",
    "        LV,Y = get_sub_model(myInputs,channel=channel)\n",
    "        \n",
    "        autoencoder = Model (inputs=myInputs,\n",
    "                             outputs =Y)\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyroModel=build_model()\n",
    "linearAccModel=build_model()\n",
    "gravityModel=build_model()\n",
    "gameVecModel=build_model(channel=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyroModel=load_model('gyroModel.h5')\n",
    "linearAccModel=load_model('linearAccModel.h5')\n",
    "gravityModel=load_model('gravityModel.h5')\n",
    "gameVecModel=load_model('gameVecModel.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "gyroModel.compile(optimizer=opt,loss='mse',metrics=['accuracy'])\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "linearAccModel.compile(optimizer=opt,loss='mse',metrics=['accuracy'])\n",
    "opt = keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "gravityModel.compile(optimizer=opt,loss='mse',metrics=['accuracy'])\n",
    "opt = keras.optimizers.SGD(lr=0.1, momentum=0.0, decay=0.0, nesterov=False)\n",
    "gameVecModel.compile(optimizer=opt,loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= np.load('watch.npy')\n",
    "np.random.shuffle(data)\n",
    "p=0.85\n",
    "train_num =int(data.shape[0]*p)\n",
    "gyro_train=data[:train_num,:,0:3]\n",
    "linearAcc_train=data[:train_num,:,3:6]\n",
    "gravity_train=data[:train_num,:,6:9]\n",
    "gameVec_train=data[:train_num,:,9:13]\n",
    "\n",
    "gyro_test =data[train_num:,:,0:3]\n",
    "linearAcc_test =data[train_num:,:,3:6]\n",
    "gravity_test =data[train_num:,:,6:9]\n",
    "gameVec_test =data[train_num:,:,9:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training round 0\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2550 - acc: 0.6736 - val_loss: 0.2693 - val_acc: 0.6712\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2529 - acc: 0.6751 - val_loss: 0.2632 - val_acc: 0.6737\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2538 - acc: 0.6745 - val_loss: 0.2621 - val_acc: 0.6731\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2568 - acc: 0.6747 - val_loss: 0.2658 - val_acc: 0.6728\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2542 - acc: 0.6749 - val_loss: 0.2647 - val_acc: 0.6723\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2539 - acc: 0.6744 - val_loss: 0.2636 - val_acc: 0.6750\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2514 - acc: 0.6755 - val_loss: 0.2658 - val_acc: 0.6712\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2540 - acc: 0.6744 - val_loss: 0.2665 - val_acc: 0.6716\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2555 - acc: 0.6755 - val_loss: 0.2702 - val_acc: 0.6746\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2544 - acc: 0.6748 - val_loss: 0.2653 - val_acc: 0.6730\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2545 - acc: 0.6740 - val_loss: 0.2632 - val_acc: 0.6739\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2534 - acc: 0.6754 - val_loss: 0.2731 - val_acc: 0.6723\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2543 - acc: 0.6749 - val_loss: 0.2731 - val_acc: 0.6708\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2513 - acc: 0.6756 - val_loss: 0.2652 - val_acc: 0.6735\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2551 - acc: 0.6749 - val_loss: 0.2660 - val_acc: 0.6709\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2541 - acc: 0.6749 - val_loss: 0.2623 - val_acc: 0.6751\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2522 - acc: 0.6753 - val_loss: 0.2686 - val_acc: 0.6719\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2538 - acc: 0.6751 - val_loss: 0.2671 - val_acc: 0.6740\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2542 - acc: 0.6752 - val_loss: 0.2647 - val_acc: 0.6746\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2516 - acc: 0.6759 - val_loss: 0.2712 - val_acc: 0.6707\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2539 - acc: 0.6748 - val_loss: 0.2676 - val_acc: 0.6731\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2536 - acc: 0.6752 - val_loss: 0.2662 - val_acc: 0.6741\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2523 - acc: 0.6755 - val_loss: 0.2634 - val_acc: 0.6729\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2513 - acc: 0.6754 - val_loss: 0.2646 - val_acc: 0.6751\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2521 - acc: 0.6761 - val_loss: 0.2687 - val_acc: 0.6732\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2551 - acc: 0.6752 - val_loss: 0.2630 - val_acc: 0.6742\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2508 - acc: 0.6762 - val_loss: 0.2746 - val_acc: 0.6650\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.2569 - acc: 0.6734 - val_loss: 0.2644 - val_acc: 0.6730\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2533 - acc: 0.6748 - val_loss: 0.2693 - val_acc: 0.6706\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2540 - acc: 0.6747 - val_loss: 0.2662 - val_acc: 0.6724\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2544 - acc: 0.6762 - val_loss: 0.2683 - val_acc: 0.6729\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2521 - acc: 0.6750 - val_loss: 0.2719 - val_acc: 0.6724\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2514 - acc: 0.6763 - val_loss: 0.2698 - val_acc: 0.6706\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2568 - acc: 0.6731 - val_loss: 0.2635 - val_acc: 0.6734\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2530 - acc: 0.6763 - val_loss: 0.2634 - val_acc: 0.6740\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2534 - acc: 0.6763 - val_loss: 0.2657 - val_acc: 0.6740\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2497 - acc: 0.6768 - val_loss: 0.2631 - val_acc: 0.6749\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2496 - acc: 0.6767 - val_loss: 0.2646 - val_acc: 0.6748\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2585 - acc: 0.6736 - val_loss: 0.2703 - val_acc: 0.6710\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2516 - acc: 0.6756 - val_loss: 0.2638 - val_acc: 0.6748\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2510 - acc: 0.6758 - val_loss: 0.2616 - val_acc: 0.6753\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2543 - acc: 0.6743 - val_loss: 0.2738 - val_acc: 0.6691\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.2550 - acc: 0.6749 - val_loss: 0.2617 - val_acc: 0.6755\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2508 - acc: 0.6765 - val_loss: 0.2648 - val_acc: 0.6742\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2523 - acc: 0.6761 - val_loss: 0.2647 - val_acc: 0.6749\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2530 - acc: 0.6763 - val_loss: 0.2637 - val_acc: 0.6725\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2534 - acc: 0.6757 - val_loss: 0.2660 - val_acc: 0.6729\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2512 - acc: 0.6762 - val_loss: 0.2614 - val_acc: 0.6751\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2517 - acc: 0.6756 - val_loss: 0.2634 - val_acc: 0.6729\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2530 - acc: 0.6753 - val_loss: 0.2663 - val_acc: 0.6726\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0556 - acc: 0.6755 - val_loss: 2.1338 - val_acc: 0.6741\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0438 - acc: 0.6746 - val_loss: 2.1558 - val_acc: 0.6756\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 2.0394 - acc: 0.6757 - val_loss: 2.1363 - val_acc: 0.6752\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0383 - acc: 0.6753 - val_loss: 2.1444 - val_acc: 0.6725\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0640 - acc: 0.6758 - val_loss: 2.1729 - val_acc: 0.6710\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0373 - acc: 0.6749 - val_loss: 2.1635 - val_acc: 0.6710\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0371 - acc: 0.6759 - val_loss: 2.1610 - val_acc: 0.6739\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0340 - acc: 0.6756 - val_loss: 2.1607 - val_acc: 0.6729\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0314 - acc: 0.6761 - val_loss: 2.2004 - val_acc: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0438 - acc: 0.6751 - val_loss: 2.1511 - val_acc: 0.6713\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0165 - acc: 0.6756 - val_loss: 2.2103 - val_acc: 0.6704\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 2.0629 - acc: 0.6754 - val_loss: 2.1315 - val_acc: 0.6739\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 2.0407 - acc: 0.6758 - val_loss: 2.1538 - val_acc: 0.6722\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 2.0351 - acc: 0.6760 - val_loss: 2.1733 - val_acc: 0.6735\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0583 - acc: 0.6763 - val_loss: 2.1610 - val_acc: 0.6754\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 2.0521 - acc: 0.6748 - val_loss: 2.2116 - val_acc: 0.6740\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0282 - acc: 0.6749 - val_loss: 2.1598 - val_acc: 0.6737\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0259 - acc: 0.6762 - val_loss: 2.1918 - val_acc: 0.6755\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 2.0479 - acc: 0.6764 - val_loss: 2.1368 - val_acc: 0.6752\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0223 - acc: 0.6763 - val_loss: 2.1849 - val_acc: 0.6730\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 2.0633 - acc: 0.6754 - val_loss: 2.6604 - val_acc: 0.6688\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 2.0373 - acc: 0.6758 - val_loss: 2.2308 - val_acc: 0.6735\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 2.0541 - acc: 0.6755 - val_loss: 2.1563 - val_acc: 0.6718\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 2.0446 - acc: 0.6758 - val_loss: 2.1471 - val_acc: 0.6714\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0322 - acc: 0.6748 - val_loss: 2.2241 - val_acc: 0.6684\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 2.0393 - acc: 0.6745 - val_loss: 2.1259 - val_acc: 0.6732\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0325 - acc: 0.6757 - val_loss: 2.2963 - val_acc: 0.6723\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 2.0523 - acc: 0.6742 - val_loss: 2.1085 - val_acc: 0.6745\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 2.0284 - acc: 0.6760 - val_loss: 2.2698 - val_acc: 0.6730\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0659 - acc: 0.6757 - val_loss: 2.1339 - val_acc: 0.6732\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0178 - acc: 0.6753 - val_loss: 2.1637 - val_acc: 0.6753\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0614 - acc: 0.6751 - val_loss: 2.1525 - val_acc: 0.6755\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0179 - acc: 0.6751 - val_loss: 2.1757 - val_acc: 0.6737\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0260 - acc: 0.6753 - val_loss: 2.2201 - val_acc: 0.6691\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0394 - acc: 0.6758 - val_loss: 2.1881 - val_acc: 0.6699\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0448 - acc: 0.6754 - val_loss: 2.1456 - val_acc: 0.6716\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0762 - acc: 0.6753 - val_loss: 2.1161 - val_acc: 0.6737\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 2.0138 - acc: 0.6764 - val_loss: 2.1367 - val_acc: 0.6726\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0104 - acc: 0.6763 - val_loss: 2.1295 - val_acc: 0.6729\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0314 - acc: 0.6754 - val_loss: 2.1882 - val_acc: 0.6735\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0490 - acc: 0.6755 - val_loss: 2.1774 - val_acc: 0.6746\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0164 - acc: 0.6759 - val_loss: 2.1387 - val_acc: 0.6744\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0556 - acc: 0.6749 - val_loss: 2.1457 - val_acc: 0.6750\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0135 - acc: 0.6761 - val_loss: 2.1914 - val_acc: 0.6734\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0506 - acc: 0.6756 - val_loss: 2.1998 - val_acc: 0.6738\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0374 - acc: 0.6760 - val_loss: 2.1907 - val_acc: 0.6692\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 2.0257 - acc: 0.6760 - val_loss: 2.1639 - val_acc: 0.6720\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0303 - acc: 0.6759 - val_loss: 2.2150 - val_acc: 0.6696\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0454 - acc: 0.6755 - val_loss: 2.1120 - val_acc: 0.6734\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0244 - acc: 0.6760 - val_loss: 2.1740 - val_acc: 0.6743\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2259 - acc: 0.9917 - val_loss: 0.2331 - val_acc: 0.9896\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2213 - acc: 0.9918 - val_loss: 0.2184 - val_acc: 0.9893\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2290 - acc: 0.9918 - val_loss: 0.2388 - val_acc: 0.9887\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2336 - acc: 0.9909 - val_loss: 0.2284 - val_acc: 0.9888\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2332 - acc: 0.9903 - val_loss: 0.2290 - val_acc: 0.9888\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2280 - acc: 0.9913 - val_loss: 0.2276 - val_acc: 0.9887\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2232 - acc: 0.9913 - val_loss: 0.2165 - val_acc: 0.9894\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2243 - acc: 0.9918 - val_loss: 0.2360 - val_acc: 0.9896\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2315 - acc: 0.9918 - val_loss: 0.2175 - val_acc: 0.9896\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2111 - acc: 0.9917 - val_loss: 0.2128 - val_acc: 0.9896\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2192 - acc: 0.9915 - val_loss: 0.2202 - val_acc: 0.9893\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2228 - acc: 0.9915 - val_loss: 0.2254 - val_acc: 0.9896\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2219 - acc: 0.9918 - val_loss: 0.2207 - val_acc: 0.9895\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2155 - acc: 0.9918 - val_loss: 0.2240 - val_acc: 0.9895\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2401 - acc: 0.9914 - val_loss: 0.2443 - val_acc: 0.9884\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2302 - acc: 0.9910 - val_loss: 0.2217 - val_acc: 0.9888\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2163 - acc: 0.9916 - val_loss: 0.2188 - val_acc: 0.9894\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2216 - acc: 0.9916 - val_loss: 0.2293 - val_acc: 0.9892\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2530 - acc: 0.9914 - val_loss: 0.2624 - val_acc: 0.9894\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2362 - acc: 0.9918 - val_loss: 0.2341 - val_acc: 0.9894\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2302 - acc: 0.9916 - val_loss: 0.2292 - val_acc: 0.9888\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2276 - acc: 0.9908 - val_loss: 0.2333 - val_acc: 0.9879\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2284 - acc: 0.9904 - val_loss: 0.2328 - val_acc: 0.9870\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2259 - acc: 0.9905 - val_loss: 0.2298 - val_acc: 0.9879\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2295 - acc: 0.9908 - val_loss: 0.2236 - val_acc: 0.9896\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2298 - acc: 0.9919 - val_loss: 0.2423 - val_acc: 0.9895\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2275 - acc: 0.9919 - val_loss: 0.2139 - val_acc: 0.9895\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2144 - acc: 0.9917 - val_loss: 0.2206 - val_acc: 0.9894\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2365 - acc: 0.9916 - val_loss: 0.2304 - val_acc: 0.9892\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2267 - acc: 0.9918 - val_loss: 0.2475 - val_acc: 0.9895\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.2431 - acc: 0.9912 - val_loss: 0.2232 - val_acc: 0.9889\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2194 - acc: 0.9915 - val_loss: 0.2138 - val_acc: 0.9894\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2107 - acc: 0.9917 - val_loss: 0.2155 - val_acc: 0.9893\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2201 - acc: 0.9913 - val_loss: 0.2304 - val_acc: 0.9889\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2305 - acc: 0.9916 - val_loss: 0.2320 - val_acc: 0.9895\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2259 - acc: 0.9919 - val_loss: 0.2284 - val_acc: 0.9894\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2235 - acc: 0.9916 - val_loss: 0.2214 - val_acc: 0.9893\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2136 - acc: 0.9918 - val_loss: 0.2193 - val_acc: 0.9893\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2226 - acc: 0.9913 - val_loss: 0.2230 - val_acc: 0.9890\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2290 - acc: 0.9911 - val_loss: 0.2433 - val_acc: 0.9889\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2265 - acc: 0.9916 - val_loss: 0.2195 - val_acc: 0.9895\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2231 - acc: 0.9918 - val_loss: 0.2359 - val_acc: 0.9893\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2318 - acc: 0.9914 - val_loss: 0.2334 - val_acc: 0.9896\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2211 - acc: 0.9918 - val_loss: 0.2100 - val_acc: 0.9896\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 0.2098 - acc: 0.9919 - val_loss: 0.2186 - val_acc: 0.9895\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2216 - acc: 0.9918 - val_loss: 0.2260 - val_acc: 0.9894\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2211 - acc: 0.9919 - val_loss: 0.2279 - val_acc: 0.9896\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2252 - acc: 0.9917 - val_loss: 0.2223 - val_acc: 0.9895\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2229 - acc: 0.9918 - val_loss: 0.2312 - val_acc: 0.9893\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2385 - acc: 0.9912 - val_loss: 0.2350 - val_acc: 0.9883\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9547 - val_loss: 0.0036 - val_acc: 0.9578\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0035 - acc: 0.9535 - val_loss: 0.0035 - val_acc: 0.9606\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0035 - acc: 0.9562 - val_loss: 0.0036 - val_acc: 0.9592\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0035 - acc: 0.9566 - val_loss: 0.0035 - val_acc: 0.9609\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0035 - acc: 0.9562 - val_loss: 0.0035 - val_acc: 0.9613\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0034 - acc: 0.9580 - val_loss: 0.0035 - val_acc: 0.9608\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.0034 - acc: 0.9575 - val_loss: 0.0035 - val_acc: 0.9604\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0034 - acc: 0.9548 - val_loss: 0.0037 - val_acc: 0.9577\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0037 - acc: 0.9496 - val_loss: 0.0035 - val_acc: 0.9611\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0034 - acc: 0.9576 - val_loss: 0.0034 - val_acc: 0.9611\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.0034 - acc: 0.9578 - val_loss: 0.0037 - val_acc: 0.9558\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0038 - acc: 0.9497 - val_loss: 0.0036 - val_acc: 0.9589\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0035 - acc: 0.9559 - val_loss: 0.0035 - val_acc: 0.9582\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0036 - acc: 0.9525 - val_loss: 0.0035 - val_acc: 0.9603\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.0034 - acc: 0.9575 - val_loss: 0.0035 - val_acc: 0.9589\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.0034 - acc: 0.9577 - val_loss: 0.0035 - val_acc: 0.9611\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0034 - acc: 0.9570 - val_loss: 0.0035 - val_acc: 0.9593\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0034 - acc: 0.9566 - val_loss: 0.0035 - val_acc: 0.9595\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0035 - acc: 0.9547 - val_loss: 0.0036 - val_acc: 0.9572\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0034 - acc: 0.9547 - val_loss: 0.0036 - val_acc: 0.9569\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0035 - acc: 0.9536 - val_loss: 0.0035 - val_acc: 0.9598\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0034 - acc: 0.9561 - val_loss: 0.0035 - val_acc: 0.9619\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0034 - acc: 0.9577 - val_loss: 0.0035 - val_acc: 0.9606\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0034 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9610\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.0035 - acc: 0.9535 - val_loss: 0.0035 - val_acc: 0.9604\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0035 - acc: 0.9540 - val_loss: 0.0037 - val_acc: 0.9547\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0035 - acc: 0.9536 - val_loss: 0.0036 - val_acc: 0.9581\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0036 - acc: 0.9525 - val_loss: 0.0035 - val_acc: 0.9602\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0034 - val_acc: 0.9609\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0034 - acc: 0.9553 - val_loss: 0.0035 - val_acc: 0.9604\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0034 - acc: 0.9564 - val_loss: 0.0036 - val_acc: 0.9590\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0035 - acc: 0.9527 - val_loss: 0.0035 - val_acc: 0.9608\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0034 - acc: 0.9564 - val_loss: 0.0037 - val_acc: 0.9573\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0035 - acc: 0.9546 - val_loss: 0.0035 - val_acc: 0.9617\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0034 - acc: 0.9567 - val_loss: 0.0036 - val_acc: 0.9606\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0035 - acc: 0.9578 - val_loss: 0.0036 - val_acc: 0.9610\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0036 - acc: 0.9537 - val_loss: 0.0036 - val_acc: 0.9618\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9573 - val_loss: 0.0035 - val_acc: 0.9610\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9562 - val_loss: 0.0035 - val_acc: 0.9614\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9567 - val_loss: 0.0035 - val_acc: 0.9603\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.0034 - acc: 0.9570 - val_loss: 0.0035 - val_acc: 0.9616\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9568 - val_loss: 0.0035 - val_acc: 0.9618\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0034 - acc: 0.9574 - val_loss: 0.0034 - val_acc: 0.9613\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0034 - acc: 0.9574 - val_loss: 0.0036 - val_acc: 0.9593\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0036 - acc: 0.9535 - val_loss: 0.0037 - val_acc: 0.9572\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0036 - acc: 0.9518 - val_loss: 0.0034 - val_acc: 0.9614\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0034 - acc: 0.9560 - val_loss: 0.0039 - val_acc: 0.9526\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0035 - acc: 0.9528 - val_loss: 0.0034 - val_acc: 0.9606\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0034 - acc: 0.9574 - val_loss: 0.0036 - val_acc: 0.9574\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0036 - acc: 0.9528 - val_loss: 0.0036 - val_acc: 0.9568\n",
      "start training round 1\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2537 - acc: 0.6749 - val_loss: 0.2647 - val_acc: 0.6717\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2513 - acc: 0.6755 - val_loss: 0.2628 - val_acc: 0.6747\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2506 - acc: 0.6762 - val_loss: 0.2630 - val_acc: 0.6734\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.2501 - acc: 0.6768 - val_loss: 0.2713 - val_acc: 0.6723\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2533 - acc: 0.6750 - val_loss: 0.2694 - val_acc: 0.6737\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2540 - acc: 0.6759 - val_loss: 0.2701 - val_acc: 0.6708\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2510 - acc: 0.6768 - val_loss: 0.2714 - val_acc: 0.6736\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2561 - acc: 0.6747 - val_loss: 0.2733 - val_acc: 0.6719\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2520 - acc: 0.6758 - val_loss: 0.2751 - val_acc: 0.6735\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2543 - acc: 0.6762 - val_loss: 0.2701 - val_acc: 0.6743\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2525 - acc: 0.6761 - val_loss: 0.2643 - val_acc: 0.6750\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2530 - acc: 0.6757 - val_loss: 0.2605 - val_acc: 0.6752\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2498 - acc: 0.6762 - val_loss: 0.2734 - val_acc: 0.6706\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.2523 - acc: 0.6752 - val_loss: 0.2602 - val_acc: 0.6754\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2497 - acc: 0.6769 - val_loss: 0.2667 - val_acc: 0.6727\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2578 - acc: 0.6723 - val_loss: 0.2764 - val_acc: 0.6715\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2529 - acc: 0.6761 - val_loss: 0.2641 - val_acc: 0.6752\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2515 - acc: 0.6762 - val_loss: 0.2662 - val_acc: 0.6737\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2492 - acc: 0.6771 - val_loss: 0.2638 - val_acc: 0.6743\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2534 - acc: 0.6763 - val_loss: 0.2670 - val_acc: 0.6725\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2516 - acc: 0.6759 - val_loss: 0.2651 - val_acc: 0.6739\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2551 - acc: 0.6761 - val_loss: 0.2650 - val_acc: 0.6737\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2520 - acc: 0.6751 - val_loss: 0.2617 - val_acc: 0.6755\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2508 - acc: 0.6764 - val_loss: 0.2665 - val_acc: 0.6727\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2530 - acc: 0.6759 - val_loss: 0.2681 - val_acc: 0.6717\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2529 - acc: 0.6766 - val_loss: 0.2628 - val_acc: 0.6744\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2523 - acc: 0.6772 - val_loss: 0.2644 - val_acc: 0.6749\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2525 - acc: 0.6753 - val_loss: 0.2654 - val_acc: 0.6687\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2484 - acc: 0.6769 - val_loss: 0.2693 - val_acc: 0.6728\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2523 - acc: 0.6771 - val_loss: 0.2715 - val_acc: 0.6740\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2514 - acc: 0.6769 - val_loss: 0.2636 - val_acc: 0.6751\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2526 - acc: 0.6757 - val_loss: 0.2624 - val_acc: 0.6764\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2511 - acc: 0.6765 - val_loss: 0.2647 - val_acc: 0.6753\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2545 - acc: 0.6754 - val_loss: 0.2618 - val_acc: 0.6740\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2513 - acc: 0.6763 - val_loss: 0.2673 - val_acc: 0.6709\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2497 - acc: 0.6765 - val_loss: 0.2607 - val_acc: 0.6750\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2495 - acc: 0.6767 - val_loss: 0.2671 - val_acc: 0.6726\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2519 - acc: 0.6757 - val_loss: 0.2632 - val_acc: 0.6754\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2501 - acc: 0.6764 - val_loss: 0.2633 - val_acc: 0.6757\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2501 - acc: 0.6776 - val_loss: 0.2642 - val_acc: 0.6756\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2504 - acc: 0.6764 - val_loss: 0.2651 - val_acc: 0.6739\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2524 - acc: 0.6762 - val_loss: 0.2663 - val_acc: 0.6752\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2542 - acc: 0.6748 - val_loss: 0.2606 - val_acc: 0.6751\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2472 - acc: 0.6780 - val_loss: 0.2667 - val_acc: 0.6730\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2516 - acc: 0.6766 - val_loss: 0.2724 - val_acc: 0.6710\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2547 - acc: 0.6756 - val_loss: 0.2646 - val_acc: 0.6755\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2521 - acc: 0.6776 - val_loss: 0.2622 - val_acc: 0.6749\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 0.2499 - acc: 0.6764 - val_loss: 0.2657 - val_acc: 0.6737\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2507 - acc: 0.6770 - val_loss: 0.2632 - val_acc: 0.6760\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2509 - acc: 0.6768 - val_loss: 0.2808 - val_acc: 0.6660\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0613 - acc: 0.6755 - val_loss: 2.1107 - val_acc: 0.6757\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0205 - acc: 0.6770 - val_loss: 2.2129 - val_acc: 0.6761\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0474 - acc: 0.6759 - val_loss: 2.1908 - val_acc: 0.6731\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0695 - acc: 0.6737 - val_loss: 2.1904 - val_acc: 0.6758\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0228 - acc: 0.6758 - val_loss: 2.1648 - val_acc: 0.6744\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0120 - acc: 0.6764 - val_loss: 2.2433 - val_acc: 0.6702\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0716 - acc: 0.6755 - val_loss: 2.1518 - val_acc: 0.6734\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0366 - acc: 0.6754 - val_loss: 2.1877 - val_acc: 0.6713\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 2.0329 - acc: 0.6752 - val_loss: 2.1316 - val_acc: 0.6733\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0319 - acc: 0.6751 - val_loss: 2.1864 - val_acc: 0.6672\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0568 - acc: 0.6741 - val_loss: 2.1358 - val_acc: 0.6734\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0188 - acc: 0.6763 - val_loss: 2.1709 - val_acc: 0.6733\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0127 - acc: 0.6752 - val_loss: 2.1575 - val_acc: 0.6743\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0276 - acc: 0.6754 - val_loss: 2.1602 - val_acc: 0.6757\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0580 - acc: 0.6755 - val_loss: 2.1787 - val_acc: 0.6744\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 2.0451 - acc: 0.6757 - val_loss: 2.1411 - val_acc: 0.6722\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0458 - acc: 0.6757 - val_loss: 2.1362 - val_acc: 0.6749\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0285 - acc: 0.6760 - val_loss: 2.1291 - val_acc: 0.6731\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0345 - acc: 0.6761 - val_loss: 2.1258 - val_acc: 0.6730\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0122 - acc: 0.6759 - val_loss: 2.1484 - val_acc: 0.6731\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0441 - acc: 0.6753 - val_loss: 2.2600 - val_acc: 0.6754\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 2.0526 - acc: 0.6765 - val_loss: 2.1568 - val_acc: 0.6748\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0584 - acc: 0.6747 - val_loss: 2.1087 - val_acc: 0.6732\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0132 - acc: 0.6762 - val_loss: 2.1754 - val_acc: 0.6757\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0617 - acc: 0.6756 - val_loss: 2.1253 - val_acc: 0.6740\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0057 - acc: 0.6761 - val_loss: 2.1437 - val_acc: 0.6719\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0236 - acc: 0.6757 - val_loss: 2.1388 - val_acc: 0.6706\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 2.0467 - acc: 0.6754 - val_loss: 2.1828 - val_acc: 0.6741\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0137 - acc: 0.6762 - val_loss: 2.1356 - val_acc: 0.6709\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 2.0214 - acc: 0.6761 - val_loss: 2.1479 - val_acc: 0.6727\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0104 - acc: 0.6766 - val_loss: 2.1564 - val_acc: 0.6725\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0469 - acc: 0.6758 - val_loss: 2.1150 - val_acc: 0.6752\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0245 - acc: 0.6761 - val_loss: 2.1423 - val_acc: 0.6756\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0610 - acc: 0.6744 - val_loss: 2.1353 - val_acc: 0.6751\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0294 - acc: 0.6750 - val_loss: 2.1601 - val_acc: 0.6742\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0159 - acc: 0.6755 - val_loss: 2.1630 - val_acc: 0.6749\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 2.0438 - acc: 0.6763 - val_loss: 2.1582 - val_acc: 0.6737\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0211 - acc: 0.6766 - val_loss: 2.1394 - val_acc: 0.6736\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9962 - acc: 0.6765 - val_loss: 2.1709 - val_acc: 0.6729\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0233 - acc: 0.6754 - val_loss: 2.1536 - val_acc: 0.6767\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0567 - acc: 0.6765 - val_loss: 2.2608 - val_acc: 0.6732\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0625 - acc: 0.6761 - val_loss: 2.1615 - val_acc: 0.6721\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0266 - acc: 0.6767 - val_loss: 2.2067 - val_acc: 0.6732\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0329 - acc: 0.6760 - val_loss: 2.1906 - val_acc: 0.6697\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0316 - acc: 0.6757 - val_loss: 2.1877 - val_acc: 0.6715\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0162 - acc: 0.6757 - val_loss: 2.1357 - val_acc: 0.6740\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 2.0357 - acc: 0.6760 - val_loss: 2.1278 - val_acc: 0.6735\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0127 - acc: 0.6764 - val_loss: 2.1342 - val_acc: 0.6726\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0008 - acc: 0.6759 - val_loss: 2.1205 - val_acc: 0.6741\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0066 - acc: 0.6765 - val_loss: 2.1310 - val_acc: 0.6735\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2277 - acc: 0.9904 - val_loss: 0.2241 - val_acc: 0.9889\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2333 - acc: 0.9907 - val_loss: 0.2598 - val_acc: 0.9872\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2488 - acc: 0.9911 - val_loss: 0.2333 - val_acc: 0.9896\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2203 - acc: 0.9919 - val_loss: 0.2215 - val_acc: 0.9896\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2232 - acc: 0.9919 - val_loss: 0.2188 - val_acc: 0.9894\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2189 - acc: 0.9918 - val_loss: 0.2191 - val_acc: 0.9895\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2195 - acc: 0.9918 - val_loss: 0.2261 - val_acc: 0.9893\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2267 - acc: 0.9915 - val_loss: 0.2286 - val_acc: 0.9892\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2185 - acc: 0.9918 - val_loss: 0.2213 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2243 - acc: 0.9917 - val_loss: 0.2297 - val_acc: 0.9893\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2314 - acc: 0.9916 - val_loss: 0.2339 - val_acc: 0.9888\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2204 - acc: 0.9914 - val_loss: 0.2201 - val_acc: 0.9893\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2217 - acc: 0.9912 - val_loss: 0.2295 - val_acc: 0.9883\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2253 - acc: 0.9909 - val_loss: 0.2257 - val_acc: 0.9891\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2266 - acc: 0.9913 - val_loss: 0.2271 - val_acc: 0.9895\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2217 - acc: 0.9918 - val_loss: 0.2206 - val_acc: 0.9895\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2224 - acc: 0.9913 - val_loss: 0.2417 - val_acc: 0.9886\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2274 - acc: 0.9914 - val_loss: 0.2225 - val_acc: 0.9895\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2148 - acc: 0.9918 - val_loss: 0.2147 - val_acc: 0.9895\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2134 - acc: 0.9919 - val_loss: 0.2155 - val_acc: 0.9894\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2109 - acc: 0.9919 - val_loss: 0.2194 - val_acc: 0.9896\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2251 - acc: 0.9917 - val_loss: 0.2295 - val_acc: 0.9895\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2344 - acc: 0.9915 - val_loss: 0.2429 - val_acc: 0.9893\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.2319 - acc: 0.9919 - val_loss: 0.2367 - val_acc: 0.9895\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2228 - acc: 0.9920 - val_loss: 0.2306 - val_acc: 0.9896\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2213 - acc: 0.9918 - val_loss: 0.2148 - val_acc: 0.9895\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2135 - acc: 0.9917 - val_loss: 0.2205 - val_acc: 0.9890\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 0.2265 - acc: 0.9905 - val_loss: 0.2434 - val_acc: 0.9869\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2328 - acc: 0.9899 - val_loss: 0.2296 - val_acc: 0.9886\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2175 - acc: 0.9910 - val_loss: 0.2166 - val_acc: 0.9889\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2176 - acc: 0.9915 - val_loss: 0.2298 - val_acc: 0.9893\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.2521 - acc: 0.9917 - val_loss: 0.2389 - val_acc: 0.9893\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2337 - acc: 0.9919 - val_loss: 0.2372 - val_acc: 0.9896\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2238 - acc: 0.9919 - val_loss: 0.2180 - val_acc: 0.9894\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2095 - acc: 0.9919 - val_loss: 0.2093 - val_acc: 0.9896\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2076 - acc: 0.9919 - val_loss: 0.2152 - val_acc: 0.9895\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2184 - acc: 0.9917 - val_loss: 0.2360 - val_acc: 0.9886\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2371 - acc: 0.9901 - val_loss: 0.2223 - val_acc: 0.9884\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2152 - acc: 0.9913 - val_loss: 0.2137 - val_acc: 0.9894\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2141 - acc: 0.9920 - val_loss: 0.2235 - val_acc: 0.9896\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2356 - acc: 0.9919 - val_loss: 0.2489 - val_acc: 0.9896\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2298 - acc: 0.9918 - val_loss: 0.2265 - val_acc: 0.9892\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 0.2179 - acc: 0.9914 - val_loss: 0.2216 - val_acc: 0.9889\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 0.2235 - acc: 0.9904 - val_loss: 0.2177 - val_acc: 0.9890\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2164 - acc: 0.9912 - val_loss: 0.2166 - val_acc: 0.9891\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2118 - acc: 0.9916 - val_loss: 0.2123 - val_acc: 0.9895\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2133 - acc: 0.9919 - val_loss: 0.2280 - val_acc: 0.9896\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2503 - acc: 0.9919 - val_loss: 0.2392 - val_acc: 0.9896\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2196 - acc: 0.9919 - val_loss: 0.2111 - val_acc: 0.9895\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2095 - acc: 0.9918 - val_loss: 0.2178 - val_acc: 0.9892\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0035 - acc: 0.9548 - val_loss: 0.0036 - val_acc: 0.9541\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0035 - acc: 0.9523 - val_loss: 0.0035 - val_acc: 0.9587\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0034 - acc: 0.9574 - val_loss: 0.0035 - val_acc: 0.9613\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0034 - acc: 0.9567 - val_loss: 0.0035 - val_acc: 0.9586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0034 - acc: 0.9566 - val_loss: 0.0036 - val_acc: 0.9572\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0035 - acc: 0.9551 - val_loss: 0.0039 - val_acc: 0.9516\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.0035 - acc: 0.9531 - val_loss: 0.0036 - val_acc: 0.9584\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0036 - acc: 0.9532 - val_loss: 0.0035 - val_acc: 0.9619\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0034 - acc: 0.9573 - val_loss: 0.0035 - val_acc: 0.9602\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0034 - acc: 0.9572 - val_loss: 0.0034 - val_acc: 0.9614\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9599\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.0035 - acc: 0.9548 - val_loss: 0.0035 - val_acc: 0.9588\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0034 - acc: 0.9570 - val_loss: 0.0035 - val_acc: 0.9580\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0036 - acc: 0.9518 - val_loss: 0.0035 - val_acc: 0.9591\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0034 - acc: 0.9567 - val_loss: 0.0035 - val_acc: 0.9599\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0035 - acc: 0.9527 - val_loss: 0.0034 - val_acc: 0.9598\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9570 - val_loss: 0.0035 - val_acc: 0.9601\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0034 - acc: 0.9573 - val_loss: 0.0035 - val_acc: 0.9596\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0035 - acc: 0.9564 - val_loss: 0.0036 - val_acc: 0.9567\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0035 - acc: 0.9553 - val_loss: 0.0036 - val_acc: 0.9550\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.0035 - acc: 0.9536 - val_loss: 0.0035 - val_acc: 0.9585\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0034 - acc: 0.9551 - val_loss: 0.0037 - val_acc: 0.9552\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0035 - acc: 0.9523 - val_loss: 0.0037 - val_acc: 0.9574\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0034 - acc: 0.9568 - val_loss: 0.0034 - val_acc: 0.9610\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0033 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9615\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0035 - acc: 0.9537 - val_loss: 0.0039 - val_acc: 0.9533\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0036 - acc: 0.9521 - val_loss: 0.0035 - val_acc: 0.9615\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9579 - val_loss: 0.0035 - val_acc: 0.9596\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.0035 - acc: 0.9552 - val_loss: 0.0036 - val_acc: 0.9602\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0035 - acc: 0.9577 - val_loss: 0.0035 - val_acc: 0.9596\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0034 - acc: 0.9552 - val_loss: 0.0034 - val_acc: 0.9614\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0034 - acc: 0.9576 - val_loss: 0.0036 - val_acc: 0.9616\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0034 - acc: 0.9567 - val_loss: 0.0035 - val_acc: 0.9592\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0035 - acc: 0.9532 - val_loss: 0.0035 - val_acc: 0.9605\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9572 - val_loss: 0.0036 - val_acc: 0.9618\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0034 - acc: 0.9570 - val_loss: 0.0036 - val_acc: 0.9593\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0036 - acc: 0.9533 - val_loss: 0.0035 - val_acc: 0.9599\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9566 - val_loss: 0.0034 - val_acc: 0.9609\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0033 - acc: 0.9579 - val_loss: 0.0034 - val_acc: 0.9610\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0034 - val_acc: 0.9611\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0034 - acc: 0.9575 - val_loss: 0.0035 - val_acc: 0.9616\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0035 - acc: 0.9533 - val_loss: 0.0041 - val_acc: 0.9541\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0037 - acc: 0.9499 - val_loss: 0.0035 - val_acc: 0.9611\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9568 - val_loss: 0.0035 - val_acc: 0.9616\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9569 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0033 - acc: 0.9568 - val_loss: 0.0035 - val_acc: 0.9590\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0034 - acc: 0.9558 - val_loss: 0.0035 - val_acc: 0.9600\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0035 - acc: 0.9539 - val_loss: 0.0036 - val_acc: 0.9546\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0035 - acc: 0.9543 - val_loss: 0.0034 - val_acc: 0.9596\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0035 - acc: 0.9535 - val_loss: 0.0035 - val_acc: 0.9596\n",
      "start training round 2\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2568 - acc: 0.6753 - val_loss: 0.2654 - val_acc: 0.6746\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2494 - acc: 0.6775 - val_loss: 0.2608 - val_acc: 0.6761\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2507 - acc: 0.6763 - val_loss: 0.2723 - val_acc: 0.6685\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2512 - acc: 0.6763 - val_loss: 0.2631 - val_acc: 0.6741\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2544 - acc: 0.6754 - val_loss: 0.2642 - val_acc: 0.6734\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2501 - acc: 0.6765 - val_loss: 0.2625 - val_acc: 0.6723\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2498 - acc: 0.6768 - val_loss: 0.2664 - val_acc: 0.6730\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2504 - acc: 0.6763 - val_loss: 0.2642 - val_acc: 0.6743\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2507 - acc: 0.6764 - val_loss: 0.2646 - val_acc: 0.6739\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2525 - acc: 0.6762 - val_loss: 0.2616 - val_acc: 0.6754\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2487 - acc: 0.6771 - val_loss: 0.2615 - val_acc: 0.6751\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2512 - acc: 0.6776 - val_loss: 0.2642 - val_acc: 0.6752\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2500 - acc: 0.6772 - val_loss: 0.2605 - val_acc: 0.6776\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2501 - acc: 0.6757 - val_loss: 0.2658 - val_acc: 0.6732\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2540 - acc: 0.6751 - val_loss: 0.2646 - val_acc: 0.6753\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2513 - acc: 0.6772 - val_loss: 0.2608 - val_acc: 0.6765\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2507 - acc: 0.6774 - val_loss: 0.2632 - val_acc: 0.6752\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2501 - acc: 0.6775 - val_loss: 0.2684 - val_acc: 0.6720\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2517 - acc: 0.6758 - val_loss: 0.2621 - val_acc: 0.6754\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2525 - acc: 0.6766 - val_loss: 0.2627 - val_acc: 0.6748\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2484 - acc: 0.6768 - val_loss: 0.2635 - val_acc: 0.6727\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 0.2497 - acc: 0.6767 - val_loss: 0.2629 - val_acc: 0.6742\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2486 - acc: 0.6783 - val_loss: 0.2595 - val_acc: 0.6761\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2492 - acc: 0.6780 - val_loss: 0.2605 - val_acc: 0.6767\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 0.2511 - acc: 0.6766 - val_loss: 0.2727 - val_acc: 0.6720\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2526 - acc: 0.6757 - val_loss: 0.2585 - val_acc: 0.6761\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2510 - acc: 0.6769 - val_loss: 0.2753 - val_acc: 0.6750\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2549 - acc: 0.6755 - val_loss: 0.2630 - val_acc: 0.6747\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2489 - acc: 0.6780 - val_loss: 0.2587 - val_acc: 0.6771\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2480 - acc: 0.6777 - val_loss: 0.2651 - val_acc: 0.6754\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2508 - acc: 0.6773 - val_loss: 0.2642 - val_acc: 0.6749\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2495 - acc: 0.6776 - val_loss: 0.2606 - val_acc: 0.6767\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2488 - acc: 0.6776 - val_loss: 0.2612 - val_acc: 0.6744\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2518 - acc: 0.6763 - val_loss: 0.2602 - val_acc: 0.6738\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2498 - acc: 0.6773 - val_loss: 0.2650 - val_acc: 0.6750\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2483 - acc: 0.6776 - val_loss: 0.2617 - val_acc: 0.6765\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2517 - acc: 0.6771 - val_loss: 0.2628 - val_acc: 0.6756\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2514 - acc: 0.6767 - val_loss: 0.2655 - val_acc: 0.6743\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2489 - acc: 0.6778 - val_loss: 0.2616 - val_acc: 0.6770\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2477 - acc: 0.6780 - val_loss: 0.2584 - val_acc: 0.6780\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2482 - acc: 0.6770 - val_loss: 0.2630 - val_acc: 0.6751\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2488 - acc: 0.6780 - val_loss: 0.2609 - val_acc: 0.6763\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2521 - acc: 0.6770 - val_loss: 0.2726 - val_acc: 0.6721\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2534 - acc: 0.6772 - val_loss: 0.2679 - val_acc: 0.6739\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2525 - acc: 0.6769 - val_loss: 0.2632 - val_acc: 0.6740\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2497 - acc: 0.6767 - val_loss: 0.2668 - val_acc: 0.6731\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2512 - acc: 0.6762 - val_loss: 0.2628 - val_acc: 0.6757\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2480 - acc: 0.6785 - val_loss: 0.2611 - val_acc: 0.6754\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2490 - acc: 0.6779 - val_loss: 0.2636 - val_acc: 0.6736\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2487 - acc: 0.6776 - val_loss: 0.2579 - val_acc: 0.6775\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0230 - acc: 0.6756 - val_loss: 2.1404 - val_acc: 0.6719\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0439 - acc: 0.6762 - val_loss: 2.1404 - val_acc: 0.6719\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 2.0273 - acc: 0.6761 - val_loss: 2.1986 - val_acc: 0.6708\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0292 - acc: 0.6757 - val_loss: 2.1925 - val_acc: 0.6688\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0533 - acc: 0.6754 - val_loss: 2.2073 - val_acc: 0.6753\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0524 - acc: 0.6752 - val_loss: 2.1593 - val_acc: 0.6746\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0414 - acc: 0.6764 - val_loss: 2.1129 - val_acc: 0.6749\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 2.0432 - acc: 0.6764 - val_loss: 2.1591 - val_acc: 0.6747\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0260 - acc: 0.6770 - val_loss: 2.2189 - val_acc: 0.6769\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0459 - acc: 0.6759 - val_loss: 2.1416 - val_acc: 0.6740\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0409 - acc: 0.6754 - val_loss: 2.1396 - val_acc: 0.6758\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0521 - acc: 0.6750 - val_loss: 2.1478 - val_acc: 0.6758\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0174 - acc: 0.6764 - val_loss: 2.1535 - val_acc: 0.6738\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0408 - acc: 0.6761 - val_loss: 2.1971 - val_acc: 0.6744\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0134 - acc: 0.6764 - val_loss: 2.1185 - val_acc: 0.6738\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0324 - acc: 0.6764 - val_loss: 2.1110 - val_acc: 0.6750\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0242 - acc: 0.6760 - val_loss: 2.1583 - val_acc: 0.6748\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0419 - acc: 0.6755 - val_loss: 2.1133 - val_acc: 0.6755\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 2.0182 - acc: 0.6757 - val_loss: 2.2215 - val_acc: 0.6724\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 2.0379 - acc: 0.6750 - val_loss: 2.1180 - val_acc: 0.6739\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0231 - acc: 0.6761 - val_loss: 2.1387 - val_acc: 0.6755\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0308 - acc: 0.6764 - val_loss: 2.1834 - val_acc: 0.6733\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0155 - acc: 0.6752 - val_loss: 2.2238 - val_acc: 0.6732\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0406 - acc: 0.6756 - val_loss: 2.2168 - val_acc: 0.6740\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0428 - acc: 0.6757 - val_loss: 2.1610 - val_acc: 0.6764\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0115 - acc: 0.6761 - val_loss: 2.1361 - val_acc: 0.6748\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0315 - acc: 0.6752 - val_loss: 2.2539 - val_acc: 0.6664\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 2.0488 - acc: 0.6752 - val_loss: 2.1393 - val_acc: 0.6737\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 2.0260 - acc: 0.6765 - val_loss: 2.1987 - val_acc: 0.6724\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 2.0366 - acc: 0.6755 - val_loss: 2.1530 - val_acc: 0.6706\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0313 - acc: 0.6761 - val_loss: 2.1280 - val_acc: 0.6741\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0273 - acc: 0.6770 - val_loss: 2.1634 - val_acc: 0.6738\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0287 - acc: 0.6759 - val_loss: 2.1679 - val_acc: 0.6752\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0327 - acc: 0.6760 - val_loss: 2.1358 - val_acc: 0.6760\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0115 - acc: 0.6769 - val_loss: 2.1385 - val_acc: 0.6730\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 2.0155 - acc: 0.6753 - val_loss: 2.1410 - val_acc: 0.6726\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0121 - acc: 0.6754 - val_loss: 2.2413 - val_acc: 0.6760\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0461 - acc: 0.6759 - val_loss: 2.1109 - val_acc: 0.6757\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9901 - acc: 0.6761 - val_loss: 2.1459 - val_acc: 0.6732\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0446 - acc: 0.6754 - val_loss: 2.1185 - val_acc: 0.6757\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0294 - acc: 0.6753 - val_loss: 2.1697 - val_acc: 0.6743\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0296 - acc: 0.6752 - val_loss: 2.2239 - val_acc: 0.6727\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0160 - acc: 0.6758 - val_loss: 2.1361 - val_acc: 0.6726\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0162 - acc: 0.6768 - val_loss: 2.1835 - val_acc: 0.6714\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0305 - acc: 0.6766 - val_loss: 2.2043 - val_acc: 0.6737\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0475 - acc: 0.6762 - val_loss: 2.1582 - val_acc: 0.6748\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0311 - acc: 0.6759 - val_loss: 2.2211 - val_acc: 0.6756\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0496 - acc: 0.6762 - val_loss: 2.1298 - val_acc: 0.6750\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0178 - acc: 0.6763 - val_loss: 2.1550 - val_acc: 0.6756\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0348 - acc: 0.6761 - val_loss: 2.2305 - val_acc: 0.6680\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2212 - acc: 0.9916 - val_loss: 0.2330 - val_acc: 0.9890\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2320 - acc: 0.9908 - val_loss: 0.2359 - val_acc: 0.9881\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2234 - acc: 0.9912 - val_loss: 0.2254 - val_acc: 0.9893\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2349 - acc: 0.9915 - val_loss: 0.2418 - val_acc: 0.9893\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2322 - acc: 0.9918 - val_loss: 0.2176 - val_acc: 0.9896\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - ETA: 0s - loss: 0.2103 - acc: 0.991 - 3s 381us/step - loss: 0.2105 - acc: 0.9919 - val_loss: 0.2095 - val_acc: 0.9895\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2085 - acc: 0.9919 - val_loss: 0.2217 - val_acc: 0.9895\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2198 - acc: 0.9919 - val_loss: 0.2327 - val_acc: 0.9896\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2276 - acc: 0.9918 - val_loss: 0.2184 - val_acc: 0.9895\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2191 - acc: 0.9918 - val_loss: 0.2121 - val_acc: 0.9896\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2100 - acc: 0.9918 - val_loss: 0.2120 - val_acc: 0.9895\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2229 - acc: 0.9919 - val_loss: 0.2434 - val_acc: 0.9897\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2324 - acc: 0.9919 - val_loss: 0.2243 - val_acc: 0.9896\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2222 - acc: 0.9919 - val_loss: 0.2348 - val_acc: 0.9897\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2300 - acc: 0.9919 - val_loss: 0.2187 - val_acc: 0.9896\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2152 - acc: 0.9919 - val_loss: 0.2130 - val_acc: 0.9895\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2088 - acc: 0.9919 - val_loss: 0.2096 - val_acc: 0.9896\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2109 - acc: 0.9916 - val_loss: 0.2208 - val_acc: 0.9889\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2326 - acc: 0.9899 - val_loss: 0.2364 - val_acc: 0.9875\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2218 - acc: 0.9910 - val_loss: 0.2271 - val_acc: 0.9885\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2311 - acc: 0.9910 - val_loss: 0.2292 - val_acc: 0.9892\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2195 - acc: 0.9915 - val_loss: 0.2123 - val_acc: 0.9897\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2297 - acc: 0.9919 - val_loss: 0.2552 - val_acc: 0.9896\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2394 - acc: 0.9919 - val_loss: 0.2271 - val_acc: 0.9896\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2140 - acc: 0.9920 - val_loss: 0.2124 - val_acc: 0.9896\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 0.2071 - acc: 0.9920 - val_loss: 0.2085 - val_acc: 0.9896\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2093 - acc: 0.9920 - val_loss: 0.2134 - val_acc: 0.9896\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2076 - acc: 0.9917 - val_loss: 0.2167 - val_acc: 0.9891\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2296 - acc: 0.9904 - val_loss: 0.2358 - val_acc: 0.9874\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2254 - acc: 0.9908 - val_loss: 0.2198 - val_acc: 0.9893\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2109 - acc: 0.9918 - val_loss: 0.2099 - val_acc: 0.9895\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2243 - acc: 0.9911 - val_loss: 0.2472 - val_acc: 0.9871\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2365 - acc: 0.9907 - val_loss: 0.2323 - val_acc: 0.9891\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2266 - acc: 0.9918 - val_loss: 0.2268 - val_acc: 0.9897\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2287 - acc: 0.9918 - val_loss: 0.2286 - val_acc: 0.9896\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2241 - acc: 0.9919 - val_loss: 0.2174 - val_acc: 0.9897\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2110 - acc: 0.9919 - val_loss: 0.2090 - val_acc: 0.9897\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 0.2092 - acc: 0.9920 - val_loss: 0.2155 - val_acc: 0.9895\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2206 - acc: 0.9918 - val_loss: 0.2215 - val_acc: 0.9895\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2198 - acc: 0.9920 - val_loss: 0.2305 - val_acc: 0.9897\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2403 - acc: 0.9919 - val_loss: 0.2360 - val_acc: 0.9895\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2203 - acc: 0.9916 - val_loss: 0.2142 - val_acc: 0.9891\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2090 - acc: 0.9917 - val_loss: 0.2104 - val_acc: 0.9896\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2074 - acc: 0.9917 - val_loss: 0.2093 - val_acc: 0.9897\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2108 - acc: 0.9916 - val_loss: 0.2137 - val_acc: 0.9891\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2163 - acc: 0.9911 - val_loss: 0.2232 - val_acc: 0.9884\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2284 - acc: 0.9908 - val_loss: 0.2449 - val_acc: 0.9885\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2324 - acc: 0.9916 - val_loss: 0.2288 - val_acc: 0.9896\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 0.2228 - acc: 0.9920 - val_loss: 0.2236 - val_acc: 0.9896\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2311 - acc: 0.9919 - val_loss: 0.2289 - val_acc: 0.9895\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.0034 - acc: 0.9553 - val_loss: 0.0035 - val_acc: 0.9618\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0034 - acc: 0.9568 - val_loss: 0.0036 - val_acc: 0.9588\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9562 - val_loss: 0.0036 - val_acc: 0.9605\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0034 - acc: 0.9576 - val_loss: 0.0035 - val_acc: 0.9615\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0034 - acc: 0.9557 - val_loss: 0.0035 - val_acc: 0.9606\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.0036 - acc: 0.9518 - val_loss: 0.0034 - val_acc: 0.9610\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9605\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0034 - val_acc: 0.9611\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0035 - val_acc: 0.9606\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0034 - acc: 0.9568 - val_loss: 0.0036 - val_acc: 0.9574\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0036 - acc: 0.9545 - val_loss: 0.0037 - val_acc: 0.9570\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.0036 - acc: 0.9536 - val_loss: 0.0035 - val_acc: 0.9580\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0034 - acc: 0.9559 - val_loss: 0.0035 - val_acc: 0.9593\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0034 - val_acc: 0.9601\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0035 - acc: 0.9553 - val_loss: 0.0036 - val_acc: 0.9580\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0035 - acc: 0.9565 - val_loss: 0.0035 - val_acc: 0.9605\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0034 - acc: 0.9575 - val_loss: 0.0035 - val_acc: 0.9603\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0034 - acc: 0.9577 - val_loss: 0.0034 - val_acc: 0.9609\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0035 - val_acc: 0.9591\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0034 - acc: 0.9534 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0034 - acc: 0.9573 - val_loss: 0.0039 - val_acc: 0.9496\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0036 - acc: 0.9496 - val_loss: 0.0035 - val_acc: 0.9578\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0034 - acc: 0.9559 - val_loss: 0.0035 - val_acc: 0.9584\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0035 - acc: 0.9548 - val_loss: 0.0035 - val_acc: 0.9579\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0035 - acc: 0.9556 - val_loss: 0.0037 - val_acc: 0.9539\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0035 - acc: 0.9524 - val_loss: 0.0036 - val_acc: 0.9556\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.0035 - acc: 0.9521 - val_loss: 0.0036 - val_acc: 0.9574\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9575 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0034 - acc: 0.9559 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0034 - acc: 0.9558 - val_loss: 0.0035 - val_acc: 0.9601\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.0034 - acc: 0.9544 - val_loss: 0.0034 - val_acc: 0.9611\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0034 - val_acc: 0.9609\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0034 - acc: 0.9551 - val_loss: 0.0035 - val_acc: 0.9618\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0034 - acc: 0.9563 - val_loss: 0.0039 - val_acc: 0.9535\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0036 - acc: 0.9513 - val_loss: 0.0036 - val_acc: 0.9599\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0034 - acc: 0.9567 - val_loss: 0.0034 - val_acc: 0.9615\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0035 - acc: 0.9534 - val_loss: 0.0037 - val_acc: 0.9556\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0034 - acc: 0.9554 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9570 - val_loss: 0.0036 - val_acc: 0.9571\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0036 - acc: 0.9515 - val_loss: 0.0034 - val_acc: 0.9597\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9607\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0034 - acc: 0.9572 - val_loss: 0.0035 - val_acc: 0.9587\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0034 - acc: 0.9570 - val_loss: 0.0035 - val_acc: 0.9603\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0034 - acc: 0.9578 - val_loss: 0.0035 - val_acc: 0.9605\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.957 - 3s 390us/step - loss: 0.0034 - acc: 0.9570 - val_loss: 0.0035 - val_acc: 0.9591\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0035 - val_acc: 0.9574\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0034 - acc: 0.9553 - val_loss: 0.0034 - val_acc: 0.9607\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0033 - acc: 0.9568 - val_loss: 0.0035 - val_acc: 0.9572\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0034 - acc: 0.9554 - val_loss: 0.0034 - val_acc: 0.9596\n",
      "start training round 3\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2468 - acc: 0.6781 - val_loss: 0.2602 - val_acc: 0.6764\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2469 - acc: 0.6787 - val_loss: 0.2595 - val_acc: 0.6769\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2505 - acc: 0.6778 - val_loss: 0.2642 - val_acc: 0.6758\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2496 - acc: 0.6765 - val_loss: 0.2686 - val_acc: 0.6763\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2537 - acc: 0.6774 - val_loss: 0.2595 - val_acc: 0.6750\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2470 - acc: 0.6784 - val_loss: 0.2605 - val_acc: 0.6759\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2486 - acc: 0.6781 - val_loss: 0.2648 - val_acc: 0.6727\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2515 - acc: 0.6761 - val_loss: 0.2573 - val_acc: 0.6775\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2478 - acc: 0.6786 - val_loss: 0.2656 - val_acc: 0.6744\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2524 - acc: 0.6778 - val_loss: 0.2632 - val_acc: 0.6757\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2498 - acc: 0.6772 - val_loss: 0.2588 - val_acc: 0.6782\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2480 - acc: 0.6775 - val_loss: 0.2629 - val_acc: 0.6760\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2498 - acc: 0.6774 - val_loss: 0.2623 - val_acc: 0.6772\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2516 - acc: 0.6783 - val_loss: 0.2589 - val_acc: 0.6756\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2482 - acc: 0.6774 - val_loss: 0.2600 - val_acc: 0.6746\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2500 - acc: 0.6767 - val_loss: 0.2687 - val_acc: 0.6731\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2521 - acc: 0.6765 - val_loss: 0.2613 - val_acc: 0.6762\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2499 - acc: 0.6774 - val_loss: 0.2842 - val_acc: 0.6708\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2532 - acc: 0.6761 - val_loss: 0.2574 - val_acc: 0.6763\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2466 - acc: 0.6791 - val_loss: 0.2606 - val_acc: 0.6763\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2473 - acc: 0.6789 - val_loss: 0.2617 - val_acc: 0.6772\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2495 - acc: 0.6784 - val_loss: 0.2740 - val_acc: 0.6728\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2483 - acc: 0.6777 - val_loss: 0.2605 - val_acc: 0.6756\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2465 - acc: 0.6791 - val_loss: 0.2615 - val_acc: 0.6755\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2478 - acc: 0.6782 - val_loss: 0.2605 - val_acc: 0.6769\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2514 - acc: 0.6768 - val_loss: 0.2645 - val_acc: 0.6721\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2495 - acc: 0.6779 - val_loss: 0.2670 - val_acc: 0.6750\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2522 - acc: 0.6779 - val_loss: 0.2720 - val_acc: 0.6712\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2525 - acc: 0.6775 - val_loss: 0.2595 - val_acc: 0.6760\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2469 - acc: 0.6788 - val_loss: 0.2607 - val_acc: 0.6745\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2480 - acc: 0.6770 - val_loss: 0.2622 - val_acc: 0.6731\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2481 - acc: 0.6779 - val_loss: 0.2576 - val_acc: 0.6775\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2476 - acc: 0.6788 - val_loss: 0.2639 - val_acc: 0.6741\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2486 - acc: 0.6779 - val_loss: 0.2600 - val_acc: 0.6748\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2488 - acc: 0.6782 - val_loss: 0.2603 - val_acc: 0.6754\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2455 - acc: 0.6795 - val_loss: 0.2635 - val_acc: 0.6766\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2513 - acc: 0.6770 - val_loss: 0.2605 - val_acc: 0.6737\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2468 - acc: 0.6788 - val_loss: 0.2578 - val_acc: 0.6770\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2482 - acc: 0.6790 - val_loss: 0.2628 - val_acc: 0.6780\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2498 - acc: 0.6790 - val_loss: 0.2603 - val_acc: 0.6765\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2495 - acc: 0.6795 - val_loss: 0.2581 - val_acc: 0.6766\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2476 - acc: 0.6780 - val_loss: 0.2666 - val_acc: 0.6711\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2500 - acc: 0.6774 - val_loss: 0.2654 - val_acc: 0.6735\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2510 - acc: 0.6761 - val_loss: 0.2637 - val_acc: 0.6712\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2456 - acc: 0.6788 - val_loss: 0.2604 - val_acc: 0.6744\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2461 - acc: 0.6786 - val_loss: 0.2612 - val_acc: 0.6755\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2516 - acc: 0.6765 - val_loss: 0.2746 - val_acc: 0.6726\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2506 - acc: 0.6774 - val_loss: 0.2619 - val_acc: 0.6781\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2527 - acc: 0.6777 - val_loss: 0.2626 - val_acc: 0.6779\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2502 - acc: 0.6786 - val_loss: 0.2618 - val_acc: 0.6750\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0377 - acc: 0.6751 - val_loss: 2.1080 - val_acc: 0.6720\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0124 - acc: 0.6757 - val_loss: 2.2855 - val_acc: 0.6662\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0345 - acc: 0.6757 - val_loss: 2.1452 - val_acc: 0.6763\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0346 - acc: 0.6757 - val_loss: 2.1260 - val_acc: 0.6768\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0120 - acc: 0.6764 - val_loss: 2.1182 - val_acc: 0.6757\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0049 - acc: 0.6766 - val_loss: 2.1188 - val_acc: 0.6763\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 2.0292 - acc: 0.6756 - val_loss: 2.1736 - val_acc: 0.6768\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0559 - acc: 0.6759 - val_loss: 2.1658 - val_acc: 0.6758\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0009 - acc: 0.6766 - val_loss: 2.1814 - val_acc: 0.6754\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0343 - acc: 0.6744 - val_loss: 2.1783 - val_acc: 0.6747\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0229 - acc: 0.6765 - val_loss: 2.2292 - val_acc: 0.6705\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 2.0324 - acc: 0.6767 - val_loss: 2.2042 - val_acc: 0.6750\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0607 - acc: 0.6761 - val_loss: 2.1403 - val_acc: 0.6761\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0185 - acc: 0.6770 - val_loss: 2.1716 - val_acc: 0.6745\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0194 - acc: 0.6765 - val_loss: 2.1252 - val_acc: 0.6733\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0126 - acc: 0.6758 - val_loss: 2.1690 - val_acc: 0.6734\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0085 - acc: 0.6760 - val_loss: 2.1653 - val_acc: 0.6693\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 2.0322 - acc: 0.6751 - val_loss: 2.1137 - val_acc: 0.6730\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0090 - acc: 0.6769 - val_loss: 2.1319 - val_acc: 0.6767\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0369 - acc: 0.6763 - val_loss: 2.1423 - val_acc: 0.6756\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0418 - acc: 0.6767 - val_loss: 2.1475 - val_acc: 0.6765\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0239 - acc: 0.6760 - val_loss: 2.1354 - val_acc: 0.6765\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0168 - acc: 0.6763 - val_loss: 2.1293 - val_acc: 0.6770\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0326 - acc: 0.6761 - val_loss: 2.1107 - val_acc: 0.6753\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0239 - acc: 0.6765 - val_loss: 2.2095 - val_acc: 0.6726\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0695 - acc: 0.6756 - val_loss: 2.2753 - val_acc: 0.6737\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0052 - acc: 0.6761 - val_loss: 2.2313 - val_acc: 0.6674\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0283 - acc: 0.6761 - val_loss: 2.1318 - val_acc: 0.6742\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9851 - acc: 0.6771 - val_loss: 2.1765 - val_acc: 0.6705\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0300 - acc: 0.6763 - val_loss: 2.1821 - val_acc: 0.6721\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0466 - acc: 0.6755 - val_loss: 2.1456 - val_acc: 0.6754\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0168 - acc: 0.6759 - val_loss: 2.1237 - val_acc: 0.6737\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 2.0037 - acc: 0.6761 - val_loss: 2.1149 - val_acc: 0.6740\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0393 - acc: 0.6758 - val_loss: 2.2668 - val_acc: 0.6737\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0176 - acc: 0.6765 - val_loss: 2.1306 - val_acc: 0.6734\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0315 - acc: 0.6762 - val_loss: 2.1501 - val_acc: 0.6725\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0025 - acc: 0.6762 - val_loss: 2.1322 - val_acc: 0.6707\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0365 - acc: 0.6753 - val_loss: 2.1151 - val_acc: 0.6748\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0273 - acc: 0.6767 - val_loss: 2.2705 - val_acc: 0.6743\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0031 - acc: 0.6769 - val_loss: 2.1123 - val_acc: 0.6735\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0342 - acc: 0.6763 - val_loss: 2.1428 - val_acc: 0.6751\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0095 - acc: 0.6769 - val_loss: 2.1693 - val_acc: 0.6728\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0334 - acc: 0.6767 - val_loss: 2.1356 - val_acc: 0.6734\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0388 - acc: 0.6766 - val_loss: 2.1945 - val_acc: 0.6717\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0393 - acc: 0.6747 - val_loss: 2.1280 - val_acc: 0.6761\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0225 - acc: 0.6765 - val_loss: 2.1304 - val_acc: 0.6757\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0133 - acc: 0.6766 - val_loss: 2.2138 - val_acc: 0.6723\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0213 - acc: 0.6769 - val_loss: 2.2518 - val_acc: 0.6754\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0353 - acc: 0.6766 - val_loss: 2.1676 - val_acc: 0.6762\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 2.0235 - acc: 0.6753 - val_loss: 2.1737 - val_acc: 0.6761\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2084 - acc: 0.9919 - val_loss: 0.2042 - val_acc: 0.9896\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2135 - acc: 0.9909 - val_loss: 0.2232 - val_acc: 0.9887\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2259 - acc: 0.9899 - val_loss: 0.2192 - val_acc: 0.9887\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2094 - acc: 0.9913 - val_loss: 0.2111 - val_acc: 0.9893\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2136 - acc: 0.9914 - val_loss: 0.2367 - val_acc: 0.9893\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2384 - acc: 0.9918 - val_loss: 0.2502 - val_acc: 0.9896\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2305 - acc: 0.9919 - val_loss: 0.2170 - val_acc: 0.9896\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2105 - acc: 0.9920 - val_loss: 0.2205 - val_acc: 0.9896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2210 - acc: 0.9920 - val_loss: 0.2340 - val_acc: 0.9895\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2256 - acc: 0.9914 - val_loss: 0.2409 - val_acc: 0.9892\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2208 - acc: 0.9917 - val_loss: 0.2153 - val_acc: 0.9895\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2109 - acc: 0.9919 - val_loss: 0.2208 - val_acc: 0.9897\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2302 - acc: 0.9918 - val_loss: 0.2258 - val_acc: 0.9897\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2262 - acc: 0.9919 - val_loss: 0.2263 - val_acc: 0.9897\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2146 - acc: 0.9920 - val_loss: 0.2085 - val_acc: 0.9897\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2052 - acc: 0.9916 - val_loss: 0.2119 - val_acc: 0.9894\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2086 - acc: 0.9913 - val_loss: 0.2137 - val_acc: 0.9893\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2200 - acc: 0.9907 - val_loss: 0.2358 - val_acc: 0.9871\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2239 - acc: 0.9908 - val_loss: 0.2295 - val_acc: 0.9890\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2266 - acc: 0.9916 - val_loss: 0.2296 - val_acc: 0.9896\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2263 - acc: 0.9919 - val_loss: 0.2225 - val_acc: 0.9896\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2212 - acc: 0.9919 - val_loss: 0.2202 - val_acc: 0.9896\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2100 - acc: 0.9917 - val_loss: 0.2102 - val_acc: 0.9894\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2042 - acc: 0.9919 - val_loss: 0.2078 - val_acc: 0.9896\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2063 - acc: 0.9920 - val_loss: 0.2158 - val_acc: 0.9896\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2178 - acc: 0.9920 - val_loss: 0.2315 - val_acc: 0.9896\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2233 - acc: 0.9920 - val_loss: 0.2185 - val_acc: 0.9894\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2242 - acc: 0.9911 - val_loss: 0.2258 - val_acc: 0.9881\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2289 - acc: 0.9896 - val_loss: 0.2317 - val_acc: 0.9871\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2301 - acc: 0.9902 - val_loss: 0.2252 - val_acc: 0.9893\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2203 - acc: 0.9918 - val_loss: 0.2207 - val_acc: 0.9898\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2116 - acc: 0.9920 - val_loss: 0.2173 - val_acc: 0.9895\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 0.2217 - acc: 0.9919 - val_loss: 0.2266 - val_acc: 0.9896\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2249 - acc: 0.9919 - val_loss: 0.2175 - val_acc: 0.9898\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2176 - acc: 0.9920 - val_loss: 0.2273 - val_acc: 0.9896\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.2297 - acc: 0.9920 - val_loss: 0.2229 - val_acc: 0.9897\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2144 - acc: 0.9920 - val_loss: 0.2078 - val_acc: 0.9898\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2055 - acc: 0.9920 - val_loss: 0.2130 - val_acc: 0.9891\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2165 - acc: 0.9909 - val_loss: 0.2370 - val_acc: 0.9877\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.2296 - acc: 0.9903 - val_loss: 0.2130 - val_acc: 0.9894\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2059 - acc: 0.9919 - val_loss: 0.2077 - val_acc: 0.9897\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2154 - acc: 0.9920 - val_loss: 0.2339 - val_acc: 0.9896\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2393 - acc: 0.9919 - val_loss: 0.2430 - val_acc: 0.9894\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2200 - acc: 0.9919 - val_loss: 0.2083 - val_acc: 0.9896\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 0.2070 - acc: 0.9918 - val_loss: 0.2082 - val_acc: 0.9896\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2157 - acc: 0.9919 - val_loss: 0.2254 - val_acc: 0.9896\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2190 - acc: 0.9917 - val_loss: 0.2125 - val_acc: 0.9895\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2070 - acc: 0.9917 - val_loss: 0.2058 - val_acc: 0.9895\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2066 - acc: 0.9915 - val_loss: 0.2154 - val_acc: 0.9883\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2217 - acc: 0.9902 - val_loss: 0.2183 - val_acc: 0.9884\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9559 - val_loss: 0.0037 - val_acc: 0.9529\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0034 - acc: 0.9537 - val_loss: 0.0034 - val_acc: 0.9601\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.0033 - acc: 0.9579 - val_loss: 0.0035 - val_acc: 0.9601\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0034 - acc: 0.9554 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0034 - acc: 0.9565 - val_loss: 0.0034 - val_acc: 0.9615\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9565 - val_loss: 0.0035 - val_acc: 0.9579\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0034 - acc: 0.9537 - val_loss: 0.0034 - val_acc: 0.9601\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0034 - acc: 0.9560 - val_loss: 0.0035 - val_acc: 0.9577\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0035 - acc: 0.9511 - val_loss: 0.0034 - val_acc: 0.9609\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0036 - val_acc: 0.9564\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0035 - acc: 0.9511 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9582 - val_loss: 0.0035 - val_acc: 0.9618\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0034 - acc: 0.9579 - val_loss: 0.0037 - val_acc: 0.9615\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0035 - acc: 0.9555 - val_loss: 0.0035 - val_acc: 0.9615\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9618\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0036 - val_acc: 0.9572\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0035 - acc: 0.9515 - val_loss: 0.0035 - val_acc: 0.9589\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0034 - acc: 0.9564 - val_loss: 0.0035 - val_acc: 0.9599\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0034 - acc: 0.9557 - val_loss: 0.0036 - val_acc: 0.9560\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0035 - acc: 0.9546 - val_loss: 0.0036 - val_acc: 0.9538\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0037 - acc: 0.9487 - val_loss: 0.0034 - val_acc: 0.9606\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.0033 - acc: 0.9579 - val_loss: 0.0035 - val_acc: 0.9616\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0034 - acc: 0.9552 - val_loss: 0.0034 - val_acc: 0.9619\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0034 - acc: 0.9553 - val_loss: 0.0039 - val_acc: 0.9497\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0034 - acc: 0.9553 - val_loss: 0.0034 - val_acc: 0.9586\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0033 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9609\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9605\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0034 - acc: 0.9551 - val_loss: 0.0034 - val_acc: 0.9598\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0035 - acc: 0.9521 - val_loss: 0.0036 - val_acc: 0.9570\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0034 - acc: 0.9566 - val_loss: 0.0035 - val_acc: 0.9591\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0034 - acc: 0.9573 - val_loss: 0.0035 - val_acc: 0.9595\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9569 - val_loss: 0.0035 - val_acc: 0.9589\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0034 - acc: 0.9540 - val_loss: 0.0035 - val_acc: 0.9586\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0034 - acc: 0.9574 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0034 - val_acc: 0.9598\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9596\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0034 - acc: 0.9553 - val_loss: 0.0035 - val_acc: 0.9582\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0034 - acc: 0.9540 - val_loss: 0.0034 - val_acc: 0.9577\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0033 - acc: 0.9573 - val_loss: 0.0034 - val_acc: 0.9609\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0034 - acc: 0.9567 - val_loss: 0.0035 - val_acc: 0.9592\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0033 - acc: 0.9571 - val_loss: 0.0035 - val_acc: 0.9580\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0035 - acc: 0.9536 - val_loss: 0.0037 - val_acc: 0.9556\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0035 - acc: 0.9548 - val_loss: 0.0035 - val_acc: 0.9584\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9558 - val_loss: 0.0036 - val_acc: 0.9585\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0034 - acc: 0.9573 - val_loss: 0.0034 - val_acc: 0.9610\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0035 - acc: 0.9508 - val_loss: 0.0035 - val_acc: 0.9608\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0034 - acc: 0.9558 - val_loss: 0.0034 - val_acc: 0.9618\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0035 - acc: 0.9529 - val_loss: 0.0035 - val_acc: 0.9596\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0035 - acc: 0.9539 - val_loss: 0.0035 - val_acc: 0.9591\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0033 - acc: 0.9569 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "start training round 4\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2490 - acc: 0.6790 - val_loss: 0.2614 - val_acc: 0.6761\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2464 - acc: 0.6788 - val_loss: 0.2658 - val_acc: 0.6701\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2519 - acc: 0.6762 - val_loss: 0.2712 - val_acc: 0.6721\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2510 - acc: 0.6768 - val_loss: 0.2683 - val_acc: 0.6726\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2458 - acc: 0.6789 - val_loss: 0.2616 - val_acc: 0.6748\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2483 - acc: 0.6790 - val_loss: 0.2635 - val_acc: 0.6749\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2481 - acc: 0.6782 - val_loss: 0.2613 - val_acc: 0.6764\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2501 - acc: 0.6772 - val_loss: 0.2738 - val_acc: 0.6704\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2493 - acc: 0.6769 - val_loss: 0.2606 - val_acc: 0.6760\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2459 - acc: 0.6797 - val_loss: 0.2587 - val_acc: 0.6777\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2477 - acc: 0.6786 - val_loss: 0.2594 - val_acc: 0.6772\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2503 - acc: 0.6780 - val_loss: 0.2635 - val_acc: 0.6767\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2483 - acc: 0.6796 - val_loss: 0.2585 - val_acc: 0.6768\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2452 - acc: 0.6797 - val_loss: 0.2614 - val_acc: 0.6730\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2496 - acc: 0.6771 - val_loss: 0.2654 - val_acc: 0.6723\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2486 - acc: 0.6773 - val_loss: 0.2600 - val_acc: 0.6776\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2466 - acc: 0.6784 - val_loss: 0.2585 - val_acc: 0.6789\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2471 - acc: 0.6790 - val_loss: 0.2577 - val_acc: 0.6780\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2468 - acc: 0.6789 - val_loss: 0.2673 - val_acc: 0.6750\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2496 - acc: 0.6783 - val_loss: 0.2681 - val_acc: 0.6706\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2491 - acc: 0.6774 - val_loss: 0.2587 - val_acc: 0.6767\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2478 - acc: 0.6778 - val_loss: 0.2580 - val_acc: 0.6763\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2466 - acc: 0.6791 - val_loss: 0.2695 - val_acc: 0.6716\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2487 - acc: 0.6787 - val_loss: 0.2606 - val_acc: 0.6763\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2490 - acc: 0.6799 - val_loss: 0.2582 - val_acc: 0.6776\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2482 - acc: 0.6782 - val_loss: 0.2642 - val_acc: 0.6746\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2500 - acc: 0.6777 - val_loss: 0.2630 - val_acc: 0.6761\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2472 - acc: 0.6777 - val_loss: 0.2585 - val_acc: 0.6772\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2470 - acc: 0.6785 - val_loss: 0.2601 - val_acc: 0.6771\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2493 - acc: 0.6787 - val_loss: 0.2612 - val_acc: 0.6767\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2456 - acc: 0.6799 - val_loss: 0.2561 - val_acc: 0.6776\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2436 - acc: 0.6801 - val_loss: 0.2607 - val_acc: 0.6780\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2491 - acc: 0.6779 - val_loss: 0.2683 - val_acc: 0.6755\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2489 - acc: 0.6790 - val_loss: 0.2572 - val_acc: 0.6769\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2482 - acc: 0.6780 - val_loss: 0.2610 - val_acc: 0.6765\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2487 - acc: 0.6777 - val_loss: 0.2590 - val_acc: 0.6767\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2464 - acc: 0.6792 - val_loss: 0.2603 - val_acc: 0.6762\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2448 - acc: 0.6802 - val_loss: 0.2577 - val_acc: 0.6790\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2483 - acc: 0.6782 - val_loss: 0.2577 - val_acc: 0.6771\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2450 - acc: 0.6804 - val_loss: 0.2607 - val_acc: 0.6749\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2441 - acc: 0.6806 - val_loss: 0.2671 - val_acc: 0.6759\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2515 - acc: 0.6774 - val_loss: 0.2650 - val_acc: 0.6766\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2525 - acc: 0.6781 - val_loss: 0.2569 - val_acc: 0.6782\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2462 - acc: 0.6796 - val_loss: 0.2588 - val_acc: 0.6768\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2484 - acc: 0.6791 - val_loss: 0.2667 - val_acc: 0.6724\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2516 - acc: 0.6761 - val_loss: 0.2616 - val_acc: 0.6783\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2472 - acc: 0.6794 - val_loss: 0.2587 - val_acc: 0.6773\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2472 - acc: 0.6800 - val_loss: 0.2607 - val_acc: 0.6775\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2479 - acc: 0.6791 - val_loss: 0.2574 - val_acc: 0.6768\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2458 - acc: 0.6798 - val_loss: 0.2601 - val_acc: 0.6780\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0108 - acc: 0.6761 - val_loss: 2.2236 - val_acc: 0.6750\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0409 - acc: 0.6755 - val_loss: 2.1747 - val_acc: 0.6725\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0268 - acc: 0.6768 - val_loss: 2.1366 - val_acc: 0.6728\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0183 - acc: 0.6762 - val_loss: 2.1519 - val_acc: 0.6736\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0063 - acc: 0.6765 - val_loss: 2.2151 - val_acc: 0.6683\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0201 - acc: 0.6759 - val_loss: 2.1899 - val_acc: 0.6692\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 2.0075 - acc: 0.6768 - val_loss: 2.1853 - val_acc: 0.6723\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0415 - acc: 0.6769 - val_loss: 2.1775 - val_acc: 0.6706\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 2.0219 - acc: 0.6770 - val_loss: 2.1222 - val_acc: 0.6762\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0019 - acc: 0.6761 - val_loss: 2.2447 - val_acc: 0.6703\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0590 - acc: 0.6766 - val_loss: 2.1961 - val_acc: 0.6719\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0197 - acc: 0.6769 - val_loss: 2.1095 - val_acc: 0.6739\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0347 - acc: 0.6765 - val_loss: 2.1612 - val_acc: 0.6740\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 1.9916 - acc: 0.6777 - val_loss: 2.1265 - val_acc: 0.6746\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0038 - acc: 0.6762 - val_loss: 2.1687 - val_acc: 0.6690\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0327 - acc: 0.6750 - val_loss: 2.2269 - val_acc: 0.6710\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0284 - acc: 0.6764 - val_loss: 2.1489 - val_acc: 0.6758\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0425 - acc: 0.6763 - val_loss: 2.1520 - val_acc: 0.6771\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0033 - acc: 0.6761 - val_loss: 2.1583 - val_acc: 0.6719\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0226 - acc: 0.6758 - val_loss: 2.1720 - val_acc: 0.6705\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 2.0220 - acc: 0.6757 - val_loss: 2.1550 - val_acc: 0.6721\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9932 - acc: 0.6762 - val_loss: 2.1431 - val_acc: 0.6747\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9986 - acc: 0.6769 - val_loss: 2.1412 - val_acc: 0.6753\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9882 - acc: 0.6772 - val_loss: 2.2234 - val_acc: 0.6695\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0331 - acc: 0.6751 - val_loss: 2.1989 - val_acc: 0.6693\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0404 - acc: 0.6761 - val_loss: 2.1897 - val_acc: 0.6732\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0167 - acc: 0.6770 - val_loss: 2.1781 - val_acc: 0.6717\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0393 - acc: 0.6765 - val_loss: 2.1307 - val_acc: 0.6751\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0421 - acc: 0.6765 - val_loss: 2.1156 - val_acc: 0.6781\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0069 - acc: 0.6772 - val_loss: 2.2308 - val_acc: 0.6746\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0395 - acc: 0.6765 - val_loss: 2.1278 - val_acc: 0.6764\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0058 - acc: 0.6765 - val_loss: 2.1409 - val_acc: 0.6723\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0195 - acc: 0.6760 - val_loss: 2.1252 - val_acc: 0.6729\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0243 - acc: 0.6767 - val_loss: 2.1221 - val_acc: 0.67330.677\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0017 - acc: 0.6761 - val_loss: 2.1468 - val_acc: 0.6714\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0422 - acc: 0.6755 - val_loss: 2.2467 - val_acc: 0.6680\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0145 - acc: 0.6775 - val_loss: 2.2068 - val_acc: 0.6737\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 2.0195 - acc: 0.6771 - val_loss: 2.1346 - val_acc: 0.6742\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9970 - acc: 0.6766 - val_loss: 2.1009 - val_acc: 0.6765\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0100 - acc: 0.6763 - val_loss: 2.1490 - val_acc: 0.6723\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0263 - acc: 0.6763 - val_loss: 2.2323 - val_acc: 0.6692\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0215 - acc: 0.6766 - val_loss: 2.1157 - val_acc: 0.6757\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0105 - acc: 0.6766 - val_loss: 2.1542 - val_acc: 0.6743\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0110 - acc: 0.6760 - val_loss: 2.1362 - val_acc: 0.6721\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 2.0259 - acc: 0.6767 - val_loss: 2.1820 - val_acc: 0.6760\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0367 - acc: 0.6768 - val_loss: 2.3155 - val_acc: 0.6735\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 2.0155 - acc: 0.6768 - val_loss: 2.1788 - val_acc: 0.6741\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0108 - acc: 0.6764 - val_loss: 2.1781 - val_acc: 0.6768\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0036 - acc: 0.6771 - val_loss: 2.1550 - val_acc: 0.6757\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0154 - acc: 0.6765 - val_loss: 2.2859 - val_acc: 0.6714\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2145 - acc: 0.9909 - val_loss: 0.2202 - val_acc: 0.9890\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2108 - acc: 0.9914 - val_loss: 0.2134 - val_acc: 0.9892\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2223 - acc: 0.9913 - val_loss: 0.2342 - val_acc: 0.9896\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2286 - acc: 0.9920 - val_loss: 0.2298 - val_acc: 0.9895\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2405 - acc: 0.9914 - val_loss: 0.2269 - val_acc: 0.9892\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2151 - acc: 0.9915 - val_loss: 0.2149 - val_acc: 0.9897\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2138 - acc: 0.9919 - val_loss: 0.2146 - val_acc: 0.9897\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2198 - acc: 0.9919 - val_loss: 0.2177 - val_acc: 0.9896\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2053 - acc: 0.9920 - val_loss: 0.2046 - val_acc: 0.9896\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2102 - acc: 0.9918 - val_loss: 0.2229 - val_acc: 0.9893\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2190 - acc: 0.9913 - val_loss: 0.2158 - val_acc: 0.9891\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2113 - acc: 0.9911 - val_loss: 0.2124 - val_acc: 0.9892\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2097 - acc: 0.9916 - val_loss: 0.2088 - val_acc: 0.9895\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2080 - acc: 0.9917 - val_loss: 0.2127 - val_acc: 0.9896\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2195 - acc: 0.9919 - val_loss: 0.2337 - val_acc: 0.9896\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2297 - acc: 0.9920 - val_loss: 0.2276 - val_acc: 0.9896\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2245 - acc: 0.9920 - val_loss: 0.2217 - val_acc: 0.9896\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2207 - acc: 0.9920 - val_loss: 0.2160 - val_acc: 0.9895\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2179 - acc: 0.9919 - val_loss: 0.2213 - val_acc: 0.9895\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2117 - acc: 0.9917 - val_loss: 0.2208 - val_acc: 0.9891\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2158 - acc: 0.9911 - val_loss: 0.2116 - val_acc: 0.9893\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2056 - acc: 0.9915 - val_loss: 0.2123 - val_acc: 0.9890\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2129 - acc: 0.9910 - val_loss: 0.2231 - val_acc: 0.9889\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2273 - acc: 0.9905 - val_loss: 0.2229 - val_acc: 0.9887\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2099 - acc: 0.9913 - val_loss: 0.2140 - val_acc: 0.9895\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2133 - acc: 0.9918 - val_loss: 0.2128 - val_acc: 0.9896\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2120 - acc: 0.9920 - val_loss: 0.2251 - val_acc: 0.9897\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2331 - acc: 0.9920 - val_loss: 0.2322 - val_acc: 0.9898\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2256 - acc: 0.9920 - val_loss: 0.2200 - val_acc: 0.9898\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2160 - acc: 0.9920 - val_loss: 0.2118 - val_acc: 0.9896\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 0.2166 - acc: 0.9920 - val_loss: 0.2269 - val_acc: 0.9897\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2299 - acc: 0.9914 - val_loss: 0.2254 - val_acc: 0.9893\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2066 - acc: 0.9920 - val_loss: 0.2051 - val_acc: 0.9898\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2006 - acc: 0.9920 - val_loss: 0.2027 - val_acc: 0.9897\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1985 - acc: 0.9920 - val_loss: 0.1999 - val_acc: 0.9897\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.1978 - acc: 0.9920 - val_loss: 0.2001 - val_acc: 0.9898\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2028 - acc: 0.9920 - val_loss: 0.2261 - val_acc: 0.9895\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2436 - acc: 0.9909 - val_loss: 0.2430 - val_acc: 0.9893\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 0.2231 - acc: 0.9920 - val_loss: 0.2191 - val_acc: 0.9896\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2077 - acc: 0.9919 - val_loss: 0.2105 - val_acc: 0.9894\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2287 - acc: 0.9905 - val_loss: 0.2410 - val_acc: 0.9880\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2250 - acc: 0.9914 - val_loss: 0.2086 - val_acc: 0.9896\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2045 - acc: 0.9919 - val_loss: 0.2043 - val_acc: 0.9897\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2002 - acc: 0.9918 - val_loss: 0.2012 - val_acc: 0.9896\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2009 - acc: 0.9918 - val_loss: 0.2085 - val_acc: 0.9892\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2225 - acc: 0.9911 - val_loss: 0.2275 - val_acc: 0.9896\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2286 - acc: 0.9920 - val_loss: 0.2234 - val_acc: 0.9896\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2193 - acc: 0.9916 - val_loss: 0.2193 - val_acc: 0.9892ss: 0.2203\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2102 - acc: 0.9918 - val_loss: 0.2165 - val_acc: 0.9896\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2144 - acc: 0.9918 - val_loss: 0.2101 - val_acc: 0.9895\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9579 - val_loss: 0.0035 - val_acc: 0.9622\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0034 - acc: 0.9568 - val_loss: 0.0035 - val_acc: 0.9612\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0033 - acc: 0.9582 - val_loss: 0.0034 - val_acc: 0.9617\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0034 - acc: 0.9557 - val_loss: 0.0034 - val_acc: 0.9609\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9574 - val_loss: 0.0034 - val_acc: 0.9590\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0034 - acc: 0.9557 - val_loss: 0.0034 - val_acc: 0.9620\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0034 - acc: 0.9571 - val_loss: 0.0035 - val_acc: 0.9615\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0034 - acc: 0.9572 - val_loss: 0.0035 - val_acc: 0.9584\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0034 - acc: 0.9539 - val_loss: 0.0035 - val_acc: 0.9593\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.0034 - acc: 0.9559 - val_loss: 0.0034 - val_acc: 0.9591\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9543 - val_loss: 0.0035 - val_acc: 0.9580\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.0034 - acc: 0.9529 - val_loss: 0.0035 - val_acc: 0.9575\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0034 - acc: 0.9553 - val_loss: 0.0035 - val_acc: 0.9574\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0034 - acc: 0.9558 - val_loss: 0.0035 - val_acc: 0.9580\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0034 - val_acc: 0.9600\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0033 - acc: 0.9575 - val_loss: 0.0034 - val_acc: 0.9610\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0034 - val_acc: 0.9611\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9545 - val_loss: 0.0035 - val_acc: 0.9611\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0034 - acc: 0.9560 - val_loss: 0.0035 - val_acc: 0.9590\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9573 - val_loss: 0.0034 - val_acc: 0.9613\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0035 - val_acc: 0.9619\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0034 - acc: 0.9571 - val_loss: 0.0035 - val_acc: 0.9596\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0034 - acc: 0.9547 - val_loss: 0.0034 - val_acc: 0.9606\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0034 - val_acc: 0.9604\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0034 - acc: 0.9557 - val_loss: 0.0035 - val_acc: 0.9587\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0034 - acc: 0.9563 - val_loss: 0.0040 - val_acc: 0.9502\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0036 - acc: 0.9507 - val_loss: 0.0035 - val_acc: 0.9590\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9614\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9583 - val_loss: 0.0034 - val_acc: 0.9610\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0035 - val_acc: 0.9584\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0035 - acc: 0.9542 - val_loss: 0.0036 - val_acc: 0.9564\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0034 - acc: 0.9571 - val_loss: 0.0034 - val_acc: 0.9602\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0034 - val_acc: 0.9610\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0035 - val_acc: 0.9584\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.0033 - acc: 0.9570 - val_loss: 0.0035 - val_acc: 0.9585\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0034 - acc: 0.9546 - val_loss: 0.0035 - val_acc: 0.9577\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0035 - acc: 0.9525 - val_loss: 0.0034 - val_acc: 0.9599\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0035 - val_acc: 0.9612\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0035 - acc: 0.9523 - val_loss: 0.0035 - val_acc: 0.9610\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9544 - val_loss: 0.0036 - val_acc: 0.9548\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0034 - val_acc: 0.9618\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0033 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9619\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0034 - val_acc: 0.9617\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0034 - acc: 0.9537 - val_loss: 0.0035 - val_acc: 0.9571\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0034 - acc: 0.9546 - val_loss: 0.0036 - val_acc: 0.9552\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0035 - acc: 0.9524 - val_loss: 0.0037 - val_acc: 0.9559\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0034 - acc: 0.9526 - val_loss: 0.0035 - val_acc: 0.9603\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0033 - acc: 0.9563 - val_loss: 0.0034 - val_acc: 0.9622\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0034 - val_acc: 0.9599\n",
      "start training round 5\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2493 - acc: 0.6779 - val_loss: 0.2610 - val_acc: 0.6740\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2460 - acc: 0.6784 - val_loss: 0.2623 - val_acc: 0.6725\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2483 - acc: 0.6782 - val_loss: 0.2592 - val_acc: 0.6770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2467 - acc: 0.6791 - val_loss: 0.2665 - val_acc: 0.6750\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2471 - acc: 0.6791 - val_loss: 0.2582 - val_acc: 0.6767\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2461 - acc: 0.6784 - val_loss: 0.2639 - val_acc: 0.6716\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2471 - acc: 0.6788 - val_loss: 0.2606 - val_acc: 0.6776\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2463 - acc: 0.6795 - val_loss: 0.2606 - val_acc: 0.6752\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2476 - acc: 0.6785 - val_loss: 0.2656 - val_acc: 0.6756\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2497 - acc: 0.6782 - val_loss: 0.2622 - val_acc: 0.6766\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2466 - acc: 0.6796 - val_loss: 0.2576 - val_acc: 0.6794\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2442 - acc: 0.6804 - val_loss: 0.2585 - val_acc: 0.6768\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2500 - acc: 0.6779 - val_loss: 0.2557 - val_acc: 0.6779\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.2447 - acc: 0.6799 - val_loss: 0.2579 - val_acc: 0.6771\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2460 - acc: 0.6796 - val_loss: 0.2587 - val_acc: 0.6766\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2492 - acc: 0.6778 - val_loss: 0.2663 - val_acc: 0.6788\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2515 - acc: 0.6796 - val_loss: 0.2579 - val_acc: 0.6784\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2424 - acc: 0.6811 - val_loss: 0.2565 - val_acc: 0.6785\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2476 - acc: 0.6779 - val_loss: 0.2594 - val_acc: 0.6752\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2456 - acc: 0.6787 - val_loss: 0.2580 - val_acc: 0.6765\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2454 - acc: 0.6803 - val_loss: 0.2603 - val_acc: 0.6786\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2476 - acc: 0.6803 - val_loss: 0.2583 - val_acc: 0.6785\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2438 - acc: 0.6805 - val_loss: 0.2574 - val_acc: 0.6787\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2499 - acc: 0.6779 - val_loss: 0.2590 - val_acc: 0.6758\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2444 - acc: 0.6804 - val_loss: 0.2581 - val_acc: 0.6778\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2453 - acc: 0.6796 - val_loss: 0.2563 - val_acc: 0.6776\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2466 - acc: 0.6794 - val_loss: 0.2654 - val_acc: 0.6744\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2466 - acc: 0.6790 - val_loss: 0.2631 - val_acc: 0.6743\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2490 - acc: 0.6779 - val_loss: 0.2601 - val_acc: 0.6755\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2441 - acc: 0.6795 - val_loss: 0.2597 - val_acc: 0.6742\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2461 - acc: 0.6793 - val_loss: 0.2567 - val_acc: 0.6767\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2474 - acc: 0.6796 - val_loss: 0.2580 - val_acc: 0.6757\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2440 - acc: 0.6799 - val_loss: 0.2590 - val_acc: 0.6764\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2449 - acc: 0.6802 - val_loss: 0.2641 - val_acc: 0.6751\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2488 - acc: 0.6780 - val_loss: 0.2590 - val_acc: 0.6780\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2502 - acc: 0.6781 - val_loss: 0.2595 - val_acc: 0.6785\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2468 - acc: 0.6793 - val_loss: 0.2557 - val_acc: 0.6790\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2441 - acc: 0.6802 - val_loss: 0.2640 - val_acc: 0.6781\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2468 - acc: 0.6804 - val_loss: 0.2636 - val_acc: 0.6753\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2461 - acc: 0.6805 - val_loss: 0.2610 - val_acc: 0.6767\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2472 - acc: 0.6795 - val_loss: 0.2682 - val_acc: 0.6779\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2468 - acc: 0.6795 - val_loss: 0.2583 - val_acc: 0.6765\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2453 - acc: 0.6792 - val_loss: 0.2597 - val_acc: 0.6766\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2460 - acc: 0.6799 - val_loss: 0.2555 - val_acc: 0.6794\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2478 - acc: 0.6809 - val_loss: 0.2590 - val_acc: 0.6780\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2463 - acc: 0.6801 - val_loss: 0.2598 - val_acc: 0.6789\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2457 - acc: 0.6801 - val_loss: 0.2565 - val_acc: 0.6788\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2452 - acc: 0.6796 - val_loss: 0.2628 - val_acc: 0.6751\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2464 - acc: 0.6789 - val_loss: 0.2583 - val_acc: 0.6777\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2445 - acc: 0.6801 - val_loss: 0.2551 - val_acc: 0.6773\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0327 - acc: 0.6768 - val_loss: 2.1687 - val_acc: 0.6750\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 2.0337 - acc: 0.6762 - val_loss: 2.1906 - val_acc: 0.6726\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0224 - acc: 0.6752 - val_loss: 2.1030 - val_acc: 0.6759\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 2.0111 - acc: 0.6770 - val_loss: 2.1073 - val_acc: 0.6763\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0047 - acc: 0.6766 - val_loss: 2.1161 - val_acc: 0.6758\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0346 - acc: 0.6774 - val_loss: 2.1256 - val_acc: 0.6742\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0019 - acc: 0.6767 - val_loss: 2.2147 - val_acc: 0.6709\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0391 - acc: 0.6763 - val_loss: 2.1591 - val_acc: 0.6718\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0058 - acc: 0.6774 - val_loss: 2.1484 - val_acc: 0.6718\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0042 - acc: 0.6771 - val_loss: 2.1347 - val_acc: 0.6717\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0243 - acc: 0.6760 - val_loss: 2.1907 - val_acc: 0.6698\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0038 - acc: 0.6764 - val_loss: 2.1293 - val_acc: 0.6761\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9977 - acc: 0.6778 - val_loss: 2.1432 - val_acc: 0.6744\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0244 - acc: 0.6766 - val_loss: 2.1285 - val_acc: 0.6754\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9966 - acc: 0.6762 - val_loss: 2.2887 - val_acc: 0.6735\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0432 - acc: 0.6759 - val_loss: 2.1127 - val_acc: 0.6756\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9998 - acc: 0.6761 - val_loss: 2.1335 - val_acc: 0.6741\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0417 - acc: 0.6761 - val_loss: 2.2088 - val_acc: 0.6713\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 2.0092 - acc: 0.6767 - val_loss: 2.1536 - val_acc: 0.6719\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0012 - acc: 0.6772 - val_loss: 2.1626 - val_acc: 0.6719\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0143 - acc: 0.6767 - val_loss: 2.1272 - val_acc: 0.6761\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 2.0156 - acc: 0.6771 - val_loss: 2.2915 - val_acc: 0.6739\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0352 - acc: 0.6765 - val_loss: 2.1256 - val_acc: 0.6756\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 1.9950 - acc: 0.6775 - val_loss: 2.2171 - val_acc: 0.6749\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0198 - acc: 0.6776 - val_loss: 2.1211 - val_acc: 0.6772\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9999 - acc: 0.6771 - val_loss: 2.1673 - val_acc: 0.6717\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0250 - acc: 0.6759 - val_loss: 2.1257 - val_acc: 0.6739\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9844 - acc: 0.6768 - val_loss: 2.1528 - val_acc: 0.6750\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 2.0366 - acc: 0.6759 - val_loss: 2.1315 - val_acc: 0.6777\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0036 - acc: 0.6770 - val_loss: 2.1264 - val_acc: 0.6745\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0347 - acc: 0.6775 - val_loss: 2.1274 - val_acc: 0.6746\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0049 - acc: 0.6781 - val_loss: 2.1740 - val_acc: 0.6724\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0248 - acc: 0.6773 - val_loss: 2.2187 - val_acc: 0.6753\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0375 - acc: 0.6770 - val_loss: 2.1250 - val_acc: 0.6732\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0000 - acc: 0.6755 - val_loss: 2.1305 - val_acc: 0.6761\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0284 - acc: 0.6759 - val_loss: 2.1328 - val_acc: 0.6753\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0106 - acc: 0.6772 - val_loss: 2.2222 - val_acc: 0.6672\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0335 - acc: 0.6771 - val_loss: 2.1445 - val_acc: 0.6745\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9997 - acc: 0.6781 - val_loss: 2.1421 - val_acc: 0.6735\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0002 - acc: 0.6769 - val_loss: 2.1977 - val_acc: 0.6721- loss:\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9966 - acc: 0.6771 - val_loss: 2.1041 - val_acc: 0.6745\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0101 - acc: 0.6773 - val_loss: 2.1276 - val_acc: 0.6727\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0205 - acc: 0.6763 - val_loss: 2.2186 - val_acc: 0.6722\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9980 - acc: 0.6776 - val_loss: 2.2307 - val_acc: 0.6693\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 2.0327 - acc: 0.6763 - val_loss: 2.1410 - val_acc: 0.6721\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0033 - acc: 0.6771 - val_loss: 2.1704 - val_acc: 0.6758\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0358 - acc: 0.6758 - val_loss: 2.1532 - val_acc: 0.6731\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0097 - acc: 0.6763 - val_loss: 2.2186 - val_acc: 0.6690\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0378 - acc: 0.6761 - val_loss: 2.1729 - val_acc: 0.6713\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0246 - acc: 0.6775 - val_loss: 2.2965 - val_acc: 0.6737\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2168 - acc: 0.9918 - val_loss: 0.2123 - val_acc: 0.9897\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2181 - acc: 0.9917 - val_loss: 0.2402 - val_acc: 0.9892\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2356 - acc: 0.9910 - val_loss: 0.2152 - val_acc: 0.9894\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2033 - acc: 0.9918 - val_loss: 0.2000 - val_acc: 0.9897\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2006 - acc: 0.9918 - val_loss: 0.2081 - val_acc: 0.9894\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2079 - acc: 0.9918 - val_loss: 0.2131 - val_acc: 0.9894\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2204 - acc: 0.9920 - val_loss: 0.2338 - val_acc: 0.9896acc: 0.99\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2315 - acc: 0.9920 - val_loss: 0.2202 - val_acc: 0.9898\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2103 - acc: 0.9920 - val_loss: 0.2178 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2191 - acc: 0.9920 - val_loss: 0.2163 - val_acc: 0.9897\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2066 - acc: 0.9920 - val_loss: 0.2032 - val_acc: 0.9897\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1992 - acc: 0.9920 - val_loss: 0.2027 - val_acc: 0.9897\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2050 - acc: 0.9916 - val_loss: 0.2344 - val_acc: 0.9888\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2343 - acc: 0.9900 - val_loss: 0.2342 - val_acc: 0.9878\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2223 - acc: 0.9903 - val_loss: 0.2159 - val_acc: 0.9889\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2066 - acc: 0.9913 - val_loss: 0.2026 - val_acc: 0.9895\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2020 - acc: 0.9919 - val_loss: 0.2095 - val_acc: 0.9897\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2084 - acc: 0.9920 - val_loss: 0.2116 - val_acc: 0.9896\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2193 - acc: 0.9915 - val_loss: 0.2398 - val_acc: 0.9894\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2379 - acc: 0.9919 - val_loss: 0.2508 - val_acc: 0.9897\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2240 - acc: 0.9920 - val_loss: 0.2163 - val_acc: 0.9897\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.2140 - acc: 0.9919 - val_loss: 0.2133 - val_acc: 0.9897\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2066 - acc: 0.9920 - val_loss: 0.2039 - val_acc: 0.9898\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2048 - acc: 0.9920 - val_loss: 0.2094 - val_acc: 0.9896\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2137 - acc: 0.9920 - val_loss: 0.2144 - val_acc: 0.9896\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2071 - acc: 0.9918 - val_loss: 0.2193 - val_acc: 0.9895\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2159 - acc: 0.9916 - val_loss: 0.2191 - val_acc: 0.9896\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2277 - acc: 0.9919 - val_loss: 0.2473 - val_acc: 0.9893\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2350 - acc: 0.9913 - val_loss: 0.2208 - val_acc: 0.9889\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2137 - acc: 0.9915 - val_loss: 0.2105 - val_acc: 0.9889\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2145 - acc: 0.9906 - val_loss: 0.2124 - val_acc: 0.9886\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2042 - acc: 0.9917 - val_loss: 0.2104 - val_acc: 0.9896\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.2108 - acc: 0.9919 - val_loss: 0.2146 - val_acc: 0.9898\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2140 - acc: 0.9921 - val_loss: 0.2128 - val_acc: 0.9898\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2196 - acc: 0.9921 - val_loss: 0.2238 - val_acc: 0.9898\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2077 - acc: 0.9920 - val_loss: 0.2023 - val_acc: 0.9896\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 0.2014 - acc: 0.9920 - val_loss: 0.2030 - val_acc: 0.9899\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2086 - acc: 0.9920 - val_loss: 0.2225 - val_acc: 0.9896\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2147 - acc: 0.9918 - val_loss: 0.2143 - val_acc: 0.9897\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2060 - acc: 0.9920 - val_loss: 0.2075 - val_acc: 0.9897\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2049 - acc: 0.9919 - val_loss: 0.2107 - val_acc: 0.9896\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2160 - acc: 0.9920 - val_loss: 0.2345 - val_acc: 0.9894\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2265 - acc: 0.9914 - val_loss: 0.2331 - val_acc: 0.9873\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2296 - acc: 0.9900 - val_loss: 0.2195 - val_acc: 0.9888\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 364us/step - loss: 0.2137 - acc: 0.9912 - val_loss: 0.2198 - val_acc: 0.9894\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2204 - acc: 0.9917 - val_loss: 0.2356 - val_acc: 0.9897\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2188 - acc: 0.9916 - val_loss: 0.2144 - val_acc: 0.9892\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2052 - acc: 0.9916 - val_loss: 0.2100 - val_acc: 0.9892\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2030 - acc: 0.9915 - val_loss: 0.2083 - val_acc: 0.9892\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2064 - acc: 0.9913 - val_loss: 0.2092 - val_acc: 0.9894\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0035 - val_acc: 0.9579\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9545 - val_loss: 0.0037 - val_acc: 0.9517\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0035 - acc: 0.9548 - val_loss: 0.0035 - val_acc: 0.9578\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0034 - acc: 0.9548 - val_loss: 0.0035 - val_acc: 0.9579\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0034 - acc: 0.9545 - val_loss: 0.0034 - val_acc: 0.9609\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0033 - acc: 0.9583 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0034 - acc: 0.9557 - val_loss: 0.0034 - val_acc: 0.9587\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0034 - val_acc: 0.9593\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0034 - acc: 0.9562 - val_loss: 0.0035 - val_acc: 0.9576\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0034 - acc: 0.9537 - val_loss: 0.0034 - val_acc: 0.9584\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0033 - acc: 0.9561 - val_loss: 0.0035 - val_acc: 0.9615\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 409us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0035 - val_acc: 0.9564\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0033 - acc: 0.9564 - val_loss: 0.0035 - val_acc: 0.9617\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0034 - acc: 0.9564 - val_loss: 0.0034 - val_acc: 0.9621\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0037 - val_acc: 0.9540\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0034 - acc: 0.9543 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0033 - acc: 0.9549 - val_loss: 0.0035 - val_acc: 0.9590\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0033 - acc: 0.9567 - val_loss: 0.0037 - val_acc: 0.9550\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0033 - acc: 0.9550 - val_loss: 0.0034 - val_acc: 0.9620\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9579 - val_loss: 0.0034 - val_acc: 0.9602\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0034 - acc: 0.9554 - val_loss: 0.0035 - val_acc: 0.9595\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0034 - acc: 0.9551 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0033 - acc: 0.9579 - val_loss: 0.0035 - val_acc: 0.9601\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.0035 - acc: 0.9517 - val_loss: 0.0035 - val_acc: 0.9605\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0035 - acc: 0.9545 - val_loss: 0.0036 - val_acc: 0.9548\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0035 - acc: 0.9524 - val_loss: 0.0034 - val_acc: 0.9618\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0033 - acc: 0.9567 - val_loss: 0.0035 - val_acc: 0.9619\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9561 - val_loss: 0.0035 - val_acc: 0.9620\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0034 - acc: 0.9568 - val_loss: 0.0035 - val_acc: 0.9595\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0033 - acc: 0.9557 - val_loss: 0.0035 - val_acc: 0.9582\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9562 - val_loss: 0.0034 - val_acc: 0.9611\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.0033 - acc: 0.9582 - val_loss: 0.0034 - val_acc: 0.9598\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0035 - acc: 0.9525 - val_loss: 0.0036 - val_acc: 0.9567\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0033 - acc: 0.9570 - val_loss: 0.0035 - val_acc: 0.9588\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0033 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9571 - val_loss: 0.0034 - val_acc: 0.9601\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0035 - val_acc: 0.9603\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0033 - acc: 0.9574 - val_loss: 0.0036 - val_acc: 0.9573\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0035 - acc: 0.9506 - val_loss: 0.0034 - val_acc: 0.9615\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9539 - val_loss: 0.0035 - val_acc: 0.9597\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9560 - val_loss: 0.0034 - val_acc: 0.9621\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0035 - val_acc: 0.9608\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0036 - val_acc: 0.9585\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0034 - acc: 0.9558 - val_loss: 0.0035 - val_acc: 0.9623\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9537 - val_loss: 0.0034 - val_acc: 0.9603\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0034 - acc: 0.9552 - val_loss: 0.0034 - val_acc: 0.9617\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0033 - acc: 0.9583 - val_loss: 0.0034 - val_acc: 0.9591\n",
      "start training round 6\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2471 - acc: 0.6798 - val_loss: 0.2627 - val_acc: 0.6764\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2482 - acc: 0.6784 - val_loss: 0.2622 - val_acc: 0.6753\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2476 - acc: 0.6793 - val_loss: 0.2581 - val_acc: 0.6771\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2463 - acc: 0.6795 - val_loss: 0.2571 - val_acc: 0.6781\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2470 - acc: 0.6796 - val_loss: 0.2571 - val_acc: 0.6768\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2427 - acc: 0.6813 - val_loss: 0.2561 - val_acc: 0.6771\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2481 - acc: 0.6807 - val_loss: 0.2621 - val_acc: 0.6791\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2485 - acc: 0.6792 - val_loss: 0.2551 - val_acc: 0.6784\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2440 - acc: 0.6804 - val_loss: 0.2584 - val_acc: 0.6785\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2491 - acc: 0.6784 - val_loss: 0.2565 - val_acc: 0.6798\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2451 - acc: 0.6805 - val_loss: 0.2590 - val_acc: 0.6784\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2436 - acc: 0.6808 - val_loss: 0.2602 - val_acc: 0.6770\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2477 - acc: 0.6790 - val_loss: 0.2589 - val_acc: 0.6779\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2440 - acc: 0.6808 - val_loss: 0.2568 - val_acc: 0.6781\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 0.2435 - acc: 0.6808 - val_loss: 0.2553 - val_acc: 0.6789\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2494 - acc: 0.6788 - val_loss: 0.2581 - val_acc: 0.6759\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2439 - acc: 0.6797 - val_loss: 0.2539 - val_acc: 0.6794\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2449 - acc: 0.6801 - val_loss: 0.2575 - val_acc: 0.6783\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2482 - acc: 0.6787 - val_loss: 0.2685 - val_acc: 0.6724\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2476 - acc: 0.6791 - val_loss: 0.2570 - val_acc: 0.6772\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2463 - acc: 0.6804 - val_loss: 0.2600 - val_acc: 0.6749\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2455 - acc: 0.6796 - val_loss: 0.2556 - val_acc: 0.6782\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2460 - acc: 0.6786 - val_loss: 0.2557 - val_acc: 0.6796\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2453 - acc: 0.6790 - val_loss: 0.2576 - val_acc: 0.6800\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2424 - acc: 0.6809 - val_loss: 0.2574 - val_acc: 0.6777\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2437 - acc: 0.6807 - val_loss: 0.2592 - val_acc: 0.6785\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2463 - acc: 0.6809 - val_loss: 0.2722 - val_acc: 0.6760\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2483 - acc: 0.6803 - val_loss: 0.2544 - val_acc: 0.6795\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2428 - acc: 0.6814 - val_loss: 0.2577 - val_acc: 0.6760\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2449 - acc: 0.6793 - val_loss: 0.2561 - val_acc: 0.6783\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2462 - acc: 0.6812 - val_loss: 0.2579 - val_acc: 0.6800\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2451 - acc: 0.6799 - val_loss: 0.2572 - val_acc: 0.6788\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2461 - acc: 0.6789 - val_loss: 0.2599 - val_acc: 0.6777\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2483 - acc: 0.6792 - val_loss: 0.2624 - val_acc: 0.6738\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2455 - acc: 0.6794 - val_loss: 0.2581 - val_acc: 0.6801\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2444 - acc: 0.6806 - val_loss: 0.2566 - val_acc: 0.6781\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2468 - acc: 0.6798 - val_loss: 0.2559 - val_acc: 0.6787\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.2496 - acc: 0.6786 - val_loss: 0.2667 - val_acc: 0.6766\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2451 - acc: 0.6803 - val_loss: 0.2550 - val_acc: 0.6792\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2443 - acc: 0.6804 - val_loss: 0.2635 - val_acc: 0.6757\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2473 - acc: 0.6783 - val_loss: 0.2585 - val_acc: 0.6758\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2422 - acc: 0.6812 - val_loss: 0.2563 - val_acc: 0.6782\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2446 - acc: 0.6802 - val_loss: 0.2548 - val_acc: 0.6793\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2461 - acc: 0.6801 - val_loss: 0.2588 - val_acc: 0.6779\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2450 - acc: 0.6802 - val_loss: 0.2560 - val_acc: 0.6783\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2457 - acc: 0.6811 - val_loss: 0.2658 - val_acc: 0.6743\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2481 - acc: 0.6795 - val_loss: 0.2553 - val_acc: 0.6792\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2422 - acc: 0.6818 - val_loss: 0.2570 - val_acc: 0.6772\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2440 - acc: 0.6803 - val_loss: 0.2574 - val_acc: 0.6763\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2453 - acc: 0.6789 - val_loss: 0.2578 - val_acc: 0.6763\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0657 - acc: 0.6750 - val_loss: 2.0984 - val_acc: 0.6765\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9677 - acc: 0.6783 - val_loss: 2.1337 - val_acc: 0.6752\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0288 - acc: 0.6775 - val_loss: 2.1289 - val_acc: 0.6727\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0051 - acc: 0.6767 - val_loss: 2.1306 - val_acc: 0.6727\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0130 - acc: 0.6773 - val_loss: 2.1147 - val_acc: 0.6739\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0073 - acc: 0.6766 - val_loss: 2.1897 - val_acc: 0.6720\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0244 - acc: 0.6773 - val_loss: 2.1373 - val_acc: 0.6738\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0063 - acc: 0.6768 - val_loss: 2.1175 - val_acc: 0.6743\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0080 - acc: 0.6771 - val_loss: 2.1272 - val_acc: 0.6770\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0190 - acc: 0.6775 - val_loss: 2.1858 - val_acc: 0.6703\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 2.0323 - acc: 0.6773 - val_loss: 2.1324 - val_acc: 0.6727\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0140 - acc: 0.6758 - val_loss: 2.1135 - val_acc: 0.6744\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9806 - acc: 0.6777 - val_loss: 2.1397 - val_acc: 0.6745\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0136 - acc: 0.6782 - val_loss: 2.1132 - val_acc: 0.6742\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0032 - acc: 0.6769 - val_loss: 2.1358 - val_acc: 0.6752\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0438 - acc: 0.6763 - val_loss: 2.2006 - val_acc: 0.6743\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0380 - acc: 0.6774 - val_loss: 2.1000 - val_acc: 0.6768\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 2.0113 - acc: 0.6773 - val_loss: 2.1180 - val_acc: 0.6779\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9812 - acc: 0.6785 - val_loss: 2.0967 - val_acc: 0.6752\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9775 - acc: 0.6781 - val_loss: 2.1150 - val_acc: 0.6769\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0035 - acc: 0.6774 - val_loss: 2.1779 - val_acc: 0.6781\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0189 - acc: 0.6773 - val_loss: 2.1249 - val_acc: 0.6767\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0086 - acc: 0.6783 - val_loss: 2.1413 - val_acc: 0.6755\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0269 - acc: 0.6755 - val_loss: 2.1420 - val_acc: 0.6728\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0050 - acc: 0.6770 - val_loss: 2.1242 - val_acc: 0.6769\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 2.0016 - acc: 0.6778 - val_loss: 2.1865 - val_acc: 0.6779\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0309 - acc: 0.6767 - val_loss: 2.1487 - val_acc: 0.6724\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0027 - acc: 0.6773 - val_loss: 2.1569 - val_acc: 0.6718\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0144 - acc: 0.6776 - val_loss: 2.1493 - val_acc: 0.6727\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0058 - acc: 0.6778 - val_loss: 2.1127 - val_acc: 0.6746\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9883 - acc: 0.6771 - val_loss: 2.1733 - val_acc: 0.6765\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 2.0240 - acc: 0.6768 - val_loss: 2.1613 - val_acc: 0.6767\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0171 - acc: 0.6770 - val_loss: 2.1779 - val_acc: 0.6757\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9984 - acc: 0.6772 - val_loss: 2.1375 - val_acc: 0.6737\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9810 - acc: 0.6772 - val_loss: 2.1458 - val_acc: 0.6724\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0175 - acc: 0.6772 - val_loss: 2.1637 - val_acc: 0.6768\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 2.0252 - acc: 0.6763 - val_loss: 2.1358 - val_acc: 0.6777\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0168 - acc: 0.6775 - val_loss: 2.3484 - val_acc: 0.6706\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 2.0283 - acc: 0.6754 - val_loss: 2.2344 - val_acc: 0.6756\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 2.0417 - acc: 0.6770 - val_loss: 2.1258 - val_acc: 0.6747\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9987 - acc: 0.6769 - val_loss: 2.1909 - val_acc: 0.6756\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 2.0002 - acc: 0.6763 - val_loss: 2.1414 - val_acc: 0.6720\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 1.9961 - acc: 0.6758 - val_loss: 2.1589 - val_acc: 0.6700\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 2.0064 - acc: 0.6768 - val_loss: 2.1889 - val_acc: 0.6747\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0169 - acc: 0.6777 - val_loss: 2.0953 - val_acc: 0.6766\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0027 - acc: 0.6780 - val_loss: 2.1433 - val_acc: 0.6754\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 1.9994 - acc: 0.6783 - val_loss: 2.2578 - val_acc: 0.6750\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0388 - acc: 0.6774 - val_loss: 2.1397 - val_acc: 0.6746\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9961 - acc: 0.6769 - val_loss: 2.1481 - val_acc: 0.6701\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0253 - acc: 0.6768 - val_loss: 2.0948 - val_acc: 0.6755\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2048 - acc: 0.9919 - val_loss: 0.2085 - val_acc: 0.9897\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.2124 - acc: 0.9921 - val_loss: 0.2135 - val_acc: 0.9897\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2104 - acc: 0.9920 - val_loss: 0.2266 - val_acc: 0.9898\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2359 - acc: 0.9918 - val_loss: 0.2546 - val_acc: 0.9885\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2263 - acc: 0.9916 - val_loss: 0.2249 - val_acc: 0.9891\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2178 - acc: 0.9918 - val_loss: 0.2079 - val_acc: 0.9895\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2089 - acc: 0.9920 - val_loss: 0.2062 - val_acc: 0.9898\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2065 - acc: 0.9919 - val_loss: 0.2111 - val_acc: 0.9895\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2098 - acc: 0.9916 - val_loss: 0.2131 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2068 - acc: 0.9919 - val_loss: 0.1995 - val_acc: 0.9898\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2043 - acc: 0.9918 - val_loss: 0.2225 - val_acc: 0.9891\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2283 - acc: 0.9912 - val_loss: 0.2180 - val_acc: 0.9896\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2211 - acc: 0.9919 - val_loss: 0.2183 - val_acc: 0.9896\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2065 - acc: 0.9920 - val_loss: 0.2045 - val_acc: 0.9897\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2111 - acc: 0.9918 - val_loss: 0.2233 - val_acc: 0.9891\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2168 - acc: 0.9913 - val_loss: 0.2157 - val_acc: 0.9895\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2231 - acc: 0.9910 - val_loss: 0.2242 - val_acc: 0.9890\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2130 - acc: 0.9915 - val_loss: 0.2201 - val_acc: 0.9893\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2123 - acc: 0.9914 - val_loss: 0.2116 - val_acc: 0.9893\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2082 - acc: 0.9920 - val_loss: 0.2239 - val_acc: 0.9899\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2273 - acc: 0.9919 - val_loss: 0.2276 - val_acc: 0.9897\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2149 - acc: 0.9920 - val_loss: 0.2081 - val_acc: 0.9899\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.2069 - acc: 0.9920 - val_loss: 0.2071 - val_acc: 0.9896\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.2039 - acc: 0.9918 - val_loss: 0.1986 - val_acc: 0.9896\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.1945 - acc: 0.9920 - val_loss: 0.1985 - val_acc: 0.9897\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2012 - acc: 0.9917 - val_loss: 0.2078 - val_acc: 0.9894\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2170 - acc: 0.9907 - val_loss: 0.2416 - val_acc: 0.9870\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2334 - acc: 0.9901 - val_loss: 0.2407 - val_acc: 0.9887\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2323 - acc: 0.9917 - val_loss: 0.2198 - val_acc: 0.9896\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2066 - acc: 0.9920 - val_loss: 0.2016 - val_acc: 0.9898\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2033 - acc: 0.9920 - val_loss: 0.2074 - val_acc: 0.9898\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2105 - acc: 0.9921 - val_loss: 0.2303 - val_acc: 0.9896\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2260 - acc: 0.9918 - val_loss: 0.2120 - val_acc: 0.9896\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2025 - acc: 0.9918 - val_loss: 0.2097 - val_acc: 0.9894\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2228 - acc: 0.9912 - val_loss: 0.2170 - val_acc: 0.9894\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2126 - acc: 0.9919 - val_loss: 0.2068 - val_acc: 0.9898\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2007 - acc: 0.9921 - val_loss: 0.2052 - val_acc: 0.9898\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2010 - acc: 0.9921 - val_loss: 0.2053 - val_acc: 0.9898\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2083 - acc: 0.9920 - val_loss: 0.2136 - val_acc: 0.9896\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2041 - acc: 0.9920 - val_loss: 0.2058 - val_acc: 0.9898\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 360us/step - loss: 0.2123 - acc: 0.9919 - val_loss: 0.2147 - val_acc: 0.9896\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2124 - acc: 0.9917 - val_loss: 0.2080 - val_acc: 0.9895\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2119 - acc: 0.9915 - val_loss: 0.2286 - val_acc: 0.9892\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2218 - acc: 0.9913 - val_loss: 0.2120 - val_acc: 0.9891\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2107 - acc: 0.9912 - val_loss: 0.2035 - val_acc: 0.9893\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2047 - acc: 0.9913 - val_loss: 0.2084 - val_acc: 0.9895\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2109 - acc: 0.9916 - val_loss: 0.2047 - val_acc: 0.9897\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.2173 - acc: 0.9919 - val_loss: 0.2222 - val_acc: 0.9893\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2263 - acc: 0.9918 - val_loss: 0.2114 - val_acc: 0.9898\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2085 - acc: 0.9921 - val_loss: 0.2026 - val_acc: 0.9898\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0035 - acc: 0.9526 - val_loss: 0.0034 - val_acc: 0.9592\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0033 - acc: 0.9582 - val_loss: 0.0034 - val_acc: 0.9600\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9558 - val_loss: 0.0037 - val_acc: 0.9518\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0034 - acc: 0.9544 - val_loss: 0.0036 - val_acc: 0.9549\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9539 - val_loss: 0.0034 - val_acc: 0.9601\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0033 - acc: 0.9565 - val_loss: 0.0034 - val_acc: 0.9618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0033 - acc: 0.9575 - val_loss: 0.0036 - val_acc: 0.9616\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0035 - acc: 0.9532 - val_loss: 0.0036 - val_acc: 0.9577\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0034 - acc: 0.9565 - val_loss: 0.0035 - val_acc: 0.9619\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.0034 - acc: 0.9565 - val_loss: 0.0034 - val_acc: 0.9618\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0033 - acc: 0.9586 - val_loss: 0.0034 - val_acc: 0.9615\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.0034 - acc: 0.9541 - val_loss: 0.0035 - val_acc: 0.9532\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0033 - acc: 0.9558 - val_loss: 0.0035 - val_acc: 0.9598\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9562 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9582 - val_loss: 0.0034 - val_acc: 0.9603\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0035 - acc: 0.9507 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9548 - val_loss: 0.0035 - val_acc: 0.9606\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0034 - acc: 0.9540 - val_loss: 0.0035 - val_acc: 0.9604\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0034 - acc: 0.9562 - val_loss: 0.0035 - val_acc: 0.9616\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0035 - acc: 0.9520 - val_loss: 0.0034 - val_acc: 0.9622\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.0033 - acc: 0.9583 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0034 - val_acc: 0.9615\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9580 - val_loss: 0.0034 - val_acc: 0.9615\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.0033 - acc: 0.9564 - val_loss: 0.0035 - val_acc: 0.9587\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0033 - acc: 0.9568 - val_loss: 0.0034 - val_acc: 0.9595\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0033 - acc: 0.9562 - val_loss: 0.0034 - val_acc: 0.9604\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.0033 - acc: 0.9573 - val_loss: 0.0034 - val_acc: 0.9619\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0034 - acc: 0.9563 - val_loss: 0.0035 - val_acc: 0.9594\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9569 - val_loss: 0.0035 - val_acc: 0.9621\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0034 - acc: 0.9543 - val_loss: 0.0034 - val_acc: 0.9619\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0033 - acc: 0.9574 - val_loss: 0.0037 - val_acc: 0.9516\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0035 - acc: 0.9492 - val_loss: 0.0034 - val_acc: 0.9594\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0033 - acc: 0.9555 - val_loss: 0.0039 - val_acc: 0.9530\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0036 - acc: 0.9497 - val_loss: 0.0035 - val_acc: 0.9606\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0034 - acc: 0.9571 - val_loss: 0.0035 - val_acc: 0.9609\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0034 - acc: 0.9541 - val_loss: 0.0034 - val_acc: 0.9622\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0033 - acc: 0.9586 - val_loss: 0.0034 - val_acc: 0.9620\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0035 - val_acc: 0.9621\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0034 - val_acc: 0.9601\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0034 - val_acc: 0.9619\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0033 - acc: 0.9562 - val_loss: 0.0037 - val_acc: 0.9546\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0034 - acc: 0.9535 - val_loss: 0.0035 - val_acc: 0.9597\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0034 - acc: 0.9548 - val_loss: 0.0034 - val_acc: 0.9622\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0034 - acc: 0.9523 - val_loss: 0.0035 - val_acc: 0.9611\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0034 - val_acc: 0.9624\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.0034 - acc: 0.9561 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "start training round 7\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2426 - acc: 0.6811 - val_loss: 0.2549 - val_acc: 0.6792\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2453 - acc: 0.6812 - val_loss: 0.2567 - val_acc: 0.6782\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2459 - acc: 0.6807 - val_loss: 0.2649 - val_acc: 0.6763\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2459 - acc: 0.6792 - val_loss: 0.2661 - val_acc: 0.6769\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2475 - acc: 0.6801 - val_loss: 0.2619 - val_acc: 0.6764\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.2452 - acc: 0.6803 - val_loss: 0.2621 - val_acc: 0.6802\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2473 - acc: 0.6791 - val_loss: 0.2561 - val_acc: 0.6794\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2411 - acc: 0.6822 - val_loss: 0.2583 - val_acc: 0.6786\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2436 - acc: 0.6810 - val_loss: 0.2580 - val_acc: 0.6779\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2473 - acc: 0.6803 - val_loss: 0.2533 - val_acc: 0.6801\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2425 - acc: 0.6810 - val_loss: 0.2550 - val_acc: 0.6792\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2418 - acc: 0.6816 - val_loss: 0.2538 - val_acc: 0.6800\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2429 - acc: 0.6814 - val_loss: 0.2607 - val_acc: 0.6768\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2475 - acc: 0.6801 - val_loss: 0.2579 - val_acc: 0.6777\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2456 - acc: 0.6794 - val_loss: 0.2570 - val_acc: 0.6784\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2471 - acc: 0.6791 - val_loss: 0.2569 - val_acc: 0.6764\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2452 - acc: 0.6796 - val_loss: 0.2561 - val_acc: 0.6790\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2435 - acc: 0.6805 - val_loss: 0.2530 - val_acc: 0.6794\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2416 - acc: 0.6820 - val_loss: 0.2594 - val_acc: 0.6804\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2482 - acc: 0.6812 - val_loss: 0.2540 - val_acc: 0.6799\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2406 - acc: 0.6822 - val_loss: 0.2543 - val_acc: 0.6799\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.2436 - acc: 0.6810 - val_loss: 0.2601 - val_acc: 0.6755\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2436 - acc: 0.6797 - val_loss: 0.2569 - val_acc: 0.6770\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2454 - acc: 0.6798 - val_loss: 0.2563 - val_acc: 0.6777\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2422 - acc: 0.6809 - val_loss: 0.2543 - val_acc: 0.6790\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.2437 - acc: 0.6813 - val_loss: 0.2616 - val_acc: 0.6766\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.2456 - acc: 0.6804 - val_loss: 0.2539 - val_acc: 0.6780\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2433 - acc: 0.6809 - val_loss: 0.2618 - val_acc: 0.6764\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2457 - acc: 0.6804 - val_loss: 0.2559 - val_acc: 0.6782\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2454 - acc: 0.6798 - val_loss: 0.2583 - val_acc: 0.6782\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2450 - acc: 0.6804 - val_loss: 0.2547 - val_acc: 0.6785\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2437 - acc: 0.6807 - val_loss: 0.2696 - val_acc: 0.6770\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2462 - acc: 0.6805 - val_loss: 0.2553 - val_acc: 0.6795\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2471 - acc: 0.6800 - val_loss: 0.2577 - val_acc: 0.6791\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2475 - acc: 0.6790 - val_loss: 0.2596 - val_acc: 0.6777\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2419 - acc: 0.6815 - val_loss: 0.2538 - val_acc: 0.6808\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2424 - acc: 0.6808 - val_loss: 0.2544 - val_acc: 0.6792\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2423 - acc: 0.6814 - val_loss: 0.2603 - val_acc: 0.6780\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2465 - acc: 0.6799 - val_loss: 0.2530 - val_acc: 0.6797\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2439 - acc: 0.6822 - val_loss: 0.2618 - val_acc: 0.6782\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2444 - acc: 0.6812 - val_loss: 0.2600 - val_acc: 0.6796\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2453 - acc: 0.6810 - val_loss: 0.2574 - val_acc: 0.6817\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2457 - acc: 0.6805 - val_loss: 0.2597 - val_acc: 0.6773\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2438 - acc: 0.6807 - val_loss: 0.2534 - val_acc: 0.6788\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2413 - acc: 0.6821 - val_loss: 0.2573 - val_acc: 0.6763\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2437 - acc: 0.6805 - val_loss: 0.2563 - val_acc: 0.6766\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2426 - acc: 0.6805 - val_loss: 0.2615 - val_acc: 0.6777\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2465 - acc: 0.6810 - val_loss: 0.2533 - val_acc: 0.6800\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2408 - acc: 0.6824 - val_loss: 0.2537 - val_acc: 0.6788\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2457 - acc: 0.6805 - val_loss: 0.2541 - val_acc: 0.6787\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 1.9995 - acc: 0.6763 - val_loss: 2.1706 - val_acc: 0.6726\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0054 - acc: 0.6768 - val_loss: 2.1427 - val_acc: 0.6742\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 1.9862 - acc: 0.6768 - val_loss: 2.1303 - val_acc: 0.6721\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 2.0226 - acc: 0.6769 - val_loss: 2.1657 - val_acc: 0.6708\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0134 - acc: 0.6770 - val_loss: 2.1774 - val_acc: 0.6757\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0056 - acc: 0.6782 - val_loss: 2.1958 - val_acc: 0.6706\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0055 - acc: 0.6769 - val_loss: 2.1166 - val_acc: 0.6740\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9768 - acc: 0.6775 - val_loss: 2.1122 - val_acc: 0.6735\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0288 - acc: 0.6767 - val_loss: 2.2289 - val_acc: 0.6730\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 1.9988 - acc: 0.6782 - val_loss: 2.1376 - val_acc: 0.6776\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 1.9862 - acc: 0.6777 - val_loss: 2.1585 - val_acc: 0.6731\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0068 - acc: 0.6771 - val_loss: 2.1268 - val_acc: 0.6737\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0052 - acc: 0.6783 - val_loss: 2.1318 - val_acc: 0.6772\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0106 - acc: 0.6774 - val_loss: 2.1372 - val_acc: 0.6760\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0144 - acc: 0.6775 - val_loss: 2.2398 - val_acc: 0.6771\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0178 - acc: 0.6781 - val_loss: 2.1165 - val_acc: 0.6782\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0005 - acc: 0.6770 - val_loss: 2.0980 - val_acc: 0.6770\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9888 - acc: 0.6782 - val_loss: 2.1675 - val_acc: 0.6742\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0408 - acc: 0.6759 - val_loss: 2.1374 - val_acc: 0.6773\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9930 - acc: 0.6780 - val_loss: 2.1304 - val_acc: 0.6736\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 2.0132 - acc: 0.6775 - val_loss: 2.1197 - val_acc: 0.6746\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9919 - acc: 0.6782 - val_loss: 2.1025 - val_acc: 0.6750\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9786 - acc: 0.6777 - val_loss: 2.0933 - val_acc: 0.6761\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 2.0162 - acc: 0.6781 - val_loss: 2.1312 - val_acc: 0.6747\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 1.9809 - acc: 0.6779 - val_loss: 2.1063 - val_acc: 0.6736\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0176 - acc: 0.6767 - val_loss: 2.2307 - val_acc: 0.6749\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0322 - acc: 0.6779 - val_loss: 2.0965 - val_acc: 0.6769\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9768 - acc: 0.6780 - val_loss: 2.1155 - val_acc: 0.6747\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0157 - acc: 0.6761 - val_loss: 2.1917 - val_acc: 0.6740\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0200 - acc: 0.6769 - val_loss: 2.1247 - val_acc: 0.6739\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0135 - acc: 0.6774 - val_loss: 2.1373 - val_acc: 0.6739\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0383 - acc: 0.6781 - val_loss: 2.1076 - val_acc: 0.6751\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 1.9926 - acc: 0.6769 - val_loss: 2.1118 - val_acc: 0.6748\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 1.9986 - acc: 0.6773 - val_loss: 2.2511 - val_acc: 0.6699\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 2.0174 - acc: 0.6779 - val_loss: 2.1785 - val_acc: 0.6711\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0037 - acc: 0.6781 - val_loss: 2.0985 - val_acc: 0.6747\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9996 - acc: 0.6782 - val_loss: 2.1206 - val_acc: 0.6745\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0271 - acc: 0.6768 - val_loss: 2.0880 - val_acc: 0.6768\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9990 - acc: 0.6786 - val_loss: 2.1680 - val_acc: 0.6773\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0148 - acc: 0.6770 - val_loss: 2.1505 - val_acc: 0.6756\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0141 - acc: 0.6766 - val_loss: 2.1034 - val_acc: 0.6766\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 2.0178 - acc: 0.6777 - val_loss: 2.1484 - val_acc: 0.6782\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0073 - acc: 0.6778 - val_loss: 2.1723 - val_acc: 0.6784\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9943 - acc: 0.6769 - val_loss: 2.1119 - val_acc: 0.6733\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9979 - acc: 0.6765 - val_loss: 2.1507 - val_acc: 0.6714\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9966 - acc: 0.6769 - val_loss: 2.1232 - val_acc: 0.6757\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9928 - acc: 0.6781 - val_loss: 2.1367 - val_acc: 0.6728\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0276 - acc: 0.6779 - val_loss: 2.1365 - val_acc: 0.6750\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9890 - acc: 0.6780 - val_loss: 2.0892 - val_acc: 0.6762\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9829 - acc: 0.6777 - val_loss: 2.1752 - val_acc: 0.6745\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.1989 - acc: 0.9920 - val_loss: 0.2021 - val_acc: 0.9895\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.1985 - acc: 0.9918 - val_loss: 0.2021 - val_acc: 0.9897\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2120 - acc: 0.9910 - val_loss: 0.2363 - val_acc: 0.9871\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2320 - acc: 0.9894 - val_loss: 0.2146 - val_acc: 0.9890\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2058 - acc: 0.9914 - val_loss: 0.2057 - val_acc: 0.9894\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2064 - acc: 0.9917 - val_loss: 0.2021 - val_acc: 0.9897\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2058 - acc: 0.9920 - val_loss: 0.2256 - val_acc: 0.9899\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2196 - acc: 0.9920 - val_loss: 0.2143 - val_acc: 0.9899\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2154 - acc: 0.9920 - val_loss: 0.2372 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2523 - acc: 0.9920 - val_loss: 0.2203 - val_acc: 0.9898\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2072 - acc: 0.9920 - val_loss: 0.2041 - val_acc: 0.9897\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2022 - acc: 0.9916 - val_loss: 0.2098 - val_acc: 0.9888\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2122 - acc: 0.9907 - val_loss: 0.2215 - val_acc: 0.9891\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2164 - acc: 0.9912 - val_loss: 0.2219 - val_acc: 0.9889\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2128 - acc: 0.9917 - val_loss: 0.2078 - val_acc: 0.9897\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2077 - acc: 0.9921 - val_loss: 0.2154 - val_acc: 0.9897\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2167 - acc: 0.9916 - val_loss: 0.2273 - val_acc: 0.9893\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2115 - acc: 0.9914 - val_loss: 0.2088 - val_acc: 0.9897\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2014 - acc: 0.9921 - val_loss: 0.2013 - val_acc: 0.9897\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1965 - acc: 0.9919 - val_loss: 0.1989 - val_acc: 0.9898\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.1971 - acc: 0.9921 - val_loss: 0.1982 - val_acc: 0.9897\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1960 - acc: 0.9920 - val_loss: 0.2035 - val_acc: 0.9895\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2113 - acc: 0.9914 - val_loss: 0.2197 - val_acc: 0.9894: 0.2112 - acc: 0\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2243 - acc: 0.9912 - val_loss: 0.2314 - val_acc: 0.9895\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2221 - acc: 0.9920 - val_loss: 0.2242 - val_acc: 0.9897\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2202 - acc: 0.9916 - val_loss: 0.2180 - val_acc: 0.9895\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2100 - acc: 0.9919 - val_loss: 0.2152 - val_acc: 0.9897\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2057 - acc: 0.9921 - val_loss: 0.2096 - val_acc: 0.9896 0\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2115 - acc: 0.9919 - val_loss: 0.2112 - val_acc: 0.9893\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2116 - acc: 0.9915 - val_loss: 0.2113 - val_acc: 0.9892\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2069 - acc: 0.9910 - val_loss: 0.2059 - val_acc: 0.9889\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2027 - acc: 0.9912 - val_loss: 0.2044 - val_acc: 0.9892\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1994 - acc: 0.9916 - val_loss: 0.2019 - val_acc: 0.9894\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2091 - acc: 0.9909 - val_loss: 0.2262 - val_acc: 0.9880\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2121 - acc: 0.9907 - val_loss: 0.2080 - val_acc: 0.9894\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2221 - acc: 0.9918 - val_loss: 0.2232 - val_acc: 0.9898\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2301 - acc: 0.9921 - val_loss: 0.2142 - val_acc: 0.9898\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2049 - acc: 0.9921 - val_loss: 0.1978 - val_acc: 0.9898\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1941 - acc: 0.9921 - val_loss: 0.1955 - val_acc: 0.9900\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1965 - acc: 0.9921 - val_loss: 0.2115 - val_acc: 0.9898\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2198 - acc: 0.9921 - val_loss: 0.2088 - val_acc: 0.9899\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.1986 - acc: 0.9921 - val_loss: 0.2020 - val_acc: 0.9900\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.1980 - acc: 0.9921 - val_loss: 0.1982 - val_acc: 0.9899\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.1989 - acc: 0.9921 - val_loss: 0.1988 - val_acc: 0.9898\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2004 - acc: 0.9921 - val_loss: 0.2065 - val_acc: 0.9898\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2164 - acc: 0.9921 - val_loss: 0.2180 - val_acc: 0.9898\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2124 - acc: 0.9919 - val_loss: 0.2159 - val_acc: 0.9891\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2163 - acc: 0.9907 - val_loss: 0.2176 - val_acc: 0.9888\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2065 - acc: 0.9914 - val_loss: 0.2014 - val_acc: 0.9894\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2003 - acc: 0.9916 - val_loss: 0.2023 - val_acc: 0.9895\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0033 - acc: 0.9579 - val_loss: 0.0035 - val_acc: 0.9571\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0033 - acc: 0.9562 - val_loss: 0.0033 - val_acc: 0.9602\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.0033 - acc: 0.9561 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0032 - acc: 0.9582 - val_loss: 0.0034 - val_acc: 0.9602\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9575 - val_loss: 0.0038 - val_acc: 0.9529\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0035 - acc: 0.9506 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0034 - val_acc: 0.9621\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0033 - acc: 0.9579 - val_loss: 0.0037 - val_acc: 0.9596\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0035 - acc: 0.9554 - val_loss: 0.0035 - val_acc: 0.9615\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9621\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0033 - acc: 0.9567 - val_loss: 0.0036 - val_acc: 0.9530\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0035 - acc: 0.9501 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0032 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0033 - acc: 0.9585 - val_loss: 0.0037 - val_acc: 0.9561\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0036 - acc: 0.9535 - val_loss: 0.0034 - val_acc: 0.9615\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9595\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0033 - acc: 0.9547 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0032 - acc: 0.9581 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9582 - val_loss: 0.0033 - val_acc: 0.9606\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0033 - acc: 0.9575 - val_loss: 0.0033 - val_acc: 0.9612\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9580\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9557 - val_loss: 0.0036 - val_acc: 0.9547\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0035 - acc: 0.9547 - val_loss: 0.0034 - val_acc: 0.9596\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9579 - val_loss: 0.0033 - val_acc: 0.9610\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9541 - val_loss: 0.0034 - val_acc: 0.9598\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0033 - acc: 0.9570 - val_loss: 0.0035 - val_acc: 0.9610\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.0033 - acc: 0.9549 - val_loss: 0.0034 - val_acc: 0.9605\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0033 - acc: 0.9575 - val_loss: 0.0034 - val_acc: 0.9604\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9608\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0034 - val_acc: 0.9606\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9581 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0033 - acc: 0.9579 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0034 - acc: 0.9539 - val_loss: 0.0039 - val_acc: 0.9466\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0035 - acc: 0.9510 - val_loss: 0.0034 - val_acc: 0.9618\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 409us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0037 - val_acc: 0.9543\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0034 - acc: 0.9549 - val_loss: 0.0037 - val_acc: 0.9518\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0033 - acc: 0.9545 - val_loss: 0.0035 - val_acc: 0.9593\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0035 - acc: 0.9507 - val_loss: 0.0036 - val_acc: 0.9568\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.0034 - acc: 0.9566 - val_loss: 0.0039 - val_acc: 0.9590\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0035 - acc: 0.9538 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0034 - val_acc: 0.9626\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0036 - val_acc: 0.9566\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9554 - val_loss: 0.0036 - val_acc: 0.9521\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0034 - acc: 0.9516 - val_loss: 0.0033 - val_acc: 0.9602\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0033 - acc: 0.9573 - val_loss: 0.0035 - val_acc: 0.9584\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0035 - acc: 0.9538 - val_loss: 0.0036 - val_acc: 0.9532\n",
      "start training round 8\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2423 - acc: 0.6810 - val_loss: 0.2538 - val_acc: 0.6793\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2444 - acc: 0.6802 - val_loss: 0.2580 - val_acc: 0.6756\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2466 - acc: 0.6814 - val_loss: 0.2699 - val_acc: 0.6783\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2486 - acc: 0.6805 - val_loss: 0.2589 - val_acc: 0.6771\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2433 - acc: 0.6810 - val_loss: 0.2564 - val_acc: 0.6786\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2414 - acc: 0.6822 - val_loss: 0.2547 - val_acc: 0.6791\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2430 - acc: 0.6813 - val_loss: 0.2539 - val_acc: 0.6799\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2443 - acc: 0.6810 - val_loss: 0.2575 - val_acc: 0.6784\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2427 - acc: 0.6816 - val_loss: 0.2578 - val_acc: 0.6804\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2475 - acc: 0.6794 - val_loss: 0.2541 - val_acc: 0.6813\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2439 - acc: 0.6815 - val_loss: 0.2542 - val_acc: 0.6806\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2430 - acc: 0.6817 - val_loss: 0.2542 - val_acc: 0.6798\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2424 - acc: 0.6819 - val_loss: 0.2526 - val_acc: 0.6793\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2446 - acc: 0.6804 - val_loss: 0.2521 - val_acc: 0.6811\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2404 - acc: 0.6824 - val_loss: 0.2566 - val_acc: 0.6797\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.2440 - acc: 0.6818 - val_loss: 0.2570 - val_acc: 0.6799\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2412 - acc: 0.6825 - val_loss: 0.2559 - val_acc: 0.6812\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2473 - acc: 0.6814 - val_loss: 0.2573 - val_acc: 0.6768\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2426 - acc: 0.6817 - val_loss: 0.2536 - val_acc: 0.6780\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2397 - acc: 0.6829 - val_loss: 0.2560 - val_acc: 0.6782\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2449 - acc: 0.6802 - val_loss: 0.2582 - val_acc: 0.6785\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2448 - acc: 0.6802 - val_loss: 0.2565 - val_acc: 0.6797\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2430 - acc: 0.6812 - val_loss: 0.2531 - val_acc: 0.6810\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2423 - acc: 0.6826 - val_loss: 0.2590 - val_acc: 0.6776\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.2469 - acc: 0.6799 - val_loss: 0.2558 - val_acc: 0.6797\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2436 - acc: 0.6812 - val_loss: 0.2559 - val_acc: 0.6781\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2430 - acc: 0.6816 - val_loss: 0.2549 - val_acc: 0.6800\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2435 - acc: 0.6814 - val_loss: 0.2596 - val_acc: 0.6766\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2446 - acc: 0.6808 - val_loss: 0.2533 - val_acc: 0.6806\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2409 - acc: 0.6814 - val_loss: 0.2630 - val_acc: 0.6766\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2445 - acc: 0.6817 - val_loss: 0.2569 - val_acc: 0.6797\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2456 - acc: 0.6798 - val_loss: 0.2539 - val_acc: 0.6793\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2426 - acc: 0.6817 - val_loss: 0.2611 - val_acc: 0.6768\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2443 - acc: 0.6814 - val_loss: 0.2549 - val_acc: 0.6806\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2428 - acc: 0.6817 - val_loss: 0.2552 - val_acc: 0.6820\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2421 - acc: 0.6822 - val_loss: 0.2525 - val_acc: 0.6824\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2417 - acc: 0.6816 - val_loss: 0.2556 - val_acc: 0.6811\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2435 - acc: 0.6821 - val_loss: 0.2577 - val_acc: 0.6786\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2430 - acc: 0.6815 - val_loss: 0.2528 - val_acc: 0.6788\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2446 - acc: 0.6811 - val_loss: 0.2577 - val_acc: 0.6790\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2452 - acc: 0.6805 - val_loss: 0.2541 - val_acc: 0.6796\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2426 - acc: 0.6812 - val_loss: 0.2663 - val_acc: 0.6726\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2432 - acc: 0.6802 - val_loss: 0.2532 - val_acc: 0.6792\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2432 - acc: 0.6823 - val_loss: 0.2544 - val_acc: 0.6803\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2412 - acc: 0.6828 - val_loss: 0.2586 - val_acc: 0.6798\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2435 - acc: 0.6812 - val_loss: 0.2616 - val_acc: 0.6777\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2436 - acc: 0.6812 - val_loss: 0.2691 - val_acc: 0.6771\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2442 - acc: 0.6812 - val_loss: 0.2639 - val_acc: 0.6795\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2429 - acc: 0.6815 - val_loss: 0.2570 - val_acc: 0.6784\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2429 - acc: 0.6812 - val_loss: 0.2534 - val_acc: 0.6816\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9996 - acc: 0.6771 - val_loss: 2.1224 - val_acc: 0.6785\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0111 - acc: 0.6774 - val_loss: 2.1512 - val_acc: 0.6745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0063 - acc: 0.6776 - val_loss: 2.1384 - val_acc: 0.6765\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0201 - acc: 0.6769 - val_loss: 2.1913 - val_acc: 0.6728\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0191 - acc: 0.6768 - val_loss: 2.0980 - val_acc: 0.6757\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - ETA: 0s - loss: 1.9736 - acc: 0.677 - 3s 388us/step - loss: 1.9726 - acc: 0.6771 - val_loss: 2.1366 - val_acc: 0.6777\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 2.0028 - acc: 0.6776 - val_loss: 2.2107 - val_acc: 0.6769\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0492 - acc: 0.6772 - val_loss: 2.1512 - val_acc: 0.6740\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9850 - acc: 0.6782 - val_loss: 2.1498 - val_acc: 0.6723\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9817 - acc: 0.6779 - val_loss: 2.1103 - val_acc: 0.6763\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9984 - acc: 0.6768 - val_loss: 2.1892 - val_acc: 0.6762\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 2.0409 - acc: 0.6772 - val_loss: 2.0954 - val_acc: 0.6756\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9887 - acc: 0.6784 - val_loss: 2.1583 - val_acc: 0.6724\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9953 - acc: 0.6776 - val_loss: 2.1848 - val_acc: 0.6707\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0217 - acc: 0.6767 - val_loss: 2.1390 - val_acc: 0.6732\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0098 - acc: 0.6774 - val_loss: 2.1014 - val_acc: 0.6745\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9769 - acc: 0.6781 - val_loss: 2.1680 - val_acc: 0.6756\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0309 - acc: 0.6764 - val_loss: 2.1751 - val_acc: 0.6743\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 2.0134 - acc: 0.6785 - val_loss: 2.0990 - val_acc: 0.6765\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9831 - acc: 0.6781 - val_loss: 2.2109 - val_acc: 0.6698\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0090 - acc: 0.6767 - val_loss: 2.0897 - val_acc: 0.6740\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9924 - acc: 0.6777 - val_loss: 2.1252 - val_acc: 0.6744\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 1.9987 - acc: 0.6776 - val_loss: 2.1394 - val_acc: 0.6753\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9957 - acc: 0.6779 - val_loss: 2.1077 - val_acc: 0.6768\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0047 - acc: 0.6771 - val_loss: 2.1554 - val_acc: 0.6713\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 2.0199 - acc: 0.6768 - val_loss: 2.1398 - val_acc: 0.6756\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0146 - acc: 0.6777 - val_loss: 2.1183 - val_acc: 0.6766\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9970 - acc: 0.6786 - val_loss: 2.1353 - val_acc: 0.6788\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9996 - acc: 0.6784 - val_loss: 2.1433 - val_acc: 0.6779\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9924 - acc: 0.6782 - val_loss: 2.1468 - val_acc: 0.6757\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0079 - acc: 0.6771 - val_loss: 2.1240 - val_acc: 0.6748\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9832 - acc: 0.6765 - val_loss: 2.1274 - val_acc: 0.6710\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0133 - acc: 0.6766 - val_loss: 2.1415 - val_acc: 0.6756\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0172 - acc: 0.6782 - val_loss: 2.1071 - val_acc: 0.6756\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0228 - acc: 0.6766 - val_loss: 2.1199 - val_acc: 0.6764\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0092 - acc: 0.6784 - val_loss: 2.1070 - val_acc: 0.6747\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9979 - acc: 0.6779 - val_loss: 2.1803 - val_acc: 0.6714\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0148 - acc: 0.6769 - val_loss: 2.1302 - val_acc: 0.6734\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0158 - acc: 0.6773 - val_loss: 2.1556 - val_acc: 0.6711\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0068 - acc: 0.6784 - val_loss: 2.1098 - val_acc: 0.6757\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9820 - acc: 0.6789 - val_loss: 2.1078 - val_acc: 0.6752\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 1.9944 - acc: 0.6776 - val_loss: 2.1909 - val_acc: 0.6754\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9839 - acc: 0.6781 - val_loss: 2.1989 - val_acc: 0.6744\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0061 - acc: 0.6773 - val_loss: 2.1781 - val_acc: 0.6766\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0120 - acc: 0.6777 - val_loss: 2.1241 - val_acc: 0.6764\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9850 - acc: 0.6782 - val_loss: 2.1024 - val_acc: 0.6748\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0025 - acc: 0.6777 - val_loss: 2.1373 - val_acc: 0.6761\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9905 - acc: 0.6781 - val_loss: 2.1091 - val_acc: 0.6761\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 2.0049 - acc: 0.6772 - val_loss: 2.1530 - val_acc: 0.6737\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0430 - acc: 0.6781 - val_loss: 2.0907 - val_acc: 0.6752\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2059 - acc: 0.9914 - val_loss: 0.2065 - val_acc: 0.9896\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2023 - acc: 0.9917 - val_loss: 0.2010 - val_acc: 0.9896\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2009 - acc: 0.9916 - val_loss: 0.2059 - val_acc: 0.9896\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2090 - acc: 0.9918 - val_loss: 0.2230 - val_acc: 0.9896\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2282 - acc: 0.9919 - val_loss: 0.2369 - val_acc: 0.9898\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2220 - acc: 0.9919 - val_loss: 0.2053 - val_acc: 0.9896\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1977 - acc: 0.9921 - val_loss: 0.1997 - val_acc: 0.9899\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1976 - acc: 0.9921 - val_loss: 0.1966 - val_acc: 0.9897\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2009 - acc: 0.9917 - val_loss: 0.2117 - val_acc: 0.9892\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2113 - acc: 0.9908 - val_loss: 0.2086 - val_acc: 0.9894\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2041 - acc: 0.9909 - val_loss: 0.2029 - val_acc: 0.9895\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 365us/step - loss: 0.1992 - acc: 0.9918 - val_loss: 0.2070 - val_acc: 0.9897\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2139 - acc: 0.9919 - val_loss: 0.2326 - val_acc: 0.9899\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2342 - acc: 0.9919 - val_loss: 0.2110 - val_acc: 0.9894\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2029 - acc: 0.9916 - val_loss: 0.2064 - val_acc: 0.9894\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2036 - acc: 0.9912 - val_loss: 0.2064 - val_acc: 0.9892\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1970 - acc: 0.9917 - val_loss: 0.2016 - val_acc: 0.9893\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2073 - acc: 0.9918 - val_loss: 0.2227 - val_acc: 0.9899\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2144 - acc: 0.9921 - val_loss: 0.2160 - val_acc: 0.9899\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2081 - acc: 0.9919 - val_loss: 0.2157 - val_acc: 0.9898\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2276 - acc: 0.9920 - val_loss: 0.2463 - val_acc: 0.9896\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2204 - acc: 0.9921 - val_loss: 0.2013 - val_acc: 0.9898\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.1974 - acc: 0.9919 - val_loss: 0.2041 - val_acc: 0.9895\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2001 - acc: 0.9918 - val_loss: 0.1998 - val_acc: 0.9897\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1989 - acc: 0.9920 - val_loss: 0.2004 - val_acc: 0.9898\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2050 - acc: 0.9921 - val_loss: 0.2168 - val_acc: 0.9898\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2190 - acc: 0.9921 - val_loss: 0.2183 - val_acc: 0.9896\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2146 - acc: 0.9913 - val_loss: 0.2059 - val_acc: 0.9894\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2078 - acc: 0.9906 - val_loss: 0.2052 - val_acc: 0.9893\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1987 - acc: 0.9915 - val_loss: 0.1970 - val_acc: 0.9895\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.1957 - acc: 0.9918 - val_loss: 0.2057 - val_acc: 0.9889\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2017 - acc: 0.9913 - val_loss: 0.2100 - val_acc: 0.9891\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2090 - acc: 0.9914 - val_loss: 0.2116 - val_acc: 0.9894\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2166 - acc: 0.9917 - val_loss: 0.2239 - val_acc: 0.9898\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2135 - acc: 0.9921 - val_loss: 0.2164 - val_acc: 0.9899\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2023 - acc: 0.9922 - val_loss: 0.2015 - val_acc: 0.9899\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2043 - acc: 0.9921 - val_loss: 0.2215 - val_acc: 0.9897\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2226 - acc: 0.9921 - val_loss: 0.2194 - val_acc: 0.9899\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2133 - acc: 0.9921 - val_loss: 0.2006 - val_acc: 0.9899\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1968 - acc: 0.9921 - val_loss: 0.2012 - val_acc: 0.9897\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1990 - acc: 0.9916 - val_loss: 0.2102 - val_acc: 0.9887\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2281 - acc: 0.9893 - val_loss: 0.2214 - val_acc: 0.9885\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2079 - acc: 0.9906 - val_loss: 0.2085 - val_acc: 0.9893\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.2043 - acc: 0.9917 - val_loss: 0.2026 - val_acc: 0.9894\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2077 - acc: 0.9917 - val_loss: 0.2078 - val_acc: 0.9896\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2120 - acc: 0.9921 - val_loss: 0.2359 - val_acc: 0.9896\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2174 - acc: 0.9921 - val_loss: 0.2097 - val_acc: 0.9899\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2187 - acc: 0.9921 - val_loss: 0.2186 - val_acc: 0.9898\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2130 - acc: 0.9920 - val_loss: 0.2116 - val_acc: 0.9896\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2102 - acc: 0.9919 - val_loss: 0.2032 - val_acc: 0.9899\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0034 - acc: 0.9541 - val_loss: 0.0035 - val_acc: 0.9576\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9556 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0032 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0034 - val_acc: 0.9617\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0032 - acc: 0.9576 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9549 - val_loss: 0.0035 - val_acc: 0.9579\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0033 - acc: 0.9560 - val_loss: 0.0034 - val_acc: 0.9607\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9582 - val_loss: 0.0034 - val_acc: 0.9597\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0034 - acc: 0.9545 - val_loss: 0.0034 - val_acc: 0.9596\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0034 - val_acc: 0.9615\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0034 - acc: 0.9523 - val_loss: 0.0035 - val_acc: 0.9574\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0032 - acc: 0.9577 - val_loss: 0.0035 - val_acc: 0.9558\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0033 - acc: 0.9549 - val_loss: 0.0034 - val_acc: 0.9576\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0034 - acc: 0.9542 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0034 - val_acc: 0.9600\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9557 - val_loss: 0.0034 - val_acc: 0.9594\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0033 - acc: 0.9563 - val_loss: 0.0034 - val_acc: 0.9617\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0032 - acc: 0.9588 - val_loss: 0.0034 - val_acc: 0.9620\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0034 - acc: 0.9546 - val_loss: 0.0034 - val_acc: 0.9603\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0034 - val_acc: 0.9599\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0034 - acc: 0.9556 - val_loss: 0.0035 - val_acc: 0.9571\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0033 - acc: 0.9563 - val_loss: 0.0033 - val_acc: 0.9606\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0033 - acc: 0.9568 - val_loss: 0.0043 - val_acc: 0.9416\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 409us/step - loss: 0.0036 - acc: 0.9508 - val_loss: 0.0034 - val_acc: 0.9607\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9571 - val_loss: 0.0033 - val_acc: 0.9610\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.0034 - acc: 0.9532 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0034 - acc: 0.9557 - val_loss: 0.0034 - val_acc: 0.9579\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0033 - acc: 0.9558 - val_loss: 0.0039 - val_acc: 0.9527\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0035 - acc: 0.9507 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.0032 - acc: 0.9591 - val_loss: 0.0033 - val_acc: 0.9621\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0035 - val_acc: 0.9559\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0035 - acc: 0.9512 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.0033 - acc: 0.9562 - val_loss: 0.0034 - val_acc: 0.9605\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0033 - acc: 0.9587 - val_loss: 0.0034 - val_acc: 0.9614\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0034 - acc: 0.9553 - val_loss: 0.0034 - val_acc: 0.9605\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0033 - acc: 0.9574 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0034 - val_acc: 0.9599\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9564 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9586\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0033 - acc: 0.9566 - val_loss: 0.0033 - val_acc: 0.9619\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0033 - acc: 0.9571 - val_loss: 0.0035 - val_acc: 0.9621\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0036 - acc: 0.9517 - val_loss: 0.0034 - val_acc: 0.9623\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0033 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9624\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9563 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0035 - val_acc: 0.9589\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0035 - acc: 0.9499 - val_loss: 0.0036 - val_acc: 0.9569\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9557 - val_loss: 0.0033 - val_acc: 0.9610\n",
      "start training round 9\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2436 - acc: 0.6808 - val_loss: 0.2514 - val_acc: 0.6807\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2393 - acc: 0.6829 - val_loss: 0.2529 - val_acc: 0.6800\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2427 - acc: 0.6826 - val_loss: 0.2661 - val_acc: 0.6802\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2428 - acc: 0.6828 - val_loss: 0.2567 - val_acc: 0.6821\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2425 - acc: 0.6809 - val_loss: 0.2549 - val_acc: 0.6799\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2454 - acc: 0.6797 - val_loss: 0.2554 - val_acc: 0.6780\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2433 - acc: 0.6807 - val_loss: 0.2569 - val_acc: 0.6791\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.2447 - acc: 0.6808 - val_loss: 0.2559 - val_acc: 0.6796\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.2419 - acc: 0.6818 - val_loss: 0.2530 - val_acc: 0.6799\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2395 - acc: 0.6825 - val_loss: 0.2531 - val_acc: 0.6794\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2418 - acc: 0.6811 - val_loss: 0.2517 - val_acc: 0.6809\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2397 - acc: 0.6829 - val_loss: 0.2549 - val_acc: 0.6801\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2437 - acc: 0.6818 - val_loss: 0.2676 - val_acc: 0.6779\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2436 - acc: 0.6823 - val_loss: 0.2559 - val_acc: 0.6809\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2426 - acc: 0.6821 - val_loss: 0.2519 - val_acc: 0.6810\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2426 - acc: 0.6802 - val_loss: 0.2552 - val_acc: 0.6770\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2421 - acc: 0.6808 - val_loss: 0.2509 - val_acc: 0.6818\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2423 - acc: 0.6818 - val_loss: 0.2708 - val_acc: 0.6746\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2431 - acc: 0.6810 - val_loss: 0.2511 - val_acc: 0.6818\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2390 - acc: 0.6833 - val_loss: 0.2559 - val_acc: 0.6805\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2426 - acc: 0.6821 - val_loss: 0.2517 - val_acc: 0.6804\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2435 - acc: 0.6810 - val_loss: 0.2614 - val_acc: 0.6761\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2422 - acc: 0.6818 - val_loss: 0.2541 - val_acc: 0.6800\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2425 - acc: 0.6825 - val_loss: 0.2543 - val_acc: 0.6811\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2428 - acc: 0.6831 - val_loss: 0.2552 - val_acc: 0.6811\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2429 - acc: 0.6813 - val_loss: 0.2564 - val_acc: 0.6777\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2426 - acc: 0.6807 - val_loss: 0.2544 - val_acc: 0.6814\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2424 - acc: 0.6817 - val_loss: 0.2541 - val_acc: 0.6795\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2404 - acc: 0.6826 - val_loss: 0.2522 - val_acc: 0.6816\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2405 - acc: 0.6828 - val_loss: 0.2564 - val_acc: 0.6776\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2448 - acc: 0.6804 - val_loss: 0.2557 - val_acc: 0.6783\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2394 - acc: 0.6831 - val_loss: 0.2549 - val_acc: 0.6804\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2420 - acc: 0.6821 - val_loss: 0.2621 - val_acc: 0.6788\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2430 - acc: 0.6820 - val_loss: 0.2537 - val_acc: 0.6799\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2418 - acc: 0.6829 - val_loss: 0.2562 - val_acc: 0.6813\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2459 - acc: 0.6808 - val_loss: 0.2570 - val_acc: 0.6792\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2410 - acc: 0.6819 - val_loss: 0.2528 - val_acc: 0.6815\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2405 - acc: 0.6822 - val_loss: 0.2526 - val_acc: 0.6790\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2428 - acc: 0.6823 - val_loss: 0.2637 - val_acc: 0.6793\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2410 - acc: 0.6824 - val_loss: 0.2530 - val_acc: 0.6796\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2426 - acc: 0.6813 - val_loss: 0.2533 - val_acc: 0.6793\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2421 - acc: 0.6834 - val_loss: 0.2561 - val_acc: 0.6803\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2416 - acc: 0.6828 - val_loss: 0.2517 - val_acc: 0.6817\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2404 - acc: 0.6833 - val_loss: 0.2520 - val_acc: 0.6818\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2444 - acc: 0.6817 - val_loss: 0.2597 - val_acc: 0.6768\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2448 - acc: 0.6803 - val_loss: 0.2527 - val_acc: 0.6808\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2380 - acc: 0.6835 - val_loss: 0.2517 - val_acc: 0.6815\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2404 - acc: 0.6830 - val_loss: 0.2541 - val_acc: 0.6802\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 362us/step - loss: 0.2408 - acc: 0.6817 - val_loss: 0.2503 - val_acc: 0.6827\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2427 - acc: 0.6818 - val_loss: 0.2565 - val_acc: 0.6804\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9954 - acc: 0.6769 - val_loss: 2.0877 - val_acc: 0.6757\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9631 - acc: 0.6788 - val_loss: 2.1599 - val_acc: 0.6766\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 2.0129 - acc: 0.6766 - val_loss: 2.1337 - val_acc: 0.6767\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9851 - acc: 0.6782 - val_loss: 2.1599 - val_acc: 0.6759\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0232 - acc: 0.6782 - val_loss: 2.1595 - val_acc: 0.6738\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9802 - acc: 0.6782 - val_loss: 2.1273 - val_acc: 0.6713\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0084 - acc: 0.6769 - val_loss: 2.1909 - val_acc: 0.6697\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0227 - acc: 0.6764 - val_loss: 2.2005 - val_acc: 0.6734\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0175 - acc: 0.6777 - val_loss: 2.1302 - val_acc: 0.6775\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0174 - acc: 0.6778 - val_loss: 2.1463 - val_acc: 0.6779\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 2.0019 - acc: 0.6777 - val_loss: 2.1042 - val_acc: 0.6747\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9803 - acc: 0.6781 - val_loss: 2.1354 - val_acc: 0.6730\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0022 - acc: 0.6778 - val_loss: 2.0940 - val_acc: 0.6746\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9798 - acc: 0.6790 - val_loss: 2.1348 - val_acc: 0.6734\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0099 - acc: 0.6783 - val_loss: 2.1831 - val_acc: 0.6741\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0226 - acc: 0.6773 - val_loss: 2.1554 - val_acc: 0.6722\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 1.9820 - acc: 0.6786 - val_loss: 2.1130 - val_acc: 0.6747\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0149 - acc: 0.6782 - val_loss: 2.1136 - val_acc: 0.6751\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0165 - acc: 0.6768 - val_loss: 2.0856 - val_acc: 0.6776\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9914 - acc: 0.6780 - val_loss: 2.1148 - val_acc: 0.6769\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0092 - acc: 0.6783 - val_loss: 2.1615 - val_acc: 0.6740\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9872 - acc: 0.6785 - val_loss: 2.1722 - val_acc: 0.6719\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9924 - acc: 0.6782 - val_loss: 2.1169 - val_acc: 0.6726\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9892 - acc: 0.6792 - val_loss: 2.1290 - val_acc: 0.6741\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 1.9919 - acc: 0.6783 - val_loss: 2.1338 - val_acc: 0.6736\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9939 - acc: 0.6765 - val_loss: 2.1095 - val_acc: 0.6753\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0012 - acc: 0.6770 - val_loss: 2.1828 - val_acc: 0.6740\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 2.0053 - acc: 0.6771 - val_loss: 2.2442 - val_acc: 0.6772\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0402 - acc: 0.6782 - val_loss: 2.0953 - val_acc: 0.6763\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 1.9987 - acc: 0.6786 - val_loss: 2.0992 - val_acc: 0.6766\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9696 - acc: 0.6788 - val_loss: 2.0971 - val_acc: 0.6765\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0031 - acc: 0.6783 - val_loss: 2.1271 - val_acc: 0.6746\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9982 - acc: 0.6772 - val_loss: 2.1030 - val_acc: 0.6766\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9991 - acc: 0.6775 - val_loss: 2.1427 - val_acc: 0.6741\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9888 - acc: 0.6768 - val_loss: 2.1216 - val_acc: 0.6728\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0043 - acc: 0.6771 - val_loss: 2.1574 - val_acc: 0.6773\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 2.0075 - acc: 0.6772 - val_loss: 2.1522 - val_acc: 0.6772\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9949 - acc: 0.6778 - val_loss: 2.1592 - val_acc: 0.6748\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0210 - acc: 0.6777 - val_loss: 2.0923 - val_acc: 0.6776\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9705 - acc: 0.6786 - val_loss: 2.1531 - val_acc: 0.6724\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9890 - acc: 0.6776 - val_loss: 2.0887 - val_acc: 0.6744\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0095 - acc: 0.6770 - val_loss: 2.1618 - val_acc: 0.6760\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 2.0327 - acc: 0.6776 - val_loss: 2.1197 - val_acc: 0.6742\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9959 - acc: 0.6779 - val_loss: 2.0862 - val_acc: 0.6756\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9827 - acc: 0.6778 - val_loss: 2.1223 - val_acc: 0.6766\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0076 - acc: 0.6780 - val_loss: 2.1556 - val_acc: 0.6771\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0019 - acc: 0.6786 - val_loss: 2.1387 - val_acc: 0.6736\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9594 - acc: 0.6794 - val_loss: 2.1161 - val_acc: 0.6775\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0011 - acc: 0.6782 - val_loss: 2.1067 - val_acc: 0.6741\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 1.9795 - acc: 0.6785 - val_loss: 2.0952 - val_acc: 0.6738\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1946 - acc: 0.9920 - val_loss: 0.1966 - val_acc: 0.9896\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.1973 - acc: 0.9917 - val_loss: 0.1998 - val_acc: 0.9897\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1979 - acc: 0.9916 - val_loss: 0.2101 - val_acc: 0.9894\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2123 - acc: 0.9920 - val_loss: 0.2117 - val_acc: 0.9899\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 0.2031 - acc: 0.9921 - val_loss: 0.2053 - val_acc: 0.9899\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2068 - acc: 0.9918 - val_loss: 0.2190 - val_acc: 0.9889\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2021 - acc: 0.9918 - val_loss: 0.1963 - val_acc: 0.9897\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2004 - acc: 0.9917 - val_loss: 0.2111 - val_acc: 0.9896\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2166 - acc: 0.9920 - val_loss: 0.2149 - val_acc: 0.9900\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2057 - acc: 0.9921 - val_loss: 0.2057 - val_acc: 0.9898\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2026 - acc: 0.9920 - val_loss: 0.2250 - val_acc: 0.9889\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2303 - acc: 0.9912 - val_loss: 0.2413 - val_acc: 0.9896\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2117 - acc: 0.9920 - val_loss: 0.2014 - val_acc: 0.9900\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1923 - acc: 0.9922 - val_loss: 0.1923 - val_acc: 0.9899\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.1926 - acc: 0.9921 - val_loss: 0.1991 - val_acc: 0.9894\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2065 - acc: 0.9915 - val_loss: 0.2270 - val_acc: 0.9883\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2164 - acc: 0.9906 - val_loss: 0.2170 - val_acc: 0.9882\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2030 - acc: 0.9913 - val_loss: 0.2027 - val_acc: 0.9895\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.2042 - acc: 0.9917 - val_loss: 0.2209 - val_acc: 0.9895\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2090 - acc: 0.9921 - val_loss: 0.2077 - val_acc: 0.9898\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2027 - acc: 0.9919 - val_loss: 0.2085 - val_acc: 0.9895\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2167 - acc: 0.9917 - val_loss: 0.2348 - val_acc: 0.9898\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2200 - acc: 0.9920 - val_loss: 0.2136 - val_acc: 0.9900\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2021 - acc: 0.9921 - val_loss: 0.2079 - val_acc: 0.9897\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2120 - acc: 0.9914 - val_loss: 0.2094 - val_acc: 0.9894\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1973 - acc: 0.9918 - val_loss: 0.1998 - val_acc: 0.9897\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2050 - acc: 0.9912 - val_loss: 0.2139 - val_acc: 0.9891\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2133 - acc: 0.9915 - val_loss: 0.2149 - val_acc: 0.9894\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2105 - acc: 0.9921 - val_loss: 0.2033 - val_acc: 0.9899\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1999 - acc: 0.9920 - val_loss: 0.2054 - val_acc: 0.9893\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 0.2125 - acc: 0.9912 - val_loss: 0.2160 - val_acc: 0.9891\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2099 - acc: 0.9914 - val_loss: 0.2133 - val_acc: 0.9892\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2013 - acc: 0.9918 - val_loss: 0.1999 - val_acc: 0.9898\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2000 - acc: 0.9920 - val_loss: 0.2080 - val_acc: 0.9898\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2103 - acc: 0.9918 - val_loss: 0.2097 - val_acc: 0.9892\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2022 - acc: 0.9918 - val_loss: 0.2115 - val_acc: 0.9890\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2217 - acc: 0.9909 - val_loss: 0.2136 - val_acc: 0.9889\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2085 - acc: 0.9911 - val_loss: 0.2035 - val_acc: 0.9893\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2094 - acc: 0.9909 - val_loss: 0.2148 - val_acc: 0.9892\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2076 - acc: 0.9916 - val_loss: 0.2047 - val_acc: 0.9895\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2019 - acc: 0.9919 - val_loss: 0.2003 - val_acc: 0.9899\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1933 - acc: 0.9921 - val_loss: 0.1941 - val_acc: 0.9900\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2022 - acc: 0.9922 - val_loss: 0.2284 - val_acc: 0.9898\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2210 - acc: 0.9921 - val_loss: 0.2147 - val_acc: 0.9899\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2017 - acc: 0.9921 - val_loss: 0.1961 - val_acc: 0.9899\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1984 - acc: 0.9917 - val_loss: 0.2119 - val_acc: 0.9891\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2057 - acc: 0.9913 - val_loss: 0.2029 - val_acc: 0.9893\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2018 - acc: 0.9913 - val_loss: 0.2050 - val_acc: 0.9891\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2001 - acc: 0.9916 - val_loss: 0.2027 - val_acc: 0.9896\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2062 - acc: 0.9910 - val_loss: 0.2174 - val_acc: 0.9888\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0033 - acc: 0.9549 - val_loss: 0.0034 - val_acc: 0.9583\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9594\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0033 - acc: 0.9563 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0033 - acc: 0.9584 - val_loss: 0.0034 - val_acc: 0.9589\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9568 - val_loss: 0.0034 - val_acc: 0.9598\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0033 - acc: 0.9567 - val_loss: 0.0034 - val_acc: 0.9595\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0034 - val_acc: 0.9597\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0034 - acc: 0.9547 - val_loss: 0.0036 - val_acc: 0.9544\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9526 - val_loss: 0.0035 - val_acc: 0.9555\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0033 - acc: 0.9555 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0033 - acc: 0.9564 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.0032 - acc: 0.9591 - val_loss: 0.0037 - val_acc: 0.9534\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0035 - acc: 0.9531 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0033 - val_acc: 0.9612\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9563 - val_loss: 0.0040 - val_acc: 0.9502\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0035 - acc: 0.9515 - val_loss: 0.0033 - val_acc: 0.9612\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0032 - acc: 0.9568 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0033 - acc: 0.9563 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0034 - val_acc: 0.9607\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0033 - acc: 0.9582 - val_loss: 0.0035 - val_acc: 0.9609\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0034 - acc: 0.9547 - val_loss: 0.0034 - val_acc: 0.9610\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0034 - val_acc: 0.9620\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9575 - val_loss: 0.0035 - val_acc: 0.9597\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0032 - acc: 0.9589 - val_loss: 0.0033 - val_acc: 0.9619\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9551 - val_loss: 0.0034 - val_acc: 0.9594\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0035 - acc: 0.9518 - val_loss: 0.0033 - val_acc: 0.9620\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0034 - acc: 0.9544 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0032 - acc: 0.9568 - val_loss: 0.0034 - val_acc: 0.9607\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0034 - val_acc: 0.9603\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0034 - val_acc: 0.9613\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0033 - acc: 0.9556 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0033 - acc: 0.9573 - val_loss: 0.0034 - val_acc: 0.9587\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9542 - val_loss: 0.0033 - val_acc: 0.9621\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9620\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.0033 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9619\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0034 - val_acc: 0.9621\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.0034 - acc: 0.9543 - val_loss: 0.0034 - val_acc: 0.9576\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0039 - val_acc: 0.9537\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0033 - acc: 0.9552 - val_loss: 0.0034 - val_acc: 0.9622\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0033 - val_acc: 0.9624\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0032 - acc: 0.9581 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0032 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9619\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9624\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.0032 - acc: 0.9589 - val_loss: 0.0033 - val_acc: 0.9602\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0034 - val_acc: 0.9582\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0034 - acc: 0.9524 - val_loss: 0.0033 - val_acc: 0.9599\n",
      "start training round 10\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2427 - acc: 0.6821 - val_loss: 0.2543 - val_acc: 0.6802\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2437 - acc: 0.6814 - val_loss: 0.2541 - val_acc: 0.6793\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2409 - acc: 0.6821 - val_loss: 0.2598 - val_acc: 0.6784\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2416 - acc: 0.6817 - val_loss: 0.2555 - val_acc: 0.6818\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2434 - acc: 0.6830 - val_loss: 0.2647 - val_acc: 0.6798\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2447 - acc: 0.6828 - val_loss: 0.2597 - val_acc: 0.6784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2394 - acc: 0.6828 - val_loss: 0.2533 - val_acc: 0.6812\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2438 - acc: 0.6816 - val_loss: 0.2585 - val_acc: 0.6770\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2419 - acc: 0.6816 - val_loss: 0.2556 - val_acc: 0.6794\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2424 - acc: 0.6821 - val_loss: 0.2566 - val_acc: 0.6817\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2423 - acc: 0.6813 - val_loss: 0.2513 - val_acc: 0.6825\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2408 - acc: 0.6821 - val_loss: 0.2522 - val_acc: 0.6816\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2425 - acc: 0.6816 - val_loss: 0.2527 - val_acc: 0.6817\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2398 - acc: 0.6830 - val_loss: 0.2532 - val_acc: 0.6815\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2412 - acc: 0.6823 - val_loss: 0.2522 - val_acc: 0.6822\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2413 - acc: 0.6831 - val_loss: 0.2510 - val_acc: 0.6830\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2385 - acc: 0.6835 - val_loss: 0.2573 - val_acc: 0.6800\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2453 - acc: 0.6805 - val_loss: 0.2544 - val_acc: 0.6801\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2417 - acc: 0.6822 - val_loss: 0.2769 - val_acc: 0.6749\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2473 - acc: 0.6808 - val_loss: 0.2510 - val_acc: 0.6816\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2394 - acc: 0.6832 - val_loss: 0.2539 - val_acc: 0.6795\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2418 - acc: 0.6833 - val_loss: 0.2508 - val_acc: 0.6821\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2384 - acc: 0.6837 - val_loss: 0.2515 - val_acc: 0.6825\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2421 - acc: 0.6827 - val_loss: 0.2530 - val_acc: 0.6822\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2396 - acc: 0.6838 - val_loss: 0.2523 - val_acc: 0.6810\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2422 - acc: 0.6825 - val_loss: 0.2507 - val_acc: 0.6831\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2410 - acc: 0.6828 - val_loss: 0.2623 - val_acc: 0.6804\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2427 - acc: 0.6812 - val_loss: 0.2511 - val_acc: 0.6826\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2385 - acc: 0.6833 - val_loss: 0.2553 - val_acc: 0.6789\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2447 - acc: 0.6814 - val_loss: 0.2627 - val_acc: 0.6788\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2458 - acc: 0.6804 - val_loss: 0.2512 - val_acc: 0.6812\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2381 - acc: 0.6837 - val_loss: 0.2512 - val_acc: 0.6817\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2394 - acc: 0.6831 - val_loss: 0.2604 - val_acc: 0.6752\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2435 - acc: 0.6811 - val_loss: 0.2535 - val_acc: 0.6822\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2408 - acc: 0.6830 - val_loss: 0.2515 - val_acc: 0.6806\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2392 - acc: 0.6825 - val_loss: 0.2518 - val_acc: 0.6802\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2407 - acc: 0.6821 - val_loss: 0.2520 - val_acc: 0.6805\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2451 - acc: 0.6811 - val_loss: 0.2632 - val_acc: 0.6792\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2430 - acc: 0.6826 - val_loss: 0.2508 - val_acc: 0.6821\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2403 - acc: 0.6838 - val_loss: 0.2544 - val_acc: 0.6825\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2401 - acc: 0.6837 - val_loss: 0.2571 - val_acc: 0.6790\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2409 - acc: 0.6822 - val_loss: 0.2524 - val_acc: 0.6813\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2393 - acc: 0.6831 - val_loss: 0.2502 - val_acc: 0.6820\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2404 - acc: 0.6832 - val_loss: 0.2545 - val_acc: 0.6815\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2404 - acc: 0.6822 - val_loss: 0.2544 - val_acc: 0.6804\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2410 - acc: 0.6826 - val_loss: 0.2580 - val_acc: 0.6767\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2403 - acc: 0.6831 - val_loss: 0.2544 - val_acc: 0.6803\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2421 - acc: 0.6826 - val_loss: 0.2556 - val_acc: 0.6801\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.2390 - acc: 0.6835 - val_loss: 0.2566 - val_acc: 0.6791\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2395 - acc: 0.6829 - val_loss: 0.2550 - val_acc: 0.6818\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9869 - acc: 0.6772 - val_loss: 2.1412 - val_acc: 0.6744\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0033 - acc: 0.6783 - val_loss: 2.0893 - val_acc: 0.6755\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0012 - acc: 0.6778 - val_loss: 2.2181 - val_acc: 0.6731\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0371 - acc: 0.6777 - val_loss: 2.1162 - val_acc: 0.6781\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9916 - acc: 0.6789 - val_loss: 2.1296 - val_acc: 0.6770\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9955 - acc: 0.6789 - val_loss: 2.1311 - val_acc: 0.6766\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0005 - acc: 0.6786 - val_loss: 2.1147 - val_acc: 0.6773\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0084 - acc: 0.6775 - val_loss: 2.1140 - val_acc: 0.6754\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9821 - acc: 0.6779 - val_loss: 2.1471 - val_acc: 0.6752\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 2.0035 - acc: 0.6783 - val_loss: 2.1359 - val_acc: 0.6750\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9986 - acc: 0.6774 - val_loss: 2.1106 - val_acc: 0.6720\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0061 - acc: 0.6774 - val_loss: 2.1242 - val_acc: 0.6753\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 1.9750 - acc: 0.6787 - val_loss: 2.1211 - val_acc: 0.6772\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0214 - acc: 0.6777 - val_loss: 2.1223 - val_acc: 0.6757\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 2.0050 - acc: 0.6774 - val_loss: 2.1785 - val_acc: 0.6754\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 392us/step - loss: 2.0021 - acc: 0.6782 - val_loss: 2.1007 - val_acc: 0.6780\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 1.9844 - acc: 0.6788 - val_loss: 2.1616 - val_acc: 0.6783\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0192 - acc: 0.6782 - val_loss: 2.1313 - val_acc: 0.6727\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 1.9857 - acc: 0.6780 - val_loss: 2.2181 - val_acc: 0.6707\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 2.0031 - acc: 0.6774 - val_loss: 2.0968 - val_acc: 0.6761\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9858 - acc: 0.6787 - val_loss: 2.0836 - val_acc: 0.6748\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9990 - acc: 0.6786 - val_loss: 2.0946 - val_acc: 0.6744\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 1.9859 - acc: 0.6765 - val_loss: 2.1398 - val_acc: 0.6759\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0011 - acc: 0.6776 - val_loss: 2.1693 - val_acc: 0.6748\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0081 - acc: 0.6774 - val_loss: 2.0990 - val_acc: 0.6764\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9903 - acc: 0.6783 - val_loss: 2.1018 - val_acc: 0.6752\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 1.9738 - acc: 0.6779 - val_loss: 2.0988 - val_acc: 0.6737\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 1.9947 - acc: 0.6780 - val_loss: 2.1900 - val_acc: 0.6692\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0270 - acc: 0.6777 - val_loss: 2.1636 - val_acc: 0.6751\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 1.9982 - acc: 0.6786 - val_loss: 2.1916 - val_acc: 0.6752\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0009 - acc: 0.6786 - val_loss: 2.0799 - val_acc: 0.6760\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9746 - acc: 0.6778 - val_loss: 2.1078 - val_acc: 0.6758\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9832 - acc: 0.6782 - val_loss: 2.1968 - val_acc: 0.6762\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9914 - acc: 0.6788 - val_loss: 2.1384 - val_acc: 0.6750\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 1.9818 - acc: 0.6774 - val_loss: 2.1317 - val_acc: 0.6762\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9991 - acc: 0.6772 - val_loss: 2.1317 - val_acc: 0.6768\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0024 - acc: 0.6778 - val_loss: 2.1474 - val_acc: 0.6748\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9977 - acc: 0.6776 - val_loss: 2.0912 - val_acc: 0.6759\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0048 - acc: 0.6788 - val_loss: 2.1390 - val_acc: 0.6768\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0017 - acc: 0.6779 - val_loss: 2.1110 - val_acc: 0.6757\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 1.9895 - acc: 0.6780 - val_loss: 2.1240 - val_acc: 0.6778\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9837 - acc: 0.6794 - val_loss: 2.0979 - val_acc: 0.6781\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0043 - acc: 0.6783 - val_loss: 2.1704 - val_acc: 0.6748\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 1.9907 - acc: 0.6784 - val_loss: 2.1446 - val_acc: 0.6749\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 1.9868 - acc: 0.6784 - val_loss: 2.1496 - val_acc: 0.6766\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 2.0011 - acc: 0.6780 - val_loss: 2.1234 - val_acc: 0.6762\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9971 - acc: 0.6785 - val_loss: 2.1265 - val_acc: 0.6745\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9727 - acc: 0.6780 - val_loss: 2.1175 - val_acc: 0.6744\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0002 - acc: 0.6771 - val_loss: 2.1420 - val_acc: 0.6737\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9856 - acc: 0.6784 - val_loss: 2.1009 - val_acc: 0.6777\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2106 - acc: 0.9917 - val_loss: 0.2059 - val_acc: 0.9895\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1983 - acc: 0.9919 - val_loss: 0.2014 - val_acc: 0.9896\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2027 - acc: 0.9921 - val_loss: 0.2230 - val_acc: 0.9899\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2332 - acc: 0.9922 - val_loss: 0.2286 - val_acc: 0.9897\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2125 - acc: 0.9915 - val_loss: 0.2128 - val_acc: 0.9894\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1983 - acc: 0.9919 - val_loss: 0.1961 - val_acc: 0.9899\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.1966 - acc: 0.9922 - val_loss: 0.2069 - val_acc: 0.9898\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2018 - acc: 0.9920 - val_loss: 0.2013 - val_acc: 0.9896\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2013 - acc: 0.9920 - val_loss: 0.2056 - val_acc: 0.9900\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1978 - acc: 0.9922 - val_loss: 0.2030 - val_acc: 0.9899\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2046 - acc: 0.9919 - val_loss: 0.2157 - val_acc: 0.9895\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2072 - acc: 0.9920 - val_loss: 0.2075 - val_acc: 0.9899\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1949 - acc: 0.9920 - val_loss: 0.1976 - val_acc: 0.9899\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2026 - acc: 0.9918 - val_loss: 0.2177 - val_acc: 0.9895\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2223 - acc: 0.9912 - val_loss: 0.2053 - val_acc: 0.9895\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2017 - acc: 0.9917 - val_loss: 0.2114 - val_acc: 0.9886\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2073 - acc: 0.9907 - val_loss: 0.2103 - val_acc: 0.9886\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2063 - acc: 0.9910 - val_loss: 0.2015 - val_acc: 0.9896\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2033 - acc: 0.9920 - val_loss: 0.2134 - val_acc: 0.9899\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2102 - acc: 0.9920 - val_loss: 0.2272 - val_acc: 0.9893\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2078 - acc: 0.9921 - val_loss: 0.1945 - val_acc: 0.9900\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1921 - acc: 0.9921 - val_loss: 0.1966 - val_acc: 0.9897\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2015 - acc: 0.9920 - val_loss: 0.2067 - val_acc: 0.9899\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2035 - acc: 0.9922 - val_loss: 0.1970 - val_acc: 0.9899\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.1947 - acc: 0.9921 - val_loss: 0.2009 - val_acc: 0.9900\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1989 - acc: 0.9921 - val_loss: 0.2054 - val_acc: 0.9895\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2036 - acc: 0.9917 - val_loss: 0.2077 - val_acc: 0.9896\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 361us/step - loss: 0.1999 - acc: 0.9919 - val_loss: 0.2005 - val_acc: 0.9897\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.1973 - acc: 0.9921 - val_loss: 0.1951 - val_acc: 0.9900\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2029 - acc: 0.9921 - val_loss: 0.2130 - val_acc: 0.9899\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2120 - acc: 0.9922 - val_loss: 0.2160 - val_acc: 0.9900\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2092 - acc: 0.9919 - val_loss: 0.1998 - val_acc: 0.9900\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1961 - acc: 0.9920 - val_loss: 0.1947 - val_acc: 0.9900\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.1951 - acc: 0.9922 - val_loss: 0.1938 - val_acc: 0.9899\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.1920 - acc: 0.9921 - val_loss: 0.2003 - val_acc: 0.9892\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2137 - acc: 0.9908 - val_loss: 0.2321 - val_acc: 0.9881\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2192 - acc: 0.9905 - val_loss: 0.2048 - val_acc: 0.9892\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2014 - acc: 0.9913 - val_loss: 0.2113 - val_acc: 0.9896\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2083 - acc: 0.9916 - val_loss: 0.2033 - val_acc: 0.9897\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.1997 - acc: 0.9922 - val_loss: 0.2104 - val_acc: 0.9900\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2189 - acc: 0.9922 - val_loss: 0.2203 - val_acc: 0.9898\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2030 - acc: 0.9921 - val_loss: 0.1974 - val_acc: 0.9900\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1913 - acc: 0.9921 - val_loss: 0.1912 - val_acc: 0.9899\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.1894 - acc: 0.9922 - val_loss: 0.1942 - val_acc: 0.9900\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.1935 - acc: 0.9921 - val_loss: 0.2019 - val_acc: 0.9895\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2087 - acc: 0.9913 - val_loss: 0.2224 - val_acc: 0.9889\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2117 - acc: 0.9914 - val_loss: 0.2018 - val_acc: 0.9894\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1957 - acc: 0.9916 - val_loss: 0.1947 - val_acc: 0.9894\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.1984 - acc: 0.9916 - val_loss: 0.2037 - val_acc: 0.9895\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2020 - acc: 0.9918 - val_loss: 0.2087 - val_acc: 0.9900\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9573 - val_loss: 0.0033 - val_acc: 0.9600\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0032 - acc: 0.9569 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9570 - val_loss: 0.0033 - val_acc: 0.9604\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9555 - val_loss: 0.0034 - val_acc: 0.9589\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0034 - acc: 0.9536 - val_loss: 0.0034 - val_acc: 0.9592\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0033 - acc: 0.9568 - val_loss: 0.0034 - val_acc: 0.9588\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0034 - acc: 0.9562 - val_loss: 0.0034 - val_acc: 0.9600\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9580 - val_loss: 0.0034 - val_acc: 0.9591\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0033 - acc: 0.9555 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0036 - val_acc: 0.9542\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9530 - val_loss: 0.0034 - val_acc: 0.9598\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0032 - acc: 0.9582 - val_loss: 0.0036 - val_acc: 0.9550\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0033 - acc: 0.9555 - val_loss: 0.0033 - val_acc: 0.9602\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9555 - val_loss: 0.0034 - val_acc: 0.9618\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0032 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9619\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.0033 - acc: 0.9575 - val_loss: 0.0033 - val_acc: 0.9596\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0035 - val_acc: 0.9595\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0035 - acc: 0.9504 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0032 - acc: 0.9574 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0032 - acc: 0.9565 - val_loss: 0.0033 - val_acc: 0.9604\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0035 - val_acc: 0.9558\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0033 - acc: 0.9541 - val_loss: 0.0034 - val_acc: 0.9610\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0036 - val_acc: 0.9558\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0035 - acc: 0.9502 - val_loss: 0.0037 - val_acc: 0.9557\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0035 - acc: 0.9519 - val_loss: 0.0036 - val_acc: 0.9599\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9546 - val_loss: 0.0033 - val_acc: 0.9624\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0034 - val_acc: 0.9595\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0032 - acc: 0.9574 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0032 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9613\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.0032 - acc: 0.9577 - val_loss: 0.0035 - val_acc: 0.9597\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9563 - val_loss: 0.0034 - val_acc: 0.9622\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0033 - acc: 0.9577 - val_loss: 0.0036 - val_acc: 0.9570\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0035 - acc: 0.9505 - val_loss: 0.0037 - val_acc: 0.9526\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0033 - acc: 0.9530 - val_loss: 0.0038 - val_acc: 0.9522\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0034 - acc: 0.9536 - val_loss: 0.0033 - val_acc: 0.9619\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0032 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9621\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9589 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0033 - acc: 0.9570 - val_loss: 0.0034 - val_acc: 0.9619\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0033 - acc: 0.9566 - val_loss: 0.0035 - val_acc: 0.9565\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0033 - acc: 0.9546 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0032 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9602\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0032 - acc: 0.9575 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0034 - val_acc: 0.9611\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0034 - acc: 0.9527 - val_loss: 0.0034 - val_acc: 0.9582\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0034 - val_acc: 0.9617\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0033 - acc: 0.9539 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "start training round 11\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2375 - acc: 0.6838 - val_loss: 0.2512 - val_acc: 0.6813\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2422 - acc: 0.6827 - val_loss: 0.2552 - val_acc: 0.6809\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2422 - acc: 0.6833 - val_loss: 0.2565 - val_acc: 0.6814\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2395 - acc: 0.6837 - val_loss: 0.2493 - val_acc: 0.6825\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2388 - acc: 0.6831 - val_loss: 0.2505 - val_acc: 0.6814\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2428 - acc: 0.6817 - val_loss: 0.2574 - val_acc: 0.6781\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2419 - acc: 0.6815 - val_loss: 0.2579 - val_acc: 0.6806\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2398 - acc: 0.6829 - val_loss: 0.2549 - val_acc: 0.6807\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2413 - acc: 0.6826 - val_loss: 0.2515 - val_acc: 0.6825\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2409 - acc: 0.6834 - val_loss: 0.2498 - val_acc: 0.6822\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2389 - acc: 0.6840 - val_loss: 0.2521 - val_acc: 0.6818\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2387 - acc: 0.6828 - val_loss: 0.2534 - val_acc: 0.6802\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2416 - acc: 0.6831 - val_loss: 0.2540 - val_acc: 0.6805\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2407 - acc: 0.6830 - val_loss: 0.2514 - val_acc: 0.6817\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2395 - acc: 0.6829 - val_loss: 0.2512 - val_acc: 0.6813\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2422 - acc: 0.6826 - val_loss: 0.2545 - val_acc: 0.6804\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2394 - acc: 0.6831 - val_loss: 0.2504 - val_acc: 0.6834\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2382 - acc: 0.6839 - val_loss: 0.2523 - val_acc: 0.6828\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2398 - acc: 0.6839 - val_loss: 0.2566 - val_acc: 0.6784\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2431 - acc: 0.6813 - val_loss: 0.2545 - val_acc: 0.6811\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2390 - acc: 0.6834 - val_loss: 0.2518 - val_acc: 0.6827\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2398 - acc: 0.6823 - val_loss: 0.2500 - val_acc: 0.6831\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2418 - acc: 0.6830 - val_loss: 0.2540 - val_acc: 0.6790\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2400 - acc: 0.6828 - val_loss: 0.2578 - val_acc: 0.6777\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2426 - acc: 0.6829 - val_loss: 0.2619 - val_acc: 0.6813\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2405 - acc: 0.6836 - val_loss: 0.2504 - val_acc: 0.6825\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2405 - acc: 0.6830 - val_loss: 0.2544 - val_acc: 0.6802\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2411 - acc: 0.6806 - val_loss: 0.2492 - val_acc: 0.6829\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2370 - acc: 0.6841 - val_loss: 0.2507 - val_acc: 0.6826\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2377 - acc: 0.6841 - val_loss: 0.2494 - val_acc: 0.6835\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2388 - acc: 0.6836 - val_loss: 0.2540 - val_acc: 0.6814\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2403 - acc: 0.6830 - val_loss: 0.2575 - val_acc: 0.6804\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2440 - acc: 0.6821 - val_loss: 0.2509 - val_acc: 0.6821\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2394 - acc: 0.6833 - val_loss: 0.2598 - val_acc: 0.6789\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2432 - acc: 0.6828 - val_loss: 0.2521 - val_acc: 0.6814\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2387 - acc: 0.6833 - val_loss: 0.2502 - val_acc: 0.6829\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2411 - acc: 0.6829 - val_loss: 0.2593 - val_acc: 0.6809\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2413 - acc: 0.6824 - val_loss: 0.2548 - val_acc: 0.6806\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2397 - acc: 0.6829 - val_loss: 0.2521 - val_acc: 0.6793\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2387 - acc: 0.6834 - val_loss: 0.2550 - val_acc: 0.6810\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2427 - acc: 0.6836 - val_loss: 0.2514 - val_acc: 0.6824\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2383 - acc: 0.6835 - val_loss: 0.2521 - val_acc: 0.6793\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2413 - acc: 0.6826 - val_loss: 0.2490 - val_acc: 0.6828\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2364 - acc: 0.6845 - val_loss: 0.2532 - val_acc: 0.6803\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2402 - acc: 0.6832 - val_loss: 0.2539 - val_acc: 0.6805\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.2414 - acc: 0.6825 - val_loss: 0.2656 - val_acc: 0.6782\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2434 - acc: 0.6818 - val_loss: 0.2508 - val_acc: 0.6827\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2398 - acc: 0.6827 - val_loss: 0.2505 - val_acc: 0.6828\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2379 - acc: 0.6841 - val_loss: 0.2545 - val_acc: 0.6818\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2391 - acc: 0.6831 - val_loss: 0.2611 - val_acc: 0.6800\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0107 - acc: 0.6777 - val_loss: 2.1442 - val_acc: 0.6779\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0004 - acc: 0.6791 - val_loss: 2.1124 - val_acc: 0.6771\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9858 - acc: 0.6784 - val_loss: 2.1207 - val_acc: 0.6758\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9654 - acc: 0.6784 - val_loss: 2.2380 - val_acc: 0.6679\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0257 - acc: 0.6766 - val_loss: 2.1630 - val_acc: 0.6714\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9839 - acc: 0.6790 - val_loss: 2.1613 - val_acc: 0.6760\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0082 - acc: 0.6782 - val_loss: 2.1388 - val_acc: 0.6765\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9922 - acc: 0.6775 - val_loss: 2.1854 - val_acc: 0.6723\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0039 - acc: 0.6769 - val_loss: 2.0879 - val_acc: 0.6742\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 1.9729 - acc: 0.6787 - val_loss: 2.1266 - val_acc: 0.6733\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 1.9888 - acc: 0.6787 - val_loss: 2.1315 - val_acc: 0.6728\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 2.0063 - acc: 0.6777 - val_loss: 2.1059 - val_acc: 0.6768\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9860 - acc: 0.6793 - val_loss: 2.0805 - val_acc: 0.6771\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 1.9687 - acc: 0.6785 - val_loss: 2.0729 - val_acc: 0.6773\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 1.9659 - acc: 0.6793 - val_loss: 2.2004 - val_acc: 0.6729\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 2.0108 - acc: 0.6770 - val_loss: 2.1923 - val_acc: 0.6753\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9753 - acc: 0.6786 - val_loss: 2.1272 - val_acc: 0.6743\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9891 - acc: 0.6770 - val_loss: 2.1707 - val_acc: 0.6771\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0109 - acc: 0.6781 - val_loss: 2.1507 - val_acc: 0.6763\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9772 - acc: 0.6783 - val_loss: 2.1404 - val_acc: 0.6772\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0181 - acc: 0.6777 - val_loss: 2.1235 - val_acc: 0.6764\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0046 - acc: 0.6793 - val_loss: 2.0923 - val_acc: 0.6766\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9972 - acc: 0.6784 - val_loss: 2.1042 - val_acc: 0.6744\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9707 - acc: 0.6785 - val_loss: 2.1186 - val_acc: 0.6752\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9958 - acc: 0.6774 - val_loss: 2.0886 - val_acc: 0.6754\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 369us/step - loss: 1.9973 - acc: 0.6780 - val_loss: 2.1023 - val_acc: 0.6752\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0109 - acc: 0.6778 - val_loss: 2.1261 - val_acc: 0.6761\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0135 - acc: 0.6781 - val_loss: 2.1197 - val_acc: 0.6778\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9985 - acc: 0.6781 - val_loss: 2.1871 - val_acc: 0.6749\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9978 - acc: 0.6786 - val_loss: 2.1486 - val_acc: 0.6747\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9960 - acc: 0.6781 - val_loss: 2.1729 - val_acc: 0.6719\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0064 - acc: 0.6782 - val_loss: 2.1234 - val_acc: 0.6752\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0010 - acc: 0.6785 - val_loss: 2.1145 - val_acc: 0.6766\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0066 - acc: 0.6774 - val_loss: 2.1078 - val_acc: 0.6757\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9862 - acc: 0.6779 - val_loss: 2.1501 - val_acc: 0.6755\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 1.9880 - acc: 0.6780 - val_loss: 2.1739 - val_acc: 0.6729\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9833 - acc: 0.6769 - val_loss: 2.0904 - val_acc: 0.6770\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9952 - acc: 0.6782 - val_loss: 2.1052 - val_acc: 0.6781\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0227 - acc: 0.6786 - val_loss: 2.1783 - val_acc: 0.6754\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9927 - acc: 0.6787 - val_loss: 2.1053 - val_acc: 0.6780\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 1.9689 - acc: 0.6794 - val_loss: 2.1338 - val_acc: 0.6768\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9885 - acc: 0.6779 - val_loss: 2.1266 - val_acc: 0.6750\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 2.0057 - acc: 0.6786 - val_loss: 2.0797 - val_acc: 0.6761\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9917 - acc: 0.6777 - val_loss: 2.1471 - val_acc: 0.6716\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9823 - acc: 0.6776 - val_loss: 2.1400 - val_acc: 0.6731\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 1.9839 - acc: 0.6786 - val_loss: 2.2554 - val_acc: 0.6760\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0041 - acc: 0.6779 - val_loss: 2.1048 - val_acc: 0.6770\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9811 - acc: 0.6786 - val_loss: 2.1162 - val_acc: 0.6773\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9785 - acc: 0.6781 - val_loss: 2.1083 - val_acc: 0.6759\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 1.9814 - acc: 0.6785 - val_loss: 2.1246 - val_acc: 0.6762\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2034 - acc: 0.9921 - val_loss: 0.2046 - val_acc: 0.9896\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2071 - acc: 0.9920 - val_loss: 0.2117 - val_acc: 0.9893\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2091 - acc: 0.9915 - val_loss: 0.1975 - val_acc: 0.9897\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1963 - acc: 0.9920 - val_loss: 0.2055 - val_acc: 0.9898\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2009 - acc: 0.9920 - val_loss: 0.2084 - val_acc: 0.9898\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2025 - acc: 0.9921 - val_loss: 0.2050 - val_acc: 0.9898\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 0.2114 - acc: 0.9919 - val_loss: 0.2146 - val_acc: 0.9891\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2114 - acc: 0.9914 - val_loss: 0.2032 - val_acc: 0.9893\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.1987 - acc: 0.9910 - val_loss: 0.1968 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.1946 - acc: 0.9915 - val_loss: 0.1983 - val_acc: 0.9893\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1999 - acc: 0.9908 - val_loss: 0.2023 - val_acc: 0.9888\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 0.1996 - acc: 0.9911 - val_loss: 0.2066 - val_acc: 0.9889\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2043 - acc: 0.9910 - val_loss: 0.2012 - val_acc: 0.9894\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 365us/step - loss: 0.2017 - acc: 0.9919 - val_loss: 0.2024 - val_acc: 0.9896\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2014 - acc: 0.9920 - val_loss: 0.2085 - val_acc: 0.9899\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2074 - acc: 0.9922 - val_loss: 0.2149 - val_acc: 0.9899\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2265 - acc: 0.9921 - val_loss: 0.2529 - val_acc: 0.9899\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2147 - acc: 0.9922 - val_loss: 0.2012 - val_acc: 0.9900\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.1935 - acc: 0.9922 - val_loss: 0.1960 - val_acc: 0.9899\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1922 - acc: 0.9922 - val_loss: 0.1943 - val_acc: 0.9899\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1951 - acc: 0.9923 - val_loss: 0.2050 - val_acc: 0.9900\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.1985 - acc: 0.9922 - val_loss: 0.2026 - val_acc: 0.9900\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1983 - acc: 0.9922 - val_loss: 0.1983 - val_acc: 0.9899\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2002 - acc: 0.9921 - val_loss: 0.2061 - val_acc: 0.9899\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2066 - acc: 0.9921 - val_loss: 0.2210 - val_acc: 0.9898\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 366us/step - loss: 0.2184 - acc: 0.9921 - val_loss: 0.2149 - val_acc: 0.9899\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2010 - acc: 0.9920 - val_loss: 0.1926 - val_acc: 0.9898\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.1895 - acc: 0.9922 - val_loss: 0.1948 - val_acc: 0.9898\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1964 - acc: 0.9920 - val_loss: 0.2027 - val_acc: 0.9893\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2052 - acc: 0.9911 - val_loss: 0.2105 - val_acc: 0.9892\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2089 - acc: 0.9906 - val_loss: 0.2164 - val_acc: 0.9879\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2077 - acc: 0.9905 - val_loss: 0.1966 - val_acc: 0.9895\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1930 - acc: 0.9916 - val_loss: 0.1983 - val_acc: 0.9893\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2104 - acc: 0.9914 - val_loss: 0.2124 - val_acc: 0.9896\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2079 - acc: 0.9919 - val_loss: 0.2052 - val_acc: 0.9898\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1961 - acc: 0.9922 - val_loss: 0.1926 - val_acc: 0.9898\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1987 - acc: 0.9916 - val_loss: 0.1982 - val_acc: 0.9896\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.1938 - acc: 0.9921 - val_loss: 0.1959 - val_acc: 0.9899\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2024 - acc: 0.9923 - val_loss: 0.1985 - val_acc: 0.9900\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1971 - acc: 0.9922 - val_loss: 0.2072 - val_acc: 0.9900\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2118 - acc: 0.9922 - val_loss: 0.2084 - val_acc: 0.9899\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2167 - acc: 0.9911 - val_loss: 0.2137 - val_acc: 0.9891\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.2096 - acc: 0.9915 - val_loss: 0.2143 - val_acc: 0.9893\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2058 - acc: 0.9920 - val_loss: 0.2039 - val_acc: 0.9898\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2001 - acc: 0.9919 - val_loss: 0.2204 - val_acc: 0.9891\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2114 - acc: 0.9913 - val_loss: 0.2052 - val_acc: 0.9886\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2042 - acc: 0.9909 - val_loss: 0.2055 - val_acc: 0.9880\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2082 - acc: 0.9906 - val_loss: 0.2190 - val_acc: 0.9878\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2028 - acc: 0.9912 - val_loss: 0.1928 - val_acc: 0.9897\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.1948 - acc: 0.9920 - val_loss: 0.2080 - val_acc: 0.9899\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0033 - val_acc: 0.9622\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0032 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9624\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9591\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0033 - acc: 0.9532 - val_loss: 0.0035 - val_acc: 0.9567\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0033 - acc: 0.9555 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0032 - acc: 0.9578 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9622\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0032 - acc: 0.9576 - val_loss: 0.0035 - val_acc: 0.9539\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9526 - val_loss: 0.0034 - val_acc: 0.9572\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.0034 - acc: 0.9544 - val_loss: 0.0035 - val_acc: 0.9514\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0034 - acc: 0.9534 - val_loss: 0.0034 - val_acc: 0.9587\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9594\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0035 - acc: 0.9523 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0032 - acc: 0.9577 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9578\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0033 - val_acc: 0.9610\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0032 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9584\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0033 - acc: 0.9575 - val_loss: 0.0034 - val_acc: 0.9608\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0035 - val_acc: 0.9558\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0034 - acc: 0.9533 - val_loss: 0.0033 - val_acc: 0.9619\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0032 - acc: 0.9592 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9593 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0034 - val_acc: 0.9599\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0033 - acc: 0.9557 - val_loss: 0.0038 - val_acc: 0.9484\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0033 - acc: 0.9539 - val_loss: 0.0033 - val_acc: 0.9605\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0032 - acc: 0.9580 - val_loss: 0.0034 - val_acc: 0.9592\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9562 - val_loss: 0.0035 - val_acc: 0.9559\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0033 - acc: 0.9561 - val_loss: 0.0034 - val_acc: 0.9590\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0034 - acc: 0.9531 - val_loss: 0.0033 - val_acc: 0.9605\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0034 - val_acc: 0.9617\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0033 - acc: 0.9572 - val_loss: 0.0035 - val_acc: 0.9539\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 409us/step - loss: 0.0033 - acc: 0.9545 - val_loss: 0.0033 - val_acc: 0.9601\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0032 - acc: 0.9567 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0032 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0034 - acc: 0.9516 - val_loss: 0.0033 - val_acc: 0.9628\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0032 - acc: 0.9576 - val_loss: 0.0033 - val_acc: 0.9597\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0032 - acc: 0.9560 - val_loss: 0.0034 - val_acc: 0.9573\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0034 - acc: 0.9511 - val_loss: 0.0033 - val_acc: 0.9610\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9589 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9614\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0033 - acc: 0.9555 - val_loss: 0.0034 - val_acc: 0.9562\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0032 - acc: 0.9565 - val_loss: 0.0034 - val_acc: 0.9590\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0032 - acc: 0.9576 - val_loss: 0.0033 - val_acc: 0.9591\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0033 - acc: 0.9546 - val_loss: 0.0035 - val_acc: 0.9554\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0034 - acc: 0.9519 - val_loss: 0.0033 - val_acc: 0.9622\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9624\n",
      "start training round 12\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2430 - acc: 0.6826 - val_loss: 0.2527 - val_acc: 0.6805\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2399 - acc: 0.6835 - val_loss: 0.2499 - val_acc: 0.6824\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2382 - acc: 0.6843 - val_loss: 0.2646 - val_acc: 0.6758\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2426 - acc: 0.6811 - val_loss: 0.2522 - val_acc: 0.6817\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2437 - acc: 0.6830 - val_loss: 0.2501 - val_acc: 0.6817\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2374 - acc: 0.6846 - val_loss: 0.2498 - val_acc: 0.6835\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2375 - acc: 0.6842 - val_loss: 0.2488 - val_acc: 0.6823\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2386 - acc: 0.6838 - val_loss: 0.2539 - val_acc: 0.6817\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2402 - acc: 0.6835 - val_loss: 0.2527 - val_acc: 0.6814\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2403 - acc: 0.6833 - val_loss: 0.2494 - val_acc: 0.6823\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2396 - acc: 0.6827 - val_loss: 0.2514 - val_acc: 0.6808\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2425 - acc: 0.6820 - val_loss: 0.2511 - val_acc: 0.6821\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2391 - acc: 0.6838 - val_loss: 0.2528 - val_acc: 0.6819\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2407 - acc: 0.6828 - val_loss: 0.2517 - val_acc: 0.6824\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2388 - acc: 0.6840 - val_loss: 0.2554 - val_acc: 0.6797\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.2378 - acc: 0.6840 - val_loss: 0.2577 - val_acc: 0.6811\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2428 - acc: 0.6834 - val_loss: 0.2507 - val_acc: 0.6829\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2411 - acc: 0.6823 - val_loss: 0.2519 - val_acc: 0.6817\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2380 - acc: 0.6837 - val_loss: 0.2506 - val_acc: 0.6829\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2409 - acc: 0.6827 - val_loss: 0.2546 - val_acc: 0.6809\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2389 - acc: 0.6834 - val_loss: 0.2507 - val_acc: 0.6812\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2393 - acc: 0.6833 - val_loss: 0.2517 - val_acc: 0.6807\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2374 - acc: 0.6836 - val_loss: 0.2511 - val_acc: 0.6806\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2362 - acc: 0.6845 - val_loss: 0.2514 - val_acc: 0.6820\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2400 - acc: 0.6838 - val_loss: 0.2546 - val_acc: 0.6810\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2365 - acc: 0.6848 - val_loss: 0.2547 - val_acc: 0.6810\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2414 - acc: 0.6841 - val_loss: 0.2481 - val_acc: 0.6832\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2389 - acc: 0.6840 - val_loss: 0.2600 - val_acc: 0.6814\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2421 - acc: 0.6819 - val_loss: 0.2600 - val_acc: 0.6798\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2416 - acc: 0.6824 - val_loss: 0.2532 - val_acc: 0.6790\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2372 - acc: 0.6837 - val_loss: 0.2492 - val_acc: 0.6822\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2405 - acc: 0.6825 - val_loss: 0.2600 - val_acc: 0.6763\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2408 - acc: 0.6824 - val_loss: 0.2521 - val_acc: 0.6817\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2407 - acc: 0.6847 - val_loss: 0.2496 - val_acc: 0.6836\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2392 - acc: 0.6843 - val_loss: 0.2492 - val_acc: 0.6833\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2373 - acc: 0.6844 - val_loss: 0.2539 - val_acc: 0.6795\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2377 - acc: 0.6836 - val_loss: 0.2501 - val_acc: 0.6819\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2377 - acc: 0.6836 - val_loss: 0.2511 - val_acc: 0.6809\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2388 - acc: 0.6829 - val_loss: 0.2506 - val_acc: 0.6823\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2392 - acc: 0.6827 - val_loss: 0.2520 - val_acc: 0.6803\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2392 - acc: 0.6841 - val_loss: 0.2563 - val_acc: 0.6805\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2397 - acc: 0.6841 - val_loss: 0.2498 - val_acc: 0.6831\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2370 - acc: 0.6839 - val_loss: 0.2499 - val_acc: 0.6826\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2393 - acc: 0.6836 - val_loss: 0.2540 - val_acc: 0.6818\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2418 - acc: 0.6841 - val_loss: 0.2695 - val_acc: 0.6796\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2435 - acc: 0.6825 - val_loss: 0.2518 - val_acc: 0.6812\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2377 - acc: 0.6843 - val_loss: 0.2504 - val_acc: 0.6825\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2364 - acc: 0.6852 - val_loss: 0.2513 - val_acc: 0.6831\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2393 - acc: 0.6848 - val_loss: 0.2515 - val_acc: 0.6823\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2397 - acc: 0.6827 - val_loss: 0.2485 - val_acc: 0.6838\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9758 - acc: 0.6792 - val_loss: 2.1803 - val_acc: 0.6734\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9881 - acc: 0.6791 - val_loss: 2.1527 - val_acc: 0.6752\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 2.0070 - acc: 0.6777 - val_loss: 2.2867 - val_acc: 0.6721\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9891 - acc: 0.6783 - val_loss: 2.1121 - val_acc: 0.6769\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 1.9853 - acc: 0.6772 - val_loss: 2.1265 - val_acc: 0.6781\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 1.9689 - acc: 0.6790 - val_loss: 2.1312 - val_acc: 0.6789\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9859 - acc: 0.6790 - val_loss: 2.1695 - val_acc: 0.6768\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9986 - acc: 0.6789 - val_loss: 2.1157 - val_acc: 0.6774\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 1.9938 - acc: 0.6771 - val_loss: 2.1324 - val_acc: 0.6762\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 1.9759 - acc: 0.6779 - val_loss: 2.1453 - val_acc: 0.6743\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 2.0061 - acc: 0.6778 - val_loss: 2.2417 - val_acc: 0.6732\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9943 - acc: 0.6779 - val_loss: 2.1299 - val_acc: 0.6731\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0089 - acc: 0.6779 - val_loss: 2.1228 - val_acc: 0.6764\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9865 - acc: 0.6780 - val_loss: 2.1167 - val_acc: 0.6756\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9781 - acc: 0.6783 - val_loss: 2.1265 - val_acc: 0.6734\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0034 - acc: 0.6791 - val_loss: 2.1380 - val_acc: 0.6744\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 1.9867 - acc: 0.6778 - val_loss: 2.0971 - val_acc: 0.6756\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9661 - acc: 0.6781 - val_loss: 2.1229 - val_acc: 0.6718\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 2.0057 - acc: 0.6777 - val_loss: 2.1052 - val_acc: 0.6773\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 1.9885 - acc: 0.6791 - val_loss: 2.1060 - val_acc: 0.6778\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 2.0077 - acc: 0.6785 - val_loss: 2.1165 - val_acc: 0.6765\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9775 - acc: 0.6777 - val_loss: 2.1528 - val_acc: 0.6736\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9733 - acc: 0.6780 - val_loss: 2.1623 - val_acc: 0.6698\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0023 - acc: 0.6779 - val_loss: 2.1268 - val_acc: 0.6764\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 2.0162 - acc: 0.6776 - val_loss: 2.0810 - val_acc: 0.6775\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9953 - acc: 0.6793 - val_loss: 2.0740 - val_acc: 0.6783\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9685 - acc: 0.6785 - val_loss: 2.1355 - val_acc: 0.6734\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0031 - acc: 0.6784 - val_loss: 2.1038 - val_acc: 0.6740\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9935 - acc: 0.6783 - val_loss: 2.1337 - val_acc: 0.6759\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9764 - acc: 0.6790 - val_loss: 2.1799 - val_acc: 0.6762\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 1.9864 - acc: 0.6784 - val_loss: 2.0971 - val_acc: 0.6769\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9643 - acc: 0.6784 - val_loss: 2.1034 - val_acc: 0.6758\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 2.0146 - acc: 0.6784 - val_loss: 2.0964 - val_acc: 0.6757\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9842 - acc: 0.6782 - val_loss: 2.0956 - val_acc: 0.6780\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9859 - acc: 0.6789 - val_loss: 2.1178 - val_acc: 0.6777\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9895 - acc: 0.6783 - val_loss: 2.1421 - val_acc: 0.6760\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9723 - acc: 0.6793 - val_loss: 2.1183 - val_acc: 0.6755\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 1.9811 - acc: 0.6788 - val_loss: 2.0877 - val_acc: 0.6759\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 1.9701 - acc: 0.6785 - val_loss: 2.3208 - val_acc: 0.6640\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0125 - acc: 0.6777 - val_loss: 2.1291 - val_acc: 0.6757\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9887 - acc: 0.6783 - val_loss: 2.1531 - val_acc: 0.6730\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9857 - acc: 0.6784 - val_loss: 2.0948 - val_acc: 0.6774\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9856 - acc: 0.6789 - val_loss: 2.1015 - val_acc: 0.6755\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 1.9798 - acc: 0.6793 - val_loss: 2.1290 - val_acc: 0.6727\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 2.0028 - acc: 0.6778 - val_loss: 2.1580 - val_acc: 0.6754\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 1.9996 - acc: 0.6788 - val_loss: 2.1089 - val_acc: 0.6767\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9907 - acc: 0.6787 - val_loss: 2.1033 - val_acc: 0.6771\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9635 - acc: 0.6795 - val_loss: 2.1143 - val_acc: 0.6747\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9568 - acc: 0.6794 - val_loss: 2.0973 - val_acc: 0.6737\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9845 - acc: 0.6785 - val_loss: 2.1192 - val_acc: 0.6738\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.2114 - acc: 0.9922 - val_loss: 0.2047 - val_acc: 0.9900\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2022 - acc: 0.9923 - val_loss: 0.2133 - val_acc: 0.9900\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2040 - acc: 0.9922 - val_loss: 0.2001 - val_acc: 0.9900\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1975 - acc: 0.9922 - val_loss: 0.2059 - val_acc: 0.9900\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1985 - acc: 0.9922 - val_loss: 0.2018 - val_acc: 0.9898\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.1936 - acc: 0.9921 - val_loss: 0.1971 - val_acc: 0.9894\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1965 - acc: 0.9913 - val_loss: 0.1985 - val_acc: 0.9895\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2000 - acc: 0.9913 - val_loss: 0.2044 - val_acc: 0.9880\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.2018 - acc: 0.9914 - val_loss: 0.2068 - val_acc: 0.9896\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.2017 - acc: 0.9921 - val_loss: 0.2003 - val_acc: 0.9900\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2071 - acc: 0.9922 - val_loss: 0.2081 - val_acc: 0.9896\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.2061 - acc: 0.9915 - val_loss: 0.2100 - val_acc: 0.9886\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.2081 - acc: 0.9904 - val_loss: 0.2091 - val_acc: 0.9887\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.2027 - acc: 0.9911 - val_loss: 0.1944 - val_acc: 0.9896\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.1895 - acc: 0.9918 - val_loss: 0.1869 - val_acc: 0.9900\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1858 - acc: 0.9922 - val_loss: 0.1892 - val_acc: 0.9900\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.1908 - acc: 0.9922 - val_loss: 0.2076 - val_acc: 0.9899\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.2239 - acc: 0.9922 - val_loss: 0.2110 - val_acc: 0.9900\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1967 - acc: 0.9922 - val_loss: 0.1982 - val_acc: 0.9898\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.1935 - acc: 0.9922 - val_loss: 0.1945 - val_acc: 0.9900\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.1999 - acc: 0.9922 - val_loss: 0.2152 - val_acc: 0.9900\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2104 - acc: 0.9918 - val_loss: 0.2002 - val_acc: 0.9896\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1927 - acc: 0.9918 - val_loss: 0.1932 - val_acc: 0.9895\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1941 - acc: 0.9919 - val_loss: 0.1969 - val_acc: 0.9897\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.1979 - acc: 0.9921 - val_loss: 0.1980 - val_acc: 0.9901\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.2096 - acc: 0.9922 - val_loss: 0.2203 - val_acc: 0.9899\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2100 - acc: 0.9922 - val_loss: 0.2055 - val_acc: 0.9899\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2011 - acc: 0.9922 - val_loss: 0.2088 - val_acc: 0.9896\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2076 - acc: 0.9915 - val_loss: 0.2253 - val_acc: 0.9887\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.2058 - acc: 0.9914 - val_loss: 0.1928 - val_acc: 0.9894\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1880 - acc: 0.9919 - val_loss: 0.1920 - val_acc: 0.9896\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.1932 - acc: 0.9914 - val_loss: 0.1987 - val_acc: 0.9890\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1964 - acc: 0.9912 - val_loss: 0.2039 - val_acc: 0.9891\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.2015 - acc: 0.9912 - val_loss: 0.2067 - val_acc: 0.9892\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.1977 - acc: 0.9916 - val_loss: 0.2044 - val_acc: 0.9893\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.2103 - acc: 0.9914 - val_loss: 0.2188 - val_acc: 0.9899\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2122 - acc: 0.9922 - val_loss: 0.2047 - val_acc: 0.9900\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1951 - acc: 0.9922 - val_loss: 0.1966 - val_acc: 0.9900\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.1959 - acc: 0.9921 - val_loss: 0.1962 - val_acc: 0.9898\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.1989 - acc: 0.9915 - val_loss: 0.2146 - val_acc: 0.9894\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2005 - acc: 0.9915 - val_loss: 0.1994 - val_acc: 0.9895\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.1989 - acc: 0.9918 - val_loss: 0.1915 - val_acc: 0.9898\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1858 - acc: 0.9922 - val_loss: 0.1934 - val_acc: 0.9899\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.1860 - acc: 0.9922 - val_loss: 0.1891 - val_acc: 0.9898\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1896 - acc: 0.9921 - val_loss: 0.1919 - val_acc: 0.9898\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.1926 - acc: 0.9920 - val_loss: 0.2074 - val_acc: 0.9896\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2120 - acc: 0.9916 - val_loss: 0.2232 - val_acc: 0.9893\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2059 - acc: 0.9918 - val_loss: 0.2078 - val_acc: 0.9891\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2128 - acc: 0.9916 - val_loss: 0.2087 - val_acc: 0.9898\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.1985 - acc: 0.9922 - val_loss: 0.2027 - val_acc: 0.9900\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.0032 - acc: 0.9589 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0032 - acc: 0.9582 - val_loss: 0.0033 - val_acc: 0.9624\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 478us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0034 - val_acc: 0.9588\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.0033 - acc: 0.9545 - val_loss: 0.0035 - val_acc: 0.9610\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.0034 - acc: 0.9536 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.0032 - acc: 0.9589 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0032 - acc: 0.9580 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.0032 - acc: 0.9571 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.0032 - acc: 0.9571 - val_loss: 0.0035 - val_acc: 0.9575\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.0032 - acc: 0.9566 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.0031 - acc: 0.9594 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0033 - acc: 0.9551 - val_loss: 0.0034 - val_acc: 0.9571\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.0034 - acc: 0.9516 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9609\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.0033 - acc: 0.9584 - val_loss: 0.0035 - val_acc: 0.9598\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.0033 - acc: 0.9559 - val_loss: 0.0034 - val_acc: 0.9595\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.0032 - acc: 0.9574 - val_loss: 0.0034 - val_acc: 0.9571\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.0032 - acc: 0.9572 - val_loss: 0.0033 - val_acc: 0.9612\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.0032 - acc: 0.9582 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0034 - val_acc: 0.9591\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 477us/step - loss: 0.0033 - acc: 0.9511 - val_loss: 0.0034 - val_acc: 0.9567\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.0033 - acc: 0.9529 - val_loss: 0.0034 - val_acc: 0.9578\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0033 - acc: 0.9530 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0032 - acc: 0.9569 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.0032 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.0032 - acc: 0.9576 - val_loss: 0.0033 - val_acc: 0.9605\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.0033 - acc: 0.9558 - val_loss: 0.0051 - val_acc: 0.9263\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.0035 - acc: 0.9527 - val_loss: 0.0034 - val_acc: 0.9577\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.0033 - acc: 0.9566 - val_loss: 0.0036 - val_acc: 0.9558\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.0032 - acc: 0.9581 - val_loss: 0.0033 - val_acc: 0.9610\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0033 - val_acc: 0.9610\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 484us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9624\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 466us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0035 - val_acc: 0.9588\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.0032 - acc: 0.9582 - val_loss: 0.0033 - val_acc: 0.9605\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.0032 - acc: 0.9563 - val_loss: 0.0035 - val_acc: 0.9559\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.0034 - acc: 0.9499 - val_loss: 0.0033 - val_acc: 0.9605\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0034 - val_acc: 0.9617\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0032 - acc: 0.9577 - val_loss: 0.0034 - val_acc: 0.9622\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9609\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9601\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0033 - acc: 0.9540 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 473us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 472us/step - loss: 0.0034 - acc: 0.9545 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.0032 - acc: 0.9559 - val_loss: 0.0033 - val_acc: 0.9600\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 473us/step - loss: 0.0032 - acc: 0.9577 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "start training round 13\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2373 - acc: 0.6854 - val_loss: 0.2559 - val_acc: 0.6819\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2405 - acc: 0.6831 - val_loss: 0.2474 - val_acc: 0.6832\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.2383 - acc: 0.6844 - val_loss: 0.2496 - val_acc: 0.6821\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2363 - acc: 0.6844 - val_loss: 0.2496 - val_acc: 0.6828\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2416 - acc: 0.6824 - val_loss: 0.2507 - val_acc: 0.6830\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2363 - acc: 0.6847 - val_loss: 0.2502 - val_acc: 0.6833\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2365 - acc: 0.6850 - val_loss: 0.2472 - val_acc: 0.6833\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2359 - acc: 0.6848 - val_loss: 0.2552 - val_acc: 0.6808\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.2411 - acc: 0.6841 - val_loss: 0.2503 - val_acc: 0.6832\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2355 - acc: 0.6854 - val_loss: 0.2526 - val_acc: 0.6814\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.2446 - acc: 0.6819 - val_loss: 0.2483 - val_acc: 0.6819\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2367 - acc: 0.6841 - val_loss: 0.2485 - val_acc: 0.6837\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2356 - acc: 0.6846 - val_loss: 0.2490 - val_acc: 0.6839\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.2378 - acc: 0.6842 - val_loss: 0.2499 - val_acc: 0.6818\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2367 - acc: 0.6841 - val_loss: 0.2482 - val_acc: 0.6822\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2368 - acc: 0.6839 - val_loss: 0.2523 - val_acc: 0.6812\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2389 - acc: 0.6845 - val_loss: 0.2580 - val_acc: 0.6802\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.2424 - acc: 0.6834 - val_loss: 0.2577 - val_acc: 0.6806\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.2411 - acc: 0.6822 - val_loss: 0.2503 - val_acc: 0.6835\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2386 - acc: 0.6846 - val_loss: 0.2545 - val_acc: 0.6809\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2374 - acc: 0.6844 - val_loss: 0.2496 - val_acc: 0.6828\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.2397 - acc: 0.6833 - val_loss: 0.2566 - val_acc: 0.6805\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2430 - acc: 0.6819 - val_loss: 0.2488 - val_acc: 0.6843\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.2360 - acc: 0.6843 - val_loss: 0.2529 - val_acc: 0.6823\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2410 - acc: 0.6838 - val_loss: 0.2568 - val_acc: 0.6796\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.2405 - acc: 0.6840 - val_loss: 0.2502 - val_acc: 0.6828\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2353 - acc: 0.6852 - val_loss: 0.2496 - val_acc: 0.6823\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2398 - acc: 0.6840 - val_loss: 0.2538 - val_acc: 0.6808\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2381 - acc: 0.6839 - val_loss: 0.2496 - val_acc: 0.6826\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2396 - acc: 0.6833 - val_loss: 0.2484 - val_acc: 0.6842\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2352 - acc: 0.6843 - val_loss: 0.2490 - val_acc: 0.6837\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2372 - acc: 0.6844 - val_loss: 0.2543 - val_acc: 0.6795\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2398 - acc: 0.6831 - val_loss: 0.2470 - val_acc: 0.6838\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.2373 - acc: 0.6843 - val_loss: 0.2471 - val_acc: 0.6837\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.2358 - acc: 0.6844 - val_loss: 0.2517 - val_acc: 0.6811\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.2398 - acc: 0.6833 - val_loss: 0.2593 - val_acc: 0.6783\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2403 - acc: 0.6833 - val_loss: 0.2609 - val_acc: 0.6799\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2397 - acc: 0.6839 - val_loss: 0.2494 - val_acc: 0.6835\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.2382 - acc: 0.6846 - val_loss: 0.2508 - val_acc: 0.6806\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2372 - acc: 0.6841 - val_loss: 0.2580 - val_acc: 0.6787\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2433 - acc: 0.6817 - val_loss: 0.2467 - val_acc: 0.6842\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2347 - acc: 0.6857 - val_loss: 0.2470 - val_acc: 0.6842\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2354 - acc: 0.6850 - val_loss: 0.2496 - val_acc: 0.6846\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.2408 - acc: 0.6836 - val_loss: 0.2568 - val_acc: 0.6806\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2382 - acc: 0.6842 - val_loss: 0.2474 - val_acc: 0.6847\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.2349 - acc: 0.6855 - val_loss: 0.2598 - val_acc: 0.6772\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.2410 - acc: 0.6837 - val_loss: 0.2503 - val_acc: 0.6820\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.2371 - acc: 0.6850 - val_loss: 0.2472 - val_acc: 0.6844\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2371 - acc: 0.6840 - val_loss: 0.2477 - val_acc: 0.6842\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2342 - acc: 0.6855 - val_loss: 0.2499 - val_acc: 0.6827\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 2.0171 - acc: 0.6770 - val_loss: 2.2154 - val_acc: 0.6717\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 2.0026 - acc: 0.6786 - val_loss: 2.1082 - val_acc: 0.6774\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 1.9809 - acc: 0.6785 - val_loss: 2.1958 - val_acc: 0.6766\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9808 - acc: 0.6787 - val_loss: 2.1739 - val_acc: 0.6729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9850 - acc: 0.6784 - val_loss: 2.1543 - val_acc: 0.6718\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 1.9998 - acc: 0.6783 - val_loss: 2.0987 - val_acc: 0.6752\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9726 - acc: 0.6794 - val_loss: 2.0919 - val_acc: 0.6742\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 1.9872 - acc: 0.6788 - val_loss: 2.0812 - val_acc: 0.6753\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 1.9611 - acc: 0.6791 - val_loss: 2.2061 - val_acc: 0.6724\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9956 - acc: 0.6790 - val_loss: 2.1128 - val_acc: 0.6760\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9672 - acc: 0.6790 - val_loss: 2.1238 - val_acc: 0.6754\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 2.0077 - acc: 0.6786 - val_loss: 2.0860 - val_acc: 0.6770\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 1.9820 - acc: 0.6786 - val_loss: 2.1255 - val_acc: 0.6758\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 1.9889 - acc: 0.6786 - val_loss: 2.1238 - val_acc: 0.6773\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9855 - acc: 0.6788 - val_loss: 2.1382 - val_acc: 0.6772\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9744 - acc: 0.6777 - val_loss: 2.2222 - val_acc: 0.6775\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 2.0046 - acc: 0.6786 - val_loss: 2.0862 - val_acc: 0.6758\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 1.9721 - acc: 0.6792 - val_loss: 2.1190 - val_acc: 0.6759\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0112 - acc: 0.6787 - val_loss: 2.0750 - val_acc: 0.6764\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 1.9661 - acc: 0.6786 - val_loss: 2.1597 - val_acc: 0.6722\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9990 - acc: 0.6778 - val_loss: 2.0837 - val_acc: 0.6775\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 1.9985 - acc: 0.6774 - val_loss: 2.0885 - val_acc: 0.6768\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 2.0006 - acc: 0.6780 - val_loss: 2.0994 - val_acc: 0.6781\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9851 - acc: 0.6785 - val_loss: 2.0740 - val_acc: 0.6764\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9753 - acc: 0.6783 - val_loss: 2.0943 - val_acc: 0.6761\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9820 - acc: 0.6778 - val_loss: 2.1897 - val_acc: 0.6686\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 2.0046 - acc: 0.6778 - val_loss: 2.1157 - val_acc: 0.6768\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9963 - acc: 0.6787 - val_loss: 2.0905 - val_acc: 0.6798\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 1.9774 - acc: 0.6785 - val_loss: 2.0959 - val_acc: 0.6775\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9620 - acc: 0.6791 - val_loss: 2.1147 - val_acc: 0.6769\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9973 - acc: 0.6786 - val_loss: 2.1496 - val_acc: 0.6755\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9990 - acc: 0.6789 - val_loss: 2.0926 - val_acc: 0.6765\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 1.9755 - acc: 0.6782 - val_loss: 2.1105 - val_acc: 0.6777\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 1.9758 - acc: 0.6788 - val_loss: 2.1597 - val_acc: 0.6762\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0080 - acc: 0.6781 - val_loss: 2.0773 - val_acc: 0.6782\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9703 - acc: 0.6788 - val_loss: 2.0835 - val_acc: 0.6780\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9821 - acc: 0.6775 - val_loss: 2.1142 - val_acc: 0.6776\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 1.9826 - acc: 0.6786 - val_loss: 2.1160 - val_acc: 0.6774\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 2.0018 - acc: 0.6785 - val_loss: 2.0795 - val_acc: 0.6752\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9506 - acc: 0.6790 - val_loss: 2.1034 - val_acc: 0.6744\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 1.9804 - acc: 0.6787 - val_loss: 2.0941 - val_acc: 0.6753\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9960 - acc: 0.6789 - val_loss: 2.1215 - val_acc: 0.6755\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9798 - acc: 0.6787 - val_loss: 2.0901 - val_acc: 0.6759\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9765 - acc: 0.6782 - val_loss: 2.1679 - val_acc: 0.6756\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9862 - acc: 0.6795 - val_loss: 2.2146 - val_acc: 0.6765\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 2.0030 - acc: 0.6786 - val_loss: 2.0785 - val_acc: 0.6760\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9477 - acc: 0.6801 - val_loss: 2.1547 - val_acc: 0.6772\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0134 - acc: 0.6765 - val_loss: 2.1058 - val_acc: 0.6732\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0012 - acc: 0.6780 - val_loss: 2.3346 - val_acc: 0.6646\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 1.9853 - acc: 0.6791 - val_loss: 2.0746 - val_acc: 0.6765\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.1929 - acc: 0.9922 - val_loss: 0.1955 - val_acc: 0.9899\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1992 - acc: 0.9921 - val_loss: 0.2145 - val_acc: 0.9899\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2160 - acc: 0.9920 - val_loss: 0.2057 - val_acc: 0.9898\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1960 - acc: 0.9922 - val_loss: 0.1909 - val_acc: 0.9897\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1920 - acc: 0.9918 - val_loss: 0.1970 - val_acc: 0.9897\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.1911 - acc: 0.9919 - val_loss: 0.1920 - val_acc: 0.9897\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.1972 - acc: 0.9914 - val_loss: 0.2044 - val_acc: 0.9891\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2032 - acc: 0.9910 - val_loss: 0.2105 - val_acc: 0.9890\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1995 - acc: 0.9918 - val_loss: 0.1933 - val_acc: 0.9898\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1944 - acc: 0.9921 - val_loss: 0.1997 - val_acc: 0.9898\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2052 - acc: 0.9921 - val_loss: 0.2070 - val_acc: 0.9899\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2046 - acc: 0.9920 - val_loss: 0.2019 - val_acc: 0.9895\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1973 - acc: 0.9915 - val_loss: 0.2053 - val_acc: 0.9892\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2013 - acc: 0.9913 - val_loss: 0.2009 - val_acc: 0.9893\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.1956 - acc: 0.9915 - val_loss: 0.1991 - val_acc: 0.9890\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2073 - acc: 0.9910 - val_loss: 0.2129 - val_acc: 0.9888\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2050 - acc: 0.9917 - val_loss: 0.1967 - val_acc: 0.9900\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1930 - acc: 0.9921 - val_loss: 0.1944 - val_acc: 0.9898\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.1868 - acc: 0.9922 - val_loss: 0.1875 - val_acc: 0.9900\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1871 - acc: 0.9922 - val_loss: 0.1920 - val_acc: 0.9899\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1942 - acc: 0.9921 - val_loss: 0.2075 - val_acc: 0.9901\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 362us/step - loss: 0.2106 - acc: 0.9923 - val_loss: 0.2350 - val_acc: 0.9894\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2204 - acc: 0.9916 - val_loss: 0.2128 - val_acc: 0.9885\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2055 - acc: 0.9915 - val_loss: 0.2074 - val_acc: 0.9895\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.1981 - acc: 0.9920 - val_loss: 0.2047 - val_acc: 0.9899\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.1940 - acc: 0.9922 - val_loss: 0.1917 - val_acc: 0.9900\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2038 - acc: 0.9913 - val_loss: 0.2251 - val_acc: 0.9881\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.1986 - acc: 0.9913 - val_loss: 0.1886 - val_acc: 0.9899\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 0.1906 - acc: 0.9922 - val_loss: 0.2008 - val_acc: 0.9899\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2131 - acc: 0.9918 - val_loss: 0.2184 - val_acc: 0.9894\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2053 - acc: 0.9921 - val_loss: 0.1936 - val_acc: 0.9901\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.1937 - acc: 0.9921 - val_loss: 0.1920 - val_acc: 0.9897\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1878 - acc: 0.9918 - val_loss: 0.1961 - val_acc: 0.9893\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2063 - acc: 0.9908 - val_loss: 0.2030 - val_acc: 0.9887\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1940 - acc: 0.9915 - val_loss: 0.1960 - val_acc: 0.9895\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1930 - acc: 0.9916 - val_loss: 0.1983 - val_acc: 0.9897\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 0.2063 - acc: 0.9920 - val_loss: 0.2210 - val_acc: 0.9895\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2059 - acc: 0.9920 - val_loss: 0.1987 - val_acc: 0.9898\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2018 - acc: 0.9921 - val_loss: 0.1986 - val_acc: 0.9899\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1927 - acc: 0.9922 - val_loss: 0.1893 - val_acc: 0.9899\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.1893 - acc: 0.9922 - val_loss: 0.1971 - val_acc: 0.9900\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.1962 - acc: 0.9922 - val_loss: 0.2070 - val_acc: 0.9900\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2004 - acc: 0.9922 - val_loss: 0.1884 - val_acc: 0.9900\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1879 - acc: 0.9922 - val_loss: 0.2022 - val_acc: 0.9899\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2086 - acc: 0.9920 - val_loss: 0.2093 - val_acc: 0.9895\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2118 - acc: 0.9909 - val_loss: 0.2133 - val_acc: 0.9871\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2002 - acc: 0.9907 - val_loss: 0.1994 - val_acc: 0.9895\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1985 - acc: 0.9913 - val_loss: 0.1919 - val_acc: 0.9896\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1932 - acc: 0.9918 - val_loss: 0.1935 - val_acc: 0.9897\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.1918 - acc: 0.9917 - val_loss: 0.1978 - val_acc: 0.9896\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9588\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0031 - acc: 0.9584 - val_loss: 0.0032 - val_acc: 0.9623\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.0032 - acc: 0.9565 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0032 - acc: 0.9569 - val_loss: 0.0033 - val_acc: 0.9598\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0033 - acc: 0.9544 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9593\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.0034 - acc: 0.9530 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9624\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9567 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0032 - acc: 0.9566 - val_loss: 0.0033 - val_acc: 0.9584\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0032 - acc: 0.9558 - val_loss: 0.0033 - val_acc: 0.9621\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0032 - acc: 0.9582 - val_loss: 0.0033 - val_acc: 0.9622\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.0032 - acc: 0.9569 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0032 - acc: 0.9589 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9591\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0033 - acc: 0.9550 - val_loss: 0.0034 - val_acc: 0.9588\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.0033 - acc: 0.9545 - val_loss: 0.0034 - val_acc: 0.9593\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0033 - val_acc: 0.9587\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0032 - acc: 0.9550 - val_loss: 0.0033 - val_acc: 0.9606\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.0031 - acc: 0.9589 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0031 - acc: 0.9592 - val_loss: 0.0033 - val_acc: 0.9615\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0033 - acc: 0.9568 - val_loss: 0.0034 - val_acc: 0.9575\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0032 - acc: 0.9582 - val_loss: 0.0033 - val_acc: 0.9609\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9569 - val_loss: 0.0033 - val_acc: 0.9604\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9578\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0033 - acc: 0.9551 - val_loss: 0.0038 - val_acc: 0.9449\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9526 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9601\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0032 - acc: 0.9561 - val_loss: 0.0033 - val_acc: 0.9625\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0032 - acc: 0.9575 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0033 - val_acc: 0.9598\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0032 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.0033 - acc: 0.9518 - val_loss: 0.0033 - val_acc: 0.9610\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0032 - acc: 0.9569 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0032 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9610\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9568 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0032 - acc: 0.9567 - val_loss: 0.0034 - val_acc: 0.9586\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0032 - acc: 0.9568 - val_loss: 0.0036 - val_acc: 0.9542\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0034 - acc: 0.9531 - val_loss: 0.0033 - val_acc: 0.9594\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0031 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0032 - acc: 0.9572 - val_loss: 0.0035 - val_acc: 0.9562\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0033 - acc: 0.9540 - val_loss: 0.0033 - val_acc: 0.9591\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0032 - acc: 0.9575 - val_loss: 0.0034 - val_acc: 0.9589\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0033 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9607\n",
      "start training round 14\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2430 - acc: 0.6847 - val_loss: 0.2528 - val_acc: 0.6832\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2383 - acc: 0.6846 - val_loss: 0.2510 - val_acc: 0.6821\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2378 - acc: 0.6841 - val_loss: 0.2478 - val_acc: 0.6828\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2353 - acc: 0.6847 - val_loss: 0.2491 - val_acc: 0.6846\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2357 - acc: 0.6848 - val_loss: 0.2517 - val_acc: 0.6830\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2389 - acc: 0.6829 - val_loss: 0.2564 - val_acc: 0.6790\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2366 - acc: 0.6842 - val_loss: 0.2483 - val_acc: 0.6845\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2352 - acc: 0.6852 - val_loss: 0.2489 - val_acc: 0.6821\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2433 - acc: 0.6822 - val_loss: 0.2730 - val_acc: 0.6750\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2390 - acc: 0.6839 - val_loss: 0.2499 - val_acc: 0.6830\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2385 - acc: 0.6846 - val_loss: 0.2507 - val_acc: 0.6812\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.2383 - acc: 0.6847 - val_loss: 0.2470 - val_acc: 0.6841\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2358 - acc: 0.6847 - val_loss: 0.2481 - val_acc: 0.6837\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2384 - acc: 0.6836 - val_loss: 0.2550 - val_acc: 0.6795\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2387 - acc: 0.6839 - val_loss: 0.2513 - val_acc: 0.6839\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2372 - acc: 0.6838 - val_loss: 0.2460 - val_acc: 0.6836\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2333 - acc: 0.6860 - val_loss: 0.2468 - val_acc: 0.6833\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2381 - acc: 0.6844 - val_loss: 0.2609 - val_acc: 0.6788\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2406 - acc: 0.6837 - val_loss: 0.2540 - val_acc: 0.6841\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2409 - acc: 0.6848 - val_loss: 0.2608 - val_acc: 0.6817\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2380 - acc: 0.6846 - val_loss: 0.2495 - val_acc: 0.6839\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2354 - acc: 0.6855 - val_loss: 0.2499 - val_acc: 0.6826\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2410 - acc: 0.6829 - val_loss: 0.2534 - val_acc: 0.6835\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2346 - acc: 0.6857 - val_loss: 0.2473 - val_acc: 0.6831\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2353 - acc: 0.6851 - val_loss: 0.2522 - val_acc: 0.6825\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2377 - acc: 0.6838 - val_loss: 0.2544 - val_acc: 0.6810\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2404 - acc: 0.6828 - val_loss: 0.2491 - val_acc: 0.6835\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2358 - acc: 0.6853 - val_loss: 0.2503 - val_acc: 0.6830\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2379 - acc: 0.6842 - val_loss: 0.2629 - val_acc: 0.6819\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2426 - acc: 0.6826 - val_loss: 0.2468 - val_acc: 0.6848\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.2355 - acc: 0.6847 - val_loss: 0.2489 - val_acc: 0.6834\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2372 - acc: 0.6845 - val_loss: 0.2541 - val_acc: 0.6817\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2380 - acc: 0.6831 - val_loss: 0.2468 - val_acc: 0.6847\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2373 - acc: 0.6846 - val_loss: 0.2522 - val_acc: 0.6821\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2401 - acc: 0.6843 - val_loss: 0.2603 - val_acc: 0.6829\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2401 - acc: 0.6852 - val_loss: 0.2477 - val_acc: 0.6839\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2350 - acc: 0.6856 - val_loss: 0.2498 - val_acc: 0.6837\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2342 - acc: 0.6858 - val_loss: 0.2474 - val_acc: 0.6847\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2340 - acc: 0.6855 - val_loss: 0.2490 - val_acc: 0.6844\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2344 - acc: 0.6856 - val_loss: 0.2481 - val_acc: 0.6832\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2402 - acc: 0.6843 - val_loss: 0.2573 - val_acc: 0.6807\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2397 - acc: 0.6833 - val_loss: 0.2495 - val_acc: 0.6837\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2355 - acc: 0.6852 - val_loss: 0.2511 - val_acc: 0.6803\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2386 - acc: 0.6834 - val_loss: 0.2518 - val_acc: 0.6830\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2417 - acc: 0.6837 - val_loss: 0.2500 - val_acc: 0.6845\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2334 - acc: 0.6864 - val_loss: 0.2461 - val_acc: 0.6844\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2362 - acc: 0.6858 - val_loss: 0.2547 - val_acc: 0.6815\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2377 - acc: 0.6844 - val_loss: 0.2491 - val_acc: 0.6833\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2368 - acc: 0.6847 - val_loss: 0.2539 - val_acc: 0.6828\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2391 - acc: 0.6847 - val_loss: 0.2477 - val_acc: 0.6826\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9836 - acc: 0.6786 - val_loss: 2.0905 - val_acc: 0.6746\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9774 - acc: 0.6789 - val_loss: 2.0797 - val_acc: 0.6762\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 1.9814 - acc: 0.6782 - val_loss: 2.1210 - val_acc: 0.6745\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 1.9717 - acc: 0.6783 - val_loss: 2.1334 - val_acc: 0.6759\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9916 - acc: 0.6789 - val_loss: 2.1627 - val_acc: 0.6736\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9728 - acc: 0.6795 - val_loss: 2.1115 - val_acc: 0.6759\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9767 - acc: 0.6783 - val_loss: 2.0726 - val_acc: 0.6768\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9584 - acc: 0.6792 - val_loss: 2.1713 - val_acc: 0.6763\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 2.0146 - acc: 0.6785 - val_loss: 2.1750 - val_acc: 0.6764\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 1.9846 - acc: 0.6787 - val_loss: 2.1448 - val_acc: 0.6745\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9945 - acc: 0.6786 - val_loss: 2.2418 - val_acc: 0.6700\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9866 - acc: 0.6786 - val_loss: 2.0951 - val_acc: 0.6754\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9604 - acc: 0.6791 - val_loss: 2.0989 - val_acc: 0.6736\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9910 - acc: 0.6779 - val_loss: 2.1542 - val_acc: 0.6726\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9783 - acc: 0.6783 - val_loss: 2.0820 - val_acc: 0.6775\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 1.9743 - acc: 0.6789 - val_loss: 2.1499 - val_acc: 0.6760\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 1.9934 - acc: 0.6792 - val_loss: 2.1593 - val_acc: 0.6742\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9980 - acc: 0.6791 - val_loss: 2.1093 - val_acc: 0.6748\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 1.9923 - acc: 0.6784 - val_loss: 2.0889 - val_acc: 0.6764\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9774 - acc: 0.6790 - val_loss: 2.0954 - val_acc: 0.6774\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 1.9761 - acc: 0.6776 - val_loss: 2.1323 - val_acc: 0.6736\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9872 - acc: 0.6774 - val_loss: 2.1171 - val_acc: 0.6737\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0024 - acc: 0.6781 - val_loss: 2.1160 - val_acc: 0.6735\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9676 - acc: 0.6792 - val_loss: 2.1119 - val_acc: 0.6751\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9905 - acc: 0.6771 - val_loss: 2.1079 - val_acc: 0.6762\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 1.9701 - acc: 0.6786 - val_loss: 2.1762 - val_acc: 0.6763\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 2.0049 - acc: 0.6783 - val_loss: 2.2017 - val_acc: 0.6765\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9816 - acc: 0.6788 - val_loss: 2.0941 - val_acc: 0.6750\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9814 - acc: 0.6787 - val_loss: 2.0752 - val_acc: 0.6765\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 1.9509 - acc: 0.6799 - val_loss: 2.1156 - val_acc: 0.6749\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9693 - acc: 0.6789 - val_loss: 2.1793 - val_acc: 0.6760\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0114 - acc: 0.6788 - val_loss: 2.1072 - val_acc: 0.6772\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9808 - acc: 0.6786 - val_loss: 2.1035 - val_acc: 0.6742\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 1.9775 - acc: 0.6786 - val_loss: 2.1532 - val_acc: 0.6736\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0107 - acc: 0.6783 - val_loss: 2.0804 - val_acc: 0.6766\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9763 - acc: 0.6798 - val_loss: 2.1477 - val_acc: 0.6745\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 1.9634 - acc: 0.6791 - val_loss: 2.1227 - val_acc: 0.6731\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9824 - acc: 0.6774 - val_loss: 2.1063 - val_acc: 0.6747\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9845 - acc: 0.6787 - val_loss: 2.1222 - val_acc: 0.6785\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9781 - acc: 0.6794 - val_loss: 2.1148 - val_acc: 0.6779\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9859 - acc: 0.6791 - val_loss: 2.1486 - val_acc: 0.6768\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9904 - acc: 0.6777 - val_loss: 2.1206 - val_acc: 0.6757\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9638 - acc: 0.6785 - val_loss: 2.0747 - val_acc: 0.6757\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9656 - acc: 0.6790 - val_loss: 2.1068 - val_acc: 0.6736\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 1.9993 - acc: 0.6789 - val_loss: 2.0834 - val_acc: 0.6777\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9630 - acc: 0.6790 - val_loss: 2.1160 - val_acc: 0.6734\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9716 - acc: 0.6784 - val_loss: 2.0755 - val_acc: 0.6769\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9718 - acc: 0.6792 - val_loss: 2.0742 - val_acc: 0.6772\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9581 - acc: 0.6786 - val_loss: 2.0894 - val_acc: 0.6770\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9805 - acc: 0.6785 - val_loss: 2.0922 - val_acc: 0.6753\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2018 - acc: 0.9921 - val_loss: 0.2353 - val_acc: 0.9899\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2260 - acc: 0.9921 - val_loss: 0.2033 - val_acc: 0.9901\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1911 - acc: 0.9922 - val_loss: 0.1926 - val_acc: 0.9901\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1913 - acc: 0.9922 - val_loss: 0.1979 - val_acc: 0.9898\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2028 - acc: 0.9916 - val_loss: 0.2005 - val_acc: 0.9895\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1984 - acc: 0.9913 - val_loss: 0.2028 - val_acc: 0.9887\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1944 - acc: 0.9915 - val_loss: 0.1954 - val_acc: 0.9892\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1884 - acc: 0.9920 - val_loss: 0.1928 - val_acc: 0.9897\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.1881 - acc: 0.9922 - val_loss: 0.1960 - val_acc: 0.9900\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1927 - acc: 0.9923 - val_loss: 0.2021 - val_acc: 0.9901\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2115 - acc: 0.9922 - val_loss: 0.1965 - val_acc: 0.9898\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2008 - acc: 0.9917 - val_loss: 0.2041 - val_acc: 0.9892\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2028 - acc: 0.9917 - val_loss: 0.2081 - val_acc: 0.9900\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2084 - acc: 0.9922 - val_loss: 0.1986 - val_acc: 0.9900\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1889 - acc: 0.9922 - val_loss: 0.1836 - val_acc: 0.9900\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1844 - acc: 0.9921 - val_loss: 0.1954 - val_acc: 0.9896\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.1943 - acc: 0.9912 - val_loss: 0.1997 - val_acc: 0.9893\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.1975 - acc: 0.9910 - val_loss: 0.2063 - val_acc: 0.9891\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2022 - acc: 0.9913 - val_loss: 0.1992 - val_acc: 0.9896\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.1994 - acc: 0.9920 - val_loss: 0.1902 - val_acc: 0.9898\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 361us/step - loss: 0.1878 - acc: 0.9922 - val_loss: 0.1949 - val_acc: 0.9901\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2029 - acc: 0.9922 - val_loss: 0.2121 - val_acc: 0.9899\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2028 - acc: 0.9921 - val_loss: 0.2028 - val_acc: 0.9898\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2018 - acc: 0.9920 - val_loss: 0.1916 - val_acc: 0.9897\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1907 - acc: 0.9920 - val_loss: 0.1907 - val_acc: 0.9899\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1920 - acc: 0.9922 - val_loss: 0.1965 - val_acc: 0.9900\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.1988 - acc: 0.9921 - val_loss: 0.1998 - val_acc: 0.9900\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1944 - acc: 0.9922 - val_loss: 0.1948 - val_acc: 0.9901\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.1902 - acc: 0.9923 - val_loss: 0.1967 - val_acc: 0.9900\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1965 - acc: 0.9923 - val_loss: 0.2040 - val_acc: 0.9900\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1983 - acc: 0.9923 - val_loss: 0.1950 - val_acc: 0.9902\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.1959 - acc: 0.9923 - val_loss: 0.1984 - val_acc: 0.9900\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.1988 - acc: 0.9921 - val_loss: 0.2065 - val_acc: 0.9896\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2012 - acc: 0.9915 - val_loss: 0.1954 - val_acc: 0.9896\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2012 - acc: 0.9908 - val_loss: 0.1927 - val_acc: 0.9894\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1946 - acc: 0.9916 - val_loss: 0.1997 - val_acc: 0.9896\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1982 - acc: 0.9923 - val_loss: 0.2011 - val_acc: 0.9901\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1939 - acc: 0.9922 - val_loss: 0.1942 - val_acc: 0.9901\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1914 - acc: 0.9921 - val_loss: 0.1930 - val_acc: 0.9900\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1954 - acc: 0.9921 - val_loss: 0.1954 - val_acc: 0.9901\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.1885 - acc: 0.9923 - val_loss: 0.1892 - val_acc: 0.9900\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1930 - acc: 0.9923 - val_loss: 0.1974 - val_acc: 0.9902\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2031 - acc: 0.9923 - val_loss: 0.2083 - val_acc: 0.9901\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1933 - acc: 0.9922 - val_loss: 0.1908 - val_acc: 0.9898\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1854 - acc: 0.9919 - val_loss: 0.1909 - val_acc: 0.9894\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.1917 - acc: 0.9916 - val_loss: 0.2046 - val_acc: 0.9882\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2083 - acc: 0.9908 - val_loss: 0.2035 - val_acc: 0.9893\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2008 - acc: 0.9911 - val_loss: 0.1918 - val_acc: 0.9897\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 0.1901 - acc: 0.9920 - val_loss: 0.1893 - val_acc: 0.9902\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1977 - acc: 0.9923 - val_loss: 0.2060 - val_acc: 0.9898\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9571 - val_loss: 0.0035 - val_acc: 0.9548\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0032 - acc: 0.9556 - val_loss: 0.0033 - val_acc: 0.9585\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0032 - acc: 0.9562 - val_loss: 0.0036 - val_acc: 0.9525\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0033 - acc: 0.9530 - val_loss: 0.0034 - val_acc: 0.9570\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9535 - val_loss: 0.0032 - val_acc: 0.9615\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0031 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.0031 - acc: 0.9592 - val_loss: 0.0033 - val_acc: 0.9596\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0032 - acc: 0.9582 - val_loss: 0.0035 - val_acc: 0.9596\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.0034 - acc: 0.9501 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.0031 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9619\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9590\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0034 - acc: 0.9542 - val_loss: 0.0034 - val_acc: 0.9595\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0032 - acc: 0.9588 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0031 - acc: 0.9595 - val_loss: 0.0033 - val_acc: 0.9602\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0032 - val_acc: 0.9610\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.0032 - acc: 0.9592 - val_loss: 0.0033 - val_acc: 0.9602\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0033 - acc: 0.9547 - val_loss: 0.0033 - val_acc: 0.9610\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0032 - val_acc: 0.9623\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.0032 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.0033 - acc: 0.9576 - val_loss: 0.0033 - val_acc: 0.9604\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0032 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9604\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0033 - acc: 0.9550 - val_loss: 0.0033 - val_acc: 0.9611\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0032 - acc: 0.9567 - val_loss: 0.0034 - val_acc: 0.9584\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0032 - acc: 0.9568 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9578 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0033 - acc: 0.9533 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0031 - acc: 0.9592 - val_loss: 0.0033 - val_acc: 0.9604\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0033 - acc: 0.9541 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0032 - acc: 0.9578 - val_loss: 0.0033 - val_acc: 0.9589\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9535 - val_loss: 0.0032 - val_acc: 0.9610\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.0032 - acc: 0.9570 - val_loss: 0.0033 - val_acc: 0.9609\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0031 - acc: 0.9596 - val_loss: 0.0033 - val_acc: 0.9624\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0032 - acc: 0.9592 - val_loss: 0.0033 - val_acc: 0.9588\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0032 - val_acc: 0.9610\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9548 - val_loss: 0.0034 - val_acc: 0.9595\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.0033 - acc: 0.9537 - val_loss: 0.0037 - val_acc: 0.9521\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0033 - acc: 0.9525 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0033 - val_acc: 0.9590\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9575 - val_loss: 0.0033 - val_acc: 0.9609\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0031 - acc: 0.9589 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0032 - acc: 0.9575 - val_loss: 0.0033 - val_acc: 0.9598\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0031 - acc: 0.9582 - val_loss: 0.0034 - val_acc: 0.9622\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0032 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0033 - acc: 0.9554 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0032 - acc: 0.9572 - val_loss: 0.0033 - val_acc: 0.9626\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9619\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0031 - acc: 0.9589 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "start training round 15\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2346 - acc: 0.6855 - val_loss: 0.2518 - val_acc: 0.6837\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2365 - acc: 0.6844 - val_loss: 0.2499 - val_acc: 0.6836\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2380 - acc: 0.6845 - val_loss: 0.2542 - val_acc: 0.6812\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2387 - acc: 0.6842 - val_loss: 0.2521 - val_acc: 0.6827\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2406 - acc: 0.6853 - val_loss: 0.2453 - val_acc: 0.6844\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2345 - acc: 0.6861 - val_loss: 0.2478 - val_acc: 0.6839\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2357 - acc: 0.6857 - val_loss: 0.2484 - val_acc: 0.6823\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2375 - acc: 0.6837 - val_loss: 0.2468 - val_acc: 0.6847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2337 - acc: 0.6861 - val_loss: 0.2472 - val_acc: 0.6850\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2364 - acc: 0.6849 - val_loss: 0.2496 - val_acc: 0.6846\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2342 - acc: 0.6863 - val_loss: 0.2477 - val_acc: 0.6838\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2395 - acc: 0.6839 - val_loss: 0.2485 - val_acc: 0.6824\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2362 - acc: 0.6843 - val_loss: 0.2481 - val_acc: 0.6825\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2357 - acc: 0.6850 - val_loss: 0.2455 - val_acc: 0.6843\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2356 - acc: 0.6851 - val_loss: 0.2472 - val_acc: 0.6835\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2382 - acc: 0.6840 - val_loss: 0.2638 - val_acc: 0.6744\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2381 - acc: 0.6844 - val_loss: 0.2491 - val_acc: 0.6834\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2384 - acc: 0.6857 - val_loss: 0.2599 - val_acc: 0.6818\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2361 - acc: 0.6858 - val_loss: 0.2476 - val_acc: 0.6827\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2378 - acc: 0.6837 - val_loss: 0.2518 - val_acc: 0.6805\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2355 - acc: 0.6849 - val_loss: 0.2499 - val_acc: 0.6836\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2357 - acc: 0.6853 - val_loss: 0.2525 - val_acc: 0.6807\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2382 - acc: 0.6839 - val_loss: 0.2475 - val_acc: 0.6831\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2352 - acc: 0.6843 - val_loss: 0.2533 - val_acc: 0.6786\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2373 - acc: 0.6839 - val_loss: 0.2545 - val_acc: 0.6824\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2385 - acc: 0.6857 - val_loss: 0.2452 - val_acc: 0.6848\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2335 - acc: 0.6864 - val_loss: 0.2571 - val_acc: 0.6789\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2366 - acc: 0.6842 - val_loss: 0.2497 - val_acc: 0.6809\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2355 - acc: 0.6850 - val_loss: 0.2473 - val_acc: 0.6844\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2343 - acc: 0.6858 - val_loss: 0.2465 - val_acc: 0.6845\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2361 - acc: 0.6853 - val_loss: 0.2549 - val_acc: 0.6821\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2368 - acc: 0.6850 - val_loss: 0.2495 - val_acc: 0.6842\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2355 - acc: 0.6848 - val_loss: 0.2530 - val_acc: 0.6823\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2368 - acc: 0.6834 - val_loss: 0.2472 - val_acc: 0.6844\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2370 - acc: 0.6845 - val_loss: 0.2523 - val_acc: 0.6810\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2400 - acc: 0.6844 - val_loss: 0.2498 - val_acc: 0.6835\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2366 - acc: 0.6862 - val_loss: 0.2508 - val_acc: 0.6839\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2380 - acc: 0.6855 - val_loss: 0.2552 - val_acc: 0.6820\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2371 - acc: 0.6853 - val_loss: 0.2482 - val_acc: 0.6838\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2369 - acc: 0.6847 - val_loss: 0.2526 - val_acc: 0.6829\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2349 - acc: 0.6856 - val_loss: 0.2474 - val_acc: 0.6847\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2371 - acc: 0.6846 - val_loss: 0.2486 - val_acc: 0.6847\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2336 - acc: 0.6857 - val_loss: 0.2490 - val_acc: 0.6820\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2341 - acc: 0.6860 - val_loss: 0.2451 - val_acc: 0.6847\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2349 - acc: 0.6861 - val_loss: 0.2465 - val_acc: 0.6844\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2380 - acc: 0.6850 - val_loss: 0.2486 - val_acc: 0.6835\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2345 - acc: 0.6859 - val_loss: 0.2472 - val_acc: 0.6841\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2347 - acc: 0.6851 - val_loss: 0.2463 - val_acc: 0.6846\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2346 - acc: 0.6859 - val_loss: 0.2505 - val_acc: 0.6831\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2389 - acc: 0.6849 - val_loss: 0.2487 - val_acc: 0.6832\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 1.9781 - acc: 0.6797 - val_loss: 2.0869 - val_acc: 0.6763\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 2.0128 - acc: 0.6773 - val_loss: 2.0915 - val_acc: 0.6779\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9843 - acc: 0.6788 - val_loss: 2.1335 - val_acc: 0.6767\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9866 - acc: 0.6790 - val_loss: 2.1537 - val_acc: 0.6740\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 1.9683 - acc: 0.6792 - val_loss: 2.1395 - val_acc: 0.6748\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0094 - acc: 0.6788 - val_loss: 2.1286 - val_acc: 0.6725\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9604 - acc: 0.6790 - val_loss: 2.0871 - val_acc: 0.6759\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 1.9754 - acc: 0.6794 - val_loss: 2.2008 - val_acc: 0.6738\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 1.9965 - acc: 0.6787 - val_loss: 2.2556 - val_acc: 0.6745\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 2.0011 - acc: 0.6792 - val_loss: 2.1340 - val_acc: 0.6745\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9932 - acc: 0.6778 - val_loss: 2.1109 - val_acc: 0.6729\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9624 - acc: 0.6788 - val_loss: 2.1307 - val_acc: 0.6733\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0000 - acc: 0.6787 - val_loss: 2.1676 - val_acc: 0.6733\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9648 - acc: 0.6784 - val_loss: 2.1304 - val_acc: 0.6743\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9772 - acc: 0.6793 - val_loss: 2.1057 - val_acc: 0.6763\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9840 - acc: 0.6790 - val_loss: 2.1135 - val_acc: 0.6762\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9953 - acc: 0.6795 - val_loss: 2.0723 - val_acc: 0.6758\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 376us/step - loss: 1.9635 - acc: 0.6786 - val_loss: 2.1048 - val_acc: 0.6755\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 1.9621 - acc: 0.6794 - val_loss: 2.0918 - val_acc: 0.6777\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9841 - acc: 0.6791 - val_loss: 2.0919 - val_acc: 0.6759\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 1.9732 - acc: 0.6787 - val_loss: 2.1117 - val_acc: 0.6755\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 2.0250 - acc: 0.6783 - val_loss: 2.1023 - val_acc: 0.6737\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 1.9739 - acc: 0.6794 - val_loss: 2.0728 - val_acc: 0.6770\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 1.9662 - acc: 0.6793 - val_loss: 2.0918 - val_acc: 0.6763\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 2.0037 - acc: 0.6785 - val_loss: 2.1373 - val_acc: 0.6749\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9984 - acc: 0.6788 - val_loss: 2.1137 - val_acc: 0.6768\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 1.9735 - acc: 0.6787 - val_loss: 2.1258 - val_acc: 0.6783\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 1.9997 - acc: 0.6789 - val_loss: 2.1134 - val_acc: 0.6786\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9805 - acc: 0.6778 - val_loss: 2.0903 - val_acc: 0.6776\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 1.9634 - acc: 0.6795 - val_loss: 2.1071 - val_acc: 0.6765\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9637 - acc: 0.6796 - val_loss: 2.0859 - val_acc: 0.6761\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9493 - acc: 0.6793 - val_loss: 2.1120 - val_acc: 0.6756\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9781 - acc: 0.6797 - val_loss: 2.1073 - val_acc: 0.6739\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9606 - acc: 0.6797 - val_loss: 2.1007 - val_acc: 0.6734\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 2.0028 - acc: 0.6773 - val_loss: 2.0839 - val_acc: 0.6777\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 2.0052 - acc: 0.6787 - val_loss: 2.1445 - val_acc: 0.6770\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 1.9882 - acc: 0.6786 - val_loss: 2.1332 - val_acc: 0.6763\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9949 - acc: 0.6787 - val_loss: 2.1186 - val_acc: 0.6738\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9634 - acc: 0.6791 - val_loss: 2.1193 - val_acc: 0.6762\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9659 - acc: 0.6791 - val_loss: 2.2472 - val_acc: 0.6740\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 2.0044 - acc: 0.6779 - val_loss: 2.1075 - val_acc: 0.6771\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9704 - acc: 0.6788 - val_loss: 2.0722 - val_acc: 0.6785\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9740 - acc: 0.6783 - val_loss: 2.0931 - val_acc: 0.6760\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9653 - acc: 0.6788 - val_loss: 2.0825 - val_acc: 0.6764\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9635 - acc: 0.6792 - val_loss: 2.1213 - val_acc: 0.6779\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9815 - acc: 0.6795 - val_loss: 2.1594 - val_acc: 0.6765\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9659 - acc: 0.6800 - val_loss: 2.2198 - val_acc: 0.6727\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9725 - acc: 0.6794 - val_loss: 2.1041 - val_acc: 0.6754\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9923 - acc: 0.6793 - val_loss: 2.1510 - val_acc: 0.6755\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 1.9691 - acc: 0.6802 - val_loss: 2.1205 - val_acc: 0.6755\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2033 - acc: 0.9921 - val_loss: 0.1947 - val_acc: 0.9899\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1871 - acc: 0.9922 - val_loss: 0.1878 - val_acc: 0.9901\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.1935 - acc: 0.9923 - val_loss: 0.2037 - val_acc: 0.9901\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2004 - acc: 0.9923 - val_loss: 0.1996 - val_acc: 0.9901\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.1946 - acc: 0.9923 - val_loss: 0.1905 - val_acc: 0.9901\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1932 - acc: 0.9921 - val_loss: 0.1913 - val_acc: 0.9900\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1889 - acc: 0.9922 - val_loss: 0.1898 - val_acc: 0.9900\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1897 - acc: 0.9921 - val_loss: 0.2059 - val_acc: 0.9896\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.1983 - acc: 0.9913 - val_loss: 0.1953 - val_acc: 0.9893\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 363us/step - loss: 0.2034 - acc: 0.9904 - val_loss: 0.2212 - val_acc: 0.9870\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2109 - acc: 0.9901 - val_loss: 0.1916 - val_acc: 0.9895\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1887 - acc: 0.9918 - val_loss: 0.1979 - val_acc: 0.9895\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.2044 - acc: 0.9918 - val_loss: 0.2091 - val_acc: 0.9900\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2096 - acc: 0.9923 - val_loss: 0.2096 - val_acc: 0.9900\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2016 - acc: 0.9923 - val_loss: 0.1946 - val_acc: 0.9900\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1976 - acc: 0.9922 - val_loss: 0.2045 - val_acc: 0.9900\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1894 - acc: 0.9923 - val_loss: 0.1895 - val_acc: 0.9901\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1854 - acc: 0.9923 - val_loss: 0.1823 - val_acc: 0.9902\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1836 - acc: 0.9923 - val_loss: 0.1915 - val_acc: 0.9901\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.1959 - acc: 0.9923 - val_loss: 0.2028 - val_acc: 0.9902\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2067 - acc: 0.9923 - val_loss: 0.2023 - val_acc: 0.9899\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1946 - acc: 0.9920 - val_loss: 0.1993 - val_acc: 0.9893\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2039 - acc: 0.9909 - val_loss: 0.2007 - val_acc: 0.9891\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.1978 - acc: 0.9912 - val_loss: 0.1944 - val_acc: 0.9891\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.1883 - acc: 0.9916 - val_loss: 0.1899 - val_acc: 0.9899\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1918 - acc: 0.9920 - val_loss: 0.2017 - val_acc: 0.9900\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.1918 - acc: 0.9923 - val_loss: 0.1954 - val_acc: 0.9900\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1937 - acc: 0.9922 - val_loss: 0.2045 - val_acc: 0.9897\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2060 - acc: 0.9919 - val_loss: 0.2099 - val_acc: 0.9896\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1921 - acc: 0.9919 - val_loss: 0.1849 - val_acc: 0.9898\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.1850 - acc: 0.9920 - val_loss: 0.1859 - val_acc: 0.9899\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.1884 - acc: 0.9918 - val_loss: 0.1927 - val_acc: 0.9898\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.1891 - acc: 0.9920 - val_loss: 0.1845 - val_acc: 0.9898\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1924 - acc: 0.9915 - val_loss: 0.2024 - val_acc: 0.9891\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1918 - acc: 0.9912 - val_loss: 0.1939 - val_acc: 0.9893\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2010 - acc: 0.9913 - val_loss: 0.2019 - val_acc: 0.9897\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1897 - acc: 0.9920 - val_loss: 0.1913 - val_acc: 0.9900\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1968 - acc: 0.9923 - val_loss: 0.2054 - val_acc: 0.9901\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2015 - acc: 0.9923 - val_loss: 0.1938 - val_acc: 0.9901\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1898 - acc: 0.9922 - val_loss: 0.1912 - val_acc: 0.9901\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1827 - acc: 0.9921 - val_loss: 0.1821 - val_acc: 0.9900\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1825 - acc: 0.9919 - val_loss: 0.1877 - val_acc: 0.9897\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1888 - acc: 0.9916 - val_loss: 0.1987 - val_acc: 0.9890\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2015 - acc: 0.9917 - val_loss: 0.2096 - val_acc: 0.9900\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2135 - acc: 0.9922 - val_loss: 0.2108 - val_acc: 0.9898\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.2092 - acc: 0.9916 - val_loss: 0.2033 - val_acc: 0.9889\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2058 - acc: 0.9911 - val_loss: 0.2067 - val_acc: 0.9889\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1965 - acc: 0.9913 - val_loss: 0.1968 - val_acc: 0.9896\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1913 - acc: 0.9917 - val_loss: 0.1934 - val_acc: 0.9894\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1864 - acc: 0.9920 - val_loss: 0.1892 - val_acc: 0.9901\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.0032 - acc: 0.9578 - val_loss: 0.0038 - val_acc: 0.9476\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0034 - acc: 0.9502 - val_loss: 0.0033 - val_acc: 0.9597\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0031 - acc: 0.9573 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0032 - acc: 0.9553 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0032 - acc: 0.9573 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9613\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0032 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9590\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9583\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0035 - acc: 0.9509 - val_loss: 0.0033 - val_acc: 0.9577\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9610\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0031 - acc: 0.9592 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0032 - acc: 0.9564 - val_loss: 0.0033 - val_acc: 0.9601\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.0031 - acc: 0.9592 - val_loss: 0.0032 - val_acc: 0.9612\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.0032 - acc: 0.9575 - val_loss: 0.0034 - val_acc: 0.9572\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.0032 - acc: 0.9556 - val_loss: 0.0033 - val_acc: 0.9604\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.0031 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.0031 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.0032 - acc: 0.9568 - val_loss: 0.0034 - val_acc: 0.9587\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.0031 - acc: 0.9584 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0032 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9572\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0034 - acc: 0.9541 - val_loss: 0.0045 - val_acc: 0.9348\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0033 - acc: 0.9550 - val_loss: 0.0034 - val_acc: 0.9587\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.0034 - acc: 0.9537 - val_loss: 0.0034 - val_acc: 0.9582\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.0032 - acc: 0.9563 - val_loss: 0.0033 - val_acc: 0.9601\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.0033 - acc: 0.9530 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0034 - val_acc: 0.9545\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.0032 - acc: 0.9546 - val_loss: 0.0032 - val_acc: 0.9612\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.0031 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9599\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0031 - acc: 0.9573 - val_loss: 0.0034 - val_acc: 0.9613\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0032 - acc: 0.9566 - val_loss: 0.0033 - val_acc: 0.9587\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.0031 - acc: 0.9585 - val_loss: 0.0033 - val_acc: 0.9624\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0031 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9586\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.0032 - acc: 0.9560 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.0032 - acc: 0.9543 - val_loss: 0.0032 - val_acc: 0.9613\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0031 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.0031 - acc: 0.9594 - val_loss: 0.0033 - val_acc: 0.9627\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.0033 - acc: 0.9558 - val_loss: 0.0034 - val_acc: 0.9612\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.0034 - acc: 0.9528 - val_loss: 0.0033 - val_acc: 0.9619\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.0031 - acc: 0.9596 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 469us/step - loss: 0.0031 - acc: 0.9594 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9626\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.0032 - acc: 0.9575 - val_loss: 0.0033 - val_acc: 0.9627\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.0032 - acc: 0.9575 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 490us/step - loss: 0.0032 - acc: 0.9580 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 475us/step - loss: 0.0031 - acc: 0.9596 - val_loss: 0.0033 - val_acc: 0.9621\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 0.0032 - acc: 0.9559 - val_loss: 0.0033 - val_acc: 0.9598\n",
      "start training round 16\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.2380 - acc: 0.6845 - val_loss: 0.2508 - val_acc: 0.6829\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.2338 - acc: 0.6864 - val_loss: 0.2454 - val_acc: 0.6844\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.2340 - acc: 0.6860 - val_loss: 0.2602 - val_acc: 0.6750\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2358 - acc: 0.6851 - val_loss: 0.2479 - val_acc: 0.6832\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2332 - acc: 0.6869 - val_loss: 0.2483 - val_acc: 0.6840\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2347 - acc: 0.6869 - val_loss: 0.2460 - val_acc: 0.6849\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.2349 - acc: 0.6856 - val_loss: 0.2485 - val_acc: 0.6838\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2378 - acc: 0.6836 - val_loss: 0.2513 - val_acc: 0.6802\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.2358 - acc: 0.6844 - val_loss: 0.2482 - val_acc: 0.6835\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2390 - acc: 0.6848 - val_loss: 0.2461 - val_acc: 0.6835\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2353 - acc: 0.6849 - val_loss: 0.2539 - val_acc: 0.6812\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2358 - acc: 0.6851 - val_loss: 0.2498 - val_acc: 0.6838\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2401 - acc: 0.6833 - val_loss: 0.2472 - val_acc: 0.6852\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.2371 - acc: 0.6845 - val_loss: 0.2507 - val_acc: 0.6821\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2364 - acc: 0.6858 - val_loss: 0.2470 - val_acc: 0.6842\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2324 - acc: 0.6868 - val_loss: 0.2456 - val_acc: 0.6850\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.2347 - acc: 0.6859 - val_loss: 0.2499 - val_acc: 0.6805\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2380 - acc: 0.6854 - val_loss: 0.2469 - val_acc: 0.6835\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2318 - acc: 0.6868 - val_loss: 0.2465 - val_acc: 0.6847\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.2349 - acc: 0.6860 - val_loss: 0.2494 - val_acc: 0.6825\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.2360 - acc: 0.6846 - val_loss: 0.2556 - val_acc: 0.6824\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2404 - acc: 0.6852 - val_loss: 0.2467 - val_acc: 0.6839\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2332 - acc: 0.6860 - val_loss: 0.2476 - val_acc: 0.6838\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2331 - acc: 0.6866 - val_loss: 0.2485 - val_acc: 0.6838\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.2398 - acc: 0.6850 - val_loss: 0.2496 - val_acc: 0.6849\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2366 - acc: 0.6854 - val_loss: 0.2461 - val_acc: 0.6833\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2379 - acc: 0.6856 - val_loss: 0.2480 - val_acc: 0.6832\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.2374 - acc: 0.6847 - val_loss: 0.2509 - val_acc: 0.6816\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2371 - acc: 0.6844 - val_loss: 0.2531 - val_acc: 0.6822\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2385 - acc: 0.6840 - val_loss: 0.2467 - val_acc: 0.6846\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.2326 - acc: 0.6867 - val_loss: 0.2446 - val_acc: 0.6854\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2328 - acc: 0.6868 - val_loss: 0.2482 - val_acc: 0.6838\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.2375 - acc: 0.6847 - val_loss: 0.2517 - val_acc: 0.6834\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2352 - acc: 0.6863 - val_loss: 0.2507 - val_acc: 0.6843\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.2371 - acc: 0.6852 - val_loss: 0.2497 - val_acc: 0.6816\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2369 - acc: 0.6851 - val_loss: 0.2547 - val_acc: 0.6784\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.2350 - acc: 0.6843 - val_loss: 0.2467 - val_acc: 0.6828\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2321 - acc: 0.6870 - val_loss: 0.2455 - val_acc: 0.6840\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.2345 - acc: 0.6856 - val_loss: 0.2484 - val_acc: 0.6835\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2345 - acc: 0.6860 - val_loss: 0.2478 - val_acc: 0.6836\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2380 - acc: 0.6844 - val_loss: 0.2510 - val_acc: 0.6821\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2364 - acc: 0.6858 - val_loss: 0.2532 - val_acc: 0.6823\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2375 - acc: 0.6848 - val_loss: 0.2460 - val_acc: 0.6837\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.2353 - acc: 0.6849 - val_loss: 0.2503 - val_acc: 0.6837\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2359 - acc: 0.6842 - val_loss: 0.2476 - val_acc: 0.6837\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2358 - acc: 0.6853 - val_loss: 0.2490 - val_acc: 0.6832\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2353 - acc: 0.6856 - val_loss: 0.2474 - val_acc: 0.6834\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.2342 - acc: 0.6868 - val_loss: 0.2490 - val_acc: 0.6839\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.2350 - acc: 0.6860 - val_loss: 0.2475 - val_acc: 0.6823\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2355 - acc: 0.6854 - val_loss: 0.2479 - val_acc: 0.6841\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9889 - acc: 0.6791 - val_loss: 2.0861 - val_acc: 0.6775\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9782 - acc: 0.6782 - val_loss: 2.1677 - val_acc: 0.6765\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9817 - acc: 0.6788 - val_loss: 2.2256 - val_acc: 0.6758\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 1.9812 - acc: 0.6788 - val_loss: 2.1217 - val_acc: 0.6773\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 1.9754 - acc: 0.6797 - val_loss: 2.1804 - val_acc: 0.6724\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 1.9890 - acc: 0.6789 - val_loss: 2.1758 - val_acc: 0.6714\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 2.0020 - acc: 0.6786 - val_loss: 2.0777 - val_acc: 0.6767\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 1.9677 - acc: 0.6792 - val_loss: 2.1205 - val_acc: 0.6765\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9788 - acc: 0.6791 - val_loss: 2.0956 - val_acc: 0.6759\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 1.9828 - acc: 0.6787 - val_loss: 2.0738 - val_acc: 0.6769\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9649 - acc: 0.6793 - val_loss: 2.1061 - val_acc: 0.6783\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9870 - acc: 0.6797 - val_loss: 2.1016 - val_acc: 0.6772\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 1.9676 - acc: 0.6800 - val_loss: 2.0781 - val_acc: 0.6776\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9841 - acc: 0.6783 - val_loss: 2.0900 - val_acc: 0.6755\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 1.9565 - acc: 0.6781 - val_loss: 2.1709 - val_acc: 0.6709\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9764 - acc: 0.6775 - val_loss: 2.0820 - val_acc: 0.6780\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 1.9562 - acc: 0.6791 - val_loss: 2.1102 - val_acc: 0.6732\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 1.9829 - acc: 0.6791 - val_loss: 2.1232 - val_acc: 0.6752\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9812 - acc: 0.6791 - val_loss: 2.0924 - val_acc: 0.6763\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 2.0025 - acc: 0.6794 - val_loss: 2.0821 - val_acc: 0.6766\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 1.9455 - acc: 0.6790 - val_loss: 2.1631 - val_acc: 0.6711\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9857 - acc: 0.6783 - val_loss: 2.1029 - val_acc: 0.6752\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9651 - acc: 0.6795 - val_loss: 2.2440 - val_acc: 0.6766\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 1.9936 - acc: 0.6795 - val_loss: 2.1316 - val_acc: 0.6762\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 1.9709 - acc: 0.6793 - val_loss: 2.1020 - val_acc: 0.6793\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 1.9771 - acc: 0.6789 - val_loss: 2.1073 - val_acc: 0.6790\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 1.9668 - acc: 0.6797 - val_loss: 2.1067 - val_acc: 0.6793\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9799 - acc: 0.6796 - val_loss: 2.1859 - val_acc: 0.6769\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 1.9872 - acc: 0.6783 - val_loss: 2.1361 - val_acc: 0.6770\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9534 - acc: 0.6799 - val_loss: 2.1127 - val_acc: 0.6772\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 1.9613 - acc: 0.6786 - val_loss: 2.0788 - val_acc: 0.6768\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 1.9895 - acc: 0.6784 - val_loss: 2.1051 - val_acc: 0.6774\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 2.0156 - acc: 0.6788 - val_loss: 2.0781 - val_acc: 0.6780\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 1.9823 - acc: 0.6780 - val_loss: 2.1403 - val_acc: 0.6781\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9758 - acc: 0.6798 - val_loss: 2.0822 - val_acc: 0.6780\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9515 - acc: 0.6800 - val_loss: 2.0805 - val_acc: 0.6789\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 409us/step - loss: 1.9583 - acc: 0.6798 - val_loss: 2.1475 - val_acc: 0.6761\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9600 - acc: 0.6793 - val_loss: 2.0890 - val_acc: 0.6765\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 1.9639 - acc: 0.6786 - val_loss: 2.1150 - val_acc: 0.6769\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 1.9835 - acc: 0.6785 - val_loss: 2.0915 - val_acc: 0.6783\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 1.9471 - acc: 0.6789 - val_loss: 2.1625 - val_acc: 0.6723\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 1.9798 - acc: 0.6778 - val_loss: 2.1537 - val_acc: 0.6732\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9954 - acc: 0.6786 - val_loss: 2.1334 - val_acc: 0.6737\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 1.9523 - acc: 0.6799 - val_loss: 2.1297 - val_acc: 0.6758\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9927 - acc: 0.6798 - val_loss: 2.1588 - val_acc: 0.6772\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9722 - acc: 0.6792 - val_loss: 2.0613 - val_acc: 0.6770\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9594 - acc: 0.6799 - val_loss: 2.1787 - val_acc: 0.6727\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9977 - acc: 0.6791 - val_loss: 2.0978 - val_acc: 0.6791\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9790 - acc: 0.6790 - val_loss: 2.1335 - val_acc: 0.6782\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 1.9713 - acc: 0.6785 - val_loss: 2.1365 - val_acc: 0.6776\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1915 - acc: 0.9923 - val_loss: 0.1967 - val_acc: 0.9900\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.1957 - acc: 0.9919 - val_loss: 0.1865 - val_acc: 0.9900\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.1867 - acc: 0.9921 - val_loss: 0.1901 - val_acc: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.1949 - acc: 0.9922 - val_loss: 0.2033 - val_acc: 0.9900\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2050 - acc: 0.9923 - val_loss: 0.2072 - val_acc: 0.9899\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.1972 - acc: 0.9922 - val_loss: 0.2001 - val_acc: 0.9900\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1972 - acc: 0.9917 - val_loss: 0.1952 - val_acc: 0.9896\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.1914 - acc: 0.9916 - val_loss: 0.1876 - val_acc: 0.9897\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.1873 - acc: 0.9919 - val_loss: 0.1904 - val_acc: 0.9898\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.1857 - acc: 0.9921 - val_loss: 0.1832 - val_acc: 0.9900\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.1848 - acc: 0.9923 - val_loss: 0.1892 - val_acc: 0.9902\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1874 - acc: 0.9923 - val_loss: 0.1839 - val_acc: 0.9902\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.1814 - acc: 0.9923 - val_loss: 0.1835 - val_acc: 0.9901\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.1908 - acc: 0.9917 - val_loss: 0.2082 - val_acc: 0.9883\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2114 - acc: 0.9905 - val_loss: 0.2045 - val_acc: 0.9894\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.1949 - acc: 0.9917 - val_loss: 0.1905 - val_acc: 0.9898\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.1904 - acc: 0.9920 - val_loss: 0.1982 - val_acc: 0.9900\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2163 - acc: 0.9922 - val_loss: 0.2166 - val_acc: 0.9898\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.2009 - acc: 0.9922 - val_loss: 0.1987 - val_acc: 0.9899\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.1931 - acc: 0.9922 - val_loss: 0.1923 - val_acc: 0.9902\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1851 - acc: 0.9923 - val_loss: 0.1976 - val_acc: 0.9898\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1987 - acc: 0.9917 - val_loss: 0.1928 - val_acc: 0.9896\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.1876 - acc: 0.9922 - val_loss: 0.1861 - val_acc: 0.9900\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.1846 - acc: 0.9923 - val_loss: 0.1866 - val_acc: 0.9900\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.1845 - acc: 0.9923 - val_loss: 0.1947 - val_acc: 0.9899\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2100 - acc: 0.9910 - val_loss: 0.2230 - val_acc: 0.9871\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.1988 - acc: 0.9908 - val_loss: 0.1935 - val_acc: 0.9894\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.1945 - acc: 0.9919 - val_loss: 0.2000 - val_acc: 0.9900\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.1944 - acc: 0.9923 - val_loss: 0.1995 - val_acc: 0.9900\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.1963 - acc: 0.9922 - val_loss: 0.1939 - val_acc: 0.9898\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.1890 - acc: 0.9920 - val_loss: 0.1902 - val_acc: 0.9901\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.1927 - acc: 0.9923 - val_loss: 0.2047 - val_acc: 0.9900\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1956 - acc: 0.9920 - val_loss: 0.2022 - val_acc: 0.9895\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.1963 - acc: 0.9922 - val_loss: 0.1974 - val_acc: 0.9898\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.1872 - acc: 0.9922 - val_loss: 0.1839 - val_acc: 0.9902\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1819 - acc: 0.9923 - val_loss: 0.1906 - val_acc: 0.9902\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.1885 - acc: 0.9923 - val_loss: 0.1890 - val_acc: 0.9900\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1948 - acc: 0.9921 - val_loss: 0.2082 - val_acc: 0.9896\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1984 - acc: 0.9917 - val_loss: 0.1892 - val_acc: 0.9900\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1820 - acc: 0.9923 - val_loss: 0.1876 - val_acc: 0.9899\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1854 - acc: 0.9923 - val_loss: 0.1847 - val_acc: 0.9900\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.1875 - acc: 0.9923 - val_loss: 0.1986 - val_acc: 0.9901\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1987 - acc: 0.9921 - val_loss: 0.2003 - val_acc: 0.9898\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1914 - acc: 0.9918 - val_loss: 0.1961 - val_acc: 0.9895\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1905 - acc: 0.9919 - val_loss: 0.1906 - val_acc: 0.9897\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1915 - acc: 0.9912 - val_loss: 0.1911 - val_acc: 0.9897\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1867 - acc: 0.9919 - val_loss: 0.1864 - val_acc: 0.9901\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1870 - acc: 0.9923 - val_loss: 0.2132 - val_acc: 0.9896\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2012 - acc: 0.9917 - val_loss: 0.1933 - val_acc: 0.9900\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.1890 - acc: 0.9923 - val_loss: 0.1883 - val_acc: 0.9902\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.0032 - acc: 0.9563 - val_loss: 0.0036 - val_acc: 0.9522\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 461us/step - loss: 0.0032 - acc: 0.9545 - val_loss: 0.0033 - val_acc: 0.9596\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.0033 - acc: 0.9529 - val_loss: 0.0032 - val_acc: 0.9608\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 470us/step - loss: 0.0032 - acc: 0.9578 - val_loss: 0.0033 - val_acc: 0.9605\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.0033 - acc: 0.9560 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0031 - acc: 0.9595 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.0032 - acc: 0.9583 - val_loss: 0.0033 - val_acc: 0.9599\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.0032 - acc: 0.9575 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0031 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.0032 - acc: 0.9559 - val_loss: 0.0032 - val_acc: 0.9619\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0032 - val_acc: 0.9610\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0031 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9615\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0035 - val_acc: 0.9563\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0032 - acc: 0.9577 - val_loss: 0.0033 - val_acc: 0.9597\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0032 - val_acc: 0.9618\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.0032 - acc: 0.9576 - val_loss: 0.0034 - val_acc: 0.9578\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0033 - acc: 0.9528 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.0032 - acc: 0.9564 - val_loss: 0.0033 - val_acc: 0.9572\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.0032 - acc: 0.9558 - val_loss: 0.0032 - val_acc: 0.9605\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 0.0032 - acc: 0.9569 - val_loss: 0.0032 - val_acc: 0.9613\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.0031 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9593\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0032 - acc: 0.9555 - val_loss: 0.0034 - val_acc: 0.9588\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0031 - acc: 0.9578 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.0031 - acc: 0.9596 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0032 - val_acc: 0.9623\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0031 - acc: 0.9581 - val_loss: 0.0034 - val_acc: 0.9565\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.0032 - acc: 0.9557 - val_loss: 0.0034 - val_acc: 0.9575\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.0032 - acc: 0.9562 - val_loss: 0.0039 - val_acc: 0.9453\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0033 - acc: 0.9544 - val_loss: 0.0033 - val_acc: 0.9602\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0032 - acc: 0.9585 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0031 - acc: 0.9593 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.0031 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9623\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.0031 - acc: 0.9582 - val_loss: 0.0032 - val_acc: 0.9613\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0033 - val_acc: 0.9606\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.0032 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9621\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.0031 - acc: 0.9595 - val_loss: 0.0033 - val_acc: 0.9598\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0033 - acc: 0.9571 - val_loss: 0.0034 - val_acc: 0.9586\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.0032 - acc: 0.9551 - val_loss: 0.0033 - val_acc: 0.9604\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.0033 - acc: 0.9529 - val_loss: 0.0032 - val_acc: 0.9618\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.0031 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0031 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9597\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.0033 - acc: 0.9512 - val_loss: 0.0033 - val_acc: 0.9609\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0031 - acc: 0.9579 - val_loss: 0.0035 - val_acc: 0.9559\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0033 - acc: 0.9526 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 465us/step - loss: 0.0031 - acc: 0.9582 - val_loss: 0.0033 - val_acc: 0.9620\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.0032 - acc: 0.9559 - val_loss: 0.0035 - val_acc: 0.9618\n",
      "start training round 17\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.2370 - acc: 0.6844 - val_loss: 0.2539 - val_acc: 0.6820\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2346 - acc: 0.6855 - val_loss: 0.2472 - val_acc: 0.6845\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.2332 - acc: 0.6864 - val_loss: 0.2507 - val_acc: 0.6832\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2365 - acc: 0.6860 - val_loss: 0.2454 - val_acc: 0.6831\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.2317 - acc: 0.6870 - val_loss: 0.2442 - val_acc: 0.6859\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2321 - acc: 0.6872 - val_loss: 0.2462 - val_acc: 0.6839\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.2344 - acc: 0.6861 - val_loss: 0.2477 - val_acc: 0.6837\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.2330 - acc: 0.6864 - val_loss: 0.2472 - val_acc: 0.6831\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.2356 - acc: 0.6852 - val_loss: 0.2478 - val_acc: 0.6839\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2372 - acc: 0.6850 - val_loss: 0.2537 - val_acc: 0.6797\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2370 - acc: 0.6857 - val_loss: 0.2458 - val_acc: 0.6846\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.2380 - acc: 0.6865 - val_loss: 0.2471 - val_acc: 0.6849\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2330 - acc: 0.6864 - val_loss: 0.2460 - val_acc: 0.6847\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 409us/step - loss: 0.2339 - acc: 0.6852 - val_loss: 0.2452 - val_acc: 0.6842\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.2331 - acc: 0.6868 - val_loss: 0.2492 - val_acc: 0.6840\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.2357 - acc: 0.6868 - val_loss: 0.2452 - val_acc: 0.6847\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.2326 - acc: 0.6870 - val_loss: 0.2501 - val_acc: 0.6847\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2361 - acc: 0.6862 - val_loss: 0.2494 - val_acc: 0.6860\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.2374 - acc: 0.6859 - val_loss: 0.2512 - val_acc: 0.6810\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.2381 - acc: 0.6837 - val_loss: 0.2463 - val_acc: 0.6842\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2329 - acc: 0.6859 - val_loss: 0.2441 - val_acc: 0.6862\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2320 - acc: 0.6869 - val_loss: 0.2495 - val_acc: 0.6826\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.2347 - acc: 0.6864 - val_loss: 0.2453 - val_acc: 0.6838\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2342 - acc: 0.6857 - val_loss: 0.2478 - val_acc: 0.6841\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2362 - acc: 0.6851 - val_loss: 0.2542 - val_acc: 0.6793\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2339 - acc: 0.6865 - val_loss: 0.2452 - val_acc: 0.6861\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2334 - acc: 0.6867 - val_loss: 0.2507 - val_acc: 0.6817\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.2381 - acc: 0.6850 - val_loss: 0.2449 - val_acc: 0.6851\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2331 - acc: 0.6867 - val_loss: 0.2514 - val_acc: 0.6843\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2353 - acc: 0.6863 - val_loss: 0.2504 - val_acc: 0.6825\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.2340 - acc: 0.6862 - val_loss: 0.2506 - val_acc: 0.6809\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.2344 - acc: 0.6852 - val_loss: 0.2477 - val_acc: 0.6850\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.2348 - acc: 0.6861 - val_loss: 0.2521 - val_acc: 0.6823\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.2393 - acc: 0.6845 - val_loss: 0.2470 - val_acc: 0.6837\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2355 - acc: 0.6866 - val_loss: 0.2501 - val_acc: 0.6835\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.2339 - acc: 0.6861 - val_loss: 0.2488 - val_acc: 0.6843\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.2336 - acc: 0.6864 - val_loss: 0.2489 - val_acc: 0.6844\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2363 - acc: 0.6852 - val_loss: 0.2458 - val_acc: 0.6853\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.2363 - acc: 0.6863 - val_loss: 0.2489 - val_acc: 0.6843\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 472us/step - loss: 0.2391 - acc: 0.6854 - val_loss: 0.2439 - val_acc: 0.6848\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.2330 - acc: 0.6868 - val_loss: 0.2484 - val_acc: 0.6827\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2332 - acc: 0.6865 - val_loss: 0.2450 - val_acc: 0.6842\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2340 - acc: 0.6865 - val_loss: 0.2458 - val_acc: 0.6856\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2323 - acc: 0.6871 - val_loss: 0.2458 - val_acc: 0.6841\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.2355 - acc: 0.6854 - val_loss: 0.2445 - val_acc: 0.6850\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2335 - acc: 0.6869 - val_loss: 0.2544 - val_acc: 0.6830\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.2395 - acc: 0.6849 - val_loss: 0.2523 - val_acc: 0.6825\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2328 - acc: 0.6865 - val_loss: 0.2467 - val_acc: 0.6847\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.2333 - acc: 0.6864 - val_loss: 0.2471 - val_acc: 0.6835\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2332 - acc: 0.6863 - val_loss: 0.2475 - val_acc: 0.6829\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 1.9707 - acc: 0.6789 - val_loss: 2.0973 - val_acc: 0.6764\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9691 - acc: 0.6789 - val_loss: 2.1455 - val_acc: 0.6770\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9870 - acc: 0.6787 - val_loss: 2.2326 - val_acc: 0.6752\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9805 - acc: 0.6792 - val_loss: 2.2175 - val_acc: 0.6734\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 2.0121 - acc: 0.6789 - val_loss: 2.1035 - val_acc: 0.6781\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9658 - acc: 0.6792 - val_loss: 2.1112 - val_acc: 0.6770\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9641 - acc: 0.6795 - val_loss: 2.1211 - val_acc: 0.6770\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9713 - acc: 0.6787 - val_loss: 2.1279 - val_acc: 0.6776\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9909 - acc: 0.6781 - val_loss: 2.1305 - val_acc: 0.6792\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 2.0040 - acc: 0.6787 - val_loss: 2.1165 - val_acc: 0.6771\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9518 - acc: 0.6798 - val_loss: 2.1351 - val_acc: 0.6748\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 1.9911 - acc: 0.6795 - val_loss: 2.1036 - val_acc: 0.6751\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 1.9558 - acc: 0.6800 - val_loss: 2.1281 - val_acc: 0.6756\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9778 - acc: 0.6793 - val_loss: 2.2130 - val_acc: 0.6756\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 1.9906 - acc: 0.6785 - val_loss: 2.0963 - val_acc: 0.6755\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 1.9796 - acc: 0.6792 - val_loss: 2.0597 - val_acc: 0.6765\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9467 - acc: 0.6797 - val_loss: 2.0631 - val_acc: 0.6773\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9689 - acc: 0.6788 - val_loss: 2.0741 - val_acc: 0.6785\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 1.9868 - acc: 0.6796 - val_loss: 2.2058 - val_acc: 0.6790\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9619 - acc: 0.6800 - val_loss: 2.0992 - val_acc: 0.6797\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9716 - acc: 0.6792 - val_loss: 2.1129 - val_acc: 0.6785\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9727 - acc: 0.6788 - val_loss: 2.1082 - val_acc: 0.6743\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 1.9708 - acc: 0.6789 - val_loss: 2.0923 - val_acc: 0.6757\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 1.9628 - acc: 0.6791 - val_loss: 2.0935 - val_acc: 0.6762\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9657 - acc: 0.6779 - val_loss: 2.0851 - val_acc: 0.6778\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9811 - acc: 0.6787 - val_loss: 2.0821 - val_acc: 0.6752\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 1.9573 - acc: 0.6799 - val_loss: 2.1162 - val_acc: 0.6750\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 1.9769 - acc: 0.6798 - val_loss: 2.0849 - val_acc: 0.6772\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9647 - acc: 0.6798 - val_loss: 2.1033 - val_acc: 0.6753\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9594 - acc: 0.6786 - val_loss: 2.1306 - val_acc: 0.6755\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 429us/step - loss: 2.0117 - acc: 0.6786 - val_loss: 2.1858 - val_acc: 0.6728\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9718 - acc: 0.6791 - val_loss: 2.0968 - val_acc: 0.6751\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 1.9529 - acc: 0.6802 - val_loss: 2.0752 - val_acc: 0.6771\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 1.9554 - acc: 0.6805 - val_loss: 2.1844 - val_acc: 0.6754\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 2.0087 - acc: 0.6789 - val_loss: 2.2227 - val_acc: 0.6772\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9757 - acc: 0.6788 - val_loss: 2.1627 - val_acc: 0.6763\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 1.9746 - acc: 0.6794 - val_loss: 2.1046 - val_acc: 0.6783\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9672 - acc: 0.6795 - val_loss: 2.1107 - val_acc: 0.6798\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9808 - acc: 0.6788 - val_loss: 2.1156 - val_acc: 0.6755\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9578 - acc: 0.6794 - val_loss: 2.1259 - val_acc: 0.6796\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 1.9376 - acc: 0.6802 - val_loss: 2.0739 - val_acc: 0.6774\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 1.9756 - acc: 0.6791 - val_loss: 2.1352 - val_acc: 0.6752\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 1.9743 - acc: 0.6790 - val_loss: 2.0874 - val_acc: 0.6758\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 1.9864 - acc: 0.6780 - val_loss: 2.0744 - val_acc: 0.6773\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9597 - acc: 0.6800 - val_loss: 2.1244 - val_acc: 0.6757\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 2.0135 - acc: 0.6784 - val_loss: 2.1543 - val_acc: 0.6744\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9517 - acc: 0.6795 - val_loss: 2.0702 - val_acc: 0.6791\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 1.9803 - acc: 0.6796 - val_loss: 2.1004 - val_acc: 0.6797\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9607 - acc: 0.6800 - val_loss: 2.0613 - val_acc: 0.6792\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9571 - acc: 0.6788 - val_loss: 2.1099 - val_acc: 0.6748\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.1901 - acc: 0.9923 - val_loss: 0.1966 - val_acc: 0.9900\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.1925 - acc: 0.9923 - val_loss: 0.2050 - val_acc: 0.9900\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.2033 - acc: 0.9921 - val_loss: 0.1967 - val_acc: 0.9901\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.1888 - acc: 0.9921 - val_loss: 0.1892 - val_acc: 0.9899\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.1867 - acc: 0.9915 - val_loss: 0.1959 - val_acc: 0.9889\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.2015 - acc: 0.9904 - val_loss: 0.2066 - val_acc: 0.9877\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.1943 - acc: 0.9910 - val_loss: 0.1960 - val_acc: 0.9895\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.1915 - acc: 0.9921 - val_loss: 0.1866 - val_acc: 0.9900\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.1939 - acc: 0.9923 - val_loss: 0.2079 - val_acc: 0.9902\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2036 - acc: 0.9923 - val_loss: 0.1902 - val_acc: 0.9902\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1920 - acc: 0.9923 - val_loss: 0.1998 - val_acc: 0.9901\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1932 - acc: 0.9923 - val_loss: 0.2123 - val_acc: 0.9900\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.1981 - acc: 0.9922 - val_loss: 0.1880 - val_acc: 0.9903\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1817 - acc: 0.9923 - val_loss: 0.1826 - val_acc: 0.9899\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.1868 - acc: 0.9921 - val_loss: 0.1892 - val_acc: 0.9896\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.1863 - acc: 0.9918 - val_loss: 0.1857 - val_acc: 0.9899\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.1870 - acc: 0.9917 - val_loss: 0.1969 - val_acc: 0.9892\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.1926 - acc: 0.9912 - val_loss: 0.1891 - val_acc: 0.9895\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.1900 - acc: 0.9915 - val_loss: 0.2084 - val_acc: 0.9895\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.2109 - acc: 0.9914 - val_loss: 0.1840 - val_acc: 0.9901\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.1782 - acc: 0.9923 - val_loss: 0.1835 - val_acc: 0.9900\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.1876 - acc: 0.9920 - val_loss: 0.1976 - val_acc: 0.9900\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1990 - acc: 0.9923 - val_loss: 0.1978 - val_acc: 0.9901\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2035 - acc: 0.9923 - val_loss: 0.2053 - val_acc: 0.9900\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2042 - acc: 0.9921 - val_loss: 0.2090 - val_acc: 0.9898\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.1967 - acc: 0.9920 - val_loss: 0.2033 - val_acc: 0.9890\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.1955 - acc: 0.9912 - val_loss: 0.1904 - val_acc: 0.9895\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.1882 - acc: 0.9914 - val_loss: 0.1966 - val_acc: 0.9883\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1894 - acc: 0.9913 - val_loss: 0.1879 - val_acc: 0.9899\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.1941 - acc: 0.9917 - val_loss: 0.2014 - val_acc: 0.9897\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.1954 - acc: 0.9922 - val_loss: 0.1952 - val_acc: 0.9902\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.1846 - acc: 0.9924 - val_loss: 0.1939 - val_acc: 0.9901\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.1962 - acc: 0.9923 - val_loss: 0.2060 - val_acc: 0.9902\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.2021 - acc: 0.9923 - val_loss: 0.1915 - val_acc: 0.9903\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.1860 - acc: 0.9923 - val_loss: 0.1864 - val_acc: 0.9903\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.1880 - acc: 0.9923 - val_loss: 0.1934 - val_acc: 0.9902\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1954 - acc: 0.9923 - val_loss: 0.1912 - val_acc: 0.9900\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1886 - acc: 0.9922 - val_loss: 0.1847 - val_acc: 0.9900\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1860 - acc: 0.9921 - val_loss: 0.1966 - val_acc: 0.9896\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.1928 - acc: 0.9917 - val_loss: 0.1908 - val_acc: 0.9895\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1912 - acc: 0.9915 - val_loss: 0.2112 - val_acc: 0.9886\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2055 - acc: 0.9913 - val_loss: 0.2015 - val_acc: 0.9900\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.1973 - acc: 0.9923 - val_loss: 0.1943 - val_acc: 0.9903\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.1931 - acc: 0.9923 - val_loss: 0.1947 - val_acc: 0.9900\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.1887 - acc: 0.9922 - val_loss: 0.1828 - val_acc: 0.9900\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1806 - acc: 0.9922 - val_loss: 0.1884 - val_acc: 0.9899\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.1945 - acc: 0.9917 - val_loss: 0.1916 - val_acc: 0.9897\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1851 - acc: 0.9920 - val_loss: 0.1882 - val_acc: 0.9900\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.1887 - acc: 0.9923 - val_loss: 0.1837 - val_acc: 0.9902\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.1838 - acc: 0.9923 - val_loss: 0.1876 - val_acc: 0.9902\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.0033 - acc: 0.9558 - val_loss: 0.0033 - val_acc: 0.9626\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0032 - acc: 0.9551 - val_loss: 0.0034 - val_acc: 0.9534\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0031 - acc: 0.9578 - val_loss: 0.0034 - val_acc: 0.9565\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0033 - acc: 0.9543 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 487us/step - loss: 0.0031 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.0031 - acc: 0.9577 - val_loss: 0.0033 - val_acc: 0.9626\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.0032 - acc: 0.9575 - val_loss: 0.0033 - val_acc: 0.9625\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.0031 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 474us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0032 - val_acc: 0.9625\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0031 - acc: 0.9576 - val_loss: 0.0032 - val_acc: 0.9619\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.0031 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9623\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 461us/step - loss: 0.0032 - acc: 0.9534 - val_loss: 0.0034 - val_acc: 0.9581\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.0032 - acc: 0.9562 - val_loss: 0.0037 - val_acc: 0.9569\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.0033 - acc: 0.9545 - val_loss: 0.0034 - val_acc: 0.9616\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 465us/step - loss: 0.0032 - acc: 0.9556 - val_loss: 0.0033 - val_acc: 0.9625\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.0032 - acc: 0.9554 - val_loss: 0.0033 - val_acc: 0.9627\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 495us/step - loss: 0.0033 - acc: 0.9549 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.0031 - acc: 0.9600 - val_loss: 0.0033 - val_acc: 0.9617\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0032 - acc: 0.9564 - val_loss: 0.0034 - val_acc: 0.9602\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 480us/step - loss: 0.0032 - acc: 0.9569 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.0032 - acc: 0.9565 - val_loss: 0.0033 - val_acc: 0.9583\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.0032 - acc: 0.9560 - val_loss: 0.0032 - val_acc: 0.9623\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.0031 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0031 - acc: 0.9580 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0032 - val_acc: 0.9616\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0031 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9625\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0032 - acc: 0.9568 - val_loss: 0.0034 - val_acc: 0.9549\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0032 - acc: 0.9552 - val_loss: 0.0033 - val_acc: 0.9625\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0031 - acc: 0.9582 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0032 - acc: 0.9596 - val_loss: 0.0033 - val_acc: 0.9632\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0031 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9625\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0031 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0031 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0033 - val_acc: 0.9622\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9624\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0032 - acc: 0.9562 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.0031 - acc: 0.9583 - val_loss: 0.0034 - val_acc: 0.9570\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0034 - acc: 0.9482 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0031 - acc: 0.9584 - val_loss: 0.0033 - val_acc: 0.9627\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.0031 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0032 - acc: 0.9562 - val_loss: 0.0033 - val_acc: 0.9599\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9623\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9619\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0031 - acc: 0.9581 - val_loss: 0.0032 - val_acc: 0.9631\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0033 - acc: 0.9536 - val_loss: 0.0033 - val_acc: 0.9622\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0033 - acc: 0.9547 - val_loss: 0.0033 - val_acc: 0.9621\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0031 - acc: 0.9579 - val_loss: 0.0033 - val_acc: 0.9609\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0032 - acc: 0.9548 - val_loss: 0.0032 - val_acc: 0.9611\n",
      "start training round 18\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2373 - acc: 0.6870 - val_loss: 0.2503 - val_acc: 0.6845\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2335 - acc: 0.6873 - val_loss: 0.2470 - val_acc: 0.6854\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2336 - acc: 0.6856 - val_loss: 0.2504 - val_acc: 0.6836\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.2368 - acc: 0.6853 - val_loss: 0.2483 - val_acc: 0.6829\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.2354 - acc: 0.6862 - val_loss: 0.2476 - val_acc: 0.6836\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2340 - acc: 0.6859 - val_loss: 0.2468 - val_acc: 0.6831\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.2323 - acc: 0.6869 - val_loss: 0.2451 - val_acc: 0.6841\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2354 - acc: 0.6863 - val_loss: 0.2483 - val_acc: 0.6856\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2348 - acc: 0.6868 - val_loss: 0.2513 - val_acc: 0.6826\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2363 - acc: 0.6844 - val_loss: 0.2450 - val_acc: 0.6842\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.2329 - acc: 0.6870 - val_loss: 0.2500 - val_acc: 0.6838\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2353 - acc: 0.6859 - val_loss: 0.2439 - val_acc: 0.6855\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2317 - acc: 0.6868 - val_loss: 0.2478 - val_acc: 0.6846\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2335 - acc: 0.6860 - val_loss: 0.2462 - val_acc: 0.6858\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2310 - acc: 0.6875 - val_loss: 0.2442 - val_acc: 0.6858\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2312 - acc: 0.6869 - val_loss: 0.2472 - val_acc: 0.6848\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2400 - acc: 0.6842 - val_loss: 0.2502 - val_acc: 0.6813\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2350 - acc: 0.6859 - val_loss: 0.2442 - val_acc: 0.6854\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2332 - acc: 0.6869 - val_loss: 0.2467 - val_acc: 0.6841\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2354 - acc: 0.6864 - val_loss: 0.2443 - val_acc: 0.6853\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2324 - acc: 0.6871 - val_loss: 0.2453 - val_acc: 0.6852\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.2325 - acc: 0.6866 - val_loss: 0.2511 - val_acc: 0.6836\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2354 - acc: 0.6865 - val_loss: 0.2475 - val_acc: 0.6833\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2347 - acc: 0.6858 - val_loss: 0.2457 - val_acc: 0.6842\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2318 - acc: 0.6871 - val_loss: 0.2448 - val_acc: 0.6845\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2336 - acc: 0.6862 - val_loss: 0.2441 - val_acc: 0.6848\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2351 - acc: 0.6869 - val_loss: 0.2476 - val_acc: 0.6836\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2364 - acc: 0.6859 - val_loss: 0.2506 - val_acc: 0.6827\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2339 - acc: 0.6855 - val_loss: 0.2513 - val_acc: 0.6838\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2321 - acc: 0.6872 - val_loss: 0.2504 - val_acc: 0.6846\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2356 - acc: 0.6862 - val_loss: 0.2506 - val_acc: 0.6820\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.2372 - acc: 0.6848 - val_loss: 0.2526 - val_acc: 0.6835\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2336 - acc: 0.6868 - val_loss: 0.2439 - val_acc: 0.6862\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2341 - acc: 0.6859 - val_loss: 0.2462 - val_acc: 0.6841\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2358 - acc: 0.6855 - val_loss: 0.2441 - val_acc: 0.6868\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2331 - acc: 0.6875 - val_loss: 0.2510 - val_acc: 0.6853\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2339 - acc: 0.6872 - val_loss: 0.2493 - val_acc: 0.6850\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2316 - acc: 0.6879 - val_loss: 0.2474 - val_acc: 0.6851\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2324 - acc: 0.6876 - val_loss: 0.2493 - val_acc: 0.6833\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2364 - acc: 0.6865 - val_loss: 0.2455 - val_acc: 0.6834\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2352 - acc: 0.6855 - val_loss: 0.2452 - val_acc: 0.6848\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2307 - acc: 0.6878 - val_loss: 0.2479 - val_acc: 0.6838\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2375 - acc: 0.6849 - val_loss: 0.2450 - val_acc: 0.6836\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.2334 - acc: 0.6872 - val_loss: 0.2441 - val_acc: 0.6852\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2303 - acc: 0.6878 - val_loss: 0.2460 - val_acc: 0.6844\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.2297 - acc: 0.6881 - val_loss: 0.2442 - val_acc: 0.6853\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2344 - acc: 0.6868 - val_loss: 0.2504 - val_acc: 0.6842\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.2343 - acc: 0.6860 - val_loss: 0.2475 - val_acc: 0.6842\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2350 - acc: 0.6860 - val_loss: 0.2487 - val_acc: 0.6832\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2337 - acc: 0.6868 - val_loss: 0.2448 - val_acc: 0.6852\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9849 - acc: 0.6793 - val_loss: 2.1068 - val_acc: 0.6766\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 1.9634 - acc: 0.6801 - val_loss: 2.1333 - val_acc: 0.6759\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9702 - acc: 0.6796 - val_loss: 2.0924 - val_acc: 0.6752\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9662 - acc: 0.6799 - val_loss: 2.2071 - val_acc: 0.6708\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 1.9676 - acc: 0.6795 - val_loss: 2.0857 - val_acc: 0.6756\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 1.9601 - acc: 0.6792 - val_loss: 2.1675 - val_acc: 0.6717\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9608 - acc: 0.6788 - val_loss: 2.1514 - val_acc: 0.6745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9916 - acc: 0.6782 - val_loss: 2.0944 - val_acc: 0.6764\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 1.9697 - acc: 0.6798 - val_loss: 2.1893 - val_acc: 0.6753\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9714 - acc: 0.6794 - val_loss: 2.1090 - val_acc: 0.6779\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9537 - acc: 0.6794 - val_loss: 2.2061 - val_acc: 0.6739\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 1.9573 - acc: 0.6792 - val_loss: 2.2073 - val_acc: 0.6757\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 2.0033 - acc: 0.6787 - val_loss: 2.1101 - val_acc: 0.6744\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9795 - acc: 0.6787 - val_loss: 2.1021 - val_acc: 0.6747\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9906 - acc: 0.6790 - val_loss: 2.1045 - val_acc: 0.6784\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 1.9832 - acc: 0.6794 - val_loss: 2.0818 - val_acc: 0.6760\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 1.9582 - acc: 0.6796 - val_loss: 2.0998 - val_acc: 0.6752\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9456 - acc: 0.6797 - val_loss: 2.1224 - val_acc: 0.6745\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9434 - acc: 0.6803 - val_loss: 2.1751 - val_acc: 0.6733\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9676 - acc: 0.6797 - val_loss: 2.1094 - val_acc: 0.6747\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 1.9956 - acc: 0.6781 - val_loss: 2.0758 - val_acc: 0.6760\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9756 - acc: 0.6802 - val_loss: 2.0833 - val_acc: 0.6777\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9456 - acc: 0.6802 - val_loss: 2.1153 - val_acc: 0.6786\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9861 - acc: 0.6788 - val_loss: 2.1044 - val_acc: 0.6769\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 1.9753 - acc: 0.6785 - val_loss: 2.0975 - val_acc: 0.6759\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9680 - acc: 0.6799 - val_loss: 2.1322 - val_acc: 0.6766\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9791 - acc: 0.6791 - val_loss: 2.0858 - val_acc: 0.6789\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9626 - acc: 0.6797 - val_loss: 2.1218 - val_acc: 0.6773\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9577 - acc: 0.6793 - val_loss: 2.0810 - val_acc: 0.6786\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9702 - acc: 0.6797 - val_loss: 2.1082 - val_acc: 0.6794\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9749 - acc: 0.6796 - val_loss: 2.1014 - val_acc: 0.6776\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9542 - acc: 0.6800 - val_loss: 2.0812 - val_acc: 0.6789\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9683 - acc: 0.6787 - val_loss: 2.1941 - val_acc: 0.6766\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 1.9779 - acc: 0.6785 - val_loss: 2.0853 - val_acc: 0.6783\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9684 - acc: 0.6798 - val_loss: 2.0802 - val_acc: 0.6795\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 1.9492 - acc: 0.6797 - val_loss: 2.1083 - val_acc: 0.6784\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9819 - acc: 0.6791 - val_loss: 2.0782 - val_acc: 0.6766\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9491 - acc: 0.6808 - val_loss: 2.1786 - val_acc: 0.6738\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 1.9683 - acc: 0.6799 - val_loss: 2.1356 - val_acc: 0.6746\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9532 - acc: 0.6803 - val_loss: 2.0787 - val_acc: 0.6784\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 2.0015 - acc: 0.6784 - val_loss: 2.1315 - val_acc: 0.6769\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9512 - acc: 0.6794 - val_loss: 2.1850 - val_acc: 0.6786\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 2.0037 - acc: 0.6788 - val_loss: 2.1752 - val_acc: 0.6751\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9612 - acc: 0.6795 - val_loss: 2.0644 - val_acc: 0.6775\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 1.9711 - acc: 0.6795 - val_loss: 2.0928 - val_acc: 0.6763\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9805 - acc: 0.6803 - val_loss: 2.1102 - val_acc: 0.6777\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 1.9793 - acc: 0.6798 - val_loss: 2.1082 - val_acc: 0.6777\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9720 - acc: 0.6795 - val_loss: 2.0616 - val_acc: 0.6777\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9568 - acc: 0.6786 - val_loss: 2.0767 - val_acc: 0.6760\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9611 - acc: 0.6790 - val_loss: 2.0639 - val_acc: 0.6779\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.1842 - acc: 0.9924 - val_loss: 0.1930 - val_acc: 0.9902\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.1971 - acc: 0.9920 - val_loss: 0.2094 - val_acc: 0.9896\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1985 - acc: 0.9919 - val_loss: 0.1974 - val_acc: 0.9899\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.1952 - acc: 0.9920 - val_loss: 0.2009 - val_acc: 0.9899\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1872 - acc: 0.9922 - val_loss: 0.1886 - val_acc: 0.9902\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1935 - acc: 0.9922 - val_loss: 0.1934 - val_acc: 0.9900\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1920 - acc: 0.9917 - val_loss: 0.1955 - val_acc: 0.9894\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.1944 - acc: 0.9912 - val_loss: 0.1917 - val_acc: 0.9898\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1891 - acc: 0.9918 - val_loss: 0.1874 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.1855 - acc: 0.9919 - val_loss: 0.1884 - val_acc: 0.9897\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.1896 - acc: 0.9916 - val_loss: 0.1986 - val_acc: 0.9892\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1984 - acc: 0.9912 - val_loss: 0.1930 - val_acc: 0.9893\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 371us/step - loss: 0.1888 - acc: 0.9915 - val_loss: 0.1949 - val_acc: 0.9892\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.1951 - acc: 0.9916 - val_loss: 0.1895 - val_acc: 0.9900\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.1937 - acc: 0.9923 - val_loss: 0.1993 - val_acc: 0.9903\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1941 - acc: 0.9923 - val_loss: 0.1846 - val_acc: 0.9902\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.1823 - acc: 0.9924 - val_loss: 0.1838 - val_acc: 0.9902\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1831 - acc: 0.9923 - val_loss: 0.1857 - val_acc: 0.9899\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.1859 - acc: 0.9916 - val_loss: 0.1841 - val_acc: 0.9898\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1885 - acc: 0.9917 - val_loss: 0.1896 - val_acc: 0.9899\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1906 - acc: 0.9922 - val_loss: 0.1873 - val_acc: 0.9901\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.1816 - acc: 0.9924 - val_loss: 0.1887 - val_acc: 0.9901\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.1877 - acc: 0.9923 - val_loss: 0.1897 - val_acc: 0.9900\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1795 - acc: 0.9922 - val_loss: 0.1881 - val_acc: 0.9893\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1884 - acc: 0.9915 - val_loss: 0.1922 - val_acc: 0.9896\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2026 - acc: 0.9917 - val_loss: 0.2200 - val_acc: 0.9897\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2013 - acc: 0.9923 - val_loss: 0.1985 - val_acc: 0.9900\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1922 - acc: 0.9920 - val_loss: 0.1859 - val_acc: 0.9899\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.1855 - acc: 0.9920 - val_loss: 0.1906 - val_acc: 0.9899\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1834 - acc: 0.9920 - val_loss: 0.1861 - val_acc: 0.9898\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1871 - acc: 0.9915 - val_loss: 0.1904 - val_acc: 0.9897\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.1915 - acc: 0.9920 - val_loss: 0.2100 - val_acc: 0.9900\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1980 - acc: 0.9922 - val_loss: 0.1935 - val_acc: 0.9903\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1955 - acc: 0.9923 - val_loss: 0.1890 - val_acc: 0.9899\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.1816 - acc: 0.9923 - val_loss: 0.1875 - val_acc: 0.9900\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 0.1804 - acc: 0.9921 - val_loss: 0.1867 - val_acc: 0.9897\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1943 - acc: 0.9916 - val_loss: 0.2051 - val_acc: 0.9895\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.1907 - acc: 0.9917 - val_loss: 0.1851 - val_acc: 0.9896\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.1879 - acc: 0.9915 - val_loss: 0.1894 - val_acc: 0.9898\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1861 - acc: 0.9921 - val_loss: 0.1924 - val_acc: 0.9901\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1900 - acc: 0.9923 - val_loss: 0.1915 - val_acc: 0.9901\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1851 - acc: 0.9924 - val_loss: 0.1936 - val_acc: 0.9901\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2031 - acc: 0.9918 - val_loss: 0.2075 - val_acc: 0.9897\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.1968 - acc: 0.9918 - val_loss: 0.1812 - val_acc: 0.9902\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.1804 - acc: 0.9923 - val_loss: 0.1822 - val_acc: 0.9903\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1842 - acc: 0.9923 - val_loss: 0.1970 - val_acc: 0.9903\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1985 - acc: 0.9923 - val_loss: 0.2110 - val_acc: 0.9900\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1925 - acc: 0.9923 - val_loss: 0.1892 - val_acc: 0.9900\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.1812 - acc: 0.9924 - val_loss: 0.1798 - val_acc: 0.9902\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.1779 - acc: 0.9923 - val_loss: 0.1797 - val_acc: 0.9902\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0033 - val_acc: 0.9631\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0031 - acc: 0.9592 - val_loss: 0.0032 - val_acc: 0.9615\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0031 - acc: 0.9586 - val_loss: 0.0032 - val_acc: 0.9618\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0031 - acc: 0.9574 - val_loss: 0.0032 - val_acc: 0.9623\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0031 - acc: 0.9569 - val_loss: 0.0032 - val_acc: 0.9600\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.0032 - acc: 0.9551 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0031 - acc: 0.9578 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0031 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9618\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0032 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9604\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0032 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9616\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.0031 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9608\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0031 - acc: 0.9583 - val_loss: 0.0033 - val_acc: 0.9597\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0031 - acc: 0.9578 - val_loss: 0.0035 - val_acc: 0.9556\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9545 - val_loss: 0.0033 - val_acc: 0.9599\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0031 - acc: 0.9576 - val_loss: 0.0032 - val_acc: 0.9609\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0032 - acc: 0.9557 - val_loss: 0.0034 - val_acc: 0.9579\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0033 - acc: 0.9537 - val_loss: 0.0033 - val_acc: 0.9589\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0031 - acc: 0.9577 - val_loss: 0.0032 - val_acc: 0.9629\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9616\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0032 - val_acc: 0.9604\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9596\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0032 - acc: 0.9561 - val_loss: 0.0035 - val_acc: 0.9559\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0031 - acc: 0.9578 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0032 - acc: 0.9574 - val_loss: 0.0034 - val_acc: 0.9596\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0032 - acc: 0.9569 - val_loss: 0.0035 - val_acc: 0.9536\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0031 - acc: 0.9571 - val_loss: 0.0037 - val_acc: 0.9513\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0033 - acc: 0.9520 - val_loss: 0.0035 - val_acc: 0.9568\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0032 - acc: 0.9552 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0031 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9627\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0032 - acc: 0.9555 - val_loss: 0.0032 - val_acc: 0.9602\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0031 - acc: 0.9589 - val_loss: 0.0032 - val_acc: 0.9623\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0030 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0032 - acc: 0.9584 - val_loss: 0.0034 - val_acc: 0.9587\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9540 - val_loss: 0.0032 - val_acc: 0.9604\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9578 - val_loss: 0.0033 - val_acc: 0.9589\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9565 - val_loss: 0.0032 - val_acc: 0.9591\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.0032 - acc: 0.9557 - val_loss: 0.0033 - val_acc: 0.9583\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.0032 - acc: 0.9556 - val_loss: 0.0033 - val_acc: 0.9602\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.0032 - acc: 0.9554 - val_loss: 0.0037 - val_acc: 0.9514\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0034 - acc: 0.9519 - val_loss: 0.0032 - val_acc: 0.9629\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.0032 - acc: 0.9555 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0031 - acc: 0.9586 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "start training round 19\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2334 - acc: 0.6870 - val_loss: 0.2474 - val_acc: 0.6839\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2319 - acc: 0.6867 - val_loss: 0.2435 - val_acc: 0.6859\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2336 - acc: 0.6875 - val_loss: 0.2431 - val_acc: 0.6860\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2303 - acc: 0.6878 - val_loss: 0.2486 - val_acc: 0.6854\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2342 - acc: 0.6876 - val_loss: 0.2528 - val_acc: 0.6854\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2321 - acc: 0.6869 - val_loss: 0.2502 - val_acc: 0.6835\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2324 - acc: 0.6865 - val_loss: 0.2472 - val_acc: 0.6856\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2367 - acc: 0.6852 - val_loss: 0.2442 - val_acc: 0.6859\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2331 - acc: 0.6862 - val_loss: 0.2466 - val_acc: 0.6842\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2360 - acc: 0.6857 - val_loss: 0.2463 - val_acc: 0.6845\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.2315 - acc: 0.6874 - val_loss: 0.2458 - val_acc: 0.6833\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2303 - acc: 0.6878 - val_loss: 0.2461 - val_acc: 0.6845\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2325 - acc: 0.6871 - val_loss: 0.2471 - val_acc: 0.6830\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2344 - acc: 0.6875 - val_loss: 0.2515 - val_acc: 0.6851\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2328 - acc: 0.6875 - val_loss: 0.2460 - val_acc: 0.6848\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2314 - acc: 0.6872 - val_loss: 0.2466 - val_acc: 0.6839\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2349 - acc: 0.6861 - val_loss: 0.2468 - val_acc: 0.6835\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2310 - acc: 0.6880 - val_loss: 0.2481 - val_acc: 0.6844\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2326 - acc: 0.6872 - val_loss: 0.2442 - val_acc: 0.6833\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2325 - acc: 0.6869 - val_loss: 0.2493 - val_acc: 0.6846\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2366 - acc: 0.6866 - val_loss: 0.2520 - val_acc: 0.6817\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2335 - acc: 0.6867 - val_loss: 0.2500 - val_acc: 0.6843\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2366 - acc: 0.6851 - val_loss: 0.2450 - val_acc: 0.6846\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.2318 - acc: 0.6871 - val_loss: 0.2442 - val_acc: 0.6847\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2339 - acc: 0.6867 - val_loss: 0.2531 - val_acc: 0.6804\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2368 - acc: 0.6847 - val_loss: 0.2459 - val_acc: 0.6842\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2309 - acc: 0.6876 - val_loss: 0.2441 - val_acc: 0.6864\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2342 - acc: 0.6861 - val_loss: 0.2449 - val_acc: 0.6854\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2326 - acc: 0.6869 - val_loss: 0.2488 - val_acc: 0.6859\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2353 - acc: 0.6861 - val_loss: 0.2513 - val_acc: 0.6843\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2354 - acc: 0.6863 - val_loss: 0.2476 - val_acc: 0.6839\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2354 - acc: 0.6863 - val_loss: 0.2482 - val_acc: 0.6844\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2318 - acc: 0.6879 - val_loss: 0.2526 - val_acc: 0.6844\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2359 - acc: 0.6857 - val_loss: 0.2451 - val_acc: 0.6842\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2304 - acc: 0.6881 - val_loss: 0.2540 - val_acc: 0.6806\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2354 - acc: 0.6864 - val_loss: 0.2488 - val_acc: 0.6849\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2323 - acc: 0.6876 - val_loss: 0.2497 - val_acc: 0.6826\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 0.2310 - acc: 0.6871 - val_loss: 0.2483 - val_acc: 0.6820\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2335 - acc: 0.6867 - val_loss: 0.2432 - val_acc: 0.6848\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2299 - acc: 0.6883 - val_loss: 0.2415 - val_acc: 0.6865\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2340 - acc: 0.6875 - val_loss: 0.2472 - val_acc: 0.6854\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2341 - acc: 0.6870 - val_loss: 0.2442 - val_acc: 0.6864\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2302 - acc: 0.6880 - val_loss: 0.2450 - val_acc: 0.6852\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2325 - acc: 0.6874 - val_loss: 0.2644 - val_acc: 0.6813\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.2361 - acc: 0.6869 - val_loss: 0.2485 - val_acc: 0.6854\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2324 - acc: 0.6871 - val_loss: 0.2526 - val_acc: 0.6804\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2346 - acc: 0.6862 - val_loss: 0.2481 - val_acc: 0.6825\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2330 - acc: 0.6874 - val_loss: 0.2544 - val_acc: 0.6828\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.2346 - acc: 0.6866 - val_loss: 0.2433 - val_acc: 0.6857\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2293 - acc: 0.6880 - val_loss: 0.2427 - val_acc: 0.6862\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 1.9424 - acc: 0.6807 - val_loss: 2.1203 - val_acc: 0.6764\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9784 - acc: 0.6797 - val_loss: 2.0716 - val_acc: 0.6781\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 1.9854 - acc: 0.6801 - val_loss: 2.1129 - val_acc: 0.6799\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 1.9638 - acc: 0.6802 - val_loss: 2.1199 - val_acc: 0.6798\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 1.9706 - acc: 0.6799 - val_loss: 2.1751 - val_acc: 0.6777\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9928 - acc: 0.6798 - val_loss: 2.1575 - val_acc: 0.6795\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9696 - acc: 0.6791 - val_loss: 2.0797 - val_acc: 0.6785\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9884 - acc: 0.6787 - val_loss: 2.0758 - val_acc: 0.6792\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9693 - acc: 0.6803 - val_loss: 2.0725 - val_acc: 0.6797\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9535 - acc: 0.6795 - val_loss: 2.0735 - val_acc: 0.6784\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9351 - acc: 0.6800 - val_loss: 2.1269 - val_acc: 0.6778\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9817 - acc: 0.6790 - val_loss: 2.0978 - val_acc: 0.6801\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 375us/step - loss: 1.9589 - acc: 0.6804 - val_loss: 2.1112 - val_acc: 0.6801\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9799 - acc: 0.6795 - val_loss: 2.1159 - val_acc: 0.6780\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 2.0026 - acc: 0.6788 - val_loss: 2.1606 - val_acc: 0.6722\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9711 - acc: 0.6798 - val_loss: 2.0870 - val_acc: 0.6768\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9417 - acc: 0.6800 - val_loss: 2.1453 - val_acc: 0.6748\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9586 - acc: 0.6796 - val_loss: 2.0758 - val_acc: 0.6799\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9451 - acc: 0.6792 - val_loss: 2.1450 - val_acc: 0.6747\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9838 - acc: 0.6800 - val_loss: 2.0751 - val_acc: 0.6787\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9558 - acc: 0.6801 - val_loss: 2.1302 - val_acc: 0.6795\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9801 - acc: 0.6791 - val_loss: 2.0988 - val_acc: 0.6777\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9651 - acc: 0.6805 - val_loss: 2.1638 - val_acc: 0.6745\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 1.9483 - acc: 0.6795 - val_loss: 2.0795 - val_acc: 0.6774\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9627 - acc: 0.6797 - val_loss: 2.0698 - val_acc: 0.6797\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 1.9541 - acc: 0.6799 - val_loss: 2.1068 - val_acc: 0.6767\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9530 - acc: 0.6799 - val_loss: 2.0932 - val_acc: 0.6766\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9887 - acc: 0.6792 - val_loss: 2.1412 - val_acc: 0.6746\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 1.9842 - acc: 0.6797 - val_loss: 2.1407 - val_acc: 0.6746\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 1.9600 - acc: 0.6799 - val_loss: 2.1614 - val_acc: 0.6746\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 1.9897 - acc: 0.6791 - val_loss: 2.1206 - val_acc: 0.6753\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9619 - acc: 0.6797 - val_loss: 2.0895 - val_acc: 0.6787\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 1.9506 - acc: 0.6792 - val_loss: 2.0700 - val_acc: 0.6795\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9585 - acc: 0.6802 - val_loss: 2.1515 - val_acc: 0.6780\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 1.9631 - acc: 0.6800 - val_loss: 2.0658 - val_acc: 0.6781\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 1.9732 - acc: 0.6795 - val_loss: 2.1042 - val_acc: 0.6800\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9610 - acc: 0.6795 - val_loss: 2.0820 - val_acc: 0.6754\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9646 - acc: 0.6794 - val_loss: 2.1244 - val_acc: 0.6750\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9682 - acc: 0.6797 - val_loss: 2.0871 - val_acc: 0.6766\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 1.9558 - acc: 0.6795 - val_loss: 2.1318 - val_acc: 0.6738\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9857 - acc: 0.6798 - val_loss: 2.1144 - val_acc: 0.6747\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9567 - acc: 0.6787 - val_loss: 2.1548 - val_acc: 0.6759\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9685 - acc: 0.6793 - val_loss: 2.1671 - val_acc: 0.6779\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9781 - acc: 0.6801 - val_loss: 2.1349 - val_acc: 0.6756\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 374us/step - loss: 1.9997 - acc: 0.6793 - val_loss: 2.1076 - val_acc: 0.6749\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9736 - acc: 0.6787 - val_loss: 2.0625 - val_acc: 0.6792\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 1.9437 - acc: 0.6798 - val_loss: 2.0718 - val_acc: 0.6785\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9508 - acc: 0.6798 - val_loss: 2.0737 - val_acc: 0.6776\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9560 - acc: 0.6790 - val_loss: 2.1003 - val_acc: 0.6767\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9596 - acc: 0.6799 - val_loss: 2.1732 - val_acc: 0.6753\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.1764 - acc: 0.9923 - val_loss: 0.1841 - val_acc: 0.9902\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.1801 - acc: 0.9923 - val_loss: 0.1906 - val_acc: 0.9901\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.1843 - acc: 0.9923 - val_loss: 0.1947 - val_acc: 0.9903\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.1885 - acc: 0.9924 - val_loss: 0.1884 - val_acc: 0.9903\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2018 - acc: 0.9923 - val_loss: 0.1985 - val_acc: 0.9899\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.1965 - acc: 0.9922 - val_loss: 0.1900 - val_acc: 0.9899\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.1926 - acc: 0.9915 - val_loss: 0.2004 - val_acc: 0.9885\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1949 - acc: 0.9906 - val_loss: 0.1935 - val_acc: 0.9887\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1932 - acc: 0.9910 - val_loss: 0.1915 - val_acc: 0.9895\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1871 - acc: 0.9921 - val_loss: 0.1893 - val_acc: 0.9901\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 367us/step - loss: 0.1909 - acc: 0.9923 - val_loss: 0.1982 - val_acc: 0.9903\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1945 - acc: 0.9922 - val_loss: 0.1986 - val_acc: 0.9896\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1963 - acc: 0.9914 - val_loss: 0.1802 - val_acc: 0.9899\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.1850 - acc: 0.9920 - val_loss: 0.1935 - val_acc: 0.9903\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1896 - acc: 0.9924 - val_loss: 0.1917 - val_acc: 0.9901\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.1852 - acc: 0.9923 - val_loss: 0.1909 - val_acc: 0.9900\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1872 - acc: 0.9922 - val_loss: 0.1869 - val_acc: 0.9897\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1866 - acc: 0.9917 - val_loss: 0.1939 - val_acc: 0.9895\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.1981 - acc: 0.9912 - val_loss: 0.2069 - val_acc: 0.9889\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.1903 - acc: 0.9914 - val_loss: 0.1922 - val_acc: 0.9892\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1857 - acc: 0.9920 - val_loss: 0.1854 - val_acc: 0.9902\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1898 - acc: 0.9923 - val_loss: 0.2027 - val_acc: 0.9901\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1940 - acc: 0.9924 - val_loss: 0.1903 - val_acc: 0.9903\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 376us/step - loss: 0.1994 - acc: 0.9919 - val_loss: 0.1978 - val_acc: 0.9897\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1841 - acc: 0.9920 - val_loss: 0.1855 - val_acc: 0.9900\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1823 - acc: 0.9921 - val_loss: 0.1835 - val_acc: 0.9903\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1901 - acc: 0.9923 - val_loss: 0.1944 - val_acc: 0.9899\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.1832 - acc: 0.9922 - val_loss: 0.1802 - val_acc: 0.9900\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1826 - acc: 0.9920 - val_loss: 0.1918 - val_acc: 0.9899\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1904 - acc: 0.9916 - val_loss: 0.1978 - val_acc: 0.9894\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.1867 - acc: 0.9919 - val_loss: 0.1874 - val_acc: 0.9901\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1917 - acc: 0.9923 - val_loss: 0.2092 - val_acc: 0.9899\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.1925 - acc: 0.9921 - val_loss: 0.1913 - val_acc: 0.9900\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1902 - acc: 0.9921 - val_loss: 0.1826 - val_acc: 0.9900\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.1797 - acc: 0.9920 - val_loss: 0.1865 - val_acc: 0.9898\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.1836 - acc: 0.9919 - val_loss: 0.1901 - val_acc: 0.9900\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1831 - acc: 0.9918 - val_loss: 0.1856 - val_acc: 0.9894\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1865 - acc: 0.9912 - val_loss: 0.1990 - val_acc: 0.9888\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2013 - acc: 0.9910 - val_loss: 0.1964 - val_acc: 0.9899\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1977 - acc: 0.9923 - val_loss: 0.1988 - val_acc: 0.9902\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1901 - acc: 0.9921 - val_loss: 0.1885 - val_acc: 0.9898\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.1791 - acc: 0.9922 - val_loss: 0.1770 - val_acc: 0.9900\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.1741 - acc: 0.9923 - val_loss: 0.1810 - val_acc: 0.9901\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.1873 - acc: 0.9919 - val_loss: 0.1982 - val_acc: 0.9897\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1932 - acc: 0.9920 - val_loss: 0.1910 - val_acc: 0.9902\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1844 - acc: 0.9923 - val_loss: 0.1818 - val_acc: 0.9903\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1814 - acc: 0.9924 - val_loss: 0.1871 - val_acc: 0.9903\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1840 - acc: 0.9923 - val_loss: 0.1826 - val_acc: 0.9903\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.1818 - acc: 0.9922 - val_loss: 0.1824 - val_acc: 0.9901\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1847 - acc: 0.9922 - val_loss: 0.1973 - val_acc: 0.9897\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.0031 - acc: 0.9589 - val_loss: 0.0033 - val_acc: 0.9596\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.0032 - acc: 0.9529 - val_loss: 0.0032 - val_acc: 0.9613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0032 - acc: 0.9555 - val_loss: 0.0032 - val_acc: 0.9602\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0033 - acc: 0.9552 - val_loss: 0.0033 - val_acc: 0.9599\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9587 - val_loss: 0.0032 - val_acc: 0.9619\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.0031 - acc: 0.9589 - val_loss: 0.0032 - val_acc: 0.9610\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.0032 - acc: 0.9580 - val_loss: 0.0035 - val_acc: 0.9562\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0033 - acc: 0.9537 - val_loss: 0.0032 - val_acc: 0.9611\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.0032 - acc: 0.9554 - val_loss: 0.0032 - val_acc: 0.9607\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0031 - acc: 0.9585 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0031 - acc: 0.9568 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0031 - acc: 0.9582 - val_loss: 0.0033 - val_acc: 0.9584\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0031 - acc: 0.9580 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0031 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0031 - acc: 0.9594 - val_loss: 0.0033 - val_acc: 0.9630\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0032 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9631\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0031 - acc: 0.9592 - val_loss: 0.0033 - val_acc: 0.9620\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0032 - acc: 0.9561 - val_loss: 0.0034 - val_acc: 0.9573\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0031 - acc: 0.9575 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.0031 - acc: 0.9584 - val_loss: 0.0032 - val_acc: 0.9612\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.0031 - acc: 0.9581 - val_loss: 0.0033 - val_acc: 0.9593\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0031 - acc: 0.9572 - val_loss: 0.0034 - val_acc: 0.9569\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0032 - acc: 0.9541 - val_loss: 0.0032 - val_acc: 0.9609\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0032 - val_acc: 0.9615\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0030 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9612\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.0032 - acc: 0.9569 - val_loss: 0.0033 - val_acc: 0.9596\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.0034 - acc: 0.9527 - val_loss: 0.0033 - val_acc: 0.9593\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9616\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9631\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0031 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9618\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.0031 - acc: 0.9593 - val_loss: 0.0033 - val_acc: 0.9595\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9567 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0031 - acc: 0.9580 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0031 - acc: 0.9594 - val_loss: 0.0034 - val_acc: 0.9594\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.0032 - acc: 0.9550 - val_loss: 0.0036 - val_acc: 0.9528\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0033 - acc: 0.9504 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9625\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0031 - acc: 0.9572 - val_loss: 0.0034 - val_acc: 0.9554\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0032 - acc: 0.9548 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0031 - acc: 0.9592 - val_loss: 0.0032 - val_acc: 0.9633\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0031 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9613\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.0031 - acc: 0.9585 - val_loss: 0.0032 - val_acc: 0.9623\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.0033 - acc: 0.9524 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0031 - acc: 0.9594 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.0031 - acc: 0.9598 - val_loss: 0.0035 - val_acc: 0.9599\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9547 - val_loss: 0.0032 - val_acc: 0.9629\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.0032 - acc: 0.9565 - val_loss: 0.0032 - val_acc: 0.9629\n",
      "start training round 20\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2311 - acc: 0.6876 - val_loss: 0.2533 - val_acc: 0.6835\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 368us/step - loss: 0.2342 - acc: 0.6860 - val_loss: 0.2459 - val_acc: 0.6854\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2328 - acc: 0.6875 - val_loss: 0.2434 - val_acc: 0.6862\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2361 - acc: 0.6867 - val_loss: 0.2470 - val_acc: 0.6845\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2319 - acc: 0.6878 - val_loss: 0.2445 - val_acc: 0.6851\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2319 - acc: 0.6868 - val_loss: 0.2427 - val_acc: 0.6866\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.2302 - acc: 0.6884 - val_loss: 0.2460 - val_acc: 0.6834\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2339 - acc: 0.6862 - val_loss: 0.2535 - val_acc: 0.6828\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2352 - acc: 0.6857 - val_loss: 0.2434 - val_acc: 0.6862\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2304 - acc: 0.6885 - val_loss: 0.2472 - val_acc: 0.6851\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.2333 - acc: 0.6861 - val_loss: 0.2453 - val_acc: 0.6838\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2341 - acc: 0.6871 - val_loss: 0.2434 - val_acc: 0.6856\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2321 - acc: 0.6875 - val_loss: 0.2455 - val_acc: 0.6847\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2328 - acc: 0.6875 - val_loss: 0.2421 - val_acc: 0.6868\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2295 - acc: 0.6882 - val_loss: 0.2453 - val_acc: 0.6867\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 0.2317 - acc: 0.6869 - val_loss: 0.2432 - val_acc: 0.6854\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2304 - acc: 0.6881 - val_loss: 0.2520 - val_acc: 0.6817\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2350 - acc: 0.6859 - val_loss: 0.2433 - val_acc: 0.6857\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2288 - acc: 0.6886 - val_loss: 0.2418 - val_acc: 0.6860\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.2314 - acc: 0.6862 - val_loss: 0.2450 - val_acc: 0.6838\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2332 - acc: 0.6868 - val_loss: 0.2547 - val_acc: 0.6819\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2347 - acc: 0.6865 - val_loss: 0.2441 - val_acc: 0.6857\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2309 - acc: 0.6877 - val_loss: 0.2416 - val_acc: 0.6864\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2314 - acc: 0.6875 - val_loss: 0.2457 - val_acc: 0.6856\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2320 - acc: 0.6869 - val_loss: 0.2466 - val_acc: 0.6870\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 377us/step - loss: 0.2372 - acc: 0.6870 - val_loss: 0.2463 - val_acc: 0.6853\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2313 - acc: 0.6877 - val_loss: 0.2470 - val_acc: 0.6840\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2303 - acc: 0.6875 - val_loss: 0.2434 - val_acc: 0.6861\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2330 - acc: 0.6870 - val_loss: 0.2508 - val_acc: 0.6835\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2339 - acc: 0.6876 - val_loss: 0.2580 - val_acc: 0.6829\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.2334 - acc: 0.6877 - val_loss: 0.2490 - val_acc: 0.6843\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.2360 - acc: 0.6872 - val_loss: 0.2451 - val_acc: 0.6848\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2330 - acc: 0.6873 - val_loss: 0.2525 - val_acc: 0.6850\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.2305 - acc: 0.6883 - val_loss: 0.2457 - val_acc: 0.6852\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2324 - acc: 0.6871 - val_loss: 0.2483 - val_acc: 0.6843\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2327 - acc: 0.6865 - val_loss: 0.2477 - val_acc: 0.6844\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2296 - acc: 0.6879 - val_loss: 0.2427 - val_acc: 0.6865\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2301 - acc: 0.6886 - val_loss: 0.2435 - val_acc: 0.6856\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2312 - acc: 0.6874 - val_loss: 0.2420 - val_acc: 0.6857\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2301 - acc: 0.6886 - val_loss: 0.2442 - val_acc: 0.6855\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2311 - acc: 0.6881 - val_loss: 0.2431 - val_acc: 0.6858\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2355 - acc: 0.6851 - val_loss: 0.2464 - val_acc: 0.6849\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.2322 - acc: 0.6871 - val_loss: 0.2415 - val_acc: 0.6870\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.2349 - acc: 0.6877 - val_loss: 0.2520 - val_acc: 0.6842\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2366 - acc: 0.6865 - val_loss: 0.2476 - val_acc: 0.6821\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2300 - acc: 0.6882 - val_loss: 0.2425 - val_acc: 0.6859\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2311 - acc: 0.6867 - val_loss: 0.2489 - val_acc: 0.6847\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2322 - acc: 0.6879 - val_loss: 0.2458 - val_acc: 0.6869\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.2306 - acc: 0.6884 - val_loss: 0.2431 - val_acc: 0.6859\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2293 - acc: 0.6884 - val_loss: 0.2446 - val_acc: 0.6863\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9849 - acc: 0.6795 - val_loss: 2.0775 - val_acc: 0.6770\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 1.9992 - acc: 0.6785 - val_loss: 2.0874 - val_acc: 0.6785\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9659 - acc: 0.6802 - val_loss: 2.0820 - val_acc: 0.6798\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9536 - acc: 0.6803 - val_loss: 2.1252 - val_acc: 0.6787\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9571 - acc: 0.6801 - val_loss: 2.1613 - val_acc: 0.6753\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9627 - acc: 0.6790 - val_loss: 2.0964 - val_acc: 0.6756\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9525 - acc: 0.6797 - val_loss: 2.0584 - val_acc: 0.6778\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9491 - acc: 0.6798 - val_loss: 2.1701 - val_acc: 0.6746\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 1.9776 - acc: 0.6799 - val_loss: 2.1138 - val_acc: 0.6773\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 1.9554 - acc: 0.6806 - val_loss: 2.1139 - val_acc: 0.6753\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9605 - acc: 0.6808 - val_loss: 2.0637 - val_acc: 0.6774 - acc: 0\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9540 - acc: 0.6799 - val_loss: 2.0847 - val_acc: 0.6774\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 1.9771 - acc: 0.6792 - val_loss: 2.0787 - val_acc: 0.6789\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 1.9920 - acc: 0.6796 - val_loss: 2.0656 - val_acc: 0.6779\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9366 - acc: 0.6799 - val_loss: 2.1134 - val_acc: 0.6808\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9527 - acc: 0.6800 - val_loss: 2.0823 - val_acc: 0.6788\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 1.9680 - acc: 0.6796 - val_loss: 2.1407 - val_acc: 0.6730\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9461 - acc: 0.6791 - val_loss: 2.1330 - val_acc: 0.6774\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 1.9946 - acc: 0.6791 - val_loss: 2.1296 - val_acc: 0.6775\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 370us/step - loss: 1.9963 - acc: 0.6799 - val_loss: 2.0993 - val_acc: 0.6757\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9558 - acc: 0.6797 - val_loss: 2.1500 - val_acc: 0.6763\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 1.9743 - acc: 0.6800 - val_loss: 2.1623 - val_acc: 0.6764\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9777 - acc: 0.6787 - val_loss: 2.0949 - val_acc: 0.6768\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 1.9672 - acc: 0.6790 - val_loss: 2.0860 - val_acc: 0.6760\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9589 - acc: 0.6791 - val_loss: 2.0669 - val_acc: 0.6769\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9608 - acc: 0.6783 - val_loss: 2.0814 - val_acc: 0.6780\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 1.9747 - acc: 0.6798 - val_loss: 2.0658 - val_acc: 0.6765\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 1.9543 - acc: 0.6796 - val_loss: 2.1534 - val_acc: 0.6751\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 380us/step - loss: 1.9786 - acc: 0.6809 - val_loss: 2.0743 - val_acc: 0.6776\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 1.9487 - acc: 0.6804 - val_loss: 2.1511 - val_acc: 0.6784\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 1.9761 - acc: 0.6802 - val_loss: 2.0753 - val_acc: 0.6776\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 1.9609 - acc: 0.6799 - val_loss: 2.1078 - val_acc: 0.6756\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9731 - acc: 0.6799 - val_loss: 2.0909 - val_acc: 0.6783\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9482 - acc: 0.6797 - val_loss: 2.1130 - val_acc: 0.6782\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9528 - acc: 0.6791 - val_loss: 2.1183 - val_acc: 0.6773\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9577 - acc: 0.6797 - val_loss: 2.0796 - val_acc: 0.6806\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 1.9579 - acc: 0.6799 - val_loss: 2.1569 - val_acc: 0.6809\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 1.9835 - acc: 0.6798 - val_loss: 2.0919 - val_acc: 0.6778\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9621 - acc: 0.6800 - val_loss: 2.0932 - val_acc: 0.6799\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9695 - acc: 0.6791 - val_loss: 2.0758 - val_acc: 0.6759\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9401 - acc: 0.6795 - val_loss: 2.1573 - val_acc: 0.6729\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9816 - acc: 0.6781 - val_loss: 2.0868 - val_acc: 0.6774\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9861 - acc: 0.6805 - val_loss: 2.1883 - val_acc: 0.6749\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 1.9517 - acc: 0.6806 - val_loss: 2.0920 - val_acc: 0.6757\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 1.9711 - acc: 0.6797 - val_loss: 2.1220 - val_acc: 0.6756\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 1.9504 - acc: 0.6807 - val_loss: 2.1627 - val_acc: 0.6737\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 1.9923 - acc: 0.6786 - val_loss: 2.1313 - val_acc: 0.6794\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 1.9857 - acc: 0.6805 - val_loss: 2.0788 - val_acc: 0.6797\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 1.9497 - acc: 0.6801 - val_loss: 2.1037 - val_acc: 0.6806\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 1.9522 - acc: 0.6801 - val_loss: 2.1130 - val_acc: 0.6762\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1958 - acc: 0.9923 - val_loss: 0.2039 - val_acc: 0.9904\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1908 - acc: 0.9923 - val_loss: 0.1890 - val_acc: 0.9900\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1903 - acc: 0.9914 - val_loss: 0.1856 - val_acc: 0.9894\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1842 - acc: 0.9914 - val_loss: 0.1868 - val_acc: 0.9898\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1838 - acc: 0.9915 - val_loss: 0.1771 - val_acc: 0.9901\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.1775 - acc: 0.9922 - val_loss: 0.1854 - val_acc: 0.9899\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.1941 - acc: 0.9920 - val_loss: 0.1969 - val_acc: 0.9901\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1880 - acc: 0.9924 - val_loss: 0.1859 - val_acc: 0.9902\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.1891 - acc: 0.9918 - val_loss: 0.1973 - val_acc: 0.9895\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1960 - acc: 0.9917 - val_loss: 0.2015 - val_acc: 0.9900\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 388us/step - loss: 0.1996 - acc: 0.9922 - val_loss: 0.1985 - val_acc: 0.9899\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1874 - acc: 0.9920 - val_loss: 0.1976 - val_acc: 0.9899\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.1864 - acc: 0.9921 - val_loss: 0.1815 - val_acc: 0.9899\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1816 - acc: 0.9920 - val_loss: 0.1974 - val_acc: 0.9897\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1866 - acc: 0.9920 - val_loss: 0.1916 - val_acc: 0.9899\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1851 - acc: 0.9923 - val_loss: 0.1892 - val_acc: 0.9903\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1902 - acc: 0.9924 - val_loss: 0.1923 - val_acc: 0.9904\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1916 - acc: 0.9922 - val_loss: 0.1899 - val_acc: 0.9897\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.1816 - acc: 0.9921 - val_loss: 0.1807 - val_acc: 0.9898\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1788 - acc: 0.9920 - val_loss: 0.1877 - val_acc: 0.9897\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1876 - acc: 0.9913 - val_loss: 0.1829 - val_acc: 0.9897\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 381us/step - loss: 0.1866 - acc: 0.9913 - val_loss: 0.1886 - val_acc: 0.9891\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1840 - acc: 0.9918 - val_loss: 0.1946 - val_acc: 0.9896\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.1967 - acc: 0.9919 - val_loss: 0.1993 - val_acc: 0.9900\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.1939 - acc: 0.9924 - val_loss: 0.1904 - val_acc: 0.9903\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.1827 - acc: 0.9922 - val_loss: 0.1827 - val_acc: 0.9900\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.1820 - acc: 0.9923 - val_loss: 0.1815 - val_acc: 0.9903\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1768 - acc: 0.9924 - val_loss: 0.1759 - val_acc: 0.9903\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.1735 - acc: 0.9924 - val_loss: 0.1760 - val_acc: 0.9903\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.1806 - acc: 0.9924 - val_loss: 0.1867 - val_acc: 0.9903\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1886 - acc: 0.9924 - val_loss: 0.1906 - val_acc: 0.9903\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 372us/step - loss: 0.1895 - acc: 0.9924 - val_loss: 0.1896 - val_acc: 0.9902\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.1825 - acc: 0.9923 - val_loss: 0.1827 - val_acc: 0.9899\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1810 - acc: 0.9918 - val_loss: 0.1849 - val_acc: 0.9895\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.1844 - acc: 0.9917 - val_loss: 0.1905 - val_acc: 0.9898\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 373us/step - loss: 0.1873 - acc: 0.9921 - val_loss: 0.1860 - val_acc: 0.9901\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 382us/step - loss: 0.1794 - acc: 0.9921 - val_loss: 0.1828 - val_acc: 0.9902\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.1777 - acc: 0.9923 - val_loss: 0.1827 - val_acc: 0.9903\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1802 - acc: 0.9923 - val_loss: 0.1809 - val_acc: 0.9902\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1883 - acc: 0.9922 - val_loss: 0.2047 - val_acc: 0.9900\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 384us/step - loss: 0.1954 - acc: 0.9922 - val_loss: 0.2152 - val_acc: 0.9899\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2011 - acc: 0.9920 - val_loss: 0.1950 - val_acc: 0.9900\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1814 - acc: 0.9923 - val_loss: 0.1816 - val_acc: 0.9903\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1808 - acc: 0.9924 - val_loss: 0.1838 - val_acc: 0.9901\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1808 - acc: 0.9924 - val_loss: 0.1823 - val_acc: 0.9901\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 379us/step - loss: 0.1792 - acc: 0.9920 - val_loss: 0.1819 - val_acc: 0.9899\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.1874 - acc: 0.9913 - val_loss: 0.1910 - val_acc: 0.9896\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.1939 - acc: 0.9909 - val_loss: 0.1950 - val_acc: 0.9895\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.1859 - acc: 0.9918 - val_loss: 0.1841 - val_acc: 0.9897\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.1782 - acc: 0.9921 - val_loss: 0.1847 - val_acc: 0.9900\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0031 - acc: 0.9582 - val_loss: 0.0033 - val_acc: 0.9593\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0031 - acc: 0.9569 - val_loss: 0.0033 - val_acc: 0.9570\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.0032 - acc: 0.9550 - val_loss: 0.0033 - val_acc: 0.9573\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0031 - acc: 0.9586 - val_loss: 0.0035 - val_acc: 0.9554\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.0032 - acc: 0.9542 - val_loss: 0.0035 - val_acc: 0.9559\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0032 - acc: 0.9545 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0031 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.0031 - acc: 0.9592 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0032 - acc: 0.9573 - val_loss: 0.0032 - val_acc: 0.9616\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.0031 - acc: 0.9586 - val_loss: 0.0034 - val_acc: 0.9570\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.0033 - acc: 0.9547 - val_loss: 0.0033 - val_acc: 0.9598\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0032 - acc: 0.9565 - val_loss: 0.0033 - val_acc: 0.9599\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0031 - acc: 0.9582 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.0031 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9616\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.0031 - acc: 0.9575 - val_loss: 0.0035 - val_acc: 0.9533\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0034 - acc: 0.9503 - val_loss: 0.0031 - val_acc: 0.9627\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0032 - val_acc: 0.9607\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.0031 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9596\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.0032 - acc: 0.9564 - val_loss: 0.0032 - val_acc: 0.9616\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.0031 - acc: 0.9573 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0031 - acc: 0.9581 - val_loss: 0.0032 - val_acc: 0.9629\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0031 - acc: 0.9572 - val_loss: 0.0033 - val_acc: 0.9616\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0031 - acc: 0.9564 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.0030 - acc: 0.9597 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0033 - val_acc: 0.9606\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.0031 - acc: 0.9579 - val_loss: 0.0032 - val_acc: 0.9629\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.0031 - acc: 0.9577 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0033 - val_acc: 0.9619\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9555 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9618\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.0031 - acc: 0.9578 - val_loss: 0.0032 - val_acc: 0.9631\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 386us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9632\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0031 - acc: 0.9584 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 0.0032 - acc: 0.9550 - val_loss: 0.0033 - val_acc: 0.9599\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.0031 - acc: 0.9566 - val_loss: 0.0033 - val_acc: 0.9602\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.0031 - acc: 0.9569 - val_loss: 0.0032 - val_acc: 0.9607\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9596\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0032 - acc: 0.9561 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.0031 - acc: 0.9572 - val_loss: 0.0037 - val_acc: 0.9491\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.0032 - acc: 0.9563 - val_loss: 0.0032 - val_acc: 0.9613\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0035 - val_acc: 0.9571\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 0.0032 - acc: 0.9530 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 0.0031 - acc: 0.9602 - val_loss: 0.0033 - val_acc: 0.9628\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9605\n",
      "start training round 21\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2319 - acc: 0.6872 - val_loss: 0.2431 - val_acc: 0.6866\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2346 - acc: 0.6868 - val_loss: 0.2601 - val_acc: 0.6843\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2325 - acc: 0.6880 - val_loss: 0.2494 - val_acc: 0.6839\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 0.2358 - acc: 0.6856 - val_loss: 0.2428 - val_acc: 0.6849\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 390us/step - loss: 0.2312 - acc: 0.6876 - val_loss: 0.2420 - val_acc: 0.6862\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2285 - acc: 0.6890 - val_loss: 0.2500 - val_acc: 0.6852\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2351 - acc: 0.6857 - val_loss: 0.2435 - val_acc: 0.6840\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2300 - acc: 0.6879 - val_loss: 0.2475 - val_acc: 0.6830\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2287 - acc: 0.6882 - val_loss: 0.2433 - val_acc: 0.6865\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2349 - acc: 0.6865 - val_loss: 0.2451 - val_acc: 0.6855\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2335 - acc: 0.6875 - val_loss: 0.2463 - val_acc: 0.6834\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2339 - acc: 0.6860 - val_loss: 0.2443 - val_acc: 0.6869\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.2304 - acc: 0.6886 - val_loss: 0.2419 - val_acc: 0.6860\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2306 - acc: 0.6884 - val_loss: 0.2469 - val_acc: 0.6847\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.2345 - acc: 0.6863 - val_loss: 0.2479 - val_acc: 0.6831\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.2343 - acc: 0.6874 - val_loss: 0.2418 - val_acc: 0.6869\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.2315 - acc: 0.6868 - val_loss: 0.2442 - val_acc: 0.6874\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.2292 - acc: 0.6885 - val_loss: 0.2438 - val_acc: 0.6852\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2291 - acc: 0.6886 - val_loss: 0.2460 - val_acc: 0.6847\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.2333 - acc: 0.6869 - val_loss: 0.2482 - val_acc: 0.6819\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.2333 - acc: 0.6862 - val_loss: 0.2479 - val_acc: 0.6851\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2311 - acc: 0.6885 - val_loss: 0.2420 - val_acc: 0.6863\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2290 - acc: 0.6886 - val_loss: 0.2452 - val_acc: 0.6841\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2341 - acc: 0.6867 - val_loss: 0.2434 - val_acc: 0.6843\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2298 - acc: 0.6878 - val_loss: 0.2452 - val_acc: 0.6855\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.2327 - acc: 0.6882 - val_loss: 0.2437 - val_acc: 0.6857\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 383us/step - loss: 0.2323 - acc: 0.6878 - val_loss: 0.2432 - val_acc: 0.6852\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 0.2345 - acc: 0.6866 - val_loss: 0.2449 - val_acc: 0.6861\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.2326 - acc: 0.6870 - val_loss: 0.2460 - val_acc: 0.6843\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.2303 - acc: 0.6881 - val_loss: 0.2440 - val_acc: 0.6841\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2315 - acc: 0.6872 - val_loss: 0.2429 - val_acc: 0.6862\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2298 - acc: 0.6883 - val_loss: 0.2488 - val_acc: 0.6864\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.2318 - acc: 0.6886 - val_loss: 0.2410 - val_acc: 0.6870\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.2297 - acc: 0.6880 - val_loss: 0.2448 - val_acc: 0.6871\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2312 - acc: 0.6880 - val_loss: 0.2481 - val_acc: 0.6860\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.2338 - acc: 0.6866 - val_loss: 0.2442 - val_acc: 0.6853\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.2292 - acc: 0.6884 - val_loss: 0.2497 - val_acc: 0.6817\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2344 - acc: 0.6860 - val_loss: 0.2455 - val_acc: 0.6853\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2332 - acc: 0.6869 - val_loss: 0.2418 - val_acc: 0.6862\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2316 - acc: 0.6886 - val_loss: 0.2432 - val_acc: 0.6854\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2289 - acc: 0.6880 - val_loss: 0.2447 - val_acc: 0.6842\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.2292 - acc: 0.6886 - val_loss: 0.2450 - val_acc: 0.6852\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2298 - acc: 0.6888 - val_loss: 0.2404 - val_acc: 0.6875\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2302 - acc: 0.6891 - val_loss: 0.2427 - val_acc: 0.6871\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.2310 - acc: 0.6890 - val_loss: 0.2459 - val_acc: 0.6836\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2304 - acc: 0.6877 - val_loss: 0.2470 - val_acc: 0.6848\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.2306 - acc: 0.6884 - val_loss: 0.2520 - val_acc: 0.6825\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2344 - acc: 0.6872 - val_loss: 0.2524 - val_acc: 0.6832\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.2308 - acc: 0.6875 - val_loss: 0.2433 - val_acc: 0.6843\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.2311 - acc: 0.6876 - val_loss: 0.2446 - val_acc: 0.6844\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 1.9673 - acc: 0.6799 - val_loss: 2.0623 - val_acc: 0.6773\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 1.9411 - acc: 0.6805 - val_loss: 2.0729 - val_acc: 0.6796\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 1.9461 - acc: 0.6806 - val_loss: 2.0818 - val_acc: 0.6789\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 1.9643 - acc: 0.6790 - val_loss: 2.1408 - val_acc: 0.6746\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 1.9707 - acc: 0.6795 - val_loss: 2.2728 - val_acc: 0.6763\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 1.9746 - acc: 0.6798 - val_loss: 2.1469 - val_acc: 0.6781\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 1.9500 - acc: 0.6802 - val_loss: 2.1275 - val_acc: 0.6780\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9752 - acc: 0.6804 - val_loss: 2.1562 - val_acc: 0.6769\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9605 - acc: 0.6802 - val_loss: 2.1512 - val_acc: 0.6726\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9605 - acc: 0.6801 - val_loss: 2.0946 - val_acc: 0.6782\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9588 - acc: 0.6790 - val_loss: 2.0778 - val_acc: 0.6765\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9723 - acc: 0.6795 - val_loss: 2.1137 - val_acc: 0.6753\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 1.9619 - acc: 0.6800 - val_loss: 2.0832 - val_acc: 0.6765\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9475 - acc: 0.6798 - val_loss: 2.0888 - val_acc: 0.6788\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9554 - acc: 0.6789 - val_loss: 2.1295 - val_acc: 0.6723\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9776 - acc: 0.6794 - val_loss: 2.0894 - val_acc: 0.6765\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 1.9655 - acc: 0.6790 - val_loss: 2.0803 - val_acc: 0.6793\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9667 - acc: 0.6804 - val_loss: 2.0754 - val_acc: 0.6789\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9556 - acc: 0.6802 - val_loss: 2.1050 - val_acc: 0.6784\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9504 - acc: 0.6797 - val_loss: 2.1109 - val_acc: 0.6793\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9694 - acc: 0.6802 - val_loss: 2.1323 - val_acc: 0.6800\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 1.9718 - acc: 0.6792 - val_loss: 2.0684 - val_acc: 0.6785\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 1.9642 - acc: 0.6795 - val_loss: 2.1001 - val_acc: 0.6768\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9523 - acc: 0.6804 - val_loss: 2.1301 - val_acc: 0.6787\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9757 - acc: 0.6803 - val_loss: 2.1574 - val_acc: 0.6766\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9726 - acc: 0.6808 - val_loss: 2.0631 - val_acc: 0.6775\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9383 - acc: 0.6804 - val_loss: 2.0836 - val_acc: 0.6759\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 1.9341 - acc: 0.6796 - val_loss: 2.1023 - val_acc: 0.6753\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 1.9498 - acc: 0.6795 - val_loss: 2.1316 - val_acc: 0.6779\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9854 - acc: 0.6798 - val_loss: 2.1491 - val_acc: 0.6802\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 1.9520 - acc: 0.6805 - val_loss: 2.0862 - val_acc: 0.6790\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 1.9584 - acc: 0.6797 - val_loss: 2.1046 - val_acc: 0.6767\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 1.9461 - acc: 0.6814 - val_loss: 2.1289 - val_acc: 0.6756\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9850 - acc: 0.6799 - val_loss: 2.0963 - val_acc: 0.6763\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 1.9374 - acc: 0.6813 - val_loss: 2.2069 - val_acc: 0.6779\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9777 - acc: 0.6804 - val_loss: 2.0635 - val_acc: 0.6801\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9465 - acc: 0.6802 - val_loss: 2.1311 - val_acc: 0.6782\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 1.9812 - acc: 0.6792 - val_loss: 2.0972 - val_acc: 0.6810\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9485 - acc: 0.6803 - val_loss: 2.0618 - val_acc: 0.6796\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 1.9602 - acc: 0.6808 - val_loss: 2.0779 - val_acc: 0.6788\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 1.9547 - acc: 0.6801 - val_loss: 2.1141 - val_acc: 0.6796\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9444 - acc: 0.6800 - val_loss: 2.0726 - val_acc: 0.6779\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9694 - acc: 0.6785 - val_loss: 2.0838 - val_acc: 0.6765\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 395us/step - loss: 1.9349 - acc: 0.6795 - val_loss: 2.0945 - val_acc: 0.6785\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9590 - acc: 0.6793 - val_loss: 2.2288 - val_acc: 0.6765\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9915 - acc: 0.6787 - val_loss: 2.0736 - val_acc: 0.6790\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 1.9525 - acc: 0.6798 - val_loss: 2.1715 - val_acc: 0.6796\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9755 - acc: 0.6798 - val_loss: 2.1554 - val_acc: 0.6775\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 1.9728 - acc: 0.6796 - val_loss: 2.0939 - val_acc: 0.6780\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9522 - acc: 0.6793 - val_loss: 2.0890 - val_acc: 0.6773\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.1951 - acc: 0.9917 - val_loss: 0.2047 - val_acc: 0.9897\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1856 - acc: 0.9924 - val_loss: 0.1887 - val_acc: 0.9903\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.1988 - acc: 0.9924 - val_loss: 0.2283 - val_acc: 0.9903\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2053 - acc: 0.9924 - val_loss: 0.1890 - val_acc: 0.9901\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1778 - acc: 0.9924 - val_loss: 0.1795 - val_acc: 0.9902\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.1730 - acc: 0.9923 - val_loss: 0.1764 - val_acc: 0.9901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.1725 - acc: 0.9923 - val_loss: 0.1750 - val_acc: 0.9901\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.1763 - acc: 0.9923 - val_loss: 0.1877 - val_acc: 0.9898\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.2034 - acc: 0.9912 - val_loss: 0.1997 - val_acc: 0.9890\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.1872 - acc: 0.9917 - val_loss: 0.1824 - val_acc: 0.9897\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 393us/step - loss: 0.1765 - acc: 0.9920 - val_loss: 0.1792 - val_acc: 0.9897\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.1775 - acc: 0.9919 - val_loss: 0.1859 - val_acc: 0.9897\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.1971 - acc: 0.9921 - val_loss: 0.2075 - val_acc: 0.9899\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.1907 - acc: 0.9924 - val_loss: 0.1822 - val_acc: 0.9901\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.1786 - acc: 0.9924 - val_loss: 0.1820 - val_acc: 0.9904\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1861 - acc: 0.9924 - val_loss: 0.2016 - val_acc: 0.9903\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.1935 - acc: 0.9923 - val_loss: 0.1886 - val_acc: 0.9901\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1789 - acc: 0.9923 - val_loss: 0.1775 - val_acc: 0.9901\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.1710 - acc: 0.9924 - val_loss: 0.1737 - val_acc: 0.9904\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.1713 - acc: 0.9924 - val_loss: 0.1754 - val_acc: 0.9901\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.1833 - acc: 0.9917 - val_loss: 0.1904 - val_acc: 0.9892\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.1915 - acc: 0.9909 - val_loss: 0.1988 - val_acc: 0.9885\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2003 - acc: 0.9909 - val_loss: 0.1926 - val_acc: 0.9898\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.1872 - acc: 0.9922 - val_loss: 0.1989 - val_acc: 0.9898\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1924 - acc: 0.9920 - val_loss: 0.2029 - val_acc: 0.9892\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.1998 - acc: 0.9918 - val_loss: 0.1988 - val_acc: 0.9901\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.1910 - acc: 0.9924 - val_loss: 0.1861 - val_acc: 0.9905\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.1815 - acc: 0.9924 - val_loss: 0.1816 - val_acc: 0.9900\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1785 - acc: 0.9924 - val_loss: 0.1755 - val_acc: 0.9901\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.1759 - acc: 0.9923 - val_loss: 0.1795 - val_acc: 0.9900\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.1831 - acc: 0.9921 - val_loss: 0.1949 - val_acc: 0.9893\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1956 - acc: 0.9914 - val_loss: 0.1953 - val_acc: 0.9898\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.1852 - acc: 0.9919 - val_loss: 0.1774 - val_acc: 0.9901\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1721 - acc: 0.9923 - val_loss: 0.1762 - val_acc: 0.9901\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.1739 - acc: 0.9924 - val_loss: 0.1847 - val_acc: 0.9904\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.1883 - acc: 0.9923 - val_loss: 0.2016 - val_acc: 0.9900\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.1943 - acc: 0.9921 - val_loss: 0.1829 - val_acc: 0.9902\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.1801 - acc: 0.9920 - val_loss: 0.1799 - val_acc: 0.9900\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.1822 - acc: 0.9915 - val_loss: 0.1931 - val_acc: 0.9892\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.1862 - acc: 0.9917 - val_loss: 0.1850 - val_acc: 0.9901\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1895 - acc: 0.9923 - val_loss: 0.1871 - val_acc: 0.9903\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.1809 - acc: 0.9923 - val_loss: 0.1831 - val_acc: 0.9903\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.1782 - acc: 0.9924 - val_loss: 0.1832 - val_acc: 0.9903\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1892 - acc: 0.9924 - val_loss: 0.2011 - val_acc: 0.9904\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2030 - acc: 0.9925 - val_loss: 0.1953 - val_acc: 0.9902\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.1795 - acc: 0.9923 - val_loss: 0.1780 - val_acc: 0.9902\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1787 - acc: 0.9923 - val_loss: 0.1869 - val_acc: 0.9900\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.1828 - acc: 0.9921 - val_loss: 0.1868 - val_acc: 0.9901\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.1778 - acc: 0.9924 - val_loss: 0.1823 - val_acc: 0.9905\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.1771 - acc: 0.9923 - val_loss: 0.1832 - val_acc: 0.9899\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.0031 - acc: 0.9579 - val_loss: 0.0033 - val_acc: 0.9633\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 465us/step - loss: 0.0032 - acc: 0.9568 - val_loss: 0.0033 - val_acc: 0.9627\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0031 - acc: 0.9597 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 474us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9605\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.0031 - acc: 0.9579 - val_loss: 0.0039 - val_acc: 0.9445\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0033 - acc: 0.9526 - val_loss: 0.0036 - val_acc: 0.9538\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0033 - acc: 0.9540 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0031 - val_acc: 0.9625\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.0030 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9626\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 473us/step - loss: 0.0031 - acc: 0.9583 - val_loss: 0.0033 - val_acc: 0.9577\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.0031 - acc: 0.9572 - val_loss: 0.0032 - val_acc: 0.9608\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0031 - acc: 0.9589 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.0031 - acc: 0.9574 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.0031 - acc: 0.9600 - val_loss: 0.0033 - val_acc: 0.9607\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.0031 - acc: 0.9594 - val_loss: 0.0032 - val_acc: 0.9611\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9616\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0031 - acc: 0.9555 - val_loss: 0.0032 - val_acc: 0.9591\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.0031 - acc: 0.9570 - val_loss: 0.0035 - val_acc: 0.9557\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.0032 - acc: 0.9554 - val_loss: 0.0032 - val_acc: 0.9612\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.0030 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9624\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0033 - val_acc: 0.9590\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0032 - acc: 0.9577 - val_loss: 0.0033 - val_acc: 0.9620\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.0031 - acc: 0.9569 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 469us/step - loss: 0.0032 - acc: 0.9529 - val_loss: 0.0031 - val_acc: 0.9626\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.0030 - acc: 0.9594 - val_loss: 0.0034 - val_acc: 0.9570\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.0031 - acc: 0.9568 - val_loss: 0.0032 - val_acc: 0.9592\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0033 - val_acc: 0.9600\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.0032 - acc: 0.9537 - val_loss: 0.0034 - val_acc: 0.9575\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.0031 - acc: 0.9570 - val_loss: 0.0032 - val_acc: 0.9610\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0031 - acc: 0.9577 - val_loss: 0.0032 - val_acc: 0.9611\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.0031 - acc: 0.9575 - val_loss: 0.0033 - val_acc: 0.9561\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0032 - acc: 0.9566 - val_loss: 0.0032 - val_acc: 0.9600\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.0032 - acc: 0.9559 - val_loss: 0.0034 - val_acc: 0.9555\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.0032 - acc: 0.9562 - val_loss: 0.0034 - val_acc: 0.9571\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.0031 - acc: 0.9573 - val_loss: 0.0032 - val_acc: 0.9610\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.0031 - acc: 0.9576 - val_loss: 0.0032 - val_acc: 0.9600\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.0031 - acc: 0.9582 - val_loss: 0.0032 - val_acc: 0.9602\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 0.0030 - acc: 0.9588 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0032 - val_acc: 0.9615\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0032 - acc: 0.9558 - val_loss: 0.0032 - val_acc: 0.9605\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 470us/step - loss: 0.0031 - acc: 0.9583 - val_loss: 0.0034 - val_acc: 0.9576\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.0032 - acc: 0.9574 - val_loss: 0.0033 - val_acc: 0.9591\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.0031 - acc: 0.9565 - val_loss: 0.0033 - val_acc: 0.9578\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0031 - acc: 0.9578 - val_loss: 0.0033 - val_acc: 0.9566\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.0031 - acc: 0.9550 - val_loss: 0.0031 - val_acc: 0.9627\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.0030 - acc: 0.9589 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "start training round 22\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.2286 - acc: 0.6888 - val_loss: 0.2422 - val_acc: 0.6852\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.2291 - acc: 0.6888 - val_loss: 0.2427 - val_acc: 0.6854\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2295 - acc: 0.6889 - val_loss: 0.2484 - val_acc: 0.6847\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2321 - acc: 0.6882 - val_loss: 0.2490 - val_acc: 0.6848\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.2366 - acc: 0.6868 - val_loss: 0.2481 - val_acc: 0.6845\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.2329 - acc: 0.6874 - val_loss: 0.2441 - val_acc: 0.6857\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 397us/step - loss: 0.2279 - acc: 0.6889 - val_loss: 0.2399 - val_acc: 0.6875\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.2296 - acc: 0.6886 - val_loss: 0.2447 - val_acc: 0.6874\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2326 - acc: 0.6873 - val_loss: 0.2430 - val_acc: 0.6857\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2304 - acc: 0.6881 - val_loss: 0.2470 - val_acc: 0.6863\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2316 - acc: 0.6882 - val_loss: 0.2432 - val_acc: 0.6847\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2310 - acc: 0.6874 - val_loss: 0.2425 - val_acc: 0.6860\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.2311 - acc: 0.6878 - val_loss: 0.2464 - val_acc: 0.6850\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2323 - acc: 0.6872 - val_loss: 0.2443 - val_acc: 0.6862\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.2324 - acc: 0.6876 - val_loss: 0.2471 - val_acc: 0.6836\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2288 - acc: 0.6886 - val_loss: 0.2411 - val_acc: 0.6869\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.2294 - acc: 0.6894 - val_loss: 0.2436 - val_acc: 0.6860\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2304 - acc: 0.6892 - val_loss: 0.2448 - val_acc: 0.6852\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2300 - acc: 0.6875 - val_loss: 0.2439 - val_acc: 0.6848\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2305 - acc: 0.6884 - val_loss: 0.2434 - val_acc: 0.6859\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.2301 - acc: 0.6885 - val_loss: 0.2412 - val_acc: 0.6871\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2303 - acc: 0.6883 - val_loss: 0.2477 - val_acc: 0.6850\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2306 - acc: 0.6882 - val_loss: 0.2438 - val_acc: 0.6863\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2308 - acc: 0.6887 - val_loss: 0.2453 - val_acc: 0.6840\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2306 - acc: 0.6881 - val_loss: 0.2487 - val_acc: 0.6847\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2336 - acc: 0.6872 - val_loss: 0.2485 - val_acc: 0.6830\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.2311 - acc: 0.6883 - val_loss: 0.2403 - val_acc: 0.6875\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.2280 - acc: 0.6891 - val_loss: 0.2427 - val_acc: 0.6863\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2302 - acc: 0.6883 - val_loss: 0.2437 - val_acc: 0.6871\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.2307 - acc: 0.6885 - val_loss: 0.2461 - val_acc: 0.6857\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.2300 - acc: 0.6885 - val_loss: 0.2512 - val_acc: 0.6828\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2360 - acc: 0.6867 - val_loss: 0.2433 - val_acc: 0.6865\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.2307 - acc: 0.6890 - val_loss: 0.2400 - val_acc: 0.6874\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.2315 - acc: 0.6882 - val_loss: 0.2455 - val_acc: 0.6857\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2333 - acc: 0.6864 - val_loss: 0.2418 - val_acc: 0.6865\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.2279 - acc: 0.6890 - val_loss: 0.2434 - val_acc: 0.6867\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2327 - acc: 0.6866 - val_loss: 0.2444 - val_acc: 0.6859\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2333 - acc: 0.6876 - val_loss: 0.2403 - val_acc: 0.6869\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.2306 - acc: 0.6868 - val_loss: 0.2394 - val_acc: 0.6873\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2296 - acc: 0.6896 - val_loss: 0.2413 - val_acc: 0.6855\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.2301 - acc: 0.6877 - val_loss: 0.2518 - val_acc: 0.6818\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2320 - acc: 0.6871 - val_loss: 0.2411 - val_acc: 0.6873\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2299 - acc: 0.6881 - val_loss: 0.2478 - val_acc: 0.6846\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2293 - acc: 0.6882 - val_loss: 0.2489 - val_acc: 0.6855\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2284 - acc: 0.6891 - val_loss: 0.2452 - val_acc: 0.6848\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2328 - acc: 0.6871 - val_loss: 0.2445 - val_acc: 0.6867\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2327 - acc: 0.6888 - val_loss: 0.2434 - val_acc: 0.6856\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2303 - acc: 0.6894 - val_loss: 0.2436 - val_acc: 0.6872\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.2307 - acc: 0.6885 - val_loss: 0.2423 - val_acc: 0.6871\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2316 - acc: 0.6875 - val_loss: 0.2421 - val_acc: 0.6873\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 1.9364 - acc: 0.6807 - val_loss: 2.0913 - val_acc: 0.6750\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9850 - acc: 0.6795 - val_loss: 2.1205 - val_acc: 0.6729\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9344 - acc: 0.6802 - val_loss: 2.1816 - val_acc: 0.6702\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 1.9512 - acc: 0.6788 - val_loss: 2.0722 - val_acc: 0.6776\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 1.9466 - acc: 0.6793 - val_loss: 2.1022 - val_acc: 0.6787\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 1.9739 - acc: 0.6793 - val_loss: 2.0829 - val_acc: 0.6796\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 1.9735 - acc: 0.6801 - val_loss: 2.1128 - val_acc: 0.6790\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 1.9854 - acc: 0.6808 - val_loss: 2.0845 - val_acc: 0.6777\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 1.9493 - acc: 0.6805 - val_loss: 2.1131 - val_acc: 0.6783\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9483 - acc: 0.6795 - val_loss: 2.1414 - val_acc: 0.6769\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 1.9721 - acc: 0.6795 - val_loss: 2.0969 - val_acc: 0.6767\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9719 - acc: 0.6799 - val_loss: 2.0805 - val_acc: 0.6771\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9458 - acc: 0.6807 - val_loss: 2.0920 - val_acc: 0.6772\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 1.9417 - acc: 0.6806 - val_loss: 2.1171 - val_acc: 0.6735\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 1.9654 - acc: 0.6798 - val_loss: 2.1249 - val_acc: 0.6758\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 1.9505 - acc: 0.6808 - val_loss: 2.0727 - val_acc: 0.6771\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9458 - acc: 0.6800 - val_loss: 2.0950 - val_acc: 0.6773\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 1.9694 - acc: 0.6805 - val_loss: 2.1551 - val_acc: 0.6755\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 1.9460 - acc: 0.6803 - val_loss: 2.1737 - val_acc: 0.6752\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 1.9929 - acc: 0.6795 - val_loss: 2.0856 - val_acc: 0.6787\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9502 - acc: 0.6798 - val_loss: 2.0858 - val_acc: 0.6780\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 1.9688 - acc: 0.6801 - val_loss: 2.1231 - val_acc: 0.6745\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 1.9646 - acc: 0.6798 - val_loss: 2.0758 - val_acc: 0.6782\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9538 - acc: 0.6810 - val_loss: 2.0947 - val_acc: 0.6778\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9375 - acc: 0.6804 - val_loss: 2.0926 - val_acc: 0.6793\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9586 - acc: 0.6804 - val_loss: 2.1572 - val_acc: 0.6795\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 1.9511 - acc: 0.6804 - val_loss: 2.0812 - val_acc: 0.6786\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9392 - acc: 0.6804 - val_loss: 2.0932 - val_acc: 0.6763\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 1.9319 - acc: 0.6798 - val_loss: 2.1145 - val_acc: 0.6750\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9812 - acc: 0.6783 - val_loss: 2.0986 - val_acc: 0.6760\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 1.9399 - acc: 0.6800 - val_loss: 2.0614 - val_acc: 0.6775\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 1.9555 - acc: 0.6798 - val_loss: 2.1494 - val_acc: 0.6776\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9577 - acc: 0.6801 - val_loss: 2.0911 - val_acc: 0.6799\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 450us/step - loss: 1.9584 - acc: 0.6802 - val_loss: 2.1261 - val_acc: 0.6779\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9702 - acc: 0.6799 - val_loss: 2.1104 - val_acc: 0.6792\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9768 - acc: 0.6802 - val_loss: 2.0987 - val_acc: 0.6806\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9407 - acc: 0.6808 - val_loss: 2.0859 - val_acc: 0.6793\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9760 - acc: 0.6804 - val_loss: 2.0787 - val_acc: 0.6800\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 1.9483 - acc: 0.6792 - val_loss: 2.0583 - val_acc: 0.6793\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 1.9352 - acc: 0.6809 - val_loss: 2.0625 - val_acc: 0.6795\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9324 - acc: 0.6803 - val_loss: 2.1108 - val_acc: 0.6777\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 1.9420 - acc: 0.6798 - val_loss: 2.0867 - val_acc: 0.6755\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 1.9699 - acc: 0.6800 - val_loss: 2.0947 - val_acc: 0.6777\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9517 - acc: 0.6801 - val_loss: 2.1139 - val_acc: 0.6771\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9723 - acc: 0.6793 - val_loss: 2.0661 - val_acc: 0.6798\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9493 - acc: 0.6795 - val_loss: 2.1106 - val_acc: 0.6815\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9669 - acc: 0.6803 - val_loss: 2.1096 - val_acc: 0.6797\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 1.9664 - acc: 0.6801 - val_loss: 2.0702 - val_acc: 0.6803\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 1.9682 - acc: 0.6806 - val_loss: 2.0656 - val_acc: 0.6776\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 1.9417 - acc: 0.6803 - val_loss: 2.0591 - val_acc: 0.6778\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1876 - acc: 0.9923 - val_loss: 0.1853 - val_acc: 0.9900\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.1823 - acc: 0.9917 - val_loss: 0.1818 - val_acc: 0.9897\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1814 - acc: 0.9914 - val_loss: 0.1843 - val_acc: 0.9895\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.1835 - acc: 0.9911 - val_loss: 0.1854 - val_acc: 0.9895\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.1846 - acc: 0.9913 - val_loss: 0.1820 - val_acc: 0.9897\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1824 - acc: 0.9920 - val_loss: 0.1864 - val_acc: 0.9902\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1943 - acc: 0.9924 - val_loss: 0.2193 - val_acc: 0.9901\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1974 - acc: 0.9923 - val_loss: 0.1879 - val_acc: 0.9899\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.1831 - acc: 0.9919 - val_loss: 0.1794 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.1784 - acc: 0.9918 - val_loss: 0.1795 - val_acc: 0.9897\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.1790 - acc: 0.9915 - val_loss: 0.1808 - val_acc: 0.9897\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1743 - acc: 0.9921 - val_loss: 0.1764 - val_acc: 0.9901\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1723 - acc: 0.9924 - val_loss: 0.1783 - val_acc: 0.9902\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1875 - acc: 0.9924 - val_loss: 0.2010 - val_acc: 0.9900\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.1902 - acc: 0.9923 - val_loss: 0.1908 - val_acc: 0.9904\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1880 - acc: 0.9924 - val_loss: 0.1859 - val_acc: 0.9905\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.1834 - acc: 0.9923 - val_loss: 0.1800 - val_acc: 0.9903\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1811 - acc: 0.9923 - val_loss: 0.1872 - val_acc: 0.9903\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.1806 - acc: 0.9924 - val_loss: 0.1929 - val_acc: 0.9904\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.1862 - acc: 0.9923 - val_loss: 0.1771 - val_acc: 0.9903\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1733 - acc: 0.9922 - val_loss: 0.1728 - val_acc: 0.9903\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1733 - acc: 0.9923 - val_loss: 0.1838 - val_acc: 0.9899\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.1988 - acc: 0.9915 - val_loss: 0.1966 - val_acc: 0.9901\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.1896 - acc: 0.9923 - val_loss: 0.1891 - val_acc: 0.9904\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.1911 - acc: 0.9924 - val_loss: 0.1824 - val_acc: 0.9903\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1757 - acc: 0.9925 - val_loss: 0.1748 - val_acc: 0.9903\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.1761 - acc: 0.9924 - val_loss: 0.1792 - val_acc: 0.9901\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1911 - acc: 0.9918 - val_loss: 0.1847 - val_acc: 0.9898\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.1800 - acc: 0.9919 - val_loss: 0.1807 - val_acc: 0.9897\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.1767 - acc: 0.9920 - val_loss: 0.1780 - val_acc: 0.9897\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1762 - acc: 0.9918 - val_loss: 0.1809 - val_acc: 0.9897\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.1815 - acc: 0.9917 - val_loss: 0.1761 - val_acc: 0.9900\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.1756 - acc: 0.9924 - val_loss: 0.1890 - val_acc: 0.9904\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2016 - acc: 0.9924 - val_loss: 0.2018 - val_acc: 0.9903\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1933 - acc: 0.9918 - val_loss: 0.1906 - val_acc: 0.9897\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1854 - acc: 0.9920 - val_loss: 0.1817 - val_acc: 0.9900\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1721 - acc: 0.9923 - val_loss: 0.1753 - val_acc: 0.9905\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.1783 - acc: 0.9925 - val_loss: 0.1828 - val_acc: 0.9905\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.1778 - acc: 0.9925 - val_loss: 0.1864 - val_acc: 0.9904\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.1870 - acc: 0.9924 - val_loss: 0.1867 - val_acc: 0.9904\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1785 - acc: 0.9923 - val_loss: 0.1795 - val_acc: 0.9898\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1784 - acc: 0.9920 - val_loss: 0.1829 - val_acc: 0.9898\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 403us/step - loss: 0.1853 - acc: 0.9915 - val_loss: 0.1922 - val_acc: 0.9897\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.1788 - acc: 0.9918 - val_loss: 0.1794 - val_acc: 0.9898\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1821 - acc: 0.9919 - val_loss: 0.1807 - val_acc: 0.9904\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.1859 - acc: 0.9924 - val_loss: 0.2038 - val_acc: 0.9897\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2082 - acc: 0.9912 - val_loss: 0.1835 - val_acc: 0.9900\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.1781 - acc: 0.9918 - val_loss: 0.1785 - val_acc: 0.9898\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.1767 - acc: 0.9920 - val_loss: 0.1774 - val_acc: 0.9904\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1727 - acc: 0.9924 - val_loss: 0.1758 - val_acc: 0.9902\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0030 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9626\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.0032 - acc: 0.9555 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.0031 - acc: 0.9581 - val_loss: 0.0033 - val_acc: 0.9587\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 472us/step - loss: 0.0032 - acc: 0.9565 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.0030 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9622\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9631\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.0032 - acc: 0.9557 - val_loss: 0.0033 - val_acc: 0.9612\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0031 - acc: 0.9566 - val_loss: 0.0032 - val_acc: 0.9636\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9623\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 0.0031 - acc: 0.9567 - val_loss: 0.0033 - val_acc: 0.9576\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.0030 - acc: 0.9594 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0032 - val_acc: 0.9619\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0031 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9620\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0031 - acc: 0.9593 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.0030 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 459us/step - loss: 0.0031 - acc: 0.9563 - val_loss: 0.0037 - val_acc: 0.9465\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.0032 - acc: 0.9533 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 469us/step - loss: 0.0030 - acc: 0.9606 - val_loss: 0.0032 - val_acc: 0.9633\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.0031 - acc: 0.9585 - val_loss: 0.0035 - val_acc: 0.9599\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0033 - val_acc: 0.9623\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.0031 - acc: 0.9582 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9632\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0032 - val_acc: 0.9625\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0031 - acc: 0.9585 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.0031 - acc: 0.9586 - val_loss: 0.0035 - val_acc: 0.9556\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0031 - acc: 0.9574 - val_loss: 0.0034 - val_acc: 0.9581\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0031 - acc: 0.9576 - val_loss: 0.0047 - val_acc: 0.9431\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.0033 - acc: 0.9507 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0032 - val_acc: 0.9618\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0030 - acc: 0.9597 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.0030 - acc: 0.9605 - val_loss: 0.0032 - val_acc: 0.9632\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9629\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.0031 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9634\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.0031 - acc: 0.9599 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.0031 - acc: 0.9582 - val_loss: 0.0032 - val_acc: 0.9593\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0031 - acc: 0.9567 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9618\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0030 - acc: 0.9589 - val_loss: 0.0031 - val_acc: 0.9627\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9606\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.0031 - acc: 0.9577 - val_loss: 0.0032 - val_acc: 0.9598\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9596\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.0031 - acc: 0.9564 - val_loss: 0.0033 - val_acc: 0.9588\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.0032 - acc: 0.9546 - val_loss: 0.0032 - val_acc: 0.9596\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.0030 - acc: 0.9593 - val_loss: 0.0031 - val_acc: 0.9621\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0031 - acc: 0.9556 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.0030 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9599\n",
      "start training round 23\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.2291 - acc: 0.6882 - val_loss: 0.2418 - val_acc: 0.6860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.2280 - acc: 0.6894 - val_loss: 0.2474 - val_acc: 0.6824\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.2317 - acc: 0.6874 - val_loss: 0.2512 - val_acc: 0.6850\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2329 - acc: 0.6884 - val_loss: 0.2408 - val_acc: 0.6867\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.2287 - acc: 0.6894 - val_loss: 0.2416 - val_acc: 0.6864\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2311 - acc: 0.6883 - val_loss: 0.2414 - val_acc: 0.6869\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2282 - acc: 0.6889 - val_loss: 0.2439 - val_acc: 0.6872\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.2301 - acc: 0.6888 - val_loss: 0.2404 - val_acc: 0.6868\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.2286 - acc: 0.6891 - val_loss: 0.2435 - val_acc: 0.6855\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2301 - acc: 0.6889 - val_loss: 0.2468 - val_acc: 0.6855\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.2327 - acc: 0.6872 - val_loss: 0.2431 - val_acc: 0.6849\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2311 - acc: 0.6881 - val_loss: 0.2425 - val_acc: 0.6879\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2264 - acc: 0.6898 - val_loss: 0.2432 - val_acc: 0.6853\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2310 - acc: 0.6866 - val_loss: 0.2400 - val_acc: 0.6868\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.2308 - acc: 0.6879 - val_loss: 0.2530 - val_acc: 0.6844\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.2332 - acc: 0.6883 - val_loss: 0.2514 - val_acc: 0.6874\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2320 - acc: 0.6893 - val_loss: 0.2426 - val_acc: 0.6861\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.2291 - acc: 0.6893 - val_loss: 0.2561 - val_acc: 0.6833\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2339 - acc: 0.6869 - val_loss: 0.2404 - val_acc: 0.6861\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.2276 - acc: 0.6895 - val_loss: 0.2458 - val_acc: 0.6850\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2290 - acc: 0.6890 - val_loss: 0.2455 - val_acc: 0.6868\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2315 - acc: 0.6891 - val_loss: 0.2457 - val_acc: 0.6850\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.2328 - acc: 0.6879 - val_loss: 0.2480 - val_acc: 0.6839\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.2318 - acc: 0.6868 - val_loss: 0.2453 - val_acc: 0.6843\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2309 - acc: 0.6873 - val_loss: 0.2394 - val_acc: 0.6873\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.2294 - acc: 0.6891 - val_loss: 0.2418 - val_acc: 0.6874\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.2296 - acc: 0.6885 - val_loss: 0.2438 - val_acc: 0.6862\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.2266 - acc: 0.6897 - val_loss: 0.2417 - val_acc: 0.6857\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2296 - acc: 0.6882 - val_loss: 0.2500 - val_acc: 0.6829\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2323 - acc: 0.6873 - val_loss: 0.2430 - val_acc: 0.6852\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2275 - acc: 0.6893 - val_loss: 0.2419 - val_acc: 0.6880\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 0.2292 - acc: 0.6895 - val_loss: 0.2403 - val_acc: 0.6863\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.2277 - acc: 0.6897 - val_loss: 0.2440 - val_acc: 0.6873\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.2327 - acc: 0.6875 - val_loss: 0.2414 - val_acc: 0.6880\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2306 - acc: 0.6897 - val_loss: 0.2402 - val_acc: 0.6869\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2274 - acc: 0.6896 - val_loss: 0.2420 - val_acc: 0.6858\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2284 - acc: 0.6887 - val_loss: 0.2452 - val_acc: 0.6852\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2308 - acc: 0.6883 - val_loss: 0.2407 - val_acc: 0.6879\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.2301 - acc: 0.6881 - val_loss: 0.2423 - val_acc: 0.6866\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2310 - acc: 0.6897 - val_loss: 0.2435 - val_acc: 0.6871\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2296 - acc: 0.6896 - val_loss: 0.2459 - val_acc: 0.6862\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2297 - acc: 0.6886 - val_loss: 0.2426 - val_acc: 0.6864\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2284 - acc: 0.6893 - val_loss: 0.2402 - val_acc: 0.6869\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2305 - acc: 0.6875 - val_loss: 0.2429 - val_acc: 0.6870\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.2333 - acc: 0.6872 - val_loss: 0.2399 - val_acc: 0.6875\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2263 - acc: 0.6894 - val_loss: 0.2451 - val_acc: 0.6851\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.2272 - acc: 0.6898 - val_loss: 0.2430 - val_acc: 0.6863\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2321 - acc: 0.6873 - val_loss: 0.2459 - val_acc: 0.6852\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.2306 - acc: 0.6882 - val_loss: 0.2417 - val_acc: 0.6871\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.2323 - acc: 0.6891 - val_loss: 0.2426 - val_acc: 0.6855\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9371 - acc: 0.6803 - val_loss: 2.0810 - val_acc: 0.6773\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 1.9787 - acc: 0.6800 - val_loss: 2.0562 - val_acc: 0.6790\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9187 - acc: 0.6808 - val_loss: 2.0706 - val_acc: 0.6796\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 1.9308 - acc: 0.6809 - val_loss: 2.0717 - val_acc: 0.6807\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9688 - acc: 0.6805 - val_loss: 2.1033 - val_acc: 0.6801\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 1.9617 - acc: 0.6807 - val_loss: 2.1201 - val_acc: 0.6785\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9562 - acc: 0.6797 - val_loss: 2.1596 - val_acc: 0.6761\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9748 - acc: 0.6801 - val_loss: 2.1008 - val_acc: 0.6769\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 1.9506 - acc: 0.6798 - val_loss: 2.1563 - val_acc: 0.6736\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 1.9641 - acc: 0.6803 - val_loss: 2.0721 - val_acc: 0.6791\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9621 - acc: 0.6798 - val_loss: 2.1166 - val_acc: 0.6794\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 1.9741 - acc: 0.6798 - val_loss: 2.0932 - val_acc: 0.6794\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 1.9759 - acc: 0.6799 - val_loss: 2.0819 - val_acc: 0.6794\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 1.9392 - acc: 0.6807 - val_loss: 2.0815 - val_acc: 0.6794\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 1.9380 - acc: 0.6815 - val_loss: 2.0793 - val_acc: 0.6786\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9542 - acc: 0.6796 - val_loss: 2.1345 - val_acc: 0.6761\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9786 - acc: 0.6799 - val_loss: 2.0610 - val_acc: 0.6780\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 1.9434 - acc: 0.6811 - val_loss: 2.0462 - val_acc: 0.6791\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9387 - acc: 0.6804 - val_loss: 2.0746 - val_acc: 0.6773\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9619 - acc: 0.6796 - val_loss: 2.0847 - val_acc: 0.6785\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 1.9379 - acc: 0.6806 - val_loss: 2.0946 - val_acc: 0.6813\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 1.9517 - acc: 0.6803 - val_loss: 2.0495 - val_acc: 0.6799\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9563 - acc: 0.6802 - val_loss: 2.0819 - val_acc: 0.6785\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9860 - acc: 0.6797 - val_loss: 2.1661 - val_acc: 0.6771\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9443 - acc: 0.6800 - val_loss: 2.1426 - val_acc: 0.6754\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9706 - acc: 0.6798 - val_loss: 2.0734 - val_acc: 0.6779\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9473 - acc: 0.6806 - val_loss: 2.0819 - val_acc: 0.6776\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 1.9545 - acc: 0.6801 - val_loss: 2.0839 - val_acc: 0.6783\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9707 - acc: 0.6804 - val_loss: 2.1107 - val_acc: 0.6798\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9483 - acc: 0.6806 - val_loss: 2.1116 - val_acc: 0.6769\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 1.9518 - acc: 0.6800 - val_loss: 2.1118 - val_acc: 0.6764\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9443 - acc: 0.6796 - val_loss: 2.1320 - val_acc: 0.6754\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9461 - acc: 0.6793 - val_loss: 2.1012 - val_acc: 0.6763\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9602 - acc: 0.6807 - val_loss: 2.0800 - val_acc: 0.6779\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9733 - acc: 0.6801 - val_loss: 2.0836 - val_acc: 0.6784\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 1.9403 - acc: 0.6808 - val_loss: 2.1124 - val_acc: 0.6777\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9658 - acc: 0.6786 - val_loss: 2.1175 - val_acc: 0.6775\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9464 - acc: 0.6806 - val_loss: 2.0805 - val_acc: 0.6781\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 1.9586 - acc: 0.6792 - val_loss: 2.0877 - val_acc: 0.6798\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 385us/step - loss: 1.9486 - acc: 0.6807 - val_loss: 2.0674 - val_acc: 0.6777\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9597 - acc: 0.6806 - val_loss: 2.0647 - val_acc: 0.6776\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9451 - acc: 0.6806 - val_loss: 2.1155 - val_acc: 0.6773\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 1.9634 - acc: 0.6807 - val_loss: 2.0937 - val_acc: 0.6774\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 1.9714 - acc: 0.6797 - val_loss: 2.1684 - val_acc: 0.6779\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 1.9702 - acc: 0.6791 - val_loss: 2.0640 - val_acc: 0.6790\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 1.9396 - acc: 0.6814 - val_loss: 2.1526 - val_acc: 0.6760\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 1.9385 - acc: 0.6806 - val_loss: 2.1154 - val_acc: 0.6746\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 1.9538 - acc: 0.6806 - val_loss: 2.1125 - val_acc: 0.6784\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 1.9554 - acc: 0.6810 - val_loss: 2.0486 - val_acc: 0.6781\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9314 - acc: 0.6802 - val_loss: 2.0910 - val_acc: 0.6761\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1809 - acc: 0.9921 - val_loss: 0.1842 - val_acc: 0.9904\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 0.1830 - acc: 0.9924 - val_loss: 0.1854 - val_acc: 0.9904\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1843 - acc: 0.9924 - val_loss: 0.1896 - val_acc: 0.9902\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.1970 - acc: 0.9923 - val_loss: 0.2062 - val_acc: 0.9883\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 0.1859 - acc: 0.9914 - val_loss: 0.1844 - val_acc: 0.9896\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1791 - acc: 0.9918 - val_loss: 0.1812 - val_acc: 0.9898\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.1781 - acc: 0.9917 - val_loss: 0.1919 - val_acc: 0.9898\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.1868 - acc: 0.9922 - val_loss: 0.1891 - val_acc: 0.9902\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.1833 - acc: 0.9924 - val_loss: 0.1824 - val_acc: 0.9902\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.1815 - acc: 0.9923 - val_loss: 0.1764 - val_acc: 0.9902\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.1734 - acc: 0.9922 - val_loss: 0.1739 - val_acc: 0.9902\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.1746 - acc: 0.9922 - val_loss: 0.1846 - val_acc: 0.9899\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1976 - acc: 0.9922 - val_loss: 0.1960 - val_acc: 0.9901\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1852 - acc: 0.9924 - val_loss: 0.1815 - val_acc: 0.9902\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1731 - acc: 0.9925 - val_loss: 0.1756 - val_acc: 0.9902\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1726 - acc: 0.9925 - val_loss: 0.1780 - val_acc: 0.9905\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.1785 - acc: 0.9924 - val_loss: 0.1932 - val_acc: 0.9903\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.1970 - acc: 0.9925 - val_loss: 0.1924 - val_acc: 0.9903\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1794 - acc: 0.9925 - val_loss: 0.1808 - val_acc: 0.9903\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.1783 - acc: 0.9924 - val_loss: 0.1813 - val_acc: 0.9901\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1807 - acc: 0.9924 - val_loss: 0.1837 - val_acc: 0.9901\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.1788 - acc: 0.9924 - val_loss: 0.1772 - val_acc: 0.9900\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1821 - acc: 0.9919 - val_loss: 0.1884 - val_acc: 0.9897\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.1873 - acc: 0.9918 - val_loss: 0.1908 - val_acc: 0.9897\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.1881 - acc: 0.9916 - val_loss: 0.1975 - val_acc: 0.9883\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1976 - acc: 0.9907 - val_loss: 0.1906 - val_acc: 0.9898\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.1810 - acc: 0.9923 - val_loss: 0.1797 - val_acc: 0.9905\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.1755 - acc: 0.9925 - val_loss: 0.1760 - val_acc: 0.9905\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1750 - acc: 0.9925 - val_loss: 0.1733 - val_acc: 0.9905\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.1687 - acc: 0.9925 - val_loss: 0.1707 - val_acc: 0.9904\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.1789 - acc: 0.9925 - val_loss: 0.1892 - val_acc: 0.9904\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.1833 - acc: 0.9925 - val_loss: 0.1914 - val_acc: 0.9903\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1842 - acc: 0.9925 - val_loss: 0.2028 - val_acc: 0.9903\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1907 - acc: 0.9924 - val_loss: 0.1768 - val_acc: 0.9904\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.1823 - acc: 0.9923 - val_loss: 0.1855 - val_acc: 0.9903\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.1836 - acc: 0.9917 - val_loss: 0.1844 - val_acc: 0.9895\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.1860 - acc: 0.9911 - val_loss: 0.1862 - val_acc: 0.9895\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1762 - acc: 0.9918 - val_loss: 0.1739 - val_acc: 0.9902\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1735 - acc: 0.9921 - val_loss: 0.1732 - val_acc: 0.9904\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.1696 - acc: 0.9925 - val_loss: 0.1712 - val_acc: 0.9904\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.1693 - acc: 0.9924 - val_loss: 0.1761 - val_acc: 0.9896\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.1854 - acc: 0.9915 - val_loss: 0.1912 - val_acc: 0.9900\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.1955 - acc: 0.9923 - val_loss: 0.1894 - val_acc: 0.9904\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.1888 - acc: 0.9922 - val_loss: 0.1817 - val_acc: 0.9902\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.1810 - acc: 0.9922 - val_loss: 0.1993 - val_acc: 0.9904\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1856 - acc: 0.9922 - val_loss: 0.1832 - val_acc: 0.9904\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 389us/step - loss: 0.1820 - acc: 0.9924 - val_loss: 0.1831 - val_acc: 0.9905\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1757 - acc: 0.9924 - val_loss: 0.1800 - val_acc: 0.9902\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.1779 - acc: 0.9923 - val_loss: 0.1801 - val_acc: 0.9902\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1834 - acc: 0.9923 - val_loss: 0.1979 - val_acc: 0.9902\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0031 - acc: 0.9559 - val_loss: 0.0033 - val_acc: 0.9582\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 463us/step - loss: 0.0031 - acc: 0.9552 - val_loss: 0.0034 - val_acc: 0.9552\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0030 - acc: 0.9581 - val_loss: 0.0031 - val_acc: 0.9625\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.0031 - acc: 0.9585 - val_loss: 0.0032 - val_acc: 0.9631\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0034 - val_acc: 0.9602\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0032 - acc: 0.9574 - val_loss: 0.0032 - val_acc: 0.9629\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.0031 - acc: 0.9566 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0032 - acc: 0.9589 - val_loss: 0.0033 - val_acc: 0.9614\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.0032 - acc: 0.9573 - val_loss: 0.0034 - val_acc: 0.9574\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0032 - acc: 0.9567 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9603\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.0031 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9589\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.0031 - acc: 0.9568 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0030 - acc: 0.9607 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.0031 - acc: 0.9558 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0033 - val_acc: 0.9601\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.0032 - acc: 0.9521 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.0031 - acc: 0.9572 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.0030 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9608\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.0031 - acc: 0.9549 - val_loss: 0.0032 - val_acc: 0.9605\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9631\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0033 - val_acc: 0.9629\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.0031 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9637\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0035 - val_acc: 0.9587\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0032 - acc: 0.9560 - val_loss: 0.0035 - val_acc: 0.9585\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 461us/step - loss: 0.0031 - acc: 0.9581 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0032 - acc: 0.9559 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0030 - acc: 0.9594 - val_loss: 0.0031 - val_acc: 0.9622\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9613\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.0030 - acc: 0.9576 - val_loss: 0.0032 - val_acc: 0.9605\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.0031 - acc: 0.9560 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.0032 - acc: 0.9555 - val_loss: 0.0033 - val_acc: 0.9599\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.0031 - acc: 0.9583 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.0030 - acc: 0.9607 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0030 - acc: 0.9591 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.0030 - acc: 0.9591 - val_loss: 0.0032 - val_acc: 0.9631\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.0031 - acc: 0.9562 - val_loss: 0.0036 - val_acc: 0.9568\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.0033 - acc: 0.9532 - val_loss: 0.0031 - val_acc: 0.9637\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.0030 - acc: 0.9607 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0031 - acc: 0.9599 - val_loss: 0.0033 - val_acc: 0.9632\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.0031 - acc: 0.9583 - val_loss: 0.0032 - val_acc: 0.9635\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.0030 - acc: 0.9597 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.0030 - acc: 0.9591 - val_loss: 0.0035 - val_acc: 0.9604\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.0031 - acc: 0.9579 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "start training round 24\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.2274 - acc: 0.6896 - val_loss: 0.2406 - val_acc: 0.6865\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.2294 - acc: 0.6886 - val_loss: 0.2412 - val_acc: 0.6866\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.2289 - acc: 0.6898 - val_loss: 0.2422 - val_acc: 0.6872\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2275 - acc: 0.6898 - val_loss: 0.2407 - val_acc: 0.6868\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.2307 - acc: 0.6883 - val_loss: 0.2461 - val_acc: 0.6872\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2302 - acc: 0.6891 - val_loss: 0.2480 - val_acc: 0.6839\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2319 - acc: 0.6876 - val_loss: 0.2397 - val_acc: 0.6877\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.2263 - acc: 0.6903 - val_loss: 0.2390 - val_acc: 0.6882\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.2263 - acc: 0.6901 - val_loss: 0.2443 - val_acc: 0.6862\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2330 - acc: 0.6886 - val_loss: 0.2393 - val_acc: 0.6869\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2270 - acc: 0.6895 - val_loss: 0.2420 - val_acc: 0.6863\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2321 - acc: 0.6875 - val_loss: 0.2409 - val_acc: 0.6860\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.2261 - acc: 0.6896 - val_loss: 0.2390 - val_acc: 0.6883\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2266 - acc: 0.6900 - val_loss: 0.2465 - val_acc: 0.6854\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2313 - acc: 0.6876 - val_loss: 0.2411 - val_acc: 0.6870\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2291 - acc: 0.6885 - val_loss: 0.2427 - val_acc: 0.6861\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2284 - acc: 0.6888 - val_loss: 0.2399 - val_acc: 0.6860\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2264 - acc: 0.6899 - val_loss: 0.2410 - val_acc: 0.6867\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2277 - acc: 0.6894 - val_loss: 0.2439 - val_acc: 0.6863\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.2297 - acc: 0.6883 - val_loss: 0.2474 - val_acc: 0.6864\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2319 - acc: 0.6874 - val_loss: 0.2430 - val_acc: 0.6860\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.2319 - acc: 0.6892 - val_loss: 0.2452 - val_acc: 0.6844\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.2309 - acc: 0.6884 - val_loss: 0.2428 - val_acc: 0.6850\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.2276 - acc: 0.6891 - val_loss: 0.2433 - val_acc: 0.6845\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2298 - acc: 0.6885 - val_loss: 0.2403 - val_acc: 0.6858\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.2300 - acc: 0.6883 - val_loss: 0.2514 - val_acc: 0.6825\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2294 - acc: 0.6887 - val_loss: 0.2433 - val_acc: 0.6870\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2289 - acc: 0.6877 - val_loss: 0.2412 - val_acc: 0.6861\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.2290 - acc: 0.6883 - val_loss: 0.2419 - val_acc: 0.6875\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.2272 - acc: 0.6896 - val_loss: 0.2441 - val_acc: 0.6871\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.2293 - acc: 0.6892 - val_loss: 0.2472 - val_acc: 0.6868\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.2276 - acc: 0.6891 - val_loss: 0.2406 - val_acc: 0.6868\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2287 - acc: 0.6890 - val_loss: 0.2476 - val_acc: 0.6859\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2345 - acc: 0.6871 - val_loss: 0.2411 - val_acc: 0.6868\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.2262 - acc: 0.6903 - val_loss: 0.2478 - val_acc: 0.6859\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.2288 - acc: 0.6893 - val_loss: 0.2427 - val_acc: 0.6870\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.2311 - acc: 0.6892 - val_loss: 0.2412 - val_acc: 0.6875\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.2295 - acc: 0.6903 - val_loss: 0.2449 - val_acc: 0.6862\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.2278 - acc: 0.6901 - val_loss: 0.2404 - val_acc: 0.6877\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2274 - acc: 0.6897 - val_loss: 0.2404 - val_acc: 0.6873\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2296 - acc: 0.6885 - val_loss: 0.2436 - val_acc: 0.6869\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.2301 - acc: 0.6882 - val_loss: 0.2402 - val_acc: 0.6869\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.2295 - acc: 0.6886 - val_loss: 0.2405 - val_acc: 0.6877\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2293 - acc: 0.6896 - val_loss: 0.2474 - val_acc: 0.6867\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 400us/step - loss: 0.2285 - acc: 0.6889 - val_loss: 0.2476 - val_acc: 0.6839\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.2303 - acc: 0.6881 - val_loss: 0.2408 - val_acc: 0.6879\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2280 - acc: 0.6900 - val_loss: 0.2476 - val_acc: 0.6859\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2334 - acc: 0.6879 - val_loss: 0.2438 - val_acc: 0.6851\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.2296 - acc: 0.6883 - val_loss: 0.2400 - val_acc: 0.6872\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2272 - acc: 0.6896 - val_loss: 0.2390 - val_acc: 0.6866\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9556 - acc: 0.6790 - val_loss: 2.1137 - val_acc: 0.6762\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9605 - acc: 0.6806 - val_loss: 2.1517 - val_acc: 0.6767\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 1.9724 - acc: 0.6809 - val_loss: 2.0761 - val_acc: 0.6782\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 1.9644 - acc: 0.6807 - val_loss: 2.0781 - val_acc: 0.6805\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9484 - acc: 0.6802 - val_loss: 2.0754 - val_acc: 0.6807\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9348 - acc: 0.6804 - val_loss: 2.1356 - val_acc: 0.6760\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 1.9503 - acc: 0.6799 - val_loss: 2.1199 - val_acc: 0.6748\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 1.9599 - acc: 0.6794 - val_loss: 2.1376 - val_acc: 0.6744\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9580 - acc: 0.6795 - val_loss: 2.1142 - val_acc: 0.6783\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 1.9607 - acc: 0.6803 - val_loss: 2.2204 - val_acc: 0.6742\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9619 - acc: 0.6797 - val_loss: 2.1695 - val_acc: 0.6708\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9448 - acc: 0.6798 - val_loss: 2.1031 - val_acc: 0.6791\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9492 - acc: 0.6810 - val_loss: 2.0859 - val_acc: 0.6803\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9610 - acc: 0.6806 - val_loss: 2.0754 - val_acc: 0.6790\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9446 - acc: 0.6809 - val_loss: 2.1303 - val_acc: 0.6788\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 1.9626 - acc: 0.6808 - val_loss: 2.0748 - val_acc: 0.6789\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 1.9377 - acc: 0.6800 - val_loss: 2.1112 - val_acc: 0.6769\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9469 - acc: 0.6806 - val_loss: 2.0614 - val_acc: 0.6799\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9761 - acc: 0.6793 - val_loss: 2.0905 - val_acc: 0.6764\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9490 - acc: 0.6809 - val_loss: 2.0607 - val_acc: 0.6780\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9389 - acc: 0.6807 - val_loss: 2.0987 - val_acc: 0.6811\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9519 - acc: 0.6799 - val_loss: 2.0518 - val_acc: 0.6777\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 1.9494 - acc: 0.6798 - val_loss: 2.1065 - val_acc: 0.6785\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 1.9636 - acc: 0.6798 - val_loss: 2.0834 - val_acc: 0.6789\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9413 - acc: 0.6805 - val_loss: 2.0635 - val_acc: 0.6782\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9572 - acc: 0.6803 - val_loss: 2.0663 - val_acc: 0.6766\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 1.9587 - acc: 0.6804 - val_loss: 2.1068 - val_acc: 0.6761\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9576 - acc: 0.6805 - val_loss: 2.0939 - val_acc: 0.6761\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9484 - acc: 0.6801 - val_loss: 2.0729 - val_acc: 0.6775\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9613 - acc: 0.6812 - val_loss: 2.0960 - val_acc: 0.6786\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 1.9574 - acc: 0.6797 - val_loss: 2.0602 - val_acc: 0.6798\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9425 - acc: 0.6801 - val_loss: 2.0796 - val_acc: 0.6778\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 1.9462 - acc: 0.6802 - val_loss: 2.0808 - val_acc: 0.6768\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9445 - acc: 0.6807 - val_loss: 2.1056 - val_acc: 0.6752\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 1.9756 - acc: 0.6798 - val_loss: 2.1240 - val_acc: 0.6757\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9609 - acc: 0.6809 - val_loss: 2.0671 - val_acc: 0.6780\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9200 - acc: 0.6809 - val_loss: 2.0957 - val_acc: 0.6781\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9491 - acc: 0.6800 - val_loss: 2.2183 - val_acc: 0.6758\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9816 - acc: 0.6789 - val_loss: 2.0422 - val_acc: 0.6783\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9260 - acc: 0.6806 - val_loss: 2.1464 - val_acc: 0.6769\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9402 - acc: 0.6807 - val_loss: 2.0880 - val_acc: 0.6779\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9535 - acc: 0.6798 - val_loss: 2.1135 - val_acc: 0.6767\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9518 - acc: 0.6802 - val_loss: 2.0824 - val_acc: 0.6772\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9485 - acc: 0.6808 - val_loss: 2.1303 - val_acc: 0.6740\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 1.9427 - acc: 0.6797 - val_loss: 2.1236 - val_acc: 0.6763\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 1.9564 - acc: 0.6793 - val_loss: 2.2609 - val_acc: 0.6743\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9839 - acc: 0.6794 - val_loss: 2.0898 - val_acc: 0.6774\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 1.9607 - acc: 0.6814 - val_loss: 2.2312 - val_acc: 0.6780\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9669 - acc: 0.6810 - val_loss: 2.0862 - val_acc: 0.6788\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 1.9427 - acc: 0.6805 - val_loss: 2.0736 - val_acc: 0.6796\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1996 - acc: 0.9925 - val_loss: 0.1825 - val_acc: 0.9905\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1803 - acc: 0.9920 - val_loss: 0.1796 - val_acc: 0.9901\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1790 - acc: 0.9917 - val_loss: 0.1856 - val_acc: 0.9892\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1844 - acc: 0.9911 - val_loss: 0.1761 - val_acc: 0.9898\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.1739 - acc: 0.9921 - val_loss: 0.1832 - val_acc: 0.9898\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.1880 - acc: 0.9919 - val_loss: 0.1950 - val_acc: 0.9900\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.1901 - acc: 0.9922 - val_loss: 0.1853 - val_acc: 0.9903\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.1772 - acc: 0.9923 - val_loss: 0.1799 - val_acc: 0.9898\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.1838 - acc: 0.9917 - val_loss: 0.1813 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.1845 - acc: 0.9921 - val_loss: 0.1841 - val_acc: 0.9901\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1783 - acc: 0.9924 - val_loss: 0.1749 - val_acc: 0.9905\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1743 - acc: 0.9925 - val_loss: 0.1790 - val_acc: 0.9904\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.1808 - acc: 0.9925 - val_loss: 0.1868 - val_acc: 0.9903\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.1894 - acc: 0.9923 - val_loss: 0.1918 - val_acc: 0.9904\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1849 - acc: 0.9925 - val_loss: 0.1795 - val_acc: 0.9903\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1755 - acc: 0.9925 - val_loss: 0.1767 - val_acc: 0.9902\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1830 - acc: 0.9916 - val_loss: 0.1929 - val_acc: 0.9891\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1923 - acc: 0.9914 - val_loss: 0.1933 - val_acc: 0.9894\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.1861 - acc: 0.9919 - val_loss: 0.1769 - val_acc: 0.9901\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1752 - acc: 0.9921 - val_loss: 0.1794 - val_acc: 0.9902\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.1792 - acc: 0.9922 - val_loss: 0.1790 - val_acc: 0.9902\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.1803 - acc: 0.9924 - val_loss: 0.1801 - val_acc: 0.9904\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.1745 - acc: 0.9925 - val_loss: 0.1777 - val_acc: 0.9902\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.1760 - acc: 0.9925 - val_loss: 0.1783 - val_acc: 0.9901\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1733 - acc: 0.9925 - val_loss: 0.1766 - val_acc: 0.9904\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.1754 - acc: 0.9925 - val_loss: 0.1839 - val_acc: 0.9904\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1818 - acc: 0.9925 - val_loss: 0.1871 - val_acc: 0.9905\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1793 - acc: 0.9925 - val_loss: 0.1836 - val_acc: 0.9904\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.1873 - acc: 0.9924 - val_loss: 0.2024 - val_acc: 0.9904\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1930 - acc: 0.9924 - val_loss: 0.1842 - val_acc: 0.9901\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.1745 - acc: 0.9924 - val_loss: 0.1796 - val_acc: 0.9898\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.1748 - acc: 0.9921 - val_loss: 0.1772 - val_acc: 0.9898\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.1858 - acc: 0.9913 - val_loss: 0.1991 - val_acc: 0.9873\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1876 - acc: 0.9910 - val_loss: 0.1784 - val_acc: 0.9896\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.1727 - acc: 0.9920 - val_loss: 0.1719 - val_acc: 0.9900\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.1707 - acc: 0.9921 - val_loss: 0.1742 - val_acc: 0.9902\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.1719 - acc: 0.9921 - val_loss: 0.1765 - val_acc: 0.9897\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.1791 - acc: 0.9921 - val_loss: 0.1892 - val_acc: 0.9898\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.1811 - acc: 0.9923 - val_loss: 0.1819 - val_acc: 0.9903\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1822 - acc: 0.9924 - val_loss: 0.1850 - val_acc: 0.9902\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1896 - acc: 0.9923 - val_loss: 0.2043 - val_acc: 0.9901\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.1940 - acc: 0.9924 - val_loss: 0.1875 - val_acc: 0.9902\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.1786 - acc: 0.9925 - val_loss: 0.1822 - val_acc: 0.9905\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1725 - acc: 0.9925 - val_loss: 0.1774 - val_acc: 0.9903\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 0.1756 - acc: 0.9921 - val_loss: 0.1724 - val_acc: 0.9903\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1777 - acc: 0.9916 - val_loss: 0.1868 - val_acc: 0.9892\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 0.1896 - acc: 0.9908 - val_loss: 0.1847 - val_acc: 0.9897\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.1770 - acc: 0.9917 - val_loss: 0.1820 - val_acc: 0.9896\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.1732 - acc: 0.9921 - val_loss: 0.1778 - val_acc: 0.9904\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.1761 - acc: 0.9924 - val_loss: 0.1816 - val_acc: 0.9901\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 468us/step - loss: 0.0031 - acc: 0.9564 - val_loss: 0.0034 - val_acc: 0.9546\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.0031 - acc: 0.9559 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.0030 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9627\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 468us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9606\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.0031 - acc: 0.9572 - val_loss: 0.0032 - val_acc: 0.9602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0031 - acc: 0.9556 - val_loss: 0.0032 - val_acc: 0.9574\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9567\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.0033 - acc: 0.9522 - val_loss: 0.0031 - val_acc: 0.9617\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.0031 - acc: 0.9568 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0032 - val_acc: 0.9615\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 475us/step - loss: 0.0030 - acc: 0.9593 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0033 - val_acc: 0.9600\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.0032 - acc: 0.9551 - val_loss: 0.0032 - val_acc: 0.9608\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0030 - acc: 0.9573 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0031 - acc: 0.9566 - val_loss: 0.0032 - val_acc: 0.9629\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 472us/step - loss: 0.0031 - acc: 0.9569 - val_loss: 0.0032 - val_acc: 0.9608\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.0030 - acc: 0.9604 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.0031 - acc: 0.9589 - val_loss: 0.0037 - val_acc: 0.9519\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.0030 - acc: 0.9607 - val_loss: 0.0031 - val_acc: 0.9613\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.0031 - acc: 0.9558 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.0031 - acc: 0.9569 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9610\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.0031 - acc: 0.9575 - val_loss: 0.0033 - val_acc: 0.9594\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.0032 - acc: 0.9579 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9612\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 472us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9600\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.0031 - acc: 0.9560 - val_loss: 0.0031 - val_acc: 0.9617\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.0030 - acc: 0.9608 - val_loss: 0.0032 - val_acc: 0.9636\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.0031 - acc: 0.9599 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.0031 - acc: 0.9563 - val_loss: 0.0033 - val_acc: 0.9612\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0031 - acc: 0.9557 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 470us/step - loss: 0.0030 - acc: 0.9605 - val_loss: 0.0032 - val_acc: 0.9635\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 0.0031 - acc: 0.9562 - val_loss: 0.0033 - val_acc: 0.9601\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 466us/step - loss: 0.0031 - acc: 0.9572 - val_loss: 0.0033 - val_acc: 0.9576\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.0030 - acc: 0.9588 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 477us/step - loss: 0.0030 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9635\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.0030 - acc: 0.9582 - val_loss: 0.0033 - val_acc: 0.9593\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0032 - acc: 0.9553 - val_loss: 0.0032 - val_acc: 0.9635\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0031 - val_acc: 0.9638\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.0030 - acc: 0.9594 - val_loss: 0.0036 - val_acc: 0.9526\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 466us/step - loss: 0.0032 - acc: 0.9534 - val_loss: 0.0031 - val_acc: 0.9625\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0030 - acc: 0.9584 - val_loss: 0.0032 - val_acc: 0.9610\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.0031 - acc: 0.9573 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.0030 - acc: 0.9605 - val_loss: 0.0033 - val_acc: 0.9574\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.0030 - acc: 0.9580 - val_loss: 0.0035 - val_acc: 0.9530\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.0031 - acc: 0.9552 - val_loss: 0.0031 - val_acc: 0.9626\n",
      "start training round 25\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.2258 - acc: 0.6901 - val_loss: 0.2395 - val_acc: 0.6870\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.2298 - acc: 0.6896 - val_loss: 0.2429 - val_acc: 0.6876\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.2296 - acc: 0.6890 - val_loss: 0.2464 - val_acc: 0.6866\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2290 - acc: 0.6898 - val_loss: 0.2399 - val_acc: 0.6865\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2279 - acc: 0.6892 - val_loss: 0.2414 - val_acc: 0.6859\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2310 - acc: 0.6886 - val_loss: 0.2410 - val_acc: 0.6864\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2248 - acc: 0.6905 - val_loss: 0.2384 - val_acc: 0.6871\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.2250 - acc: 0.6907 - val_loss: 0.2409 - val_acc: 0.6870\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 451us/step - loss: 0.2306 - acc: 0.6896 - val_loss: 0.2429 - val_acc: 0.6869\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2306 - acc: 0.6887 - val_loss: 0.2402 - val_acc: 0.6858\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.2268 - acc: 0.6894 - val_loss: 0.2403 - val_acc: 0.6867\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.2295 - acc: 0.6891 - val_loss: 0.2412 - val_acc: 0.6883\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.2295 - acc: 0.6897 - val_loss: 0.2431 - val_acc: 0.6882\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.2285 - acc: 0.6894 - val_loss: 0.2412 - val_acc: 0.6871\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.2299 - acc: 0.6877 - val_loss: 0.2443 - val_acc: 0.6854\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2321 - acc: 0.6877 - val_loss: 0.2393 - val_acc: 0.6889\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2255 - acc: 0.6907 - val_loss: 0.2396 - val_acc: 0.6883\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.2299 - acc: 0.6888 - val_loss: 0.2477 - val_acc: 0.6852\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 391us/step - loss: 0.2286 - acc: 0.6889 - val_loss: 0.2384 - val_acc: 0.6874\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2278 - acc: 0.6889 - val_loss: 0.2426 - val_acc: 0.6862\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 409us/step - loss: 0.2282 - acc: 0.6880 - val_loss: 0.2439 - val_acc: 0.6847\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.2278 - acc: 0.6894 - val_loss: 0.2466 - val_acc: 0.6861\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.2276 - acc: 0.6893 - val_loss: 0.2446 - val_acc: 0.6863\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.2321 - acc: 0.6876 - val_loss: 0.2400 - val_acc: 0.6873\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2258 - acc: 0.6905 - val_loss: 0.2485 - val_acc: 0.6837\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2305 - acc: 0.6890 - val_loss: 0.2413 - val_acc: 0.6871\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.2282 - acc: 0.6898 - val_loss: 0.2431 - val_acc: 0.6852\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2302 - acc: 0.6885 - val_loss: 0.2426 - val_acc: 0.6857\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.2284 - acc: 0.6890 - val_loss: 0.2453 - val_acc: 0.6847\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2273 - acc: 0.6892 - val_loss: 0.2414 - val_acc: 0.6868\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.2333 - acc: 0.6896 - val_loss: 0.2458 - val_acc: 0.6845\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2284 - acc: 0.6897 - val_loss: 0.2442 - val_acc: 0.6865\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2273 - acc: 0.6902 - val_loss: 0.2462 - val_acc: 0.6876\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2304 - acc: 0.6893 - val_loss: 0.2408 - val_acc: 0.6873\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.2261 - acc: 0.6905 - val_loss: 0.2402 - val_acc: 0.6865\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2273 - acc: 0.6899 - val_loss: 0.2410 - val_acc: 0.6876\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 387us/step - loss: 0.2302 - acc: 0.6896 - val_loss: 0.2448 - val_acc: 0.6823\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2242 - acc: 0.6906 - val_loss: 0.2395 - val_acc: 0.6883\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 398us/step - loss: 0.2280 - acc: 0.6893 - val_loss: 0.2446 - val_acc: 0.6852\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.2333 - acc: 0.6867 - val_loss: 0.2432 - val_acc: 0.6839\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2286 - acc: 0.6888 - val_loss: 0.2422 - val_acc: 0.6873\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2314 - acc: 0.6891 - val_loss: 0.2427 - val_acc: 0.6872\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2281 - acc: 0.6899 - val_loss: 0.2388 - val_acc: 0.6881\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.2277 - acc: 0.6904 - val_loss: 0.2466 - val_acc: 0.6853\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2280 - acc: 0.6894 - val_loss: 0.2445 - val_acc: 0.6866\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2304 - acc: 0.6903 - val_loss: 0.2422 - val_acc: 0.6880\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.2258 - acc: 0.6904 - val_loss: 0.2406 - val_acc: 0.6873\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.2308 - acc: 0.6876 - val_loss: 0.2399 - val_acc: 0.6879\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2264 - acc: 0.6900 - val_loss: 0.2441 - val_acc: 0.6878\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2286 - acc: 0.6898 - val_loss: 0.2377 - val_acc: 0.6890\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9566 - acc: 0.6800 - val_loss: 2.0681 - val_acc: 0.6780\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 1.9675 - acc: 0.6804 - val_loss: 2.1035 - val_acc: 0.6794\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9496 - acc: 0.6795 - val_loss: 2.0707 - val_acc: 0.6777\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 1.9455 - acc: 0.6804 - val_loss: 2.0827 - val_acc: 0.6765\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 1.9510 - acc: 0.6803 - val_loss: 2.0563 - val_acc: 0.6789\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9234 - acc: 0.6804 - val_loss: 2.1146 - val_acc: 0.6775\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 1.9540 - acc: 0.6799 - val_loss: 2.1236 - val_acc: 0.6778\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 1.9697 - acc: 0.6804 - val_loss: 2.0814 - val_acc: 0.6765\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 1.9478 - acc: 0.6804 - val_loss: 2.0668 - val_acc: 0.6778\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9385 - acc: 0.6807 - val_loss: 2.0503 - val_acc: 0.6784\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 1.9181 - acc: 0.6809 - val_loss: 2.1610 - val_acc: 0.6777\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9943 - acc: 0.6799 - val_loss: 2.1020 - val_acc: 0.6768\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 457us/step - loss: 1.9582 - acc: 0.6783 - val_loss: 2.0606 - val_acc: 0.6786\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 392us/step - loss: 1.9562 - acc: 0.6798 - val_loss: 2.0963 - val_acc: 0.6759\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 1.9444 - acc: 0.6812 - val_loss: 2.0852 - val_acc: 0.6763\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9468 - acc: 0.6802 - val_loss: 2.0605 - val_acc: 0.6790\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 1.9453 - acc: 0.6815 - val_loss: 2.0750 - val_acc: 0.6787\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 396us/step - loss: 1.9376 - acc: 0.6804 - val_loss: 2.1561 - val_acc: 0.6765\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 1.9649 - acc: 0.6806 - val_loss: 2.1209 - val_acc: 0.6792\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9703 - acc: 0.6801 - val_loss: 2.1344 - val_acc: 0.6779\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9585 - acc: 0.6805 - val_loss: 2.0722 - val_acc: 0.6797\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 1.9582 - acc: 0.6792 - val_loss: 2.1035 - val_acc: 0.6785\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9606 - acc: 0.6807 - val_loss: 2.1293 - val_acc: 0.6784\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9533 - acc: 0.6803 - val_loss: 2.0653 - val_acc: 0.6790\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 1.9306 - acc: 0.6807 - val_loss: 2.0666 - val_acc: 0.6797\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 401us/step - loss: 1.9472 - acc: 0.6810 - val_loss: 2.0659 - val_acc: 0.6785\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 1.9571 - acc: 0.6809 - val_loss: 2.0859 - val_acc: 0.6763\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9451 - acc: 0.6802 - val_loss: 2.0544 - val_acc: 0.6792\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 1.9482 - acc: 0.6804 - val_loss: 2.1140 - val_acc: 0.6765\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 402us/step - loss: 1.9569 - acc: 0.6799 - val_loss: 2.0840 - val_acc: 0.6763\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9427 - acc: 0.6800 - val_loss: 2.1385 - val_acc: 0.6786\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 399us/step - loss: 1.9705 - acc: 0.6799 - val_loss: 2.1352 - val_acc: 0.6751\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 1.9776 - acc: 0.6791 - val_loss: 2.0579 - val_acc: 0.6775\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9277 - acc: 0.6800 - val_loss: 2.0992 - val_acc: 0.6769\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 1.9695 - acc: 0.6799 - val_loss: 2.0840 - val_acc: 0.6778\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9352 - acc: 0.6809 - val_loss: 2.0798 - val_acc: 0.6767\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 1.9392 - acc: 0.6803 - val_loss: 2.0431 - val_acc: 0.6770\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 1.9248 - acc: 0.6817 - val_loss: 2.1419 - val_acc: 0.6754\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 1.9496 - acc: 0.6807 - val_loss: 2.1714 - val_acc: 0.6720\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9584 - acc: 0.6794 - val_loss: 2.0857 - val_acc: 0.6759\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9562 - acc: 0.6797 - val_loss: 2.0653 - val_acc: 0.6775\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9617 - acc: 0.6800 - val_loss: 2.0487 - val_acc: 0.6781\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 1.9598 - acc: 0.6803 - val_loss: 2.1002 - val_acc: 0.6790\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9579 - acc: 0.6796 - val_loss: 2.0763 - val_acc: 0.6783\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9564 - acc: 0.6803 - val_loss: 2.1308 - val_acc: 0.6777\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9305 - acc: 0.6805 - val_loss: 2.1015 - val_acc: 0.6766\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9411 - acc: 0.6804 - val_loss: 2.0810 - val_acc: 0.6765\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 1.9781 - acc: 0.6803 - val_loss: 2.1259 - val_acc: 0.6751\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 1.9571 - acc: 0.6801 - val_loss: 2.1141 - val_acc: 0.6784\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 1.9522 - acc: 0.6806 - val_loss: 2.0709 - val_acc: 0.6782\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 410us/step - loss: 0.1870 - acc: 0.9923 - val_loss: 0.1913 - val_acc: 0.9904\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.1935 - acc: 0.9925 - val_loss: 0.1971 - val_acc: 0.9903\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.1847 - acc: 0.9925 - val_loss: 0.1704 - val_acc: 0.9905\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1679 - acc: 0.9925 - val_loss: 0.1719 - val_acc: 0.9903\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.1686 - acc: 0.9922 - val_loss: 0.1691 - val_acc: 0.9905\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1686 - acc: 0.9923 - val_loss: 0.1790 - val_acc: 0.9899\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 0.1794 - acc: 0.9918 - val_loss: 0.1930 - val_acc: 0.9893\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1890 - acc: 0.9918 - val_loss: 0.1856 - val_acc: 0.9903\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.1777 - acc: 0.9921 - val_loss: 0.1758 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.1824 - acc: 0.9919 - val_loss: 0.1964 - val_acc: 0.9900\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.2025 - acc: 0.9920 - val_loss: 0.1928 - val_acc: 0.9905\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.1829 - acc: 0.9925 - val_loss: 0.1775 - val_acc: 0.9903\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1770 - acc: 0.9923 - val_loss: 0.1779 - val_acc: 0.9899\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1776 - acc: 0.9923 - val_loss: 0.1744 - val_acc: 0.9903\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.1729 - acc: 0.9924 - val_loss: 0.1748 - val_acc: 0.9904\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1678 - acc: 0.9925 - val_loss: 0.1707 - val_acc: 0.9904\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1705 - acc: 0.9924 - val_loss: 0.1751 - val_acc: 0.9904\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.1765 - acc: 0.9924 - val_loss: 0.1838 - val_acc: 0.9904\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1806 - acc: 0.9923 - val_loss: 0.1732 - val_acc: 0.9905\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.1695 - acc: 0.9925 - val_loss: 0.1712 - val_acc: 0.9904\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.1739 - acc: 0.9920 - val_loss: 0.1847 - val_acc: 0.9896\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1875 - acc: 0.9923 - val_loss: 0.1921 - val_acc: 0.9903\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.1851 - acc: 0.9924 - val_loss: 0.1931 - val_acc: 0.9903\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.1813 - acc: 0.9924 - val_loss: 0.1747 - val_acc: 0.9905\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.1711 - acc: 0.9925 - val_loss: 0.1729 - val_acc: 0.9905\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1760 - acc: 0.9925 - val_loss: 0.1810 - val_acc: 0.9906\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.1790 - acc: 0.9924 - val_loss: 0.1801 - val_acc: 0.9904\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.1823 - acc: 0.9921 - val_loss: 0.1945 - val_acc: 0.9898\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 406us/step - loss: 0.2018 - acc: 0.9907 - val_loss: 0.1897 - val_acc: 0.9889\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 0.1885 - acc: 0.9909 - val_loss: 0.1937 - val_acc: 0.9880\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.1810 - acc: 0.9913 - val_loss: 0.1760 - val_acc: 0.9898\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.1758 - acc: 0.9919 - val_loss: 0.1825 - val_acc: 0.9901\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.1863 - acc: 0.9924 - val_loss: 0.1943 - val_acc: 0.9905\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 415us/step - loss: 0.1852 - acc: 0.9925 - val_loss: 0.1787 - val_acc: 0.9903\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1781 - acc: 0.9925 - val_loss: 0.1810 - val_acc: 0.9904\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.1738 - acc: 0.9925 - val_loss: 0.1732 - val_acc: 0.9905\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.1681 - acc: 0.9924 - val_loss: 0.1685 - val_acc: 0.9904\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.1726 - acc: 0.9921 - val_loss: 0.1847 - val_acc: 0.9899\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.1790 - acc: 0.9919 - val_loss: 0.1826 - val_acc: 0.9896\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.1815 - acc: 0.9919 - val_loss: 0.1811 - val_acc: 0.9904\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.1875 - acc: 0.9925 - val_loss: 0.2211 - val_acc: 0.9904\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2029 - acc: 0.9925 - val_loss: 0.1782 - val_acc: 0.9904\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.1669 - acc: 0.9925 - val_loss: 0.1676 - val_acc: 0.9905\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.1645 - acc: 0.9926 - val_loss: 0.1667 - val_acc: 0.9906\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1679 - acc: 0.9923 - val_loss: 0.1739 - val_acc: 0.9901\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.1763 - acc: 0.9918 - val_loss: 0.1825 - val_acc: 0.9896\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 427us/step - loss: 0.1858 - acc: 0.9922 - val_loss: 0.1973 - val_acc: 0.9903\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.1754 - acc: 0.9924 - val_loss: 0.1756 - val_acc: 0.9905\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.1731 - acc: 0.9924 - val_loss: 0.1741 - val_acc: 0.9905\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.1688 - acc: 0.9925 - val_loss: 0.1836 - val_acc: 0.9905\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.0031 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9621\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 466us/step - loss: 0.0031 - acc: 0.9579 - val_loss: 0.0033 - val_acc: 0.9624\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.0031 - acc: 0.9579 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.0031 - acc: 0.9564 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.0030 - acc: 0.9588 - val_loss: 0.0032 - val_acc: 0.9605\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 474us/step - loss: 0.0031 - acc: 0.9571 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9633\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 470us/step - loss: 0.0030 - acc: 0.9574 - val_loss: 0.0032 - val_acc: 0.9607\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 456us/step - loss: 0.0030 - acc: 0.9578 - val_loss: 0.0031 - val_acc: 0.9607\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.0029 - acc: 0.9607 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 449us/step - loss: 0.0030 - acc: 0.9585 - val_loss: 0.0034 - val_acc: 0.9596\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.0031 - acc: 0.9567 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.0030 - acc: 0.9594 - val_loss: 0.0032 - val_acc: 0.9602\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 445us/step - loss: 0.0031 - acc: 0.9550 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0032 - val_acc: 0.9618\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.0033 - acc: 0.9521 - val_loss: 0.0031 - val_acc: 0.9638\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0032 - val_acc: 0.9632\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.0030 - acc: 0.9606 - val_loss: 0.0031 - val_acc: 0.9637\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 458us/step - loss: 0.0031 - acc: 0.9590 - val_loss: 0.0037 - val_acc: 0.9537\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 455us/step - loss: 0.0032 - acc: 0.9542 - val_loss: 0.0031 - val_acc: 0.9637\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 469us/step - loss: 0.0030 - acc: 0.9588 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 468us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0031 - val_acc: 0.9637\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.0030 - acc: 0.9608 - val_loss: 0.0033 - val_acc: 0.9630\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 487us/step - loss: 0.0032 - acc: 0.9546 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.0030 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9635\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 464us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 446us/step - loss: 0.0031 - acc: 0.9556 - val_loss: 0.0032 - val_acc: 0.9583\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 0.0031 - acc: 0.9557 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0030 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0031 - val_acc: 0.9616\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.0030 - acc: 0.9582 - val_loss: 0.0032 - val_acc: 0.9606\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 443us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0032 - val_acc: 0.9606\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 452us/step - loss: 0.0031 - acc: 0.9575 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9635\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0031 - val_acc: 0.9626\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0035 - val_acc: 0.9560\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.0031 - acc: 0.9574 - val_loss: 0.0032 - val_acc: 0.9608\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 450us/step - loss: 0.0031 - acc: 0.9568 - val_loss: 0.0031 - val_acc: 0.9621\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 462us/step - loss: 0.0031 - acc: 0.9578 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.0030 - acc: 0.9606 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0032 - val_acc: 0.9602\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 0.0031 - acc: 0.9566 - val_loss: 0.0033 - val_acc: 0.9588\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 0.0031 - acc: 0.9586 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 467us/step - loss: 0.0030 - acc: 0.9577 - val_loss: 0.0032 - val_acc: 0.9593\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 476us/step - loss: 0.0031 - acc: 0.9592 - val_loss: 0.0032 - val_acc: 0.9621\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 472us/step - loss: 0.0031 - acc: 0.9561 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "start training round 26\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2252 - acc: 0.6907 - val_loss: 0.2444 - val_acc: 0.6853\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2343 - acc: 0.6869 - val_loss: 0.2392 - val_acc: 0.6882\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2258 - acc: 0.6902 - val_loss: 0.2419 - val_acc: 0.6865\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2268 - acc: 0.6896 - val_loss: 0.2382 - val_acc: 0.6883\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 0.2291 - acc: 0.6898 - val_loss: 0.2464 - val_acc: 0.6856\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2292 - acc: 0.6892 - val_loss: 0.2413 - val_acc: 0.6863\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 425us/step - loss: 0.2295 - acc: 0.6878 - val_loss: 0.2390 - val_acc: 0.6886\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 0.2308 - acc: 0.6873 - val_loss: 0.2509 - val_acc: 0.6852\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2307 - acc: 0.6895 - val_loss: 0.2425 - val_acc: 0.6873\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.2282 - acc: 0.6890 - val_loss: 0.2397 - val_acc: 0.6883\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.2309 - acc: 0.6890 - val_loss: 0.2460 - val_acc: 0.6858\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.2276 - acc: 0.6896 - val_loss: 0.2416 - val_acc: 0.6872\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2295 - acc: 0.6882 - val_loss: 0.2385 - val_acc: 0.6886\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2270 - acc: 0.6900 - val_loss: 0.2449 - val_acc: 0.6849\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 394us/step - loss: 0.2294 - acc: 0.6897 - val_loss: 0.2394 - val_acc: 0.6886\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2317 - acc: 0.6881 - val_loss: 0.2410 - val_acc: 0.6871\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2281 - acc: 0.6903 - val_loss: 0.2390 - val_acc: 0.6875\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2273 - acc: 0.6888 - val_loss: 0.2439 - val_acc: 0.6862\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2280 - acc: 0.6899 - val_loss: 0.2423 - val_acc: 0.6868\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 419us/step - loss: 0.2279 - acc: 0.6897 - val_loss: 0.2383 - val_acc: 0.6890\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.2261 - acc: 0.6903 - val_loss: 0.2426 - val_acc: 0.6865\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 0.2269 - acc: 0.6897 - val_loss: 0.2433 - val_acc: 0.6875\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2306 - acc: 0.6878 - val_loss: 0.2384 - val_acc: 0.6874\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.2265 - acc: 0.6904 - val_loss: 0.2439 - val_acc: 0.6880\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2291 - acc: 0.6903 - val_loss: 0.2401 - val_acc: 0.6874\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 0.2333 - acc: 0.6865 - val_loss: 0.2388 - val_acc: 0.6868\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2268 - acc: 0.6895 - val_loss: 0.2423 - val_acc: 0.6848\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 428us/step - loss: 0.2305 - acc: 0.6892 - val_loss: 0.2463 - val_acc: 0.6859\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.2273 - acc: 0.6892 - val_loss: 0.2384 - val_acc: 0.6892\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 0.2253 - acc: 0.6899 - val_loss: 0.2378 - val_acc: 0.6892\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2271 - acc: 0.6896 - val_loss: 0.2423 - val_acc: 0.6877\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 4s 447us/step - loss: 0.2283 - acc: 0.6897 - val_loss: 0.2379 - val_acc: 0.6887\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 0.2273 - acc: 0.6903 - val_loss: 0.2404 - val_acc: 0.6873\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 0.2235 - acc: 0.6912 - val_loss: 0.2367 - val_acc: 0.6894\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.2252 - acc: 0.6909 - val_loss: 0.2423 - val_acc: 0.6863\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.2261 - acc: 0.6897 - val_loss: 0.2439 - val_acc: 0.6868\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 444us/step - loss: 0.2316 - acc: 0.6877 - val_loss: 0.2419 - val_acc: 0.6876\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2251 - acc: 0.6909 - val_loss: 0.2441 - val_acc: 0.6873\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 0.2304 - acc: 0.6893 - val_loss: 0.2388 - val_acc: 0.6887\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 0.2247 - acc: 0.6910 - val_loss: 0.2397 - val_acc: 0.6887\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 0.2290 - acc: 0.6896 - val_loss: 0.2404 - val_acc: 0.6869\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 0.2277 - acc: 0.6895 - val_loss: 0.2450 - val_acc: 0.6844\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 0.2289 - acc: 0.6896 - val_loss: 0.2391 - val_acc: 0.6890\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 418us/step - loss: 0.2253 - acc: 0.6912 - val_loss: 0.2380 - val_acc: 0.6889\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 438us/step - loss: 0.2282 - acc: 0.6893 - val_loss: 0.2508 - val_acc: 0.6831\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.2279 - acc: 0.6892 - val_loss: 0.2392 - val_acc: 0.6872\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 0.2257 - acc: 0.6908 - val_loss: 0.2404 - val_acc: 0.6888\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 0.2267 - acc: 0.6904 - val_loss: 0.2426 - val_acc: 0.6860\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 0.2277 - acc: 0.6890 - val_loss: 0.2376 - val_acc: 0.6884\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 413us/step - loss: 0.2240 - acc: 0.6910 - val_loss: 0.2396 - val_acc: 0.6866\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9347 - acc: 0.6808 - val_loss: 2.0823 - val_acc: 0.6785\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 434us/step - loss: 1.9562 - acc: 0.6809 - val_loss: 2.1114 - val_acc: 0.6783\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 1.9537 - acc: 0.6794 - val_loss: 2.1268 - val_acc: 0.6751\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 407us/step - loss: 1.9577 - acc: 0.6788 - val_loss: 2.0627 - val_acc: 0.6788\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 441us/step - loss: 1.9467 - acc: 0.6801 - val_loss: 2.1395 - val_acc: 0.6779\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 417us/step - loss: 1.9409 - acc: 0.6804 - val_loss: 2.0592 - val_acc: 0.6791\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9408 - acc: 0.6806 - val_loss: 2.1306 - val_acc: 0.6795\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 4s 454us/step - loss: 1.9485 - acc: 0.6799 - val_loss: 2.0648 - val_acc: 0.6794\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9669 - acc: 0.6811 - val_loss: 2.0668 - val_acc: 0.6786\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 405us/step - loss: 1.9453 - acc: 0.6799 - val_loss: 2.0992 - val_acc: 0.6789\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9361 - acc: 0.6800 - val_loss: 2.0561 - val_acc: 0.6788\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 1.9373 - acc: 0.6804 - val_loss: 2.0902 - val_acc: 0.6807\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9390 - acc: 0.6807 - val_loss: 2.0938 - val_acc: 0.6797\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9623 - acc: 0.6799 - val_loss: 2.1032 - val_acc: 0.6767\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 4s 424us/step - loss: 1.9663 - acc: 0.6794 - val_loss: 2.0918 - val_acc: 0.6749\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 1.9671 - acc: 0.6803 - val_loss: 2.2264 - val_acc: 0.6747\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 1.9803 - acc: 0.6809 - val_loss: 2.1266 - val_acc: 0.6763\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 4s 416us/step - loss: 1.9536 - acc: 0.6801 - val_loss: 2.0600 - val_acc: 0.6792\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 4s 460us/step - loss: 1.9199 - acc: 0.6814 - val_loss: 2.2045 - val_acc: 0.6784\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9740 - acc: 0.6802 - val_loss: 2.1466 - val_acc: 0.6783\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 4s 453us/step - loss: 1.9449 - acc: 0.6810 - val_loss: 2.0762 - val_acc: 0.6790\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9521 - acc: 0.6799 - val_loss: 2.1975 - val_acc: 0.6755\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9583 - acc: 0.6789 - val_loss: 2.0991 - val_acc: 0.6753\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 4s 448us/step - loss: 1.9470 - acc: 0.6801 - val_loss: 2.0843 - val_acc: 0.6778\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 404us/step - loss: 1.9478 - acc: 0.6806 - val_loss: 2.0775 - val_acc: 0.6805\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 4s 414us/step - loss: 1.9416 - acc: 0.6800 - val_loss: 2.0607 - val_acc: 0.6792\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9272 - acc: 0.6802 - val_loss: 2.0567 - val_acc: 0.6784\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 1.9267 - acc: 0.6797 - val_loss: 2.1874 - val_acc: 0.6739\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9771 - acc: 0.6794 - val_loss: 2.1702 - val_acc: 0.6772\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9587 - acc: 0.6804 - val_loss: 2.0859 - val_acc: 0.6769\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9355 - acc: 0.6802 - val_loss: 2.1416 - val_acc: 0.6779\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 408us/step - loss: 1.9532 - acc: 0.6807 - val_loss: 2.0607 - val_acc: 0.6794\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 4s 450us/step - loss: 1.9492 - acc: 0.6809 - val_loss: 2.0672 - val_acc: 0.6780\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 4s 421us/step - loss: 1.9430 - acc: 0.6807 - val_loss: 2.1273 - val_acc: 0.6752\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 4s 411us/step - loss: 1.9472 - acc: 0.6800 - val_loss: 2.0829 - val_acc: 0.6759\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9360 - acc: 0.6796 - val_loss: 2.1079 - val_acc: 0.6768\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 4s 435us/step - loss: 1.9446 - acc: 0.6810 - val_loss: 2.0885 - val_acc: 0.6783\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 4s 412us/step - loss: 1.9523 - acc: 0.6809 - val_loss: 2.1485 - val_acc: 0.6762\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 4s 426us/step - loss: 1.9420 - acc: 0.6804 - val_loss: 2.0744 - val_acc: 0.6757\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 4s 436us/step - loss: 1.9478 - acc: 0.6798 - val_loss: 2.0662 - val_acc: 0.6774\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 4s 420us/step - loss: 1.9471 - acc: 0.6798 - val_loss: 2.0900 - val_acc: 0.6768\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 4s 430us/step - loss: 1.9377 - acc: 0.6805 - val_loss: 2.0537 - val_acc: 0.6785\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9283 - acc: 0.6807 - val_loss: 2.0664 - val_acc: 0.6797\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 4s 429us/step - loss: 1.9515 - acc: 0.6799 - val_loss: 2.1231 - val_acc: 0.6781\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 4s 433us/step - loss: 1.9479 - acc: 0.6804 - val_loss: 2.1343 - val_acc: 0.6788\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 1.9845 - acc: 0.6804 - val_loss: 2.0776 - val_acc: 0.6775\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 4s 437us/step - loss: 1.9553 - acc: 0.6807 - val_loss: 2.0764 - val_acc: 0.6785\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9493 - acc: 0.6799 - val_loss: 2.0693 - val_acc: 0.6791\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 1.9215 - acc: 0.6803 - val_loss: 2.0586 - val_acc: 0.6790\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 4s 432us/step - loss: 1.9486 - acc: 0.6810 - val_loss: 2.1516 - val_acc: 0.6785\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.1858 - acc: 0.9925 - val_loss: 0.1914 - val_acc: 0.9902\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 4s 440us/step - loss: 0.1897 - acc: 0.9923 - val_loss: 0.1906 - val_acc: 0.9899\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 4s 431us/step - loss: 0.1772 - acc: 0.9920 - val_loss: 0.1734 - val_acc: 0.9902\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 4s 422us/step - loss: 0.1719 - acc: 0.9922 - val_loss: 0.1806 - val_acc: 0.9900\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 4s 439us/step - loss: 0.1832 - acc: 0.9920 - val_loss: 0.1912 - val_acc: 0.9900\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 4s 442us/step - loss: 0.1782 - acc: 0.9923 - val_loss: 0.1806 - val_acc: 0.9902\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 4s 423us/step - loss: 0.1815 - acc: 0.9925 - val_loss: 0.1885 - val_acc: 0.9906\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 378us/step - loss: 0.1754 - acc: 0.9925 - val_loss: 0.1780 - val_acc: 0.9906\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1728 - acc: 0.9924 - val_loss: 0.1743 - val_acc: 0.9901\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1760 - acc: 0.9916 - val_loss: 0.1727 - val_acc: 0.9902\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.1779 - acc: 0.9913 - val_loss: 0.1769 - val_acc: 0.9898\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 299us/step - loss: 0.1726 - acc: 0.9919 - val_loss: 0.1708 - val_acc: 0.9904\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.1738 - acc: 0.9922 - val_loss: 0.1885 - val_acc: 0.9899\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1924 - acc: 0.9919 - val_loss: 0.1913 - val_acc: 0.9904\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1847 - acc: 0.9925 - val_loss: 0.1724 - val_acc: 0.9903\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1758 - acc: 0.9925 - val_loss: 0.1905 - val_acc: 0.9904\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1932 - acc: 0.9925 - val_loss: 0.1908 - val_acc: 0.9904\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1764 - acc: 0.9926 - val_loss: 0.1719 - val_acc: 0.9904\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.1683 - acc: 0.9924 - val_loss: 0.1761 - val_acc: 0.9903\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1764 - acc: 0.9921 - val_loss: 0.1866 - val_acc: 0.9894\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1854 - acc: 0.9918 - val_loss: 0.1814 - val_acc: 0.9902\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1770 - acc: 0.9922 - val_loss: 0.1757 - val_acc: 0.9904\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1701 - acc: 0.9921 - val_loss: 0.1747 - val_acc: 0.9900\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1821 - acc: 0.9914 - val_loss: 0.2042 - val_acc: 0.9882\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1914 - acc: 0.9917 - val_loss: 0.1812 - val_acc: 0.9905\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1786 - acc: 0.9925 - val_loss: 0.1926 - val_acc: 0.9903\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 298us/step - loss: 0.1794 - acc: 0.9926 - val_loss: 0.1783 - val_acc: 0.9906\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1805 - acc: 0.9925 - val_loss: 0.1876 - val_acc: 0.9903\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1872 - acc: 0.9924 - val_loss: 0.1840 - val_acc: 0.9903\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1792 - acc: 0.9922 - val_loss: 0.1871 - val_acc: 0.9899\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1754 - acc: 0.9921 - val_loss: 0.1728 - val_acc: 0.9902\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1733 - acc: 0.9922 - val_loss: 0.1770 - val_acc: 0.9900\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1739 - acc: 0.9923 - val_loss: 0.1779 - val_acc: 0.9903\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1735 - acc: 0.9924 - val_loss: 0.1784 - val_acc: 0.9902\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1725 - acc: 0.9923 - val_loss: 0.1729 - val_acc: 0.9902\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 282us/step - loss: 0.1750 - acc: 0.9925 - val_loss: 0.1897 - val_acc: 0.9905\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.1854 - acc: 0.9922 - val_loss: 0.1906 - val_acc: 0.9901\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1803 - acc: 0.9923 - val_loss: 0.1757 - val_acc: 0.9904\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1718 - acc: 0.9923 - val_loss: 0.1771 - val_acc: 0.9904\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1726 - acc: 0.9925 - val_loss: 0.1691 - val_acc: 0.9906\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1703 - acc: 0.9921 - val_loss: 0.1826 - val_acc: 0.9892\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 283us/step - loss: 0.1838 - acc: 0.9910 - val_loss: 0.1826 - val_acc: 0.9890\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1769 - acc: 0.9915 - val_loss: 0.1877 - val_acc: 0.9892\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.1941 - acc: 0.9914 - val_loss: 0.1958 - val_acc: 0.9904\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1882 - acc: 0.9925 - val_loss: 0.1772 - val_acc: 0.9904\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1702 - acc: 0.9925 - val_loss: 0.1710 - val_acc: 0.9903\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1680 - acc: 0.9924 - val_loss: 0.1697 - val_acc: 0.9902\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1710 - acc: 0.9924 - val_loss: 0.1707 - val_acc: 0.9903\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1718 - acc: 0.9921 - val_loss: 0.1781 - val_acc: 0.9896\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1741 - acc: 0.9919 - val_loss: 0.1821 - val_acc: 0.9899\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0031 - acc: 0.9567 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 315us/step - loss: 0.0031 - acc: 0.9571 - val_loss: 0.0031 - val_acc: 0.9625\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0030 - acc: 0.9591 - val_loss: 0.0031 - val_acc: 0.9617\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.0030 - acc: 0.9586 - val_loss: 0.0031 - val_acc: 0.9622\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9579 - val_loss: 0.0031 - val_acc: 0.9618\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 299us/step - loss: 0.0030 - acc: 0.9594 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0030 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9621\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 309us/step - loss: 0.0031 - acc: 0.9574 - val_loss: 0.0031 - val_acc: 0.9606\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0030 - acc: 0.9585 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0031 - val_acc: 0.9626\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 317us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.0030 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 318us/step - loss: 0.0030 - acc: 0.9589 - val_loss: 0.0034 - val_acc: 0.9561\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0032 - acc: 0.9537 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 300us/step - loss: 0.0030 - acc: 0.9591 - val_loss: 0.0035 - val_acc: 0.9563\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0033 - acc: 0.9532 - val_loss: 0.0032 - val_acc: 0.9636\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0031 - acc: 0.9579 - val_loss: 0.0032 - val_acc: 0.9639\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.0030 - acc: 0.9606 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9597 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0029 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0030 - acc: 0.9607 - val_loss: 0.0032 - val_acc: 0.9637\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 300us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9639\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0031 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9636\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0031 - acc: 0.9583 - val_loss: 0.0035 - val_acc: 0.9535\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 299us/step - loss: 0.0031 - acc: 0.9544 - val_loss: 0.0033 - val_acc: 0.9550\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0031 - val_acc: 0.9624\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 298us/step - loss: 0.0030 - acc: 0.9604 - val_loss: 0.0032 - val_acc: 0.9615\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 301us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9613\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0031 - acc: 0.9577 - val_loss: 0.0032 - val_acc: 0.9615\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 313us/step - loss: 0.0030 - acc: 0.9590 - val_loss: 0.0031 - val_acc: 0.9619\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0031 - val_acc: 0.9626\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0030 - acc: 0.9594 - val_loss: 0.0033 - val_acc: 0.9561\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 309us/step - loss: 0.0031 - acc: 0.9594 - val_loss: 0.0032 - val_acc: 0.9610\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0032 - acc: 0.9537 - val_loss: 0.0031 - val_acc: 0.9627\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0030 - acc: 0.9604 - val_loss: 0.0032 - val_acc: 0.9619\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0030 - acc: 0.9584 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 317us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0031 - acc: 0.9574 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 316us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 312us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9637\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 301us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0030 - acc: 0.9594 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0031 - acc: 0.9572 - val_loss: 0.0032 - val_acc: 0.9609\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0030 - acc: 0.9575 - val_loss: 0.0031 - val_acc: 0.9601\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 314us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "start training round 27\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 298us/step - loss: 0.2295 - acc: 0.6874 - val_loss: 0.2407 - val_acc: 0.6875\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2297 - acc: 0.6888 - val_loss: 0.2513 - val_acc: 0.6833\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.2283 - acc: 0.6893 - val_loss: 0.2390 - val_acc: 0.6881\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2298 - acc: 0.6895 - val_loss: 0.2451 - val_acc: 0.6869\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2291 - acc: 0.6894 - val_loss: 0.2386 - val_acc: 0.6884\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.2257 - acc: 0.6905 - val_loss: 0.2436 - val_acc: 0.6848\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 0.2295 - acc: 0.6885 - val_loss: 0.2398 - val_acc: 0.6879\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2296 - acc: 0.6899 - val_loss: 0.2376 - val_acc: 0.6885\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2269 - acc: 0.6896 - val_loss: 0.2394 - val_acc: 0.6865\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2259 - acc: 0.6897 - val_loss: 0.2443 - val_acc: 0.6859\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 298us/step - loss: 0.2301 - acc: 0.6897 - val_loss: 0.2409 - val_acc: 0.6864\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.2269 - acc: 0.6898 - val_loss: 0.2392 - val_acc: 0.6880\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.2292 - acc: 0.6890 - val_loss: 0.2399 - val_acc: 0.6887\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2288 - acc: 0.6898 - val_loss: 0.2467 - val_acc: 0.6853\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.2265 - acc: 0.6897 - val_loss: 0.2413 - val_acc: 0.6861\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.2278 - acc: 0.6902 - val_loss: 0.2464 - val_acc: 0.6830\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2291 - acc: 0.6898 - val_loss: 0.2583 - val_acc: 0.6865\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2289 - acc: 0.6905 - val_loss: 0.2439 - val_acc: 0.6851\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.2272 - acc: 0.6897 - val_loss: 0.2423 - val_acc: 0.6874\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2241 - acc: 0.6911 - val_loss: 0.2375 - val_acc: 0.6883\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.2261 - acc: 0.6905 - val_loss: 0.2427 - val_acc: 0.6866\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.2311 - acc: 0.6876 - val_loss: 0.2394 - val_acc: 0.6875\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2271 - acc: 0.6892 - val_loss: 0.2398 - val_acc: 0.6855\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2266 - acc: 0.6899 - val_loss: 0.2414 - val_acc: 0.6872\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2287 - acc: 0.6894 - val_loss: 0.2435 - val_acc: 0.6854\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 283us/step - loss: 0.2296 - acc: 0.6891 - val_loss: 0.2409 - val_acc: 0.6888\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2272 - acc: 0.6897 - val_loss: 0.2402 - val_acc: 0.6882\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.2263 - acc: 0.6911 - val_loss: 0.2425 - val_acc: 0.6880\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2273 - acc: 0.6894 - val_loss: 0.2474 - val_acc: 0.6836\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2244 - acc: 0.6906 - val_loss: 0.2365 - val_acc: 0.6891\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.2243 - acc: 0.6908 - val_loss: 0.2373 - val_acc: 0.6892\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2282 - acc: 0.6890 - val_loss: 0.2399 - val_acc: 0.6887\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2256 - acc: 0.6907 - val_loss: 0.2407 - val_acc: 0.6867\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2265 - acc: 0.6893 - val_loss: 0.2414 - val_acc: 0.6874\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2306 - acc: 0.6887 - val_loss: 0.2424 - val_acc: 0.6890\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2275 - acc: 0.6901 - val_loss: 0.2441 - val_acc: 0.6861\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 280us/step - loss: 0.2269 - acc: 0.6902 - val_loss: 0.2448 - val_acc: 0.6852\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 280us/step - loss: 0.2263 - acc: 0.6900 - val_loss: 0.2441 - val_acc: 0.6845\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2272 - acc: 0.6893 - val_loss: 0.2495 - val_acc: 0.6852\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2307 - acc: 0.6896 - val_loss: 0.2426 - val_acc: 0.6868\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2288 - acc: 0.6905 - val_loss: 0.2414 - val_acc: 0.6882\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2283 - acc: 0.6911 - val_loss: 0.2437 - val_acc: 0.6885\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 283us/step - loss: 0.2244 - acc: 0.6913 - val_loss: 0.2440 - val_acc: 0.6871\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2273 - acc: 0.6889 - val_loss: 0.2370 - val_acc: 0.6893\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2285 - acc: 0.6900 - val_loss: 0.2433 - val_acc: 0.6873\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2236 - acc: 0.6911 - val_loss: 0.2370 - val_acc: 0.6890\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 0.2254 - acc: 0.6905 - val_loss: 0.2388 - val_acc: 0.6871\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2275 - acc: 0.6895 - val_loss: 0.2430 - val_acc: 0.6872\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2258 - acc: 0.6902 - val_loss: 0.2404 - val_acc: 0.6872\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2286 - acc: 0.6895 - val_loss: 0.2545 - val_acc: 0.6827\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9480 - acc: 0.6799 - val_loss: 2.0693 - val_acc: 0.6782\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9294 - acc: 0.6809 - val_loss: 2.0894 - val_acc: 0.6796\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 1.9344 - acc: 0.6809 - val_loss: 2.1147 - val_acc: 0.6770\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9538 - acc: 0.6786 - val_loss: 2.1000 - val_acc: 0.6764\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 1.9386 - acc: 0.6808 - val_loss: 2.0539 - val_acc: 0.6801\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9340 - acc: 0.6804 - val_loss: 2.1228 - val_acc: 0.6768\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 1.9576 - acc: 0.6800 - val_loss: 2.0814 - val_acc: 0.6782\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 283us/step - loss: 1.9523 - acc: 0.6806 - val_loss: 2.0885 - val_acc: 0.6775\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 281us/step - loss: 1.9467 - acc: 0.6807 - val_loss: 2.0696 - val_acc: 0.6790\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 1.9248 - acc: 0.6807 - val_loss: 2.0681 - val_acc: 0.6799\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 279us/step - loss: 1.9426 - acc: 0.6804 - val_loss: 2.1902 - val_acc: 0.6784\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9582 - acc: 0.6794 - val_loss: 2.0906 - val_acc: 0.6784\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9462 - acc: 0.6807 - val_loss: 2.0931 - val_acc: 0.6778\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9680 - acc: 0.6802 - val_loss: 2.1063 - val_acc: 0.6789\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9567 - acc: 0.6803 - val_loss: 2.0870 - val_acc: 0.6774\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 283us/step - loss: 1.9390 - acc: 0.6805 - val_loss: 2.0572 - val_acc: 0.6774\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 1.9379 - acc: 0.6798 - val_loss: 2.1211 - val_acc: 0.6750\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9491 - acc: 0.6796 - val_loss: 2.1178 - val_acc: 0.6744\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9369 - acc: 0.6801 - val_loss: 2.0568 - val_acc: 0.6784\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 1.9613 - acc: 0.6796 - val_loss: 2.0897 - val_acc: 0.6798\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9500 - acc: 0.6808 - val_loss: 2.0771 - val_acc: 0.6805\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9554 - acc: 0.6807 - val_loss: 2.0795 - val_acc: 0.6801\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 282us/step - loss: 1.9560 - acc: 0.6812 - val_loss: 2.1094 - val_acc: 0.6780\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 1.9509 - acc: 0.6799 - val_loss: 2.0498 - val_acc: 0.6769\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9478 - acc: 0.6801 - val_loss: 2.1253 - val_acc: 0.6742\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9212 - acc: 0.6802 - val_loss: 2.0837 - val_acc: 0.6755\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 283us/step - loss: 1.9623 - acc: 0.6790 - val_loss: 2.0833 - val_acc: 0.6800\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9332 - acc: 0.6807 - val_loss: 2.1526 - val_acc: 0.6783\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 1.9652 - acc: 0.6807 - val_loss: 2.1483 - val_acc: 0.6789\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9428 - acc: 0.6808 - val_loss: 2.0667 - val_acc: 0.6787\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9419 - acc: 0.6806 - val_loss: 2.0962 - val_acc: 0.6788\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 1.9467 - acc: 0.6798 - val_loss: 2.0853 - val_acc: 0.6781\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9634 - acc: 0.6798 - val_loss: 2.0640 - val_acc: 0.6791\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9261 - acc: 0.6814 - val_loss: 2.1403 - val_acc: 0.6758\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9642 - acc: 0.6803 - val_loss: 2.0604 - val_acc: 0.6771\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9305 - acc: 0.6799 - val_loss: 2.0720 - val_acc: 0.6771\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9495 - acc: 0.6810 - val_loss: 2.0674 - val_acc: 0.6785\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9497 - acc: 0.6805 - val_loss: 2.0387 - val_acc: 0.6795\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9496 - acc: 0.6805 - val_loss: 2.0735 - val_acc: 0.6798\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9765 - acc: 0.6799 - val_loss: 2.1105 - val_acc: 0.6792\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9493 - acc: 0.6802 - val_loss: 2.0818 - val_acc: 0.6785\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 298us/step - loss: 1.9492 - acc: 0.6808 - val_loss: 2.1000 - val_acc: 0.6755\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9283 - acc: 0.6804 - val_loss: 2.0531 - val_acc: 0.6780\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9413 - acc: 0.6798 - val_loss: 2.0710 - val_acc: 0.6774\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 283us/step - loss: 1.9379 - acc: 0.6809 - val_loss: 2.1283 - val_acc: 0.6791\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9539 - acc: 0.6804 - val_loss: 2.0808 - val_acc: 0.6796\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 1.9461 - acc: 0.6809 - val_loss: 2.0803 - val_acc: 0.6789\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9487 - acc: 0.6811 - val_loss: 2.1448 - val_acc: 0.6730\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9368 - acc: 0.6795 - val_loss: 2.0834 - val_acc: 0.6780\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 1.9339 - acc: 0.6799 - val_loss: 2.1278 - val_acc: 0.6782\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.1772 - acc: 0.9919 - val_loss: 0.1880 - val_acc: 0.9892\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1869 - acc: 0.9919 - val_loss: 0.1880 - val_acc: 0.9899\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1792 - acc: 0.9924 - val_loss: 0.1783 - val_acc: 0.9905\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1762 - acc: 0.9925 - val_loss: 0.1772 - val_acc: 0.9902\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1767 - acc: 0.9925 - val_loss: 0.1761 - val_acc: 0.9905\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1795 - acc: 0.9918 - val_loss: 0.1929 - val_acc: 0.9890\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1867 - acc: 0.9904 - val_loss: 0.1818 - val_acc: 0.9893\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1766 - acc: 0.9915 - val_loss: 0.1803 - val_acc: 0.9899\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1818 - acc: 0.9922 - val_loss: 0.1905 - val_acc: 0.9903\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.1838 - acc: 0.9925 - val_loss: 0.1748 - val_acc: 0.9905\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1831 - acc: 0.9925 - val_loss: 0.1876 - val_acc: 0.9902\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1782 - acc: 0.9924 - val_loss: 0.1729 - val_acc: 0.9904\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1664 - acc: 0.9926 - val_loss: 0.1663 - val_acc: 0.9905\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1692 - acc: 0.9925 - val_loss: 0.1744 - val_acc: 0.9905\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1842 - acc: 0.9925 - val_loss: 0.1788 - val_acc: 0.9905\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 0.1759 - acc: 0.9925 - val_loss: 0.1780 - val_acc: 0.9905\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1757 - acc: 0.9925 - val_loss: 0.1794 - val_acc: 0.9902\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1824 - acc: 0.9917 - val_loss: 0.1844 - val_acc: 0.9894\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1772 - acc: 0.9919 - val_loss: 0.1757 - val_acc: 0.9898\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.1734 - acc: 0.9919 - val_loss: 0.1716 - val_acc: 0.9902\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.1721 - acc: 0.9921 - val_loss: 0.1863 - val_acc: 0.9896\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1814 - acc: 0.9919 - val_loss: 0.1847 - val_acc: 0.9899\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1794 - acc: 0.9925 - val_loss: 0.1800 - val_acc: 0.9905\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1768 - acc: 0.9925 - val_loss: 0.1739 - val_acc: 0.9906\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1728 - acc: 0.9924 - val_loss: 0.1738 - val_acc: 0.9903\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.1764 - acc: 0.9923 - val_loss: 0.1785 - val_acc: 0.9903\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1861 - acc: 0.9922 - val_loss: 0.2037 - val_acc: 0.9902\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1979 - acc: 0.9925 - val_loss: 0.1800 - val_acc: 0.9907\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1704 - acc: 0.9924 - val_loss: 0.1720 - val_acc: 0.9902\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1705 - acc: 0.9920 - val_loss: 0.1743 - val_acc: 0.9901\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1718 - acc: 0.9919 - val_loss: 0.1758 - val_acc: 0.9896\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1801 - acc: 0.9911 - val_loss: 0.1821 - val_acc: 0.9892\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1810 - acc: 0.9917 - val_loss: 0.1834 - val_acc: 0.9902\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1768 - acc: 0.9924 - val_loss: 0.1763 - val_acc: 0.9906\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.1696 - acc: 0.9925 - val_loss: 0.1755 - val_acc: 0.9902\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1809 - acc: 0.9924 - val_loss: 0.1877 - val_acc: 0.9903\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1834 - acc: 0.9925 - val_loss: 0.1919 - val_acc: 0.9904\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1862 - acc: 0.9925 - val_loss: 0.1707 - val_acc: 0.9906\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1675 - acc: 0.9925 - val_loss: 0.1739 - val_acc: 0.9905\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1697 - acc: 0.9926 - val_loss: 0.1788 - val_acc: 0.9905\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1766 - acc: 0.9924 - val_loss: 0.1707 - val_acc: 0.9905\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1663 - acc: 0.9923 - val_loss: 0.1673 - val_acc: 0.9905\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1735 - acc: 0.9924 - val_loss: 0.1873 - val_acc: 0.9902\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.1845 - acc: 0.9923 - val_loss: 0.1792 - val_acc: 0.9907\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.1700 - acc: 0.9925 - val_loss: 0.1684 - val_acc: 0.9905\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1700 - acc: 0.9924 - val_loss: 0.1818 - val_acc: 0.9903\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1760 - acc: 0.9924 - val_loss: 0.1742 - val_acc: 0.9902\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.1709 - acc: 0.9924 - val_loss: 0.1753 - val_acc: 0.9900\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1780 - acc: 0.9922 - val_loss: 0.1811 - val_acc: 0.9901\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.1754 - acc: 0.9919 - val_loss: 0.1773 - val_acc: 0.9897\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0031 - acc: 0.9575 - val_loss: 0.0031 - val_acc: 0.9607\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9593 - val_loss: 0.0032 - val_acc: 0.9612\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9617\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 319us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0029 - acc: 0.9601 - val_loss: 0.0031 - val_acc: 0.9614\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0030 - acc: 0.9581 - val_loss: 0.0031 - val_acc: 0.9622\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0032 - val_acc: 0.9591\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0034 - acc: 0.9533 - val_loss: 0.0031 - val_acc: 0.9626\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 317us/step - loss: 0.0030 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9624\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0030 - acc: 0.9593 - val_loss: 0.0033 - val_acc: 0.9586\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0032 - acc: 0.9544 - val_loss: 0.0032 - val_acc: 0.9593\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9583 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 309us/step - loss: 0.0031 - acc: 0.9578 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0032 - val_acc: 0.9637\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0031 - acc: 0.9569 - val_loss: 0.0032 - val_acc: 0.9643\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9637\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0032 - val_acc: 0.9624\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0032 - acc: 0.9527 - val_loss: 0.0033 - val_acc: 0.9569\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 312us/step - loss: 0.0030 - acc: 0.9577 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0032 - val_acc: 0.9637\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0031 - val_acc: 0.9638\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0032 - val_acc: 0.9625\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0030 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9595\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0031 - acc: 0.9558 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0030 - acc: 0.9591 - val_loss: 0.0031 - val_acc: 0.9615\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 299us/step - loss: 0.0031 - acc: 0.9601 - val_loss: 0.0032 - val_acc: 0.9619\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 301us/step - loss: 0.0031 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0031 - acc: 0.9572 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0031 - acc: 0.9570 - val_loss: 0.0031 - val_acc: 0.9625\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 315us/step - loss: 0.0030 - acc: 0.9590 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 300us/step - loss: 0.0030 - acc: 0.9575 - val_loss: 0.0034 - val_acc: 0.9573\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 313us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0031 - val_acc: 0.9617\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0030 - acc: 0.9573 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0034 - val_acc: 0.9553\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0031 - acc: 0.9569 - val_loss: 0.0032 - val_acc: 0.9630\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 298us/step - loss: 0.0030 - acc: 0.9594 - val_loss: 0.0032 - val_acc: 0.9636\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0031 - acc: 0.9577 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 300us/step - loss: 0.0031 - acc: 0.9557 - val_loss: 0.0031 - val_acc: 0.9643\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 312us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0030 - acc: 0.9611 - val_loss: 0.0032 - val_acc: 0.9635\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.0031 - acc: 0.9581 - val_loss: 0.0031 - val_acc: 0.9615\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9586 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 300us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "start training round 28\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.2293 - acc: 0.6892 - val_loss: 0.2454 - val_acc: 0.6853\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2255 - acc: 0.6909 - val_loss: 0.2383 - val_acc: 0.6880\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2258 - acc: 0.6891 - val_loss: 0.2393 - val_acc: 0.6873\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2256 - acc: 0.6910 - val_loss: 0.2427 - val_acc: 0.6869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2287 - acc: 0.6899 - val_loss: 0.2511 - val_acc: 0.6854\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2262 - acc: 0.6910 - val_loss: 0.2377 - val_acc: 0.6899\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.2250 - acc: 0.6908 - val_loss: 0.2402 - val_acc: 0.6871\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2310 - acc: 0.6907 - val_loss: 0.2424 - val_acc: 0.6886\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2256 - acc: 0.6910 - val_loss: 0.2479 - val_acc: 0.6847\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 298us/step - loss: 0.2306 - acc: 0.6876 - val_loss: 0.2402 - val_acc: 0.6883\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.2274 - acc: 0.6898 - val_loss: 0.2444 - val_acc: 0.6849\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.2275 - acc: 0.6903 - val_loss: 0.2375 - val_acc: 0.6882\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2237 - acc: 0.6915 - val_loss: 0.2391 - val_acc: 0.6881\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2272 - acc: 0.6905 - val_loss: 0.2392 - val_acc: 0.6879\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.2271 - acc: 0.6911 - val_loss: 0.2401 - val_acc: 0.6869\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2258 - acc: 0.6913 - val_loss: 0.2429 - val_acc: 0.6880\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2245 - acc: 0.6908 - val_loss: 0.2421 - val_acc: 0.6851\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2272 - acc: 0.6894 - val_loss: 0.2378 - val_acc: 0.6886\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2249 - acc: 0.6915 - val_loss: 0.2496 - val_acc: 0.6876\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.2271 - acc: 0.6914 - val_loss: 0.2421 - val_acc: 0.6872\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 0.2276 - acc: 0.6892 - val_loss: 0.2420 - val_acc: 0.6867\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2244 - acc: 0.6912 - val_loss: 0.2375 - val_acc: 0.6893\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2282 - acc: 0.6892 - val_loss: 0.2508 - val_acc: 0.6819\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.2273 - acc: 0.6903 - val_loss: 0.2375 - val_acc: 0.6892\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2278 - acc: 0.6907 - val_loss: 0.2502 - val_acc: 0.6874\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.2308 - acc: 0.6895 - val_loss: 0.2412 - val_acc: 0.6878\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2253 - acc: 0.6900 - val_loss: 0.2416 - val_acc: 0.6874\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 0.2252 - acc: 0.6897 - val_loss: 0.2396 - val_acc: 0.6871\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.2253 - acc: 0.6897 - val_loss: 0.2370 - val_acc: 0.6899\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 0.2238 - acc: 0.6911 - val_loss: 0.2407 - val_acc: 0.6865\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2261 - acc: 0.6908 - val_loss: 0.2428 - val_acc: 0.6872\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.2266 - acc: 0.6899 - val_loss: 0.2401 - val_acc: 0.6871\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2315 - acc: 0.6888 - val_loss: 0.2399 - val_acc: 0.6879\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 298us/step - loss: 0.2244 - acc: 0.6910 - val_loss: 0.2379 - val_acc: 0.6891\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2245 - acc: 0.6896 - val_loss: 0.2388 - val_acc: 0.6881\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.2267 - acc: 0.6896 - val_loss: 0.2386 - val_acc: 0.6885\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.2263 - acc: 0.6911 - val_loss: 0.2389 - val_acc: 0.6873\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2257 - acc: 0.6905 - val_loss: 0.2439 - val_acc: 0.6858\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2271 - acc: 0.6906 - val_loss: 0.2443 - val_acc: 0.6862\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.2266 - acc: 0.6896 - val_loss: 0.2400 - val_acc: 0.6865\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2237 - acc: 0.6916 - val_loss: 0.2398 - val_acc: 0.6877\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.2303 - acc: 0.6880 - val_loss: 0.2376 - val_acc: 0.6891\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2239 - acc: 0.6913 - val_loss: 0.2446 - val_acc: 0.6875\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 298us/step - loss: 0.2293 - acc: 0.6897 - val_loss: 0.2369 - val_acc: 0.6893\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2235 - acc: 0.6916 - val_loss: 0.2379 - val_acc: 0.6886\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2276 - acc: 0.6897 - val_loss: 0.2412 - val_acc: 0.6870\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2253 - acc: 0.6910 - val_loss: 0.2446 - val_acc: 0.6891\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2302 - acc: 0.6901 - val_loss: 0.2387 - val_acc: 0.6888\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.2249 - acc: 0.6910 - val_loss: 0.2370 - val_acc: 0.6893\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 0.2258 - acc: 0.6900 - val_loss: 0.2364 - val_acc: 0.6896\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9551 - acc: 0.6805 - val_loss: 2.0883 - val_acc: 0.6754\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9670 - acc: 0.6804 - val_loss: 2.1324 - val_acc: 0.6785\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9304 - acc: 0.6808 - val_loss: 2.1081 - val_acc: 0.6788\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9391 - acc: 0.6799 - val_loss: 2.1380 - val_acc: 0.6745\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 1.9316 - acc: 0.6806 - val_loss: 2.0650 - val_acc: 0.6768\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9527 - acc: 0.6806 - val_loss: 2.0760 - val_acc: 0.6786\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9306 - acc: 0.6809 - val_loss: 2.0558 - val_acc: 0.6776\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 1.9135 - acc: 0.6808 - val_loss: 2.0424 - val_acc: 0.6786\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9790 - acc: 0.6804 - val_loss: 2.1633 - val_acc: 0.6755\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 281us/step - loss: 1.9443 - acc: 0.6802 - val_loss: 2.1305 - val_acc: 0.6765\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9264 - acc: 0.6806 - val_loss: 2.1139 - val_acc: 0.6791\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 1.9461 - acc: 0.6794 - val_loss: 2.0905 - val_acc: 0.6789\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9553 - acc: 0.6795 - val_loss: 2.0702 - val_acc: 0.6794\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9507 - acc: 0.6802 - val_loss: 2.0736 - val_acc: 0.6792\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 281us/step - loss: 1.9158 - acc: 0.6811 - val_loss: 2.0878 - val_acc: 0.6784\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9326 - acc: 0.6805 - val_loss: 2.1648 - val_acc: 0.6762\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9319 - acc: 0.6811 - val_loss: 2.0878 - val_acc: 0.6761\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9577 - acc: 0.6801 - val_loss: 2.2187 - val_acc: 0.6748\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9481 - acc: 0.6802 - val_loss: 2.0607 - val_acc: 0.6792\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9446 - acc: 0.6798 - val_loss: 2.2079 - val_acc: 0.6767\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 1.9611 - acc: 0.6800 - val_loss: 2.0877 - val_acc: 0.6772\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9428 - acc: 0.6809 - val_loss: 2.0923 - val_acc: 0.6777\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9354 - acc: 0.6801 - val_loss: 2.0872 - val_acc: 0.6779\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9360 - acc: 0.6797 - val_loss: 2.0510 - val_acc: 0.6781\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9459 - acc: 0.6793 - val_loss: 2.0896 - val_acc: 0.6772\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9645 - acc: 0.6802 - val_loss: 2.0748 - val_acc: 0.6754\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9264 - acc: 0.6807 - val_loss: 2.0999 - val_acc: 0.6756\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9201 - acc: 0.6802 - val_loss: 2.0841 - val_acc: 0.6793\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9198 - acc: 0.6810 - val_loss: 2.0851 - val_acc: 0.6785\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9674 - acc: 0.6795 - val_loss: 2.1195 - val_acc: 0.6770\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9331 - acc: 0.6807 - val_loss: 2.1522 - val_acc: 0.6748\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9520 - acc: 0.6811 - val_loss: 2.0688 - val_acc: 0.6777\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 1.9310 - acc: 0.6806 - val_loss: 2.0852 - val_acc: 0.6771\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9568 - acc: 0.6796 - val_loss: 2.1221 - val_acc: 0.6754\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9371 - acc: 0.6805 - val_loss: 2.0762 - val_acc: 0.6779\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9375 - acc: 0.6804 - val_loss: 2.1065 - val_acc: 0.6782\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9438 - acc: 0.6807 - val_loss: 2.1647 - val_acc: 0.6735\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9565 - acc: 0.6795 - val_loss: 2.0562 - val_acc: 0.6783\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9245 - acc: 0.6808 - val_loss: 2.1810 - val_acc: 0.6768\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9691 - acc: 0.6804 - val_loss: 2.0801 - val_acc: 0.6764\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9311 - acc: 0.6811 - val_loss: 2.1110 - val_acc: 0.6752\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9508 - acc: 0.6801 - val_loss: 2.1192 - val_acc: 0.6779\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9528 - acc: 0.6804 - val_loss: 2.1477 - val_acc: 0.6748\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 1.9488 - acc: 0.6808 - val_loss: 2.0798 - val_acc: 0.6779\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9364 - acc: 0.6797 - val_loss: 2.1072 - val_acc: 0.6793\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9771 - acc: 0.6796 - val_loss: 2.1099 - val_acc: 0.6778\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 1.9521 - acc: 0.6803 - val_loss: 2.0808 - val_acc: 0.6773\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9215 - acc: 0.6807 - val_loss: 2.0821 - val_acc: 0.6759\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9414 - acc: 0.6804 - val_loss: 2.0671 - val_acc: 0.6799\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9436 - acc: 0.6807 - val_loss: 2.1141 - val_acc: 0.6793\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1720 - acc: 0.9918 - val_loss: 0.1749 - val_acc: 0.9897\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1734 - acc: 0.9920 - val_loss: 0.1790 - val_acc: 0.9901\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1781 - acc: 0.9921 - val_loss: 0.1908 - val_acc: 0.9897\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1810 - acc: 0.9921 - val_loss: 0.1785 - val_acc: 0.9903\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1767 - acc: 0.9925 - val_loss: 0.1771 - val_acc: 0.9904\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1721 - acc: 0.9925 - val_loss: 0.1744 - val_acc: 0.9905\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1743 - acc: 0.9924 - val_loss: 0.1886 - val_acc: 0.9904\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1801 - acc: 0.9924 - val_loss: 0.1789 - val_acc: 0.9905\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.1800 - acc: 0.9925 - val_loss: 0.1812 - val_acc: 0.9904\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.1761 - acc: 0.9925 - val_loss: 0.1727 - val_acc: 0.9904\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.1675 - acc: 0.9925 - val_loss: 0.1674 - val_acc: 0.9905\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1686 - acc: 0.9926 - val_loss: 0.1756 - val_acc: 0.9905\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1754 - acc: 0.9926 - val_loss: 0.1719 - val_acc: 0.9903\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1700 - acc: 0.9925 - val_loss: 0.1713 - val_acc: 0.9903\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1716 - acc: 0.9924 - val_loss: 0.1740 - val_acc: 0.9902\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1784 - acc: 0.9918 - val_loss: 0.1800 - val_acc: 0.9895\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.1766 - acc: 0.9912 - val_loss: 0.1798 - val_acc: 0.9891\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1815 - acc: 0.9909 - val_loss: 0.1800 - val_acc: 0.9901\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1794 - acc: 0.9921 - val_loss: 0.1884 - val_acc: 0.9903\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1875 - acc: 0.9925 - val_loss: 0.1800 - val_acc: 0.9904\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1796 - acc: 0.9925 - val_loss: 0.1852 - val_acc: 0.9906\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1819 - acc: 0.9925 - val_loss: 0.1751 - val_acc: 0.9905\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1674 - acc: 0.9925 - val_loss: 0.1676 - val_acc: 0.9906\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.1627 - acc: 0.9926 - val_loss: 0.1672 - val_acc: 0.9906\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1729 - acc: 0.9923 - val_loss: 0.1824 - val_acc: 0.9899\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1771 - acc: 0.9921 - val_loss: 0.1811 - val_acc: 0.9902\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 0.1735 - acc: 0.9922 - val_loss: 0.1765 - val_acc: 0.9902\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1791 - acc: 0.9923 - val_loss: 0.1813 - val_acc: 0.9903\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1750 - acc: 0.9924 - val_loss: 0.1694 - val_acc: 0.9902\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1644 - acc: 0.9925 - val_loss: 0.1677 - val_acc: 0.9904\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1705 - acc: 0.9925 - val_loss: 0.1780 - val_acc: 0.9902\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1847 - acc: 0.9921 - val_loss: 0.1918 - val_acc: 0.9891\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1926 - acc: 0.9913 - val_loss: 0.1825 - val_acc: 0.9893\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1743 - acc: 0.9916 - val_loss: 0.1779 - val_acc: 0.9894\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.1803 - acc: 0.9919 - val_loss: 0.1846 - val_acc: 0.9900\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1740 - acc: 0.9925 - val_loss: 0.1716 - val_acc: 0.9906\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1663 - acc: 0.9926 - val_loss: 0.1635 - val_acc: 0.9906\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.1631 - acc: 0.9926 - val_loss: 0.1697 - val_acc: 0.9906\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 283us/step - loss: 0.1686 - acc: 0.9926 - val_loss: 0.1836 - val_acc: 0.9904\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1922 - acc: 0.9926 - val_loss: 0.1954 - val_acc: 0.9906\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1796 - acc: 0.9926 - val_loss: 0.1723 - val_acc: 0.9906\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1673 - acc: 0.9925 - val_loss: 0.1737 - val_acc: 0.9902\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1738 - acc: 0.9924 - val_loss: 0.1869 - val_acc: 0.9899\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.1861 - acc: 0.9918 - val_loss: 0.1863 - val_acc: 0.9898\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1750 - acc: 0.9924 - val_loss: 0.1677 - val_acc: 0.9905\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1670 - acc: 0.9925 - val_loss: 0.1756 - val_acc: 0.9903\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1678 - acc: 0.9925 - val_loss: 0.1691 - val_acc: 0.9903\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.1736 - acc: 0.9925 - val_loss: 0.1939 - val_acc: 0.9905\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 279us/step - loss: 0.1867 - acc: 0.9926 - val_loss: 0.1850 - val_acc: 0.9907\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1798 - acc: 0.9924 - val_loss: 0.1768 - val_acc: 0.9900\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 299us/step - loss: 0.0030 - acc: 0.9597 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9624\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9587\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 312us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0030 - acc: 0.9589 - val_loss: 0.0032 - val_acc: 0.9596\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0031 - acc: 0.9567 - val_loss: 0.0034 - val_acc: 0.9596\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0032 - acc: 0.9533 - val_loss: 0.0032 - val_acc: 0.9638\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0033 - val_acc: 0.9633\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 313us/step - loss: 0.0031 - acc: 0.9574 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0030 - acc: 0.9589 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0030 - acc: 0.9583 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 301us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0029 - acc: 0.9597 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0033 - val_acc: 0.9585\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 301us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 313us/step - loss: 0.0030 - acc: 0.9588 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 313us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9624\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9611\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0032 - val_acc: 0.9611\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0031 - acc: 0.9561 - val_loss: 0.0035 - val_acc: 0.9544\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0034 - acc: 0.9502 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9638\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 309us/step - loss: 0.0030 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9635\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0030 - acc: 0.9591 - val_loss: 0.0032 - val_acc: 0.9612\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0030 - acc: 0.9579 - val_loss: 0.0034 - val_acc: 0.9570\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0032 - acc: 0.9549 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 312us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9603 - val_loss: 0.0032 - val_acc: 0.9638\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0031 - val_acc: 0.9638\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9633\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0031 - acc: 0.9592 - val_loss: 0.0034 - val_acc: 0.9518\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 309us/step - loss: 0.0031 - acc: 0.9554 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 313us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0035 - val_acc: 0.9601\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 304us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9609\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0030 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0031 - acc: 0.9565 - val_loss: 0.0033 - val_acc: 0.9600\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0029 - acc: 0.9589 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 309us/step - loss: 0.0029 - acc: 0.9601 - val_loss: 0.0031 - val_acc: 0.9601\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0029 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9615\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0030 - val_acc: 0.9640\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9635\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0031 - acc: 0.9564 - val_loss: 0.0031 - val_acc: 0.9638\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 301us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0033 - val_acc: 0.9626\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0031 - acc: 0.9533 - val_loss: 0.0031 - val_acc: 0.9616\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 303us/step - loss: 0.0030 - acc: 0.9580 - val_loss: 0.0033 - val_acc: 0.9603\n",
      "start training round 29\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2261 - acc: 0.6907 - val_loss: 0.2457 - val_acc: 0.6865\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2287 - acc: 0.6897 - val_loss: 0.2387 - val_acc: 0.6893\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 283us/step - loss: 0.2266 - acc: 0.6899 - val_loss: 0.2376 - val_acc: 0.6875\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2259 - acc: 0.6901 - val_loss: 0.2408 - val_acc: 0.6859\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2267 - acc: 0.6897 - val_loss: 0.2491 - val_acc: 0.6846\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2281 - acc: 0.6899 - val_loss: 0.2411 - val_acc: 0.6871\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2264 - acc: 0.6901 - val_loss: 0.2376 - val_acc: 0.6888\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2255 - acc: 0.6910 - val_loss: 0.2428 - val_acc: 0.6871\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2274 - acc: 0.6891 - val_loss: 0.2374 - val_acc: 0.6872\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2262 - acc: 0.6898 - val_loss: 0.2396 - val_acc: 0.6880\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.2246 - acc: 0.6913 - val_loss: 0.2356 - val_acc: 0.6895\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2298 - acc: 0.6911 - val_loss: 0.2378 - val_acc: 0.6899\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.2246 - acc: 0.6918 - val_loss: 0.2366 - val_acc: 0.6898\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2246 - acc: 0.6903 - val_loss: 0.2378 - val_acc: 0.6882\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 283us/step - loss: 0.2258 - acc: 0.6905 - val_loss: 0.2439 - val_acc: 0.6868\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2266 - acc: 0.6894 - val_loss: 0.2400 - val_acc: 0.6875\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.2263 - acc: 0.6902 - val_loss: 0.2373 - val_acc: 0.6878\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2257 - acc: 0.6912 - val_loss: 0.2403 - val_acc: 0.6891\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2251 - acc: 0.6907 - val_loss: 0.2370 - val_acc: 0.6903\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2279 - acc: 0.6915 - val_loss: 0.2393 - val_acc: 0.6905\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.2229 - acc: 0.6918 - val_loss: 0.2428 - val_acc: 0.6878\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2281 - acc: 0.6913 - val_loss: 0.2425 - val_acc: 0.6871\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2263 - acc: 0.6902 - val_loss: 0.2387 - val_acc: 0.6896\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.2250 - acc: 0.6905 - val_loss: 0.2394 - val_acc: 0.6880\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 282us/step - loss: 0.2281 - acc: 0.6886 - val_loss: 0.2366 - val_acc: 0.6881\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 281us/step - loss: 0.2284 - acc: 0.6892 - val_loss: 0.2387 - val_acc: 0.6891\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.2260 - acc: 0.6904 - val_loss: 0.2381 - val_acc: 0.6876\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2259 - acc: 0.6901 - val_loss: 0.2361 - val_acc: 0.6896\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.2252 - acc: 0.6919 - val_loss: 0.2411 - val_acc: 0.6882\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2261 - acc: 0.6914 - val_loss: 0.2358 - val_acc: 0.6906\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2242 - acc: 0.6921 - val_loss: 0.2456 - val_acc: 0.6866\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2261 - acc: 0.6911 - val_loss: 0.2372 - val_acc: 0.6879\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2270 - acc: 0.6899 - val_loss: 0.2414 - val_acc: 0.6878\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.2269 - acc: 0.6907 - val_loss: 0.2373 - val_acc: 0.6896\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2244 - acc: 0.6917 - val_loss: 0.2374 - val_acc: 0.6890\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.2250 - acc: 0.6894 - val_loss: 0.2389 - val_acc: 0.6884\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2249 - acc: 0.6895 - val_loss: 0.2406 - val_acc: 0.6866\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.2246 - acc: 0.6916 - val_loss: 0.2450 - val_acc: 0.6885\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.2292 - acc: 0.6907 - val_loss: 0.2402 - val_acc: 0.6885\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2253 - acc: 0.6905 - val_loss: 0.2387 - val_acc: 0.6874\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2261 - acc: 0.6903 - val_loss: 0.2389 - val_acc: 0.6899\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 283us/step - loss: 0.2259 - acc: 0.6909 - val_loss: 0.2383 - val_acc: 0.6884\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.2264 - acc: 0.6896 - val_loss: 0.2408 - val_acc: 0.6875\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.2241 - acc: 0.6911 - val_loss: 0.2369 - val_acc: 0.6884\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.2262 - acc: 0.6910 - val_loss: 0.2439 - val_acc: 0.6869\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2252 - acc: 0.6917 - val_loss: 0.2495 - val_acc: 0.6875\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2284 - acc: 0.6905 - val_loss: 0.2424 - val_acc: 0.6861\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2271 - acc: 0.6906 - val_loss: 0.2435 - val_acc: 0.6862\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2270 - acc: 0.6904 - val_loss: 0.2365 - val_acc: 0.6887\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 0.2216 - acc: 0.6926 - val_loss: 0.2357 - val_acc: 0.6888\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9632 - acc: 0.6797 - val_loss: 2.0772 - val_acc: 0.6788\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 1.9380 - acc: 0.6797 - val_loss: 2.0634 - val_acc: 0.6790\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9265 - acc: 0.6803 - val_loss: 2.0903 - val_acc: 0.6793\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9493 - acc: 0.6798 - val_loss: 2.1049 - val_acc: 0.6782\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9389 - acc: 0.6806 - val_loss: 2.1057 - val_acc: 0.6797\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 1.9613 - acc: 0.6809 - val_loss: 2.0680 - val_acc: 0.6794\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9391 - acc: 0.6806 - val_loss: 2.1360 - val_acc: 0.6765\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 284us/step - loss: 1.9629 - acc: 0.6799 - val_loss: 2.0555 - val_acc: 0.6771\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9236 - acc: 0.6807 - val_loss: 2.1952 - val_acc: 0.6778\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9407 - acc: 0.6805 - val_loss: 2.1049 - val_acc: 0.6797\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9495 - acc: 0.6798 - val_loss: 2.0630 - val_acc: 0.6810\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9675 - acc: 0.6805 - val_loss: 2.0870 - val_acc: 0.6780\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9481 - acc: 0.6800 - val_loss: 2.0546 - val_acc: 0.6775\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9379 - acc: 0.6806 - val_loss: 2.1168 - val_acc: 0.6776\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9403 - acc: 0.6812 - val_loss: 2.0607 - val_acc: 0.6795\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9373 - acc: 0.6808 - val_loss: 2.3678 - val_acc: 0.6736\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9513 - acc: 0.6797 - val_loss: 2.1007 - val_acc: 0.6755\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 301us/step - loss: 1.9534 - acc: 0.6809 - val_loss: 2.2027 - val_acc: 0.6778\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9632 - acc: 0.6800 - val_loss: 2.0761 - val_acc: 0.6765\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 1.9413 - acc: 0.6800 - val_loss: 2.2040 - val_acc: 0.6727\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9293 - acc: 0.6805 - val_loss: 2.0567 - val_acc: 0.6775\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 1.9509 - acc: 0.6798 - val_loss: 2.0840 - val_acc: 0.6776\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9417 - acc: 0.6798 - val_loss: 2.1167 - val_acc: 0.6782\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9480 - acc: 0.6807 - val_loss: 2.0709 - val_acc: 0.6776\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9301 - acc: 0.6800 - val_loss: 2.0835 - val_acc: 0.6783\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9520 - acc: 0.6800 - val_loss: 2.2054 - val_acc: 0.6780\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9585 - acc: 0.6801 - val_loss: 2.1068 - val_acc: 0.6759\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9462 - acc: 0.6810 - val_loss: 2.0800 - val_acc: 0.6791\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 1.9274 - acc: 0.6809 - val_loss: 2.1320 - val_acc: 0.6746\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9161 - acc: 0.6806 - val_loss: 2.0546 - val_acc: 0.6769\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9273 - acc: 0.6798 - val_loss: 2.0733 - val_acc: 0.6776\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9566 - acc: 0.6794 - val_loss: 2.1169 - val_acc: 0.6785\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9669 - acc: 0.6802 - val_loss: 2.0744 - val_acc: 0.6785\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 1.9309 - acc: 0.6796 - val_loss: 2.0826 - val_acc: 0.6780\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9408 - acc: 0.6800 - val_loss: 2.0617 - val_acc: 0.6794\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9483 - acc: 0.6805 - val_loss: 2.0686 - val_acc: 0.6765\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 300us/step - loss: 1.9305 - acc: 0.6809 - val_loss: 2.0767 - val_acc: 0.6777\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 1.9277 - acc: 0.6802 - val_loss: 2.0794 - val_acc: 0.6778\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 299us/step - loss: 1.9642 - acc: 0.6798 - val_loss: 2.1082 - val_acc: 0.6743\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 1.9415 - acc: 0.6803 - val_loss: 2.0871 - val_acc: 0.6756\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 1.9433 - acc: 0.6798 - val_loss: 2.1061 - val_acc: 0.6787\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9683 - acc: 0.6809 - val_loss: 2.0464 - val_acc: 0.6803\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 299us/step - loss: 1.9279 - acc: 0.6803 - val_loss: 2.0973 - val_acc: 0.6778\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9588 - acc: 0.6803 - val_loss: 2.1407 - val_acc: 0.6779\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 1.9452 - acc: 0.6798 - val_loss: 2.1078 - val_acc: 0.6767\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9548 - acc: 0.6805 - val_loss: 2.1518 - val_acc: 0.6727\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 1.9592 - acc: 0.6802 - val_loss: 2.0682 - val_acc: 0.6783\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 1.9237 - acc: 0.6798 - val_loss: 2.0404 - val_acc: 0.6787\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9164 - acc: 0.6806 - val_loss: 2.0806 - val_acc: 0.6771\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 298us/step - loss: 1.9331 - acc: 0.6807 - val_loss: 2.0625 - val_acc: 0.6798\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.1746 - acc: 0.9917 - val_loss: 0.1826 - val_acc: 0.9893\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 301us/step - loss: 0.1748 - acc: 0.9916 - val_loss: 0.1743 - val_acc: 0.9900\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.1750 - acc: 0.9916 - val_loss: 0.1759 - val_acc: 0.9898\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1717 - acc: 0.9919 - val_loss: 0.1761 - val_acc: 0.9902\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.1708 - acc: 0.9924 - val_loss: 0.1725 - val_acc: 0.9905\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1722 - acc: 0.9924 - val_loss: 0.1775 - val_acc: 0.9906\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.1752 - acc: 0.9926 - val_loss: 0.1859 - val_acc: 0.9905\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1842 - acc: 0.9926 - val_loss: 0.1901 - val_acc: 0.9905\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1816 - acc: 0.9926 - val_loss: 0.1726 - val_acc: 0.9904\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.1719 - acc: 0.9926 - val_loss: 0.1817 - val_acc: 0.9905\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1743 - acc: 0.9925 - val_loss: 0.1692 - val_acc: 0.9903\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1710 - acc: 0.9923 - val_loss: 0.1663 - val_acc: 0.9903\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1692 - acc: 0.9921 - val_loss: 0.1791 - val_acc: 0.9897\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1728 - acc: 0.9920 - val_loss: 0.1685 - val_acc: 0.9902\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1640 - acc: 0.9923 - val_loss: 0.1656 - val_acc: 0.9903\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 298us/step - loss: 0.1636 - acc: 0.9924 - val_loss: 0.1740 - val_acc: 0.9904\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1747 - acc: 0.9922 - val_loss: 0.1805 - val_acc: 0.9900\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1853 - acc: 0.9920 - val_loss: 0.1997 - val_acc: 0.9902\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.1805 - acc: 0.9923 - val_loss: 0.1773 - val_acc: 0.9903\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1715 - acc: 0.9924 - val_loss: 0.1771 - val_acc: 0.9906\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1707 - acc: 0.9926 - val_loss: 0.1675 - val_acc: 0.9907\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 299us/step - loss: 0.1684 - acc: 0.9921 - val_loss: 0.1817 - val_acc: 0.9889\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1846 - acc: 0.9910 - val_loss: 0.1951 - val_acc: 0.9889\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1859 - acc: 0.9917 - val_loss: 0.1820 - val_acc: 0.9904\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.1691 - acc: 0.9925 - val_loss: 0.1676 - val_acc: 0.9907\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1691 - acc: 0.9926 - val_loss: 0.1709 - val_acc: 0.9907\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1758 - acc: 0.9924 - val_loss: 0.1842 - val_acc: 0.9898\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1780 - acc: 0.9920 - val_loss: 0.1743 - val_acc: 0.9902\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1697 - acc: 0.9924 - val_loss: 0.1865 - val_acc: 0.9893\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1832 - acc: 0.9916 - val_loss: 0.1738 - val_acc: 0.9897\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.1658 - acc: 0.9922 - val_loss: 0.1680 - val_acc: 0.9903\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1673 - acc: 0.9922 - val_loss: 0.1724 - val_acc: 0.9902\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1678 - acc: 0.9925 - val_loss: 0.1682 - val_acc: 0.9904\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1680 - acc: 0.9925 - val_loss: 0.1757 - val_acc: 0.9904\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.1830 - acc: 0.9926 - val_loss: 0.1814 - val_acc: 0.9903\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.1754 - acc: 0.9925 - val_loss: 0.1709 - val_acc: 0.9905\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.1725 - acc: 0.9924 - val_loss: 0.1868 - val_acc: 0.9901\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.1799 - acc: 0.9923 - val_loss: 0.1759 - val_acc: 0.9902\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.1780 - acc: 0.9923 - val_loss: 0.1713 - val_acc: 0.9901\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.1678 - acc: 0.9924 - val_loss: 0.1751 - val_acc: 0.9899\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.1676 - acc: 0.9922 - val_loss: 0.1762 - val_acc: 0.9889\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1732 - acc: 0.9918 - val_loss: 0.1719 - val_acc: 0.9902\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.1670 - acc: 0.9924 - val_loss: 0.1696 - val_acc: 0.9902\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 0.1659 - acc: 0.9922 - val_loss: 0.1693 - val_acc: 0.9902\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.1736 - acc: 0.9919 - val_loss: 0.1884 - val_acc: 0.9898\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.1849 - acc: 0.9920 - val_loss: 0.1964 - val_acc: 0.9899\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.1835 - acc: 0.9923 - val_loss: 0.1761 - val_acc: 0.9903\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.1675 - acc: 0.9926 - val_loss: 0.1683 - val_acc: 0.9907\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 0.1754 - acc: 0.9925 - val_loss: 0.1773 - val_acc: 0.9905\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.1701 - acc: 0.9924 - val_loss: 0.1657 - val_acc: 0.9907\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 309us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 312us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9582 - val_loss: 0.0031 - val_acc: 0.9611\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0031 - val_acc: 0.9627\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 318us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0030 - acc: 0.9588 - val_loss: 0.0032 - val_acc: 0.9586\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 319us/step - loss: 0.0030 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 314us/step - loss: 0.0030 - acc: 0.9569 - val_loss: 0.0031 - val_acc: 0.9612\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0030 - acc: 0.9584 - val_loss: 0.0031 - val_acc: 0.9638\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 325us/step - loss: 0.0030 - acc: 0.9613 - val_loss: 0.0035 - val_acc: 0.9590\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0031 - acc: 0.9574 - val_loss: 0.0031 - val_acc: 0.9643\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0030 - acc: 0.9585 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 314us/step - loss: 0.0030 - acc: 0.9567 - val_loss: 0.0031 - val_acc: 0.9643\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0030 - val_acc: 0.9640\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0030 - acc: 0.9593 - val_loss: 0.0031 - val_acc: 0.9603\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0030 - acc: 0.9569 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 3s 309us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0032 - val_acc: 0.9603\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0031 - acc: 0.9546 - val_loss: 0.0032 - val_acc: 0.9608\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0030 - acc: 0.9559 - val_loss: 0.0032 - val_acc: 0.9609\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 317us/step - loss: 0.0030 - acc: 0.9572 - val_loss: 0.0041 - val_acc: 0.9462\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0031 - acc: 0.9549 - val_loss: 0.0032 - val_acc: 0.9642\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9590 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 3s 306us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 317us/step - loss: 0.0029 - acc: 0.9600 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0029 - acc: 0.9607 - val_loss: 0.0037 - val_acc: 0.9571\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 313us/step - loss: 0.0033 - acc: 0.9502 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 3s 309us/step - loss: 0.0030 - acc: 0.9585 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 305us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 308us/step - loss: 0.0031 - acc: 0.9567 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 312us/step - loss: 0.0029 - acc: 0.9614 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 312us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0032 - val_acc: 0.9642\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 3s 316us/step - loss: 0.0030 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 315us/step - loss: 0.0030 - acc: 0.9606 - val_loss: 0.0031 - val_acc: 0.9644\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 317us/step - loss: 0.0029 - acc: 0.9614 - val_loss: 0.0031 - val_acc: 0.9619\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 3s 321us/step - loss: 0.0030 - acc: 0.9574 - val_loss: 0.0033 - val_acc: 0.9555\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 318us/step - loss: 0.0029 - acc: 0.9599 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 3s 307us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 315us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0030 - val_acc: 0.9641\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0029 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9606 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0030 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 3s 315us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9624\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 3s 311us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9604\n",
      "start training round 30\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2240 - acc: 0.6912 - val_loss: 0.2444 - val_acc: 0.6856\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2269 - acc: 0.6903 - val_loss: 0.2346 - val_acc: 0.6906\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2238 - acc: 0.6911 - val_loss: 0.2375 - val_acc: 0.6885\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2281 - acc: 0.6903 - val_loss: 0.2355 - val_acc: 0.6900\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.2236 - acc: 0.6910 - val_loss: 0.2435 - val_acc: 0.6835\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.2273 - acc: 0.6895 - val_loss: 0.2386 - val_acc: 0.6887\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.2230 - acc: 0.6923 - val_loss: 0.2373 - val_acc: 0.6896\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 3s 302us/step - loss: 0.2241 - acc: 0.6914 - val_loss: 0.2370 - val_acc: 0.6898\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2226 - acc: 0.6919 - val_loss: 0.2396 - val_acc: 0.6902\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 0.2262 - acc: 0.6897 - val_loss: 0.2375 - val_acc: 0.6883\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2248 - acc: 0.6911 - val_loss: 0.2361 - val_acc: 0.6894\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2264 - acc: 0.6909 - val_loss: 0.2375 - val_acc: 0.6886\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.2257 - acc: 0.6902 - val_loss: 0.2412 - val_acc: 0.6879\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2271 - acc: 0.6912 - val_loss: 0.2358 - val_acc: 0.6901\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.2237 - acc: 0.6917 - val_loss: 0.2378 - val_acc: 0.6895\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.2235 - acc: 0.6921 - val_loss: 0.2414 - val_acc: 0.6879\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2265 - acc: 0.6907 - val_loss: 0.2376 - val_acc: 0.6880\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 3s 298us/step - loss: 0.2259 - acc: 0.6914 - val_loss: 0.2376 - val_acc: 0.6890\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.2228 - acc: 0.6921 - val_loss: 0.2394 - val_acc: 0.6889\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2292 - acc: 0.6905 - val_loss: 0.2406 - val_acc: 0.6896\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.2275 - acc: 0.6901 - val_loss: 0.2386 - val_acc: 0.6886\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2233 - acc: 0.6914 - val_loss: 0.2402 - val_acc: 0.6891\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2236 - acc: 0.6907 - val_loss: 0.2383 - val_acc: 0.6883\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2223 - acc: 0.6916 - val_loss: 0.2356 - val_acc: 0.6886\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2264 - acc: 0.6907 - val_loss: 0.2404 - val_acc: 0.6874\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2243 - acc: 0.6912 - val_loss: 0.2364 - val_acc: 0.6902\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.2248 - acc: 0.6909 - val_loss: 0.2410 - val_acc: 0.6875\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 0.2246 - acc: 0.6911 - val_loss: 0.2387 - val_acc: 0.6875\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 295us/step - loss: 0.2267 - acc: 0.6907 - val_loss: 0.2461 - val_acc: 0.6869\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.2292 - acc: 0.6909 - val_loss: 0.2375 - val_acc: 0.6892\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 0.2271 - acc: 0.6903 - val_loss: 0.2379 - val_acc: 0.6886\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2249 - acc: 0.6907 - val_loss: 0.2368 - val_acc: 0.6881\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 0.2211 - acc: 0.6925 - val_loss: 0.2350 - val_acc: 0.6902\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2237 - acc: 0.6910 - val_loss: 0.2370 - val_acc: 0.6888\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.2269 - acc: 0.6904 - val_loss: 0.2396 - val_acc: 0.6877\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.2279 - acc: 0.6893 - val_loss: 0.2381 - val_acc: 0.6883\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.2255 - acc: 0.6911 - val_loss: 0.2381 - val_acc: 0.6897\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 0.2238 - acc: 0.6920 - val_loss: 0.2357 - val_acc: 0.6903\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 0.2224 - acc: 0.6915 - val_loss: 0.2348 - val_acc: 0.6900\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2239 - acc: 0.6921 - val_loss: 0.2401 - val_acc: 0.6895\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 0.2249 - acc: 0.6918 - val_loss: 0.2370 - val_acc: 0.6899\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.2264 - acc: 0.6897 - val_loss: 0.2376 - val_acc: 0.6888\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2311 - acc: 0.6913 - val_loss: 0.2354 - val_acc: 0.6901\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 0.2244 - acc: 0.6902 - val_loss: 0.2363 - val_acc: 0.6884\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.2217 - acc: 0.6925 - val_loss: 0.2381 - val_acc: 0.6878\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 0.2267 - acc: 0.6917 - val_loss: 0.2365 - val_acc: 0.6904\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 0.2220 - acc: 0.6926 - val_loss: 0.2380 - val_acc: 0.6872\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 0.2257 - acc: 0.6905 - val_loss: 0.2406 - val_acc: 0.6856\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 289us/step - loss: 0.2244 - acc: 0.6914 - val_loss: 0.2387 - val_acc: 0.6887\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 0.2294 - acc: 0.6913 - val_loss: 0.2426 - val_acc: 0.6861\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 282us/step - loss: 1.9799 - acc: 0.6787 - val_loss: 2.0404 - val_acc: 0.6792\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9270 - acc: 0.6809 - val_loss: 2.0908 - val_acc: 0.6753\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 1.9467 - acc: 0.6799 - val_loss: 2.0883 - val_acc: 0.6785\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9362 - acc: 0.6801 - val_loss: 2.0648 - val_acc: 0.6773\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9588 - acc: 0.6808 - val_loss: 2.1206 - val_acc: 0.6744\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9662 - acc: 0.6800 - val_loss: 2.0750 - val_acc: 0.6785\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9299 - acc: 0.6809 - val_loss: 2.0816 - val_acc: 0.6776\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9148 - acc: 0.6804 - val_loss: 2.1042 - val_acc: 0.6768\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9214 - acc: 0.6802 - val_loss: 2.0683 - val_acc: 0.6788\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 1.9243 - acc: 0.6808 - val_loss: 2.0321 - val_acc: 0.6801\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9438 - acc: 0.6803 - val_loss: 2.1008 - val_acc: 0.6795\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 3s 297us/step - loss: 1.9491 - acc: 0.6805 - val_loss: 2.1094 - val_acc: 0.6804\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9170 - acc: 0.6812 - val_loss: 2.0650 - val_acc: 0.6802\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9294 - acc: 0.6808 - val_loss: 2.1021 - val_acc: 0.6767\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 3s 296us/step - loss: 1.9472 - acc: 0.6803 - val_loss: 2.0737 - val_acc: 0.6763\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9478 - acc: 0.6804 - val_loss: 2.0585 - val_acc: 0.6776\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 285us/step - loss: 1.9536 - acc: 0.6796 - val_loss: 2.0453 - val_acc: 0.6787\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9458 - acc: 0.6807 - val_loss: 2.1578 - val_acc: 0.6777\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9486 - acc: 0.6804 - val_loss: 2.0857 - val_acc: 0.6787\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9470 - acc: 0.6804 - val_loss: 2.1731 - val_acc: 0.6776\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 1.9385 - acc: 0.6798 - val_loss: 2.0868 - val_acc: 0.6770\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 287us/step - loss: 1.9271 - acc: 0.6804 - val_loss: 2.1575 - val_acc: 0.6730\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9435 - acc: 0.6801 - val_loss: 2.0505 - val_acc: 0.6775\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9229 - acc: 0.6802 - val_loss: 2.0811 - val_acc: 0.6789\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9535 - acc: 0.6801 - val_loss: 2.0946 - val_acc: 0.6783\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9389 - acc: 0.6806 - val_loss: 2.0680 - val_acc: 0.6797\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9331 - acc: 0.6804 - val_loss: 2.1456 - val_acc: 0.6789\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 1.9445 - acc: 0.6799 - val_loss: 2.0991 - val_acc: 0.6766\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 3s 298us/step - loss: 1.9500 - acc: 0.6807 - val_loss: 2.1481 - val_acc: 0.6783\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 291us/step - loss: 1.9665 - acc: 0.6801 - val_loss: 2.0463 - val_acc: 0.6788\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 1.9312 - acc: 0.6814 - val_loss: 2.0978 - val_acc: 0.6764\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9326 - acc: 0.6803 - val_loss: 2.1115 - val_acc: 0.6728\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9316 - acc: 0.6792 - val_loss: 2.0750 - val_acc: 0.6770\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 288us/step - loss: 1.9503 - acc: 0.6807 - val_loss: 2.0786 - val_acc: 0.6794\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9441 - acc: 0.6801 - val_loss: 2.0556 - val_acc: 0.6796\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9392 - acc: 0.6810 - val_loss: 2.0528 - val_acc: 0.6792\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9277 - acc: 0.6804 - val_loss: 2.1845 - val_acc: 0.6757\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 3s 292us/step - loss: 1.9624 - acc: 0.6808 - val_loss: 2.0798 - val_acc: 0.6764\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9312 - acc: 0.6805 - val_loss: 2.0694 - val_acc: 0.6772\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 286us/step - loss: 1.9447 - acc: 0.6803 - val_loss: 2.0750 - val_acc: 0.6770\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 1.9085 - acc: 0.6809 - val_loss: 2.0633 - val_acc: 0.6775\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9223 - acc: 0.6807 - val_loss: 2.1438 - val_acc: 0.6767\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 292us/step - loss: 1.9819 - acc: 0.6792 - val_loss: 2.1187 - val_acc: 0.6790\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 3s 294us/step - loss: 1.9507 - acc: 0.6798 - val_loss: 2.1406 - val_acc: 0.6762\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9393 - acc: 0.6796 - val_loss: 2.0703 - val_acc: 0.6796\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 3s 293us/step - loss: 1.9075 - acc: 0.6814 - val_loss: 2.0323 - val_acc: 0.6795\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 290us/step - loss: 1.9111 - acc: 0.6808 - val_loss: 2.0876 - val_acc: 0.6795\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 1.9558 - acc: 0.6808 - val_loss: 2.0873 - val_acc: 0.6802\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 1.9344 - acc: 0.6806 - val_loss: 2.1144 - val_acc: 0.6790\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9417 - acc: 0.6806 - val_loss: 2.0645 - val_acc: 0.6800\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1657 - acc: 0.9925 - val_loss: 0.1707 - val_acc: 0.9907\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.1738 - acc: 0.9926 - val_loss: 0.1778 - val_acc: 0.9906\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1708 - acc: 0.9925 - val_loss: 0.1731 - val_acc: 0.9903\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1790 - acc: 0.9921 - val_loss: 0.1902 - val_acc: 0.9893\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1767 - acc: 0.9920 - val_loss: 0.1681 - val_acc: 0.9905\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1628 - acc: 0.9926 - val_loss: 0.1640 - val_acc: 0.9907\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1652 - acc: 0.9925 - val_loss: 0.1721 - val_acc: 0.9906\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1856 - acc: 0.9925 - val_loss: 0.1982 - val_acc: 0.9903\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1899 - acc: 0.9916 - val_loss: 0.1982 - val_acc: 0.9893\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1750 - acc: 0.9918 - val_loss: 0.1871 - val_acc: 0.9895\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1725 - acc: 0.9917 - val_loss: 0.1652 - val_acc: 0.9901\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1699 - acc: 0.9922 - val_loss: 0.1743 - val_acc: 0.9900\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1728 - acc: 0.9926 - val_loss: 0.1831 - val_acc: 0.9903\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1804 - acc: 0.9924 - val_loss: 0.1785 - val_acc: 0.9903\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1699 - acc: 0.9925 - val_loss: 0.1654 - val_acc: 0.9903\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1647 - acc: 0.9926 - val_loss: 0.1642 - val_acc: 0.9907\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1614 - acc: 0.9925 - val_loss: 0.1629 - val_acc: 0.9906\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1631 - acc: 0.9925 - val_loss: 0.1684 - val_acc: 0.9905\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1726 - acc: 0.9924 - val_loss: 0.1735 - val_acc: 0.9905\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1807 - acc: 0.9924 - val_loss: 0.2110 - val_acc: 0.9896\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1848 - acc: 0.9916 - val_loss: 0.1736 - val_acc: 0.9899\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1657 - acc: 0.9923 - val_loss: 0.1673 - val_acc: 0.9904\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1637 - acc: 0.9926 - val_loss: 0.1656 - val_acc: 0.9904\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1734 - acc: 0.9925 - val_loss: 0.1807 - val_acc: 0.9904\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1779 - acc: 0.9925 - val_loss: 0.1889 - val_acc: 0.9907\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1909 - acc: 0.9925 - val_loss: 0.1852 - val_acc: 0.9904\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1759 - acc: 0.9919 - val_loss: 0.1740 - val_acc: 0.9900\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1696 - acc: 0.9919 - val_loss: 0.1724 - val_acc: 0.9902\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1715 - acc: 0.9920 - val_loss: 0.1722 - val_acc: 0.9905\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.1739 - acc: 0.9924 - val_loss: 0.1721 - val_acc: 0.9906\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1719 - acc: 0.9926 - val_loss: 0.1749 - val_acc: 0.9906\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.1816 - acc: 0.9925 - val_loss: 0.1715 - val_acc: 0.9904\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 249us/step - loss: 0.1677 - acc: 0.9926 - val_loss: 0.1731 - val_acc: 0.9905\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.1747 - acc: 0.9926 - val_loss: 0.1708 - val_acc: 0.9906\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.1654 - acc: 0.9927 - val_loss: 0.1667 - val_acc: 0.9906\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.1614 - acc: 0.9927 - val_loss: 0.1624 - val_acc: 0.9905\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.1603 - acc: 0.9926 - val_loss: 0.1646 - val_acc: 0.9906\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.1658 - acc: 0.9925 - val_loss: 0.1795 - val_acc: 0.9905\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.1853 - acc: 0.9920 - val_loss: 0.1785 - val_acc: 0.9902\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.1772 - acc: 0.9918 - val_loss: 0.1769 - val_acc: 0.9900\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.1698 - acc: 0.9918 - val_loss: 0.1664 - val_acc: 0.9903\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.1656 - acc: 0.9921 - val_loss: 0.1690 - val_acc: 0.9899\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1754 - acc: 0.9914 - val_loss: 0.1847 - val_acc: 0.9901\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1874 - acc: 0.9923 - val_loss: 0.1949 - val_acc: 0.9908\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1835 - acc: 0.9925 - val_loss: 0.1776 - val_acc: 0.9903\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.1710 - acc: 0.9924 - val_loss: 0.1696 - val_acc: 0.9903\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - ETA: 0s - loss: 0.1684 - acc: 0.991 - 2s 234us/step - loss: 0.1684 - acc: 0.9919 - val_loss: 0.1736 - val_acc: 0.9902\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1686 - acc: 0.9923 - val_loss: 0.1698 - val_acc: 0.9903\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.1638 - acc: 0.9925 - val_loss: 0.1649 - val_acc: 0.9906\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.1662 - acc: 0.9927 - val_loss: 0.1682 - val_acc: 0.9906\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0032 - acc: 0.9550 - val_loss: 0.0031 - val_acc: 0.9617\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9621\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0031 - acc: 0.9550 - val_loss: 0.0032 - val_acc: 0.9591\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9595\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9584 - val_loss: 0.0030 - val_acc: 0.9631\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9601 - val_loss: 0.0031 - val_acc: 0.9625\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9603\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9571 - val_loss: 0.0030 - val_acc: 0.9630\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0030 - val_acc: 0.9643\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0031 - acc: 0.9563 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0031 - acc: 0.9550 - val_loss: 0.0031 - val_acc: 0.9643\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9611 - val_loss: 0.0031 - val_acc: 0.9645\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9591 - val_loss: 0.0032 - val_acc: 0.9601\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0031 - acc: 0.9537 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9582 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0031 - val_acc: 0.9637\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9600 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0031 - val_acc: 0.9624\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0030 - acc: 0.9585 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0031 - acc: 0.9577 - val_loss: 0.0032 - val_acc: 0.9600\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0032 - val_acc: 0.9616\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0030 - acc: 0.9555 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0031 - val_acc: 0.9610\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0031 - acc: 0.9564 - val_loss: 0.0033 - val_acc: 0.9592\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0031 - acc: 0.9582 - val_loss: 0.0032 - val_acc: 0.9604\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9584 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9600\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9610\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9604 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9593 - val_loss: 0.0032 - val_acc: 0.9595\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9588 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0030 - acc: 0.9585 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0030 - acc: 0.9564 - val_loss: 0.0031 - val_acc: 0.9622\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0030 - val_acc: 0.9641\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9618 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9576 - val_loss: 0.0032 - val_acc: 0.9597\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0033 - val_acc: 0.9576\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0031 - acc: 0.9569 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9617\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0031 - acc: 0.9545 - val_loss: 0.0031 - val_acc: 0.9609\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9582 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "start training round 31\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2279 - acc: 0.6902 - val_loss: 0.2372 - val_acc: 0.6890\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2241 - acc: 0.6911 - val_loss: 0.2381 - val_acc: 0.6871\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2251 - acc: 0.6911 - val_loss: 0.2426 - val_acc: 0.6877\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2268 - acc: 0.6913 - val_loss: 0.2458 - val_acc: 0.6856\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2287 - acc: 0.6903 - val_loss: 0.2371 - val_acc: 0.6898\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2236 - acc: 0.6919 - val_loss: 0.2368 - val_acc: 0.6887\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2235 - acc: 0.6921 - val_loss: 0.2344 - val_acc: 0.6901\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2206 - acc: 0.6931 - val_loss: 0.2351 - val_acc: 0.6905\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2248 - acc: 0.6907 - val_loss: 0.2399 - val_acc: 0.6867\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2266 - acc: 0.6895 - val_loss: 0.2391 - val_acc: 0.6876\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2237 - acc: 0.6918 - val_loss: 0.2450 - val_acc: 0.6880\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2262 - acc: 0.6918 - val_loss: 0.2371 - val_acc: 0.6895\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2227 - acc: 0.6925 - val_loss: 0.2346 - val_acc: 0.6911\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2211 - acc: 0.6925 - val_loss: 0.2374 - val_acc: 0.6892\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.2258 - acc: 0.6909 - val_loss: 0.2413 - val_acc: 0.6880\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2223 - acc: 0.6919 - val_loss: 0.2336 - val_acc: 0.6911\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2215 - acc: 0.6924 - val_loss: 0.2370 - val_acc: 0.6889\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2225 - acc: 0.6919 - val_loss: 0.2391 - val_acc: 0.6888\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2253 - acc: 0.6911 - val_loss: 0.2376 - val_acc: 0.6898\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2256 - acc: 0.6916 - val_loss: 0.2378 - val_acc: 0.6905\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2236 - acc: 0.6919 - val_loss: 0.2378 - val_acc: 0.6877\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2265 - acc: 0.6915 - val_loss: 0.2399 - val_acc: 0.6891\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2258 - acc: 0.6909 - val_loss: 0.2382 - val_acc: 0.6877\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2240 - acc: 0.6909 - val_loss: 0.2352 - val_acc: 0.6902\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2265 - acc: 0.6900 - val_loss: 0.2444 - val_acc: 0.6849\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2281 - acc: 0.6901 - val_loss: 0.2504 - val_acc: 0.6885\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2262 - acc: 0.6915 - val_loss: 0.2403 - val_acc: 0.6895\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2234 - acc: 0.6919 - val_loss: 0.2364 - val_acc: 0.6900\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2228 - acc: 0.6913 - val_loss: 0.2394 - val_acc: 0.6899\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2262 - acc: 0.6907 - val_loss: 0.2346 - val_acc: 0.6908\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2237 - acc: 0.6914 - val_loss: 0.2368 - val_acc: 0.6885\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2256 - acc: 0.6917 - val_loss: 0.2359 - val_acc: 0.6900\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2224 - acc: 0.6928 - val_loss: 0.2336 - val_acc: 0.6911\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2214 - acc: 0.6927 - val_loss: 0.2425 - val_acc: 0.6876\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2247 - acc: 0.6904 - val_loss: 0.2386 - val_acc: 0.6885\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2250 - acc: 0.6907 - val_loss: 0.2351 - val_acc: 0.6903\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2234 - acc: 0.6915 - val_loss: 0.2388 - val_acc: 0.6905\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2249 - acc: 0.6921 - val_loss: 0.2353 - val_acc: 0.6904\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2226 - acc: 0.6926 - val_loss: 0.2390 - val_acc: 0.6904\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2286 - acc: 0.6912 - val_loss: 0.2402 - val_acc: 0.6872\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2239 - acc: 0.6917 - val_loss: 0.2343 - val_acc: 0.6895\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2211 - acc: 0.6928 - val_loss: 0.2383 - val_acc: 0.6879\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2264 - acc: 0.6893 - val_loss: 0.2400 - val_acc: 0.6896\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2261 - acc: 0.6902 - val_loss: 0.2369 - val_acc: 0.6905\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2247 - acc: 0.6915 - val_loss: 0.2424 - val_acc: 0.6891\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2251 - acc: 0.6917 - val_loss: 0.2390 - val_acc: 0.6897\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2220 - acc: 0.6925 - val_loss: 0.2368 - val_acc: 0.6898\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2242 - acc: 0.6910 - val_loss: 0.2359 - val_acc: 0.6908\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2239 - acc: 0.6917 - val_loss: 0.2349 - val_acc: 0.6904\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2228 - acc: 0.6916 - val_loss: 0.2410 - val_acc: 0.6860\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9340 - acc: 0.6803 - val_loss: 2.0962 - val_acc: 0.6795\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9274 - acc: 0.6808 - val_loss: 2.0701 - val_acc: 0.6787\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9516 - acc: 0.6806 - val_loss: 2.0961 - val_acc: 0.6777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9441 - acc: 0.6795 - val_loss: 2.0812 - val_acc: 0.6776\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9408 - acc: 0.6805 - val_loss: 2.0700 - val_acc: 0.6782\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9328 - acc: 0.6811 - val_loss: 2.0948 - val_acc: 0.6809\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9458 - acc: 0.6807 - val_loss: 2.0854 - val_acc: 0.6765\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9521 - acc: 0.6804 - val_loss: 2.0950 - val_acc: 0.6748\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9222 - acc: 0.6807 - val_loss: 2.0441 - val_acc: 0.6811\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9434 - acc: 0.6807 - val_loss: 2.0941 - val_acc: 0.6795\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9441 - acc: 0.6806 - val_loss: 2.1327 - val_acc: 0.6800\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9575 - acc: 0.6800 - val_loss: 2.0936 - val_acc: 0.6789\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9288 - acc: 0.6809 - val_loss: 2.0963 - val_acc: 0.6751\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9283 - acc: 0.6803 - val_loss: 2.0708 - val_acc: 0.6767\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9310 - acc: 0.6802 - val_loss: 2.0619 - val_acc: 0.6773\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9217 - acc: 0.6801 - val_loss: 2.1066 - val_acc: 0.6761\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9771 - acc: 0.6797 - val_loss: 2.0898 - val_acc: 0.6783\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9447 - acc: 0.6806 - val_loss: 2.0842 - val_acc: 0.6795\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 1.9375 - acc: 0.6806 - val_loss: 2.0804 - val_acc: 0.6790\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9392 - acc: 0.6801 - val_loss: 2.0898 - val_acc: 0.6771\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9308 - acc: 0.6797 - val_loss: 2.0586 - val_acc: 0.6783\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9487 - acc: 0.6801 - val_loss: 2.0553 - val_acc: 0.6803\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9354 - acc: 0.6807 - val_loss: 2.0874 - val_acc: 0.6797\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9353 - acc: 0.6803 - val_loss: 2.0362 - val_acc: 0.6792\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9439 - acc: 0.6802 - val_loss: 2.0567 - val_acc: 0.6773\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9336 - acc: 0.6809 - val_loss: 2.0819 - val_acc: 0.6781\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9648 - acc: 0.6801 - val_loss: 2.0443 - val_acc: 0.6799\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9042 - acc: 0.6813 - val_loss: 2.0845 - val_acc: 0.6794\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9469 - acc: 0.6800 - val_loss: 2.0808 - val_acc: 0.6790\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9597 - acc: 0.6810 - val_loss: 2.0572 - val_acc: 0.6784\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9534 - acc: 0.6804 - val_loss: 2.1073 - val_acc: 0.6746\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9144 - acc: 0.6799 - val_loss: 2.0491 - val_acc: 0.6783\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9303 - acc: 0.6802 - val_loss: 2.1091 - val_acc: 0.6791\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9538 - acc: 0.6801 - val_loss: 2.1438 - val_acc: 0.6771\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9290 - acc: 0.6808 - val_loss: 2.0446 - val_acc: 0.6793\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9419 - acc: 0.6794 - val_loss: 2.0486 - val_acc: 0.6792\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9430 - acc: 0.6809 - val_loss: 2.1090 - val_acc: 0.6808\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9371 - acc: 0.6808 - val_loss: 2.2390 - val_acc: 0.6770\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9755 - acc: 0.6798 - val_loss: 2.0742 - val_acc: 0.6800\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9323 - acc: 0.6808 - val_loss: 2.1254 - val_acc: 0.6772\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9284 - acc: 0.6807 - val_loss: 2.0871 - val_acc: 0.6756\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9363 - acc: 0.6805 - val_loss: 2.0659 - val_acc: 0.6774\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9358 - acc: 0.6805 - val_loss: 2.2937 - val_acc: 0.6786\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9515 - acc: 0.6807 - val_loss: 2.0795 - val_acc: 0.6800\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9398 - acc: 0.6807 - val_loss: 2.1587 - val_acc: 0.6762\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9594 - acc: 0.6792 - val_loss: 2.0457 - val_acc: 0.6794\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9318 - acc: 0.6816 - val_loss: 2.1233 - val_acc: 0.6787\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9182 - acc: 0.6813 - val_loss: 2.0503 - val_acc: 0.6795\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9316 - acc: 0.6796 - val_loss: 2.1186 - val_acc: 0.6772\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9697 - acc: 0.6783 - val_loss: 2.0875 - val_acc: 0.6789\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1728 - acc: 0.9926 - val_loss: 0.1772 - val_acc: 0.9905\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1829 - acc: 0.9925 - val_loss: 0.1920 - val_acc: 0.9904\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1788 - acc: 0.9926 - val_loss: 0.1727 - val_acc: 0.9905\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1771 - acc: 0.9924 - val_loss: 0.1863 - val_acc: 0.9898\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1802 - acc: 0.9923 - val_loss: 0.1847 - val_acc: 0.9904\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1743 - acc: 0.9925 - val_loss: 0.1728 - val_acc: 0.9903\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1710 - acc: 0.9923 - val_loss: 0.1726 - val_acc: 0.9899\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1701 - acc: 0.9918 - val_loss: 0.1681 - val_acc: 0.9903\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1663 - acc: 0.9925 - val_loss: 0.1708 - val_acc: 0.9906\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1655 - acc: 0.9926 - val_loss: 0.1653 - val_acc: 0.9906\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1683 - acc: 0.9924 - val_loss: 0.1771 - val_acc: 0.9904\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1849 - acc: 0.9920 - val_loss: 0.1756 - val_acc: 0.9903\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1670 - acc: 0.9922 - val_loss: 0.1686 - val_acc: 0.9900\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1685 - acc: 0.9916 - val_loss: 0.1689 - val_acc: 0.9902\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1707 - acc: 0.9920 - val_loss: 0.1811 - val_acc: 0.9902\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1787 - acc: 0.9924 - val_loss: 0.1729 - val_acc: 0.9908\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1783 - acc: 0.9926 - val_loss: 0.1758 - val_acc: 0.9906\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1660 - acc: 0.9926 - val_loss: 0.1631 - val_acc: 0.9904\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1610 - acc: 0.9926 - val_loss: 0.1688 - val_acc: 0.9905\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1701 - acc: 0.9926 - val_loss: 0.1760 - val_acc: 0.9904\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1776 - acc: 0.9924 - val_loss: 0.1930 - val_acc: 0.9898\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1861 - acc: 0.9918 - val_loss: 0.1793 - val_acc: 0.9897\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1715 - acc: 0.9918 - val_loss: 0.1764 - val_acc: 0.9897\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1796 - acc: 0.9917 - val_loss: 0.1769 - val_acc: 0.9888\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1717 - acc: 0.9920 - val_loss: 0.1711 - val_acc: 0.9902\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1657 - acc: 0.9925 - val_loss: 0.1668 - val_acc: 0.9903\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1656 - acc: 0.9926 - val_loss: 0.1663 - val_acc: 0.9907\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1747 - acc: 0.9927 - val_loss: 0.1891 - val_acc: 0.9904\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1776 - acc: 0.9927 - val_loss: 0.1696 - val_acc: 0.9906\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1716 - acc: 0.9927 - val_loss: 0.1736 - val_acc: 0.9905\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1729 - acc: 0.9926 - val_loss: 0.1893 - val_acc: 0.9906\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1773 - acc: 0.9925 - val_loss: 0.1755 - val_acc: 0.9907\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1669 - acc: 0.9923 - val_loss: 0.1655 - val_acc: 0.9905\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1688 - acc: 0.9918 - val_loss: 0.1759 - val_acc: 0.9894\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1782 - acc: 0.9912 - val_loss: 0.1773 - val_acc: 0.9892\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1672 - acc: 0.9921 - val_loss: 0.1636 - val_acc: 0.9906\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1622 - acc: 0.9926 - val_loss: 0.1640 - val_acc: 0.9906\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1660 - acc: 0.9926 - val_loss: 0.1662 - val_acc: 0.9906\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1659 - acc: 0.9926 - val_loss: 0.1757 - val_acc: 0.9905\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1858 - acc: 0.9926 - val_loss: 0.1936 - val_acc: 0.9905\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1832 - acc: 0.9926 - val_loss: 0.1712 - val_acc: 0.9905\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1620 - acc: 0.9927 - val_loss: 0.1638 - val_acc: 0.9905\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1653 - acc: 0.9926 - val_loss: 0.1718 - val_acc: 0.9904\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1696 - acc: 0.9926 - val_loss: 0.1718 - val_acc: 0.9903\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1714 - acc: 0.9921 - val_loss: 0.1762 - val_acc: 0.9892\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1757 - acc: 0.9916 - val_loss: 0.1773 - val_acc: 0.9889\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1707 - acc: 0.9918 - val_loss: 0.1702 - val_acc: 0.9898\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1637 - acc: 0.9923 - val_loss: 0.1646 - val_acc: 0.9903\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1619 - acc: 0.9925 - val_loss: 0.1649 - val_acc: 0.9903\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1642 - acc: 0.9925 - val_loss: 0.1746 - val_acc: 0.9903\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0032 - val_acc: 0.9595\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9571 - val_loss: 0.0033 - val_acc: 0.9579\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0031 - acc: 0.9557 - val_loss: 0.0032 - val_acc: 0.9594\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9602 - val_loss: 0.0032 - val_acc: 0.9605\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0031 - acc: 0.9550 - val_loss: 0.0032 - val_acc: 0.9584\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9582 - val_loss: 0.0032 - val_acc: 0.9603\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9602\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9594 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0030 - val_acc: 0.9632\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9614 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9606 - val_loss: 0.0033 - val_acc: 0.9597\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0031 - acc: 0.9550 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9599 - val_loss: 0.0031 - val_acc: 0.9644\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9575 - val_loss: 0.0032 - val_acc: 0.9589\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0031 - acc: 0.9550 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0031 - val_acc: 0.9643\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9586 - val_loss: 0.0031 - val_acc: 0.9647\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0030 - val_acc: 0.9649\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9593 - val_loss: 0.0031 - val_acc: 0.9612\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9594 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9643\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0030 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9642oss: 0.0030 \n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9596 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9619\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9576 - val_loss: 0.0030 - val_acc: 0.9630\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9614 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9607 - val_loss: 0.0031 - val_acc: 0.9644\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0032 - val_acc: 0.9631\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9586 - val_loss: 0.0031 - val_acc: 0.9643\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9578 - val_loss: 0.0031 - val_acc: 0.9648\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0033 - val_acc: 0.9631\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0032 - val_acc: 0.9639\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9645\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0030 - acc: 0.9573 - val_loss: 0.0031 - val_acc: 0.9627\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0036 - val_acc: 0.9502\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0031 - acc: 0.9551 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0030 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9628\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0031 - acc: 0.9549 - val_loss: 0.0033 - val_acc: 0.9547\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9558 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9636\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0032 - acc: 0.9536 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0032 - val_acc: 0.9606\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9586\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0031 - acc: 0.9553 - val_loss: 0.0031 - val_acc: 0.9635\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0030 - val_acc: 0.9643\n",
      "start training round 32\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2262 - acc: 0.6921 - val_loss: 0.2367 - val_acc: 0.6901\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2223 - acc: 0.6926 - val_loss: 0.2470 - val_acc: 0.6879\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2274 - acc: 0.6909 - val_loss: 0.2400 - val_acc: 0.6892\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2267 - acc: 0.6899 - val_loss: 0.2373 - val_acc: 0.6886\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2236 - acc: 0.6919 - val_loss: 0.2387 - val_acc: 0.6882\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2212 - acc: 0.6923 - val_loss: 0.2350 - val_acc: 0.6897\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2231 - acc: 0.6914 - val_loss: 0.2349 - val_acc: 0.6913\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2254 - acc: 0.6911 - val_loss: 0.2476 - val_acc: 0.6863\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2251 - acc: 0.6908 - val_loss: 0.2422 - val_acc: 0.6865\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2233 - acc: 0.6914 - val_loss: 0.2364 - val_acc: 0.6881\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2232 - acc: 0.6906 - val_loss: 0.2359 - val_acc: 0.6884\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2273 - acc: 0.6908 - val_loss: 0.2357 - val_acc: 0.6905\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2204 - acc: 0.6932 - val_loss: 0.2355 - val_acc: 0.6903\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2268 - acc: 0.6913 - val_loss: 0.2347 - val_acc: 0.6901\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2218 - acc: 0.6925 - val_loss: 0.2376 - val_acc: 0.6903\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2215 - acc: 0.6931 - val_loss: 0.2376 - val_acc: 0.6911\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2266 - acc: 0.6910 - val_loss: 0.2379 - val_acc: 0.6897\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2239 - acc: 0.6922 - val_loss: 0.2343 - val_acc: 0.6910\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2246 - acc: 0.6918 - val_loss: 0.2456 - val_acc: 0.6878\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2274 - acc: 0.6911 - val_loss: 0.2359 - val_acc: 0.6895\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2206 - acc: 0.6928 - val_loss: 0.2348 - val_acc: 0.6911\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2221 - acc: 0.6929 - val_loss: 0.2337 - val_acc: 0.6911\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2264 - acc: 0.6908 - val_loss: 0.2393 - val_acc: 0.6887\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2243 - acc: 0.6916 - val_loss: 0.2401 - val_acc: 0.6901\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2266 - acc: 0.6917 - val_loss: 0.2363 - val_acc: 0.6893\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2228 - acc: 0.6921 - val_loss: 0.2386 - val_acc: 0.6880\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2236 - acc: 0.6912 - val_loss: 0.2377 - val_acc: 0.6868\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2237 - acc: 0.6908 - val_loss: 0.2380 - val_acc: 0.6899\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2249 - acc: 0.6925 - val_loss: 0.2338 - val_acc: 0.6899\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2249 - acc: 0.6900 - val_loss: 0.2411 - val_acc: 0.6875\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2285 - acc: 0.6897 - val_loss: 0.2396 - val_acc: 0.6871\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2248 - acc: 0.6915 - val_loss: 0.2350 - val_acc: 0.6910\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2208 - acc: 0.6933 - val_loss: 0.2340 - val_acc: 0.6915\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2209 - acc: 0.6926 - val_loss: 0.2373 - val_acc: 0.6909\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2242 - acc: 0.6924 - val_loss: 0.2357 - val_acc: 0.6904\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2241 - acc: 0.6921 - val_loss: 0.2417 - val_acc: 0.6877\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2263 - acc: 0.6899 - val_loss: 0.2347 - val_acc: 0.6905\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2233 - acc: 0.6914 - val_loss: 0.2340 - val_acc: 0.6912\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2208 - acc: 0.6927 - val_loss: 0.2370 - val_acc: 0.6902\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2252 - acc: 0.6907 - val_loss: 0.2339 - val_acc: 0.6907\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2232 - acc: 0.6928 - val_loss: 0.2389 - val_acc: 0.6884\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2263 - acc: 0.6912 - val_loss: 0.2471 - val_acc: 0.6844\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2252 - acc: 0.6913 - val_loss: 0.2335 - val_acc: 0.6899\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2219 - acc: 0.6927 - val_loss: 0.2364 - val_acc: 0.6892\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2220 - acc: 0.6926 - val_loss: 0.2384 - val_acc: 0.6895\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2240 - acc: 0.6932 - val_loss: 0.2436 - val_acc: 0.6881\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2269 - acc: 0.6906 - val_loss: 0.2410 - val_acc: 0.6873\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2211 - acc: 0.6931 - val_loss: 0.2348 - val_acc: 0.6915\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2226 - acc: 0.6924 - val_loss: 0.2367 - val_acc: 0.6887\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2221 - acc: 0.6927 - val_loss: 0.2366 - val_acc: 0.6889\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9228 - acc: 0.6806 - val_loss: 2.0711 - val_acc: 0.6801\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9314 - acc: 0.6810 - val_loss: 2.1043 - val_acc: 0.6788\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9449 - acc: 0.6806 - val_loss: 2.0671 - val_acc: 0.6790\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9345 - acc: 0.6800 - val_loss: 2.1562 - val_acc: 0.6725\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9354 - acc: 0.6799 - val_loss: 2.0553 - val_acc: 0.6785\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9210 - acc: 0.6808 - val_loss: 2.1033 - val_acc: 0.6788\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9118 - acc: 0.6809 - val_loss: 2.0950 - val_acc: 0.6743\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9556 - acc: 0.6796 - val_loss: 2.0504 - val_acc: 0.6775\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9324 - acc: 0.6812 - val_loss: 2.1575 - val_acc: 0.6765\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9168 - acc: 0.6808 - val_loss: 2.0419 - val_acc: 0.6785\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9387 - acc: 0.6803 - val_loss: 2.1105 - val_acc: 0.6769\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9500 - acc: 0.6803 - val_loss: 2.0638 - val_acc: 0.6766\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9401 - acc: 0.6800 - val_loss: 2.0924 - val_acc: 0.6783\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9384 - acc: 0.6801 - val_loss: 2.1556 - val_acc: 0.6776\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9602 - acc: 0.6801 - val_loss: 2.0526 - val_acc: 0.6773\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9306 - acc: 0.6800 - val_loss: 2.1526 - val_acc: 0.6742\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9371 - acc: 0.6802 - val_loss: 2.0391 - val_acc: 0.6778\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9258 - acc: 0.6808 - val_loss: 2.0717 - val_acc: 0.6775\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9275 - acc: 0.6798 - val_loss: 2.0465 - val_acc: 0.6777\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9373 - acc: 0.6795 - val_loss: 2.0790 - val_acc: 0.6800\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9189 - acc: 0.6809 - val_loss: 2.1728 - val_acc: 0.6756\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9700 - acc: 0.6805 - val_loss: 2.0879 - val_acc: 0.6793\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9178 - acc: 0.6815 - val_loss: 2.1088 - val_acc: 0.6804\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9445 - acc: 0.6807 - val_loss: 2.0847 - val_acc: 0.6773\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9640 - acc: 0.6802 - val_loss: 2.0484 - val_acc: 0.6800\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9311 - acc: 0.6805 - val_loss: 2.1160 - val_acc: 0.6791\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9228 - acc: 0.6805 - val_loss: 2.0555 - val_acc: 0.6786\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9114 - acc: 0.6810 - val_loss: 2.0999 - val_acc: 0.6790\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9267 - acc: 0.6805 - val_loss: 2.0636 - val_acc: 0.6777\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9240 - acc: 0.6802 - val_loss: 2.0763 - val_acc: 0.6760\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9364 - acc: 0.6804 - val_loss: 2.0927 - val_acc: 0.6805\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9490 - acc: 0.6810 - val_loss: 2.0696 - val_acc: 0.6799\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9485 - acc: 0.6802 - val_loss: 2.2294 - val_acc: 0.6766\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9382 - acc: 0.6803 - val_loss: 2.1274 - val_acc: 0.6805\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9212 - acc: 0.6812 - val_loss: 2.0627 - val_acc: 0.6794\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9344 - acc: 0.6809 - val_loss: 2.0762 - val_acc: 0.6790\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9412 - acc: 0.6803 - val_loss: 2.0854 - val_acc: 0.6790\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9418 - acc: 0.6796 - val_loss: 2.0672 - val_acc: 0.6793\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9347 - acc: 0.6808 - val_loss: 2.0983 - val_acc: 0.6806\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9336 - acc: 0.6807 - val_loss: 2.0939 - val_acc: 0.6804\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9142 - acc: 0.6815 - val_loss: 2.0968 - val_acc: 0.6778\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9374 - acc: 0.6805 - val_loss: 2.1105 - val_acc: 0.6780\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9550 - acc: 0.6809 - val_loss: 2.0551 - val_acc: 0.6771\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9270 - acc: 0.6807 - val_loss: 2.0526 - val_acc: 0.6771\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9436 - acc: 0.6805 - val_loss: 2.0728 - val_acc: 0.6764\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9320 - acc: 0.6802 - val_loss: 2.0758 - val_acc: 0.6796\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9625 - acc: 0.6808 - val_loss: 2.1083 - val_acc: 0.6796\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9463 - acc: 0.6803 - val_loss: 2.0814 - val_acc: 0.6781\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9173 - acc: 0.6812 - val_loss: 2.1618 - val_acc: 0.6736\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9467 - acc: 0.6800 - val_loss: 2.0492 - val_acc: 0.6786\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1848 - acc: 0.9926 - val_loss: 0.1879 - val_acc: 0.9905\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1825 - acc: 0.9925 - val_loss: 0.1913 - val_acc: 0.9904\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1880 - acc: 0.9920 - val_loss: 0.1694 - val_acc: 0.9905\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1639 - acc: 0.9925 - val_loss: 0.1657 - val_acc: 0.9907\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1633 - acc: 0.9926 - val_loss: 0.1657 - val_acc: 0.9904\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1718 - acc: 0.9926 - val_loss: 0.1725 - val_acc: 0.9904\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1690 - acc: 0.9921 - val_loss: 0.1705 - val_acc: 0.9897\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1876 - acc: 0.9898 - val_loss: 0.1824 - val_acc: 0.9885\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1747 - acc: 0.9916 - val_loss: 0.1734 - val_acc: 0.9898\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1689 - acc: 0.9925 - val_loss: 0.1716 - val_acc: 0.9904\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1722 - acc: 0.9926 - val_loss: 0.1665 - val_acc: 0.9905\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1603 - acc: 0.9926 - val_loss: 0.1624 - val_acc: 0.9903\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1631 - acc: 0.9925 - val_loss: 0.1680 - val_acc: 0.9899\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1635 - acc: 0.9924 - val_loss: 0.1657 - val_acc: 0.9904\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1626 - acc: 0.9927 - val_loss: 0.1683 - val_acc: 0.9906\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1884 - acc: 0.9927 - val_loss: 0.2092 - val_acc: 0.9905\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1875 - acc: 0.9927 - val_loss: 0.1727 - val_acc: 0.9905\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1699 - acc: 0.9925 - val_loss: 0.1708 - val_acc: 0.9903\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1677 - acc: 0.9921 - val_loss: 0.1731 - val_acc: 0.9897\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1733 - acc: 0.9915 - val_loss: 0.1713 - val_acc: 0.9896\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1680 - acc: 0.9916 - val_loss: 0.1697 - val_acc: 0.9895\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1660 - acc: 0.9920 - val_loss: 0.1713 - val_acc: 0.9896\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1680 - acc: 0.9922 - val_loss: 0.1744 - val_acc: 0.9901\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1787 - acc: 0.9925 - val_loss: 0.1870 - val_acc: 0.9908\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1760 - acc: 0.9927 - val_loss: 0.1756 - val_acc: 0.9907\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1731 - acc: 0.9926 - val_loss: 0.1712 - val_acc: 0.9907\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1682 - acc: 0.9926 - val_loss: 0.1734 - val_acc: 0.9906\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1718 - acc: 0.9922 - val_loss: 0.1802 - val_acc: 0.9895\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1743 - acc: 0.9918 - val_loss: 0.1703 - val_acc: 0.9898\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1625 - acc: 0.9922 - val_loss: 0.1637 - val_acc: 0.9905\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1688 - acc: 0.9922 - val_loss: 0.1766 - val_acc: 0.9902\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1785 - acc: 0.9923 - val_loss: 0.1830 - val_acc: 0.9906\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1710 - acc: 0.9926 - val_loss: 0.1669 - val_acc: 0.9907\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1679 - acc: 0.9927 - val_loss: 0.1741 - val_acc: 0.9906\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1688 - acc: 0.9926 - val_loss: 0.1662 - val_acc: 0.9904\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1647 - acc: 0.9925 - val_loss: 0.1650 - val_acc: 0.9905\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1642 - acc: 0.9927 - val_loss: 0.1675 - val_acc: 0.9906\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1682 - acc: 0.9927 - val_loss: 0.1772 - val_acc: 0.9906\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1733 - acc: 0.9924 - val_loss: 0.1803 - val_acc: 0.9905\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1787 - acc: 0.9922 - val_loss: 0.1735 - val_acc: 0.9903\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1683 - acc: 0.9918 - val_loss: 0.1697 - val_acc: 0.9899\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1688 - acc: 0.9922 - val_loss: 0.1687 - val_acc: 0.9905\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1671 - acc: 0.9925 - val_loss: 0.1687 - val_acc: 0.9906\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1635 - acc: 0.9925 - val_loss: 0.1726 - val_acc: 0.9906\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1808 - acc: 0.9923 - val_loss: 0.1794 - val_acc: 0.9905\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1760 - acc: 0.9926 - val_loss: 0.1865 - val_acc: 0.9908\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1746 - acc: 0.9924 - val_loss: 0.1730 - val_acc: 0.9902\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1725 - acc: 0.9919 - val_loss: 0.1769 - val_acc: 0.9894\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1739 - acc: 0.9915 - val_loss: 0.1849 - val_acc: 0.9900\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1744 - acc: 0.9920 - val_loss: 0.1707 - val_acc: 0.9899\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9647\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9589 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9583 - val_loss: 0.0031 - val_acc: 0.9647\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9643\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0031 - val_acc: 0.9644\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9645\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9595 - val_loss: 0.0031 - val_acc: 0.9647\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9557 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9635\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9582 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0033 - val_acc: 0.9591\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0031 - acc: 0.9539 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9569 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9593 - val_loss: 0.0031 - val_acc: 0.9645\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9595 - val_loss: 0.0031 - val_acc: 0.9638\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - ETA: 0s - loss: 0.0029 - acc: 0.961 - 2s 237us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0030 - val_acc: 0.9637\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0029 - acc: 0.9607 - val_loss: 0.0031 - val_acc: 0.9609\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 249us/step - loss: 0.0030 - acc: 0.9604 - val_loss: 0.0032 - val_acc: 0.9636\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0031 - acc: 0.9591 - val_loss: 0.0032 - val_acc: 0.9599\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9571 - val_loss: 0.0031 - val_acc: 0.9621\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0030 - val_acc: 0.9640\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0031 - val_acc: 0.9613\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0030 - val_acc: 0.9638\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9570 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0030 - val_acc: 0.9638\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9614 - val_loss: 0.0030 - val_acc: 0.9640\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0032 - val_acc: 0.9590\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9584 - val_loss: 0.0030 - val_acc: 0.9640\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0030 - val_acc: 0.9629\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9607 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0030 - acc: 0.9585 - val_loss: 0.0031 - val_acc: 0.9626\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9622\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9608\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0030 - val_acc: 0.9641\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0031 - val_acc: 0.9605\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9637\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0031 - acc: 0.9587 - val_loss: 0.0031 - val_acc: 0.9616\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0031 - acc: 0.9571 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "start training round 33\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2243 - acc: 0.6927 - val_loss: 0.2364 - val_acc: 0.6886\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.2261 - acc: 0.6900 - val_loss: 0.2384 - val_acc: 0.6892\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2224 - acc: 0.6912 - val_loss: 0.2347 - val_acc: 0.6901\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2238 - acc: 0.6911 - val_loss: 0.2380 - val_acc: 0.6876\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2234 - acc: 0.6903 - val_loss: 0.2346 - val_acc: 0.6912\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2219 - acc: 0.6928 - val_loss: 0.2342 - val_acc: 0.6907\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2237 - acc: 0.6917 - val_loss: 0.2498 - val_acc: 0.6867\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2257 - acc: 0.6912 - val_loss: 0.2376 - val_acc: 0.6887\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2254 - acc: 0.6914 - val_loss: 0.2360 - val_acc: 0.6896\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2220 - acc: 0.6921 - val_loss: 0.2369 - val_acc: 0.6890\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2273 - acc: 0.6909 - val_loss: 0.2384 - val_acc: 0.6902\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2239 - acc: 0.6917 - val_loss: 0.2387 - val_acc: 0.6873\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2245 - acc: 0.6904 - val_loss: 0.2352 - val_acc: 0.6889\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2243 - acc: 0.6928 - val_loss: 0.2430 - val_acc: 0.6883\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2249 - acc: 0.6911 - val_loss: 0.2383 - val_acc: 0.6899\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2246 - acc: 0.6915 - val_loss: 0.2426 - val_acc: 0.6865\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2255 - acc: 0.6913 - val_loss: 0.2375 - val_acc: 0.6886\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2210 - acc: 0.6933 - val_loss: 0.2365 - val_acc: 0.6905\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2235 - acc: 0.6913 - val_loss: 0.2349 - val_acc: 0.6906\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2244 - acc: 0.6913 - val_loss: 0.2365 - val_acc: 0.6907\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2204 - acc: 0.6935 - val_loss: 0.2331 - val_acc: 0.6904\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2236 - acc: 0.6920 - val_loss: 0.2376 - val_acc: 0.6892\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2244 - acc: 0.6912 - val_loss: 0.2343 - val_acc: 0.6911\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2220 - acc: 0.6929 - val_loss: 0.2351 - val_acc: 0.6900\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2221 - acc: 0.6930 - val_loss: 0.2350 - val_acc: 0.6911\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2223 - acc: 0.6929 - val_loss: 0.2420 - val_acc: 0.6892\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2291 - acc: 0.6909 - val_loss: 0.2353 - val_acc: 0.6907\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2214 - acc: 0.6924 - val_loss: 0.2344 - val_acc: 0.6895\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2233 - acc: 0.6916 - val_loss: 0.2340 - val_acc: 0.6909\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2223 - acc: 0.6916 - val_loss: 0.2368 - val_acc: 0.6890\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2207 - acc: 0.6936 - val_loss: 0.2385 - val_acc: 0.6894\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2250 - acc: 0.6929 - val_loss: 0.2334 - val_acc: 0.6905\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2216 - acc: 0.6924 - val_loss: 0.2339 - val_acc: 0.6907\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2222 - acc: 0.6921 - val_loss: 0.2383 - val_acc: 0.6878\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2262 - acc: 0.6903 - val_loss: 0.2351 - val_acc: 0.6916\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2256 - acc: 0.6905 - val_loss: 0.2356 - val_acc: 0.6914\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2201 - acc: 0.6932 - val_loss: 0.2377 - val_acc: 0.6903\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2249 - acc: 0.6905 - val_loss: 0.2336 - val_acc: 0.6907\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2213 - acc: 0.6927 - val_loss: 0.2399 - val_acc: 0.6893\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2227 - acc: 0.6926 - val_loss: 0.2336 - val_acc: 0.6911\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2195 - acc: 0.6936 - val_loss: 0.2352 - val_acc: 0.6898\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2238 - acc: 0.6913 - val_loss: 0.2411 - val_acc: 0.6868\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2268 - acc: 0.6902 - val_loss: 0.2376 - val_acc: 0.6900\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2239 - acc: 0.6926 - val_loss: 0.2461 - val_acc: 0.6845\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2213 - acc: 0.6926 - val_loss: 0.2354 - val_acc: 0.6897\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2234 - acc: 0.6915 - val_loss: 0.2385 - val_acc: 0.6878\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2226 - acc: 0.6920 - val_loss: 0.2401 - val_acc: 0.6886\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2216 - acc: 0.6933 - val_loss: 0.2351 - val_acc: 0.6908\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2273 - acc: 0.6916 - val_loss: 0.2390 - val_acc: 0.6902\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2228 - acc: 0.6923 - val_loss: 0.2331 - val_acc: 0.6904\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9248 - acc: 0.6801 - val_loss: 2.1440 - val_acc: 0.6737\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9516 - acc: 0.6795 - val_loss: 2.0303 - val_acc: 0.6784\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9144 - acc: 0.6808 - val_loss: 2.0538 - val_acc: 0.6776\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9239 - acc: 0.6814 - val_loss: 2.2474 - val_acc: 0.6739\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9300 - acc: 0.6807 - val_loss: 2.0407 - val_acc: 0.6807\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9240 - acc: 0.6798 - val_loss: 2.0496 - val_acc: 0.6792\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9449 - acc: 0.6801 - val_loss: 2.0785 - val_acc: 0.6749\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9155 - acc: 0.6805 - val_loss: 2.0572 - val_acc: 0.6798\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9637 - acc: 0.6803 - val_loss: 2.0991 - val_acc: 0.6762\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9483 - acc: 0.6807 - val_loss: 2.0872 - val_acc: 0.6789\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9450 - acc: 0.6797 - val_loss: 2.0602 - val_acc: 0.6812\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9226 - acc: 0.6806 - val_loss: 2.2167 - val_acc: 0.6762\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9223 - acc: 0.6808 - val_loss: 2.0442 - val_acc: 0.6806\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9266 - acc: 0.6808 - val_loss: 2.1277 - val_acc: 0.6797\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9320 - acc: 0.6804 - val_loss: 2.0677 - val_acc: 0.6792\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9201 - acc: 0.6806 - val_loss: 2.1734 - val_acc: 0.6767\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9590 - acc: 0.6808 - val_loss: 2.1329 - val_acc: 0.6771\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9341 - acc: 0.6810 - val_loss: 2.0443 - val_acc: 0.6784\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9335 - acc: 0.6811 - val_loss: 2.0924 - val_acc: 0.6788\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9092 - acc: 0.6815 - val_loss: 2.1066 - val_acc: 0.6789\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9342 - acc: 0.6803 - val_loss: 2.1101 - val_acc: 0.6794\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9265 - acc: 0.6802 - val_loss: 2.0709 - val_acc: 0.6764\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9272 - acc: 0.6800 - val_loss: 2.0355 - val_acc: 0.6776\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9255 - acc: 0.6810 - val_loss: 2.0357 - val_acc: 0.6790\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9265 - acc: 0.6808 - val_loss: 2.1127 - val_acc: 0.6754\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9445 - acc: 0.6805 - val_loss: 2.0707 - val_acc: 0.6768\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9273 - acc: 0.6805 - val_loss: 2.1114 - val_acc: 0.6757\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9301 - acc: 0.6808 - val_loss: 2.1578 - val_acc: 0.6790\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9550 - acc: 0.6810 - val_loss: 2.0630 - val_acc: 0.6805\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9425 - acc: 0.6803 - val_loss: 2.0729 - val_acc: 0.6798\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9200 - acc: 0.6814 - val_loss: 2.0915 - val_acc: 0.6798\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9247 - acc: 0.6805 - val_loss: 2.0316 - val_acc: 0.6796\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9140 - acc: 0.6812 - val_loss: 2.1352 - val_acc: 0.6790\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9343 - acc: 0.6808 - val_loss: 2.0850 - val_acc: 0.6795\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9328 - acc: 0.6803 - val_loss: 2.1576 - val_acc: 0.6792\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9297 - acc: 0.6813 - val_loss: 2.1063 - val_acc: 0.6772\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9404 - acc: 0.6809 - val_loss: 2.0954 - val_acc: 0.6781\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9252 - acc: 0.6799 - val_loss: 2.0479 - val_acc: 0.6796\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9167 - acc: 0.6808 - val_loss: 2.1718 - val_acc: 0.6797\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9467 - acc: 0.6803 - val_loss: 2.0630 - val_acc: 0.6807\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9215 - acc: 0.6809 - val_loss: 2.1441 - val_acc: 0.6793\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9933 - acc: 0.6804 - val_loss: 2.0478 - val_acc: 0.6794\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9209 - acc: 0.6814 - val_loss: 2.0466 - val_acc: 0.6801\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9214 - acc: 0.6808 - val_loss: 2.1407 - val_acc: 0.6782\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9334 - acc: 0.6806 - val_loss: 2.0470 - val_acc: 0.6800\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9239 - acc: 0.6812 - val_loss: 2.1848 - val_acc: 0.6753\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9373 - acc: 0.6811 - val_loss: 2.0570 - val_acc: 0.6792\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9355 - acc: 0.6796 - val_loss: 2.0846 - val_acc: 0.6745\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9349 - acc: 0.6803 - val_loss: 2.0905 - val_acc: 0.6762\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9410 - acc: 0.6801 - val_loss: 2.1086 - val_acc: 0.6792\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1661 - acc: 0.9920 - val_loss: 0.1682 - val_acc: 0.9899\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1742 - acc: 0.9920 - val_loss: 0.1749 - val_acc: 0.9901\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1695 - acc: 0.9925 - val_loss: 0.1676 - val_acc: 0.9905\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1628 - acc: 0.9926 - val_loss: 0.1678 - val_acc: 0.9906\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1708 - acc: 0.9927 - val_loss: 0.1753 - val_acc: 0.9906\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1713 - acc: 0.9927 - val_loss: 0.1701 - val_acc: 0.9906\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1622 - acc: 0.9927 - val_loss: 0.1633 - val_acc: 0.9905\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1613 - acc: 0.9926 - val_loss: 0.1664 - val_acc: 0.9903\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1691 - acc: 0.9924 - val_loss: 0.1795 - val_acc: 0.9897\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1857 - acc: 0.9918 - val_loss: 0.1870 - val_acc: 0.9902\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1700 - acc: 0.9925 - val_loss: 0.1662 - val_acc: 0.9907\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1610 - acc: 0.9927 - val_loss: 0.1618 - val_acc: 0.9907\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1646 - acc: 0.9926 - val_loss: 0.1689 - val_acc: 0.9907\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1744 - acc: 0.9925 - val_loss: 0.1841 - val_acc: 0.9898\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1816 - acc: 0.9919 - val_loss: 0.1794 - val_acc: 0.9904\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1691 - acc: 0.9924 - val_loss: 0.1650 - val_acc: 0.9904\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1631 - acc: 0.9925 - val_loss: 0.1662 - val_acc: 0.9904\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1635 - acc: 0.9924 - val_loss: 0.1681 - val_acc: 0.9903\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1782 - acc: 0.9925 - val_loss: 0.1949 - val_acc: 0.9904\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1792 - acc: 0.9925 - val_loss: 0.1801 - val_acc: 0.9906\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1709 - acc: 0.9927 - val_loss: 0.1707 - val_acc: 0.9904\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1666 - acc: 0.9924 - val_loss: 0.1703 - val_acc: 0.9904\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1718 - acc: 0.9927 - val_loss: 0.1758 - val_acc: 0.9906\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1664 - acc: 0.9926 - val_loss: 0.1671 - val_acc: 0.9905\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1641 - acc: 0.9927 - val_loss: 0.1666 - val_acc: 0.9903\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1643 - acc: 0.9925 - val_loss: 0.1655 - val_acc: 0.9903\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1660 - acc: 0.9922 - val_loss: 0.1708 - val_acc: 0.9897\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1659 - acc: 0.9923 - val_loss: 0.1703 - val_acc: 0.9903\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1681 - acc: 0.9923 - val_loss: 0.1681 - val_acc: 0.9901\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1646 - acc: 0.9925 - val_loss: 0.1645 - val_acc: 0.9903\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1686 - acc: 0.9921 - val_loss: 0.1680 - val_acc: 0.9902\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1603 - acc: 0.9924 - val_loss: 0.1626 - val_acc: 0.9903\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1647 - acc: 0.9922 - val_loss: 0.1777 - val_acc: 0.9897\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1849 - acc: 0.9915 - val_loss: 0.1994 - val_acc: 0.9884\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1832 - acc: 0.9917 - val_loss: 0.1691 - val_acc: 0.9904\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1689 - acc: 0.9925 - val_loss: 0.1693 - val_acc: 0.9901\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1636 - acc: 0.9926 - val_loss: 0.1685 - val_acc: 0.9906\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1713 - acc: 0.9926 - val_loss: 0.1727 - val_acc: 0.9905\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1622 - acc: 0.9927 - val_loss: 0.1597 - val_acc: 0.9905\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1599 - acc: 0.9925 - val_loss: 0.1609 - val_acc: 0.9904\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1634 - acc: 0.9921 - val_loss: 0.1719 - val_acc: 0.9890\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1703 - acc: 0.9917 - val_loss: 0.1806 - val_acc: 0.9903\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1692 - acc: 0.9924 - val_loss: 0.1754 - val_acc: 0.9907\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1767 - acc: 0.9926 - val_loss: 0.2009 - val_acc: 0.9905\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1884 - acc: 0.9921 - val_loss: 0.1756 - val_acc: 0.9905\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1682 - acc: 0.9926 - val_loss: 0.1731 - val_acc: 0.9905\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1675 - acc: 0.9924 - val_loss: 0.1643 - val_acc: 0.9908\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1621 - acc: 0.9926 - val_loss: 0.1652 - val_acc: 0.9903\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1614 - acc: 0.9926 - val_loss: 0.1630 - val_acc: 0.9904\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1647 - acc: 0.9924 - val_loss: 0.1787 - val_acc: 0.9898\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9589 - val_loss: 0.0031 - val_acc: 0.9635\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9565 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9572 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0030 - acc: 0.9576 - val_loss: 0.0032 - val_acc: 0.9590\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9594 - val_loss: 0.0032 - val_acc: 0.9597\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9588 - val_loss: 0.0031 - val_acc: 0.9638\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9645\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9618\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0031 - acc: 0.9567 - val_loss: 0.0031 - val_acc: 0.9621\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9579 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9625\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0030 - acc: 0.9579 - val_loss: 0.0031 - val_acc: 0.9619\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9598 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0030 - val_acc: 0.9636\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0030 - val_acc: 0.9643\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0031 - acc: 0.9566 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9586 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 244us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9618 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9618 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9583 - val_loss: 0.0032 - val_acc: 0.9606\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9590 - val_loss: 0.0030 - val_acc: 0.9649\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9581 - val_loss: 0.0031 - val_acc: 0.9615\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0032 - val_acc: 0.9599\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9600 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9614\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0032 - val_acc: 0.9600\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9614 - val_loss: 0.0031 - val_acc: 0.9613\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0030 - acc: 0.9578 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9582 - val_loss: 0.0031 - val_acc: 0.9598\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9598 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9589 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9584 - val_loss: 0.0035 - val_acc: 0.9538\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0031 - acc: 0.9551 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9645\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0031 - val_acc: 0.9646\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9607 - val_loss: 0.0031 - val_acc: 0.9616\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9596 - val_loss: 0.0031 - val_acc: 0.9625\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9555 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9577 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0030 - val_acc: 0.9649\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0032 - val_acc: 0.9643\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0031 - acc: 0.9540 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "start training round 34\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2211 - acc: 0.6924 - val_loss: 0.2392 - val_acc: 0.6873\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2244 - acc: 0.6907 - val_loss: 0.2345 - val_acc: 0.6901\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2205 - acc: 0.6928 - val_loss: 0.2329 - val_acc: 0.6918\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2204 - acc: 0.6937 - val_loss: 0.2381 - val_acc: 0.6903\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2236 - acc: 0.6932 - val_loss: 0.2338 - val_acc: 0.6912\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2206 - acc: 0.6934 - val_loss: 0.2365 - val_acc: 0.6886\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2239 - acc: 0.6915 - val_loss: 0.2411 - val_acc: 0.6876\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2267 - acc: 0.6908 - val_loss: 0.2361 - val_acc: 0.6910\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2234 - acc: 0.6916 - val_loss: 0.2328 - val_acc: 0.6905\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2215 - acc: 0.6931 - val_loss: 0.2432 - val_acc: 0.6880\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2224 - acc: 0.6928 - val_loss: 0.2364 - val_acc: 0.6905\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2232 - acc: 0.6918 - val_loss: 0.2347 - val_acc: 0.6902\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2264 - acc: 0.6905 - val_loss: 0.2379 - val_acc: 0.6894\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2232 - acc: 0.6918 - val_loss: 0.2363 - val_acc: 0.6899\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2219 - acc: 0.6920 - val_loss: 0.2339 - val_acc: 0.6904\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2230 - acc: 0.6920 - val_loss: 0.2398 - val_acc: 0.6890\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2228 - acc: 0.6920 - val_loss: 0.2460 - val_acc: 0.6880\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2243 - acc: 0.6915 - val_loss: 0.2324 - val_acc: 0.6921\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2220 - acc: 0.6932 - val_loss: 0.2331 - val_acc: 0.6911\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2245 - acc: 0.6912 - val_loss: 0.2365 - val_acc: 0.6902\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2218 - acc: 0.6919 - val_loss: 0.2439 - val_acc: 0.6854\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2239 - acc: 0.6916 - val_loss: 0.2345 - val_acc: 0.6912\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2217 - acc: 0.6927 - val_loss: 0.2323 - val_acc: 0.6919\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2220 - acc: 0.6927 - val_loss: 0.2358 - val_acc: 0.6890\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2226 - acc: 0.6919 - val_loss: 0.2388 - val_acc: 0.6863\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2249 - acc: 0.6926 - val_loss: 0.2332 - val_acc: 0.6916\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2240 - acc: 0.6917 - val_loss: 0.2361 - val_acc: 0.6903\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2220 - acc: 0.6928 - val_loss: 0.2367 - val_acc: 0.6907\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2228 - acc: 0.6921 - val_loss: 0.2341 - val_acc: 0.6898\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2224 - acc: 0.6927 - val_loss: 0.2346 - val_acc: 0.6908\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2220 - acc: 0.6922 - val_loss: 0.2352 - val_acc: 0.6918\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2204 - acc: 0.6936 - val_loss: 0.2391 - val_acc: 0.6902\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2256 - acc: 0.6925 - val_loss: 0.2387 - val_acc: 0.6899\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2215 - acc: 0.6925 - val_loss: 0.2345 - val_acc: 0.6910\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2227 - acc: 0.6917 - val_loss: 0.2395 - val_acc: 0.6885\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2232 - acc: 0.6924 - val_loss: 0.2341 - val_acc: 0.6897\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2226 - acc: 0.6908 - val_loss: 0.2368 - val_acc: 0.6879\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2202 - acc: 0.6925 - val_loss: 0.2334 - val_acc: 0.6915\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2238 - acc: 0.6924 - val_loss: 0.2459 - val_acc: 0.6889\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2211 - acc: 0.6933 - val_loss: 0.2334 - val_acc: 0.6914\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2212 - acc: 0.6926 - val_loss: 0.2377 - val_acc: 0.6882\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2213 - acc: 0.6931 - val_loss: 0.2378 - val_acc: 0.6907\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2267 - acc: 0.6927 - val_loss: 0.2322 - val_acc: 0.6909\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2198 - acc: 0.6931 - val_loss: 0.2373 - val_acc: 0.6894\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2202 - acc: 0.6931 - val_loss: 0.2343 - val_acc: 0.6919\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2233 - acc: 0.6926 - val_loss: 0.2381 - val_acc: 0.6891\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2244 - acc: 0.6912 - val_loss: 0.2380 - val_acc: 0.6895\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2241 - acc: 0.6921 - val_loss: 0.2343 - val_acc: 0.6908\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2240 - acc: 0.6930 - val_loss: 0.2352 - val_acc: 0.6892\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2215 - acc: 0.6936 - val_loss: 0.2470 - val_acc: 0.6886\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9387 - acc: 0.6807 - val_loss: 2.1817 - val_acc: 0.6795\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9321 - acc: 0.6807 - val_loss: 2.0971 - val_acc: 0.6766\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9232 - acc: 0.6797 - val_loss: 2.0421 - val_acc: 0.6782\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9120 - acc: 0.6816 - val_loss: 2.0847 - val_acc: 0.6755\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9258 - acc: 0.6810 - val_loss: 2.1366 - val_acc: 0.6742\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9680 - acc: 0.6801 - val_loss: 2.0678 - val_acc: 0.6799\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9221 - acc: 0.6809 - val_loss: 2.0625 - val_acc: 0.6794\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9270 - acc: 0.6817 - val_loss: 2.0853 - val_acc: 0.6757\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9224 - acc: 0.6810 - val_loss: 2.1179 - val_acc: 0.6784\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9491 - acc: 0.6805 - val_loss: 2.1319 - val_acc: 0.6776\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9294 - acc: 0.6806 - val_loss: 2.0895 - val_acc: 0.6752\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9468 - acc: 0.6808 - val_loss: 2.0685 - val_acc: 0.6796\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9288 - acc: 0.6812 - val_loss: 2.0533 - val_acc: 0.6777\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9193 - acc: 0.6808 - val_loss: 2.0588 - val_acc: 0.6796\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9218 - acc: 0.6812 - val_loss: 2.0837 - val_acc: 0.6806\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9528 - acc: 0.6799 - val_loss: 2.0584 - val_acc: 0.6790\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9243 - acc: 0.6808 - val_loss: 2.0785 - val_acc: 0.6778\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9245 - acc: 0.6812 - val_loss: 2.0408 - val_acc: 0.6778\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9146 - acc: 0.6811 - val_loss: 2.0495 - val_acc: 0.6773\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9232 - acc: 0.6806 - val_loss: 2.1396 - val_acc: 0.6785\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9505 - acc: 0.6816 - val_loss: 2.2304 - val_acc: 0.6751\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9441 - acc: 0.6807 - val_loss: 2.0505 - val_acc: 0.6778\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9206 - acc: 0.6814 - val_loss: 2.0643 - val_acc: 0.6775\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9298 - acc: 0.6805 - val_loss: 2.0573 - val_acc: 0.6780\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9167 - acc: 0.6805 - val_loss: 2.0784 - val_acc: 0.6754\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9165 - acc: 0.6814 - val_loss: 2.0669 - val_acc: 0.6777\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9395 - acc: 0.6803 - val_loss: 2.0635 - val_acc: 0.6804\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9291 - acc: 0.6818 - val_loss: 2.0400 - val_acc: 0.6797\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9052 - acc: 0.6818 - val_loss: 2.0649 - val_acc: 0.6758\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9171 - acc: 0.6810 - val_loss: 2.1077 - val_acc: 0.6812\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9632 - acc: 0.6803 - val_loss: 2.0462 - val_acc: 0.6803\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9156 - acc: 0.6815 - val_loss: 2.0837 - val_acc: 0.6788\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9270 - acc: 0.6812 - val_loss: 2.0500 - val_acc: 0.6785\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9332 - acc: 0.6810 - val_loss: 2.1339 - val_acc: 0.6730\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9356 - acc: 0.6802 - val_loss: 2.1301 - val_acc: 0.6764\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9345 - acc: 0.6804 - val_loss: 2.0936 - val_acc: 0.6767\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 1.9428 - acc: 0.6811 - val_loss: 2.0791 - val_acc: 0.6798\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9181 - acc: 0.6817 - val_loss: 2.0752 - val_acc: 0.6767\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 1.9420 - acc: 0.6802 - val_loss: 2.0744 - val_acc: 0.6780\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9223 - acc: 0.6804 - val_loss: 2.0651 - val_acc: 0.6802\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9269 - acc: 0.6814 - val_loss: 2.0458 - val_acc: 0.6807\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 1.9315 - acc: 0.6815 - val_loss: 2.0554 - val_acc: 0.6792\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 1.9290 - acc: 0.6805 - val_loss: 2.1622 - val_acc: 0.6714\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 1.9667 - acc: 0.6798 - val_loss: 2.1064 - val_acc: 0.6797\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 1.9431 - acc: 0.6803 - val_loss: 2.0512 - val_acc: 0.6798\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9107 - acc: 0.6818 - val_loss: 2.0433 - val_acc: 0.6811\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 1.9243 - acc: 0.6810 - val_loss: 2.1724 - val_acc: 0.6757\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9429 - acc: 0.6808 - val_loss: 2.1218 - val_acc: 0.6780\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9094 - acc: 0.6806 - val_loss: 2.0843 - val_acc: 0.6765\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9094 - acc: 0.6803 - val_loss: 2.0497 - val_acc: 0.6776\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1823 - acc: 0.9920 - val_loss: 0.1711 - val_acc: 0.9906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1690 - acc: 0.9924 - val_loss: 0.1704 - val_acc: 0.9906\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1665 - acc: 0.9924 - val_loss: 0.1753 - val_acc: 0.9904\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1673 - acc: 0.9925 - val_loss: 0.1663 - val_acc: 0.9907\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1669 - acc: 0.9927 - val_loss: 0.1622 - val_acc: 0.9907\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1652 - acc: 0.9927 - val_loss: 0.1796 - val_acc: 0.9905\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1889 - acc: 0.9926 - val_loss: 0.1798 - val_acc: 0.9905\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1723 - acc: 0.9926 - val_loss: 0.1723 - val_acc: 0.9908\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1639 - acc: 0.9927 - val_loss: 0.1665 - val_acc: 0.9905\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1636 - acc: 0.9926 - val_loss: 0.1656 - val_acc: 0.9903\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1594 - acc: 0.9925 - val_loss: 0.1611 - val_acc: 0.9905\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1623 - acc: 0.9926 - val_loss: 0.1768 - val_acc: 0.9906\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1777 - acc: 0.9923 - val_loss: 0.1860 - val_acc: 0.9897\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1757 - acc: 0.9921 - val_loss: 0.1759 - val_acc: 0.9904\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1725 - acc: 0.9919 - val_loss: 0.1747 - val_acc: 0.9893\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1714 - acc: 0.9911 - val_loss: 0.1766 - val_acc: 0.9896\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1728 - acc: 0.9914 - val_loss: 0.1706 - val_acc: 0.9904\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1675 - acc: 0.9923 - val_loss: 0.1660 - val_acc: 0.9904\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1647 - acc: 0.9925 - val_loss: 0.1714 - val_acc: 0.9905\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1765 - acc: 0.9926 - val_loss: 0.1788 - val_acc: 0.9906\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1717 - acc: 0.9926 - val_loss: 0.1616 - val_acc: 0.9906\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1577 - acc: 0.9926 - val_loss: 0.1623 - val_acc: 0.9903\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1627 - acc: 0.9924 - val_loss: 0.1659 - val_acc: 0.9903\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1647 - acc: 0.9922 - val_loss: 0.1678 - val_acc: 0.9904\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1648 - acc: 0.9925 - val_loss: 0.1735 - val_acc: 0.9904\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1725 - acc: 0.9925 - val_loss: 0.1783 - val_acc: 0.9906\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1697 - acc: 0.9927 - val_loss: 0.1714 - val_acc: 0.9908\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1724 - acc: 0.9923 - val_loss: 0.1745 - val_acc: 0.9905\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1734 - acc: 0.9920 - val_loss: 0.1746 - val_acc: 0.9900\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1739 - acc: 0.9918 - val_loss: 0.1775 - val_acc: 0.9906\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1677 - acc: 0.9924 - val_loss: 0.1677 - val_acc: 0.9903\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1602 - acc: 0.9924 - val_loss: 0.1614 - val_acc: 0.9906\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1601 - acc: 0.9924 - val_loss: 0.1663 - val_acc: 0.9905\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1650 - acc: 0.9924 - val_loss: 0.1618 - val_acc: 0.9906\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1617 - acc: 0.9922 - val_loss: 0.1674 - val_acc: 0.9900\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1688 - acc: 0.9920 - val_loss: 0.1675 - val_acc: 0.9901\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1670 - acc: 0.9918 - val_loss: 0.1667 - val_acc: 0.9905\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1722 - acc: 0.9924 - val_loss: 0.1976 - val_acc: 0.9909\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1887 - acc: 0.9927 - val_loss: 0.1824 - val_acc: 0.9909\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1736 - acc: 0.9927 - val_loss: 0.1733 - val_acc: 0.9907\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1688 - acc: 0.9926 - val_loss: 0.1733 - val_acc: 0.9906\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.1657 - acc: 0.9926 - val_loss: 0.1633 - val_acc: 0.9907\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1617 - acc: 0.9927 - val_loss: 0.1717 - val_acc: 0.9907\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.1684 - acc: 0.9927 - val_loss: 0.1683 - val_acc: 0.9905\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.1652 - acc: 0.9925 - val_loss: 0.1634 - val_acc: 0.9902\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.1573 - acc: 0.9926 - val_loss: 0.1626 - val_acc: 0.9903\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1681 - acc: 0.9923 - val_loss: 0.1706 - val_acc: 0.9904\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.1661 - acc: 0.9927 - val_loss: 0.1676 - val_acc: 0.9906\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1647 - acc: 0.9926 - val_loss: 0.1672 - val_acc: 0.9904\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1744 - acc: 0.9918 - val_loss: 0.1796 - val_acc: 0.9894\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0029 - acc: 0.9614 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0030 - val_acc: 0.9643\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0029 - acc: 0.9616 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0031 - val_acc: 0.9637\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0034 - val_acc: 0.9623\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0031 - acc: 0.9588 - val_loss: 0.0031 - val_acc: 0.9644\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9616 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0030 - acc: 0.9590 - val_loss: 0.0032 - val_acc: 0.9591\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9589 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9649\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9646\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9621 - val_loss: 0.0031 - val_acc: 0.9654\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0030 - acc: 0.9584 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9586 - val_loss: 0.0030 - val_acc: 0.9637\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9562 - val_loss: 0.0031 - val_acc: 0.9613\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9598 - val_loss: 0.0031 - val_acc: 0.9638\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9614 - val_loss: 0.0031 - val_acc: 0.9627\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9593 - val_loss: 0.0031 - val_acc: 0.9635\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0032 - val_acc: 0.9612\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9579 - val_loss: 0.0031 - val_acc: 0.9626\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9620 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9607 - val_loss: 0.0033 - val_acc: 0.9570\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0031 - acc: 0.9576 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9600 - val_loss: 0.0032 - val_acc: 0.9615\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9596 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9600 - val_loss: 0.0030 - val_acc: 0.9638\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0029 - acc: 0.9582 - val_loss: 0.0030 - val_acc: 0.9640\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9594 - val_loss: 0.0031 - val_acc: 0.9607\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9601 - val_loss: 0.0032 - val_acc: 0.9631\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0031 - acc: 0.9586 - val_loss: 0.0031 - val_acc: 0.9640\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9616 - val_loss: 0.0030 - val_acc: 0.9635\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0037 - val_acc: 0.9488\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0032 - acc: 0.9553 - val_loss: 0.0031 - val_acc: 0.9635\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9597 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9581 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9589 - val_loss: 0.0030 - val_acc: 0.9634\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0032 - val_acc: 0.9601\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9585 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "start training round 35\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2237 - acc: 0.6916 - val_loss: 0.2349 - val_acc: 0.6894\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2202 - acc: 0.6934 - val_loss: 0.2319 - val_acc: 0.6915\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2234 - acc: 0.6921 - val_loss: 0.2339 - val_acc: 0.6907\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2207 - acc: 0.6928 - val_loss: 0.2342 - val_acc: 0.6922\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2206 - acc: 0.6926 - val_loss: 0.2354 - val_acc: 0.6910\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2200 - acc: 0.6936 - val_loss: 0.2353 - val_acc: 0.6912\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2252 - acc: 0.6924 - val_loss: 0.2396 - val_acc: 0.6877\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2249 - acc: 0.6910 - val_loss: 0.2366 - val_acc: 0.6908\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2211 - acc: 0.6938 - val_loss: 0.2387 - val_acc: 0.6917\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2261 - acc: 0.6927 - val_loss: 0.2351 - val_acc: 0.6914\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2219 - acc: 0.6925 - val_loss: 0.2361 - val_acc: 0.6893\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2244 - acc: 0.6911 - val_loss: 0.2429 - val_acc: 0.6874\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2237 - acc: 0.6913 - val_loss: 0.2332 - val_acc: 0.6915\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2210 - acc: 0.6925 - val_loss: 0.2331 - val_acc: 0.6908\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2208 - acc: 0.6925 - val_loss: 0.2345 - val_acc: 0.6899\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2255 - acc: 0.6908 - val_loss: 0.2379 - val_acc: 0.6901\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2193 - acc: 0.6941 - val_loss: 0.2336 - val_acc: 0.6912\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2245 - acc: 0.6931 - val_loss: 0.2363 - val_acc: 0.6903\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2213 - acc: 0.6929 - val_loss: 0.2389 - val_acc: 0.6877\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2240 - acc: 0.6908 - val_loss: 0.2347 - val_acc: 0.6916\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2227 - acc: 0.6939 - val_loss: 0.2424 - val_acc: 0.6918\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2227 - acc: 0.6931 - val_loss: 0.2360 - val_acc: 0.6892\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2236 - acc: 0.6917 - val_loss: 0.2405 - val_acc: 0.6905\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2245 - acc: 0.6920 - val_loss: 0.2380 - val_acc: 0.6891\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2234 - acc: 0.6919 - val_loss: 0.2345 - val_acc: 0.6897\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2196 - acc: 0.6933 - val_loss: 0.2367 - val_acc: 0.6897\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2215 - acc: 0.6935 - val_loss: 0.2338 - val_acc: 0.6904\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2219 - acc: 0.6922 - val_loss: 0.2349 - val_acc: 0.6904\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2206 - acc: 0.6928 - val_loss: 0.2330 - val_acc: 0.6907\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2208 - acc: 0.6940 - val_loss: 0.2327 - val_acc: 0.6923\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2202 - acc: 0.6932 - val_loss: 0.2390 - val_acc: 0.6896\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2248 - acc: 0.6914 - val_loss: 0.2323 - val_acc: 0.6915\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2203 - acc: 0.6935 - val_loss: 0.2396 - val_acc: 0.6902\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2254 - acc: 0.6915 - val_loss: 0.2351 - val_acc: 0.6913\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2232 - acc: 0.6937 - val_loss: 0.2344 - val_acc: 0.6914\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2214 - acc: 0.6936 - val_loss: 0.2330 - val_acc: 0.6904\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2194 - acc: 0.6936 - val_loss: 0.2321 - val_acc: 0.6915\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2202 - acc: 0.6934 - val_loss: 0.2330 - val_acc: 0.6905\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2226 - acc: 0.6928 - val_loss: 0.2349 - val_acc: 0.6897\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2227 - acc: 0.6920 - val_loss: 0.2326 - val_acc: 0.6908\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2182 - acc: 0.6945 - val_loss: 0.2338 - val_acc: 0.6907\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2229 - acc: 0.6911 - val_loss: 0.2351 - val_acc: 0.6897\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2234 - acc: 0.6933 - val_loss: 0.2407 - val_acc: 0.6900\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2220 - acc: 0.6926 - val_loss: 0.2380 - val_acc: 0.6882\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2233 - acc: 0.6920 - val_loss: 0.2396 - val_acc: 0.6882\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2207 - acc: 0.6928 - val_loss: 0.2339 - val_acc: 0.6904\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2198 - acc: 0.6936 - val_loss: 0.2333 - val_acc: 0.6909\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2225 - acc: 0.6937 - val_loss: 0.2340 - val_acc: 0.6921\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2209 - acc: 0.6931 - val_loss: 0.2364 - val_acc: 0.6892\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2243 - acc: 0.6924 - val_loss: 0.2404 - val_acc: 0.6874\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9278 - acc: 0.6815 - val_loss: 2.1088 - val_acc: 0.6808\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9425 - acc: 0.6812 - val_loss: 2.0442 - val_acc: 0.6808\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9253 - acc: 0.6809 - val_loss: 2.0489 - val_acc: 0.6804\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9448 - acc: 0.6801 - val_loss: 2.0750 - val_acc: 0.6810\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9299 - acc: 0.6814 - val_loss: 2.0804 - val_acc: 0.6805\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9155 - acc: 0.6814 - val_loss: 2.0417 - val_acc: 0.6817\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9263 - acc: 0.6816 - val_loss: 2.1200 - val_acc: 0.6799\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9452 - acc: 0.6808 - val_loss: 2.0853 - val_acc: 0.6759\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9400 - acc: 0.6797 - val_loss: 2.0754 - val_acc: 0.6766\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9112 - acc: 0.6809 - val_loss: 2.0557 - val_acc: 0.6783\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9281 - acc: 0.6803 - val_loss: 2.0537 - val_acc: 0.6784\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9173 - acc: 0.6814 - val_loss: 2.0409 - val_acc: 0.6797\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9233 - acc: 0.6811 - val_loss: 2.1084 - val_acc: 0.6772\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9374 - acc: 0.6804 - val_loss: 2.0504 - val_acc: 0.6789\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9209 - acc: 0.6806 - val_loss: 2.0926 - val_acc: 0.6787\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9275 - acc: 0.6802 - val_loss: 2.0571 - val_acc: 0.6773\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9345 - acc: 0.6807 - val_loss: 2.0628 - val_acc: 0.6808\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9349 - acc: 0.6811 - val_loss: 2.0744 - val_acc: 0.6791\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9404 - acc: 0.6813 - val_loss: 2.0610 - val_acc: 0.6790\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9522 - acc: 0.6813 - val_loss: 2.1421 - val_acc: 0.6756\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9383 - acc: 0.6809 - val_loss: 2.0439 - val_acc: 0.6782\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9013 - acc: 0.6819 - val_loss: 2.0604 - val_acc: 0.6790\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9312 - acc: 0.6807 - val_loss: 2.0814 - val_acc: 0.6778\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9605 - acc: 0.6807 - val_loss: 2.0513 - val_acc: 0.6791\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9398 - acc: 0.6807 - val_loss: 2.0366 - val_acc: 0.6805\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9111 - acc: 0.6818 - val_loss: 2.0396 - val_acc: 0.6790\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9108 - acc: 0.6805 - val_loss: 2.0502 - val_acc: 0.6796\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9198 - acc: 0.6808 - val_loss: 2.0603 - val_acc: 0.6777\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9318 - acc: 0.6807 - val_loss: 2.1061 - val_acc: 0.6758\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9563 - acc: 0.6805 - val_loss: 2.0714 - val_acc: 0.6776\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9352 - acc: 0.6814 - val_loss: 2.0426 - val_acc: 0.6795\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9263 - acc: 0.6810 - val_loss: 2.0570 - val_acc: 0.6790\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9269 - acc: 0.6803 - val_loss: 2.0756 - val_acc: 0.6796\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9420 - acc: 0.6808 - val_loss: 2.1417 - val_acc: 0.6766\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9217 - acc: 0.6819 - val_loss: 2.0857 - val_acc: 0.6791\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9131 - acc: 0.6819 - val_loss: 2.0744 - val_acc: 0.6809\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9319 - acc: 0.6814 - val_loss: 2.0460 - val_acc: 0.6809\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9082 - acc: 0.6818 - val_loss: 2.0910 - val_acc: 0.6790\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9399 - acc: 0.6814 - val_loss: 2.0373 - val_acc: 0.6804\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9359 - acc: 0.6817 - val_loss: 2.0505 - val_acc: 0.6788\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9113 - acc: 0.6811 - val_loss: 2.0290 - val_acc: 0.6800\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9062 - acc: 0.6806 - val_loss: 2.0460 - val_acc: 0.6809\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9256 - acc: 0.6816 - val_loss: 2.0562 - val_acc: 0.6809\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9336 - acc: 0.6818 - val_loss: 2.1082 - val_acc: 0.6800\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9190 - acc: 0.6816 - val_loss: 2.0503 - val_acc: 0.6815\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9351 - acc: 0.6802 - val_loss: 2.1293 - val_acc: 0.6741\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9348 - acc: 0.6812 - val_loss: 2.0495 - val_acc: 0.6790\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9205 - acc: 0.6813 - val_loss: 2.1314 - val_acc: 0.6750\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9462 - acc: 0.6806 - val_loss: 2.0791 - val_acc: 0.6763\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9275 - acc: 0.6807 - val_loss: 2.1066 - val_acc: 0.6765\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1708 - acc: 0.9920 - val_loss: 0.1744 - val_acc: 0.9905\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1710 - acc: 0.9926 - val_loss: 0.1681 - val_acc: 0.9905\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1687 - acc: 0.9927 - val_loss: 0.1829 - val_acc: 0.9893\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1759 - acc: 0.9917 - val_loss: 0.1711 - val_acc: 0.9894\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1643 - acc: 0.9921 - val_loss: 0.1613 - val_acc: 0.9905\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1609 - acc: 0.9925 - val_loss: 0.1639 - val_acc: 0.9903\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1676 - acc: 0.9922 - val_loss: 0.1712 - val_acc: 0.9899\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1632 - acc: 0.9923 - val_loss: 0.1670 - val_acc: 0.9904\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1602 - acc: 0.9924 - val_loss: 0.1622 - val_acc: 0.9904\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1623 - acc: 0.9926 - val_loss: 0.1678 - val_acc: 0.9907\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1754 - acc: 0.9927 - val_loss: 0.1893 - val_acc: 0.9908\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1765 - acc: 0.9927 - val_loss: 0.1762 - val_acc: 0.9906\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1650 - acc: 0.9925 - val_loss: 0.1645 - val_acc: 0.9906\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1672 - acc: 0.9924 - val_loss: 0.1655 - val_acc: 0.9906\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1602 - acc: 0.9924 - val_loss: 0.1602 - val_acc: 0.9908\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1608 - acc: 0.9926 - val_loss: 0.1643 - val_acc: 0.9907\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1630 - acc: 0.9927 - val_loss: 0.1658 - val_acc: 0.9908\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1635 - acc: 0.9927 - val_loss: 0.1657 - val_acc: 0.9908\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1664 - acc: 0.9927 - val_loss: 0.1655 - val_acc: 0.9908\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1640 - acc: 0.9927 - val_loss: 0.1689 - val_acc: 0.9906\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1738 - acc: 0.9927 - val_loss: 0.1686 - val_acc: 0.9908\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1642 - acc: 0.9928 - val_loss: 0.1625 - val_acc: 0.9907\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1590 - acc: 0.9926 - val_loss: 0.1651 - val_acc: 0.9905\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1670 - acc: 0.9918 - val_loss: 0.1915 - val_acc: 0.9880\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1838 - acc: 0.9904 - val_loss: 0.1815 - val_acc: 0.9881\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1734 - acc: 0.9914 - val_loss: 0.1661 - val_acc: 0.9905\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1628 - acc: 0.9926 - val_loss: 0.1721 - val_acc: 0.9906\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1694 - acc: 0.9927 - val_loss: 0.1707 - val_acc: 0.9906\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1727 - acc: 0.9927 - val_loss: 0.1738 - val_acc: 0.9905\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1717 - acc: 0.9926 - val_loss: 0.1711 - val_acc: 0.9904\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1694 - acc: 0.9926 - val_loss: 0.1664 - val_acc: 0.9905\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1618 - acc: 0.9927 - val_loss: 0.1609 - val_acc: 0.9906\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1601 - acc: 0.9927 - val_loss: 0.1662 - val_acc: 0.9907\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1673 - acc: 0.9927 - val_loss: 0.1753 - val_acc: 0.9906\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1725 - acc: 0.9923 - val_loss: 0.1731 - val_acc: 0.9902\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1662 - acc: 0.9922 - val_loss: 0.1710 - val_acc: 0.9897\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1672 - acc: 0.9921 - val_loss: 0.1602 - val_acc: 0.9906\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1590 - acc: 0.9927 - val_loss: 0.1660 - val_acc: 0.9906\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1771 - acc: 0.9925 - val_loss: 0.1744 - val_acc: 0.9905\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1718 - acc: 0.9926 - val_loss: 0.1746 - val_acc: 0.9906\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1712 - acc: 0.9927 - val_loss: 0.1674 - val_acc: 0.9905\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1660 - acc: 0.9927 - val_loss: 0.1644 - val_acc: 0.9906\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1666 - acc: 0.9927 - val_loss: 0.1647 - val_acc: 0.9907\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1657 - acc: 0.9925 - val_loss: 0.1761 - val_acc: 0.9895\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1781 - acc: 0.9908 - val_loss: 0.1814 - val_acc: 0.9888\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1741 - acc: 0.9913 - val_loss: 0.1720 - val_acc: 0.9903\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1610 - acc: 0.9925 - val_loss: 0.1607 - val_acc: 0.9908\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1709 - acc: 0.9923 - val_loss: 0.1835 - val_acc: 0.9894\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1763 - acc: 0.9918 - val_loss: 0.1705 - val_acc: 0.9903\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1628 - acc: 0.9926 - val_loss: 0.1648 - val_acc: 0.9908\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9601 - val_loss: 0.0030 - val_acc: 0.9641\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9614 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0032 - val_acc: 0.9591\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9567 - val_loss: 0.0032 - val_acc: 0.9587\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9563 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9575 - val_loss: 0.0030 - val_acc: 0.9643\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9585 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9616\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9574 - val_loss: 0.0033 - val_acc: 0.9595\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0031 - val_acc: 0.9646\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9616 - val_loss: 0.0031 - val_acc: 0.9648\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9600 - val_loss: 0.0033 - val_acc: 0.9631\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0032 - val_acc: 0.9607\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9590 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0031 - val_acc: 0.9647\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0030 - acc: 0.9599 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9593 - val_loss: 0.0031 - val_acc: 0.9625\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9629\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9607 - val_loss: 0.0031 - val_acc: 0.9617\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0033 - val_acc: 0.9568\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0031 - acc: 0.9547 - val_loss: 0.0031 - val_acc: 0.9600\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9627\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9599 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9575 - val_loss: 0.0030 - val_acc: 0.9633\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9604 - val_loss: 0.0035 - val_acc: 0.9568\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9612\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9638\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9618 - val_loss: 0.0031 - val_acc: 0.9647\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9595 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9587 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9560 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9593 - val_loss: 0.0032 - val_acc: 0.9625\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9577 - val_loss: 0.0032 - val_acc: 0.9616\n",
      "start training round 36\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2235 - acc: 0.6933 - val_loss: 0.2340 - val_acc: 0.6907\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2201 - acc: 0.6931 - val_loss: 0.2366 - val_acc: 0.6894\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2218 - acc: 0.6919 - val_loss: 0.2368 - val_acc: 0.6876\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2204 - acc: 0.6920 - val_loss: 0.2330 - val_acc: 0.6909\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2216 - acc: 0.6931 - val_loss: 0.2370 - val_acc: 0.6906\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2235 - acc: 0.6924 - val_loss: 0.2367 - val_acc: 0.6891\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2238 - acc: 0.6911 - val_loss: 0.2322 - val_acc: 0.6907\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2215 - acc: 0.6938 - val_loss: 0.2372 - val_acc: 0.6892\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2238 - acc: 0.6922 - val_loss: 0.2333 - val_acc: 0.6909\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2228 - acc: 0.6924 - val_loss: 0.2362 - val_acc: 0.6885\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2256 - acc: 0.6918 - val_loss: 0.2328 - val_acc: 0.6907\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2191 - acc: 0.6940 - val_loss: 0.2322 - val_acc: 0.6907\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2204 - acc: 0.6934 - val_loss: 0.2333 - val_acc: 0.6896\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2226 - acc: 0.6919 - val_loss: 0.2336 - val_acc: 0.6927\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2203 - acc: 0.6944 - val_loss: 0.2369 - val_acc: 0.6896\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2226 - acc: 0.6935 - val_loss: 0.2329 - val_acc: 0.6898\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2229 - acc: 0.6921 - val_loss: 0.2325 - val_acc: 0.6918\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2199 - acc: 0.6938 - val_loss: 0.2372 - val_acc: 0.6900\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2196 - acc: 0.6934 - val_loss: 0.2329 - val_acc: 0.6899\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2183 - acc: 0.6938 - val_loss: 0.2378 - val_acc: 0.6881\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2258 - acc: 0.6915 - val_loss: 0.2466 - val_acc: 0.6871\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2203 - acc: 0.6938 - val_loss: 0.2396 - val_acc: 0.6894\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2233 - acc: 0.6918 - val_loss: 0.2370 - val_acc: 0.6889\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2227 - acc: 0.6917 - val_loss: 0.2317 - val_acc: 0.6908\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2190 - acc: 0.6938 - val_loss: 0.2339 - val_acc: 0.6917\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2232 - acc: 0.6934 - val_loss: 0.2428 - val_acc: 0.6894\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2211 - acc: 0.6935 - val_loss: 0.2357 - val_acc: 0.6894\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2221 - acc: 0.6923 - val_loss: 0.2378 - val_acc: 0.6878\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2238 - acc: 0.6916 - val_loss: 0.2311 - val_acc: 0.6917\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2183 - acc: 0.6942 - val_loss: 0.2331 - val_acc: 0.6917\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2227 - acc: 0.6915 - val_loss: 0.2429 - val_acc: 0.6878\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2239 - acc: 0.6919 - val_loss: 0.2383 - val_acc: 0.6902\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2233 - acc: 0.6923 - val_loss: 0.2340 - val_acc: 0.6917\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2217 - acc: 0.6931 - val_loss: 0.2355 - val_acc: 0.6912\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2216 - acc: 0.6932 - val_loss: 0.2417 - val_acc: 0.6890\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2202 - acc: 0.6937 - val_loss: 0.2337 - val_acc: 0.6908\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2208 - acc: 0.6937 - val_loss: 0.2313 - val_acc: 0.6913\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2220 - acc: 0.6926 - val_loss: 0.2443 - val_acc: 0.6858\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2229 - acc: 0.6927 - val_loss: 0.2347 - val_acc: 0.6912\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2191 - acc: 0.6946 - val_loss: 0.2347 - val_acc: 0.6895\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2196 - acc: 0.6935 - val_loss: 0.2374 - val_acc: 0.6892\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2209 - acc: 0.6933 - val_loss: 0.2344 - val_acc: 0.6897\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2208 - acc: 0.6932 - val_loss: 0.2332 - val_acc: 0.6913\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2189 - acc: 0.6947 - val_loss: 0.2315 - val_acc: 0.6929\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2233 - acc: 0.6942 - val_loss: 0.2331 - val_acc: 0.6923\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2251 - acc: 0.6920 - val_loss: 0.2367 - val_acc: 0.6904\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2230 - acc: 0.6926 - val_loss: 0.2334 - val_acc: 0.6910\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2197 - acc: 0.6937 - val_loss: 0.2388 - val_acc: 0.6887\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2224 - acc: 0.6923 - val_loss: 0.2342 - val_acc: 0.6908\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2211 - acc: 0.6939 - val_loss: 0.2314 - val_acc: 0.6915\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9280 - acc: 0.6812 - val_loss: 2.0614 - val_acc: 0.6784\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9197 - acc: 0.6810 - val_loss: 2.1059 - val_acc: 0.6788\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9259 - acc: 0.6816 - val_loss: 2.2169 - val_acc: 0.6761\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9488 - acc: 0.6809 - val_loss: 2.1427 - val_acc: 0.6780\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9492 - acc: 0.6807 - val_loss: 2.0770 - val_acc: 0.6806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9085 - acc: 0.6814 - val_loss: 2.0877 - val_acc: 0.6808\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9494 - acc: 0.6808 - val_loss: 2.0534 - val_acc: 0.6799\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9172 - acc: 0.6808 - val_loss: 2.0714 - val_acc: 0.6793\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9253 - acc: 0.6819 - val_loss: 2.0399 - val_acc: 0.6799\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9295 - acc: 0.6809 - val_loss: 2.0397 - val_acc: 0.6814\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9202 - acc: 0.6823 - val_loss: 2.1664 - val_acc: 0.6794\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9214 - acc: 0.6812 - val_loss: 2.0670 - val_acc: 0.6759\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9287 - acc: 0.6810 - val_loss: 2.1175 - val_acc: 0.6768\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9332 - acc: 0.6815 - val_loss: 2.0863 - val_acc: 0.6764\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9264 - acc: 0.6810 - val_loss: 2.0521 - val_acc: 0.6792\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9133 - acc: 0.6811 - val_loss: 2.1642 - val_acc: 0.6772\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9370 - acc: 0.6813 - val_loss: 2.0674 - val_acc: 0.6779\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9273 - acc: 0.6814 - val_loss: 2.0534 - val_acc: 0.6818\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9488 - acc: 0.6811 - val_loss: 2.1613 - val_acc: 0.6787\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9257 - acc: 0.6820 - val_loss: 2.0504 - val_acc: 0.6811\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9210 - acc: 0.6823 - val_loss: 2.0466 - val_acc: 0.6793\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9281 - acc: 0.6813 - val_loss: 2.0553 - val_acc: 0.6772\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9515 - acc: 0.6807 - val_loss: 2.0499 - val_acc: 0.6785\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9369 - acc: 0.6811 - val_loss: 2.0884 - val_acc: 0.6775\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9201 - acc: 0.6806 - val_loss: 2.0317 - val_acc: 0.6800\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9306 - acc: 0.6817 - val_loss: 2.0448 - val_acc: 0.6793\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9309 - acc: 0.6819 - val_loss: 2.0289 - val_acc: 0.6793\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9133 - acc: 0.6814 - val_loss: 2.0776 - val_acc: 0.6763\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9267 - acc: 0.6818 - val_loss: 2.0985 - val_acc: 0.6780\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9215 - acc: 0.6802 - val_loss: 2.0818 - val_acc: 0.6792\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9346 - acc: 0.6808 - val_loss: 2.0772 - val_acc: 0.6792\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9396 - acc: 0.6816 - val_loss: 2.0454 - val_acc: 0.6805\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9376 - acc: 0.6812 - val_loss: 2.0237 - val_acc: 0.6814\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.8984 - acc: 0.6825 - val_loss: 2.0533 - val_acc: 0.6817\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9434 - acc: 0.6818 - val_loss: 2.1516 - val_acc: 0.6759\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9337 - acc: 0.6805 - val_loss: 2.0349 - val_acc: 0.6814\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9192 - acc: 0.6815 - val_loss: 2.0566 - val_acc: 0.6823\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9199 - acc: 0.6814 - val_loss: 2.0996 - val_acc: 0.6816\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9312 - acc: 0.6813 - val_loss: 2.0829 - val_acc: 0.6800\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9093 - acc: 0.6819 - val_loss: 2.0451 - val_acc: 0.6805\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9093 - acc: 0.6811 - val_loss: 2.0782 - val_acc: 0.6777\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 1.9391 - acc: 0.6805 - val_loss: 2.0886 - val_acc: 0.6775\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9168 - acc: 0.6814 - val_loss: 2.0777 - val_acc: 0.6779\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9145 - acc: 0.6810 - val_loss: 2.0863 - val_acc: 0.6781\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9152 - acc: 0.6811 - val_loss: 2.0433 - val_acc: 0.6799\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9368 - acc: 0.6816 - val_loss: 2.0401 - val_acc: 0.6820\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9146 - acc: 0.6822 - val_loss: 2.0886 - val_acc: 0.6798\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9398 - acc: 0.6810 - val_loss: 2.0399 - val_acc: 0.6791\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9137 - acc: 0.6821 - val_loss: 2.0652 - val_acc: 0.6794\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9420 - acc: 0.6810 - val_loss: 2.0833 - val_acc: 0.6775\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1688 - acc: 0.9925 - val_loss: 0.1801 - val_acc: 0.9903\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1773 - acc: 0.9921 - val_loss: 0.1745 - val_acc: 0.9907\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1654 - acc: 0.9927 - val_loss: 0.1677 - val_acc: 0.9908\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1628 - acc: 0.9927 - val_loss: 0.1670 - val_acc: 0.9905\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1578 - acc: 0.9927 - val_loss: 0.1587 - val_acc: 0.9905\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1585 - acc: 0.9926 - val_loss: 0.1666 - val_acc: 0.9906\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1623 - acc: 0.9927 - val_loss: 0.1607 - val_acc: 0.9906\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1571 - acc: 0.9927 - val_loss: 0.1589 - val_acc: 0.9907\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1611 - acc: 0.9927 - val_loss: 0.1717 - val_acc: 0.9907\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1783 - acc: 0.9927 - val_loss: 0.1829 - val_acc: 0.9907\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1695 - acc: 0.9928 - val_loss: 0.1690 - val_acc: 0.9908\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1638 - acc: 0.9927 - val_loss: 0.1726 - val_acc: 0.9908\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1669 - acc: 0.9927 - val_loss: 0.1701 - val_acc: 0.9907\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1627 - acc: 0.9927 - val_loss: 0.1675 - val_acc: 0.9905\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1641 - acc: 0.9924 - val_loss: 0.1693 - val_acc: 0.9902\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1656 - acc: 0.9919 - val_loss: 0.1724 - val_acc: 0.9894\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1665 - acc: 0.9923 - val_loss: 0.1672 - val_acc: 0.9905\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1688 - acc: 0.9926 - val_loss: 0.1682 - val_acc: 0.9904\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1625 - acc: 0.9926 - val_loss: 0.1674 - val_acc: 0.9905\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1643 - acc: 0.9924 - val_loss: 0.1657 - val_acc: 0.9906\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1615 - acc: 0.9926 - val_loss: 0.1638 - val_acc: 0.9906\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1718 - acc: 0.9924 - val_loss: 0.1807 - val_acc: 0.9901\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1803 - acc: 0.9921 - val_loss: 0.1924 - val_acc: 0.9901\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1763 - acc: 0.9923 - val_loss: 0.1685 - val_acc: 0.9907\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1606 - acc: 0.9927 - val_loss: 0.1612 - val_acc: 0.9908\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1578 - acc: 0.9927 - val_loss: 0.1612 - val_acc: 0.9908\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1592 - acc: 0.9927 - val_loss: 0.1611 - val_acc: 0.9906\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1594 - acc: 0.9926 - val_loss: 0.1694 - val_acc: 0.9906\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1717 - acc: 0.9923 - val_loss: 0.1781 - val_acc: 0.9898\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1661 - acc: 0.9922 - val_loss: 0.1604 - val_acc: 0.9907\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1621 - acc: 0.9924 - val_loss: 0.1685 - val_acc: 0.9907\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1665 - acc: 0.9927 - val_loss: 0.1698 - val_acc: 0.9909\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1796 - acc: 0.9927 - val_loss: 0.2036 - val_acc: 0.9906\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1827 - acc: 0.9927 - val_loss: 0.1690 - val_acc: 0.9908\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1623 - acc: 0.9927 - val_loss: 0.1613 - val_acc: 0.9905\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1587 - acc: 0.9925 - val_loss: 0.1637 - val_acc: 0.9904\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1590 - acc: 0.9924 - val_loss: 0.1589 - val_acc: 0.9905\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1579 - acc: 0.9923 - val_loss: 0.1593 - val_acc: 0.9903\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1616 - acc: 0.9922 - val_loss: 0.1655 - val_acc: 0.9902\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1691 - acc: 0.9920 - val_loss: 0.1806 - val_acc: 0.9896\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1751 - acc: 0.9916 - val_loss: 0.1666 - val_acc: 0.9898\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1603 - acc: 0.9921 - val_loss: 0.1597 - val_acc: 0.9904\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1578 - acc: 0.9927 - val_loss: 0.1640 - val_acc: 0.9907\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1758 - acc: 0.9928 - val_loss: 0.1736 - val_acc: 0.9907\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1712 - acc: 0.9927 - val_loss: 0.1746 - val_acc: 0.9908\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1622 - acc: 0.9927 - val_loss: 0.1574 - val_acc: 0.9907\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1545 - acc: 0.9928 - val_loss: 0.1570 - val_acc: 0.9906\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1607 - acc: 0.9927 - val_loss: 0.1799 - val_acc: 0.9906\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1754 - acc: 0.9927 - val_loss: 0.1740 - val_acc: 0.9906\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1695 - acc: 0.9927 - val_loss: 0.1649 - val_acc: 0.9905\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0031 - val_acc: 0.9652\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0032 - val_acc: 0.9643\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0031 - acc: 0.9558 - val_loss: 0.0032 - val_acc: 0.9626\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9650\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0030 - acc: 0.9590 - val_loss: 0.0033 - val_acc: 0.9597\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9600 - val_loss: 0.0031 - val_acc: 0.9635\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9600 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9613 - val_loss: 0.0030 - val_acc: 0.9640\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0035 - val_acc: 0.9542\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0031 - acc: 0.9547 - val_loss: 0.0031 - val_acc: 0.9590\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9643\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9596 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9638\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0034 - val_acc: 0.9559\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0032 - acc: 0.9562 - val_loss: 0.0032 - val_acc: 0.9615\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9588 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9618 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0030 - val_acc: 0.9637\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9607 - val_loss: 0.0034 - val_acc: 0.9570\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9578 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9616 - val_loss: 0.0030 - val_acc: 0.9643\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9584 - val_loss: 0.0030 - val_acc: 0.9641\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9629\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9588 - val_loss: 0.0030 - val_acc: 0.9641\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9608 - val_loss: 0.0034 - val_acc: 0.9571\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0031 - acc: 0.9575 - val_loss: 0.0036 - val_acc: 0.9546\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9559 - val_loss: 0.0030 - val_acc: 0.9641\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9614 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9592 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0031 - val_acc: 0.9602\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0030 - acc: 0.9576 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0031 - acc: 0.9549 - val_loss: 0.0031 - val_acc: 0.9607\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9616 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0030 - val_acc: 0.9638\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0031 - val_acc: 0.9613\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0030 - val_acc: 0.9631\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9599 - val_loss: 0.0030 - val_acc: 0.9629\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9637\n",
      "start training round 37\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2188 - acc: 0.6942 - val_loss: 0.2364 - val_acc: 0.6904\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2220 - acc: 0.6931 - val_loss: 0.2340 - val_acc: 0.6920\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2191 - acc: 0.6946 - val_loss: 0.2350 - val_acc: 0.6896\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2214 - acc: 0.6926 - val_loss: 0.2373 - val_acc: 0.6893\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2225 - acc: 0.6928 - val_loss: 0.2466 - val_acc: 0.6891\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2248 - acc: 0.6917 - val_loss: 0.2339 - val_acc: 0.6911\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2214 - acc: 0.6935 - val_loss: 0.2356 - val_acc: 0.6901\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2205 - acc: 0.6936 - val_loss: 0.2341 - val_acc: 0.6908\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2197 - acc: 0.6939 - val_loss: 0.2318 - val_acc: 0.6923\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2199 - acc: 0.6939 - val_loss: 0.2324 - val_acc: 0.6926\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2208 - acc: 0.6932 - val_loss: 0.2402 - val_acc: 0.6862\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2252 - acc: 0.6904 - val_loss: 0.2332 - val_acc: 0.6911\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2214 - acc: 0.6926 - val_loss: 0.2435 - val_acc: 0.6883\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2231 - acc: 0.6936 - val_loss: 0.2346 - val_acc: 0.6906\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2183 - acc: 0.6946 - val_loss: 0.2315 - val_acc: 0.6922\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2191 - acc: 0.6944 - val_loss: 0.2340 - val_acc: 0.6899\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2219 - acc: 0.6914 - val_loss: 0.2318 - val_acc: 0.6910\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2213 - acc: 0.6934 - val_loss: 0.2363 - val_acc: 0.6900\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2204 - acc: 0.6939 - val_loss: 0.2324 - val_acc: 0.6914\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2198 - acc: 0.6935 - val_loss: 0.2365 - val_acc: 0.6897\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2218 - acc: 0.6923 - val_loss: 0.2428 - val_acc: 0.6883\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2251 - acc: 0.6917 - val_loss: 0.2345 - val_acc: 0.6903\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2194 - acc: 0.6930 - val_loss: 0.2305 - val_acc: 0.6918\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2181 - acc: 0.6938 - val_loss: 0.2340 - val_acc: 0.6898\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2201 - acc: 0.6935 - val_loss: 0.2334 - val_acc: 0.6913\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2237 - acc: 0.6928 - val_loss: 0.2393 - val_acc: 0.6904\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2210 - acc: 0.6936 - val_loss: 0.2375 - val_acc: 0.6901\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2209 - acc: 0.6934 - val_loss: 0.2357 - val_acc: 0.6910\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2199 - acc: 0.6935 - val_loss: 0.2343 - val_acc: 0.6911\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2213 - acc: 0.6925 - val_loss: 0.2359 - val_acc: 0.6891\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2198 - acc: 0.6931 - val_loss: 0.2396 - val_acc: 0.6876\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2208 - acc: 0.6927 - val_loss: 0.2326 - val_acc: 0.6902\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2188 - acc: 0.6943 - val_loss: 0.2402 - val_acc: 0.6869\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2229 - acc: 0.6921 - val_loss: 0.2557 - val_acc: 0.6838\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2221 - acc: 0.6928 - val_loss: 0.2331 - val_acc: 0.6901\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.2196 - acc: 0.6938 - val_loss: 0.2344 - val_acc: 0.6918\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2215 - acc: 0.6943 - val_loss: 0.2374 - val_acc: 0.6901\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.2200 - acc: 0.6937 - val_loss: 0.2325 - val_acc: 0.6920\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2202 - acc: 0.6944 - val_loss: 0.2331 - val_acc: 0.6907\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2219 - acc: 0.6931 - val_loss: 0.2342 - val_acc: 0.6894\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2207 - acc: 0.6925 - val_loss: 0.2318 - val_acc: 0.6914\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2191 - acc: 0.6933 - val_loss: 0.2312 - val_acc: 0.6918\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2192 - acc: 0.6942 - val_loss: 0.2351 - val_acc: 0.6907\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2231 - acc: 0.6921 - val_loss: 0.2331 - val_acc: 0.6917\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2192 - acc: 0.6943 - val_loss: 0.2316 - val_acc: 0.6914\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2210 - acc: 0.6931 - val_loss: 0.2405 - val_acc: 0.6890\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2202 - acc: 0.6932 - val_loss: 0.2319 - val_acc: 0.6907\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2221 - acc: 0.6923 - val_loss: 0.2323 - val_acc: 0.6916\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2186 - acc: 0.6943 - val_loss: 0.2331 - val_acc: 0.6913\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.2212 - acc: 0.6935 - val_loss: 0.2336 - val_acc: 0.6908\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9231 - acc: 0.6810 - val_loss: 2.0586 - val_acc: 0.6775\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9204 - acc: 0.6808 - val_loss: 2.0447 - val_acc: 0.6783\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9014 - acc: 0.6821 - val_loss: 2.0586 - val_acc: 0.6798\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9131 - acc: 0.6816 - val_loss: 2.1409 - val_acc: 0.6787\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9319 - acc: 0.6812 - val_loss: 2.0703 - val_acc: 0.6789\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9092 - acc: 0.6818 - val_loss: 2.0970 - val_acc: 0.6748\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 1.9398 - acc: 0.6817 - val_loss: 2.1173 - val_acc: 0.6790\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9249 - acc: 0.6816 - val_loss: 2.0372 - val_acc: 0.6783\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9180 - acc: 0.6807 - val_loss: 2.0608 - val_acc: 0.6813\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9484 - acc: 0.6818 - val_loss: 2.0660 - val_acc: 0.6805\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9285 - acc: 0.6814 - val_loss: 2.0643 - val_acc: 0.6787\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9107 - acc: 0.6817 - val_loss: 2.0243 - val_acc: 0.6795\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9016 - acc: 0.6819 - val_loss: 2.1724 - val_acc: 0.6748\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9701 - acc: 0.6806 - val_loss: 2.0539 - val_acc: 0.6779\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9268 - acc: 0.6816 - val_loss: 2.0590 - val_acc: 0.6782\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9284 - acc: 0.6809 - val_loss: 2.0516 - val_acc: 0.6797\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9080 - acc: 0.6802 - val_loss: 2.0362 - val_acc: 0.6787\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9292 - acc: 0.6810 - val_loss: 2.0686 - val_acc: 0.6784\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 1.9219 - acc: 0.6815 - val_loss: 2.0816 - val_acc: 0.6769\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9249 - acc: 0.6815 - val_loss: 2.0999 - val_acc: 0.6785\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9294 - acc: 0.6820 - val_loss: 2.1144 - val_acc: 0.6800\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9531 - acc: 0.6810 - val_loss: 2.0716 - val_acc: 0.6798\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9367 - acc: 0.6815 - val_loss: 2.0973 - val_acc: 0.6780\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9141 - acc: 0.6822 - val_loss: 2.0656 - val_acc: 0.6795\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9274 - acc: 0.6811 - val_loss: 2.0730 - val_acc: 0.6784\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9400 - acc: 0.6815 - val_loss: 2.0613 - val_acc: 0.6772\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9474 - acc: 0.6821 - val_loss: 2.0472 - val_acc: 0.6812\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9092 - acc: 0.6821 - val_loss: 2.2001 - val_acc: 0.6793\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9580 - acc: 0.6807 - val_loss: 2.0672 - val_acc: 0.6789\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9128 - acc: 0.6805 - val_loss: 2.0627 - val_acc: 0.6764\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9214 - acc: 0.6802 - val_loss: 2.1274 - val_acc: 0.6794\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9662 - acc: 0.6816 - val_loss: 2.0562 - val_acc: 0.6804\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9199 - acc: 0.6802 - val_loss: 2.0803 - val_acc: 0.6782\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9217 - acc: 0.6818 - val_loss: 2.0835 - val_acc: 0.6797\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9103 - acc: 0.6815 - val_loss: 2.0382 - val_acc: 0.6807\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9143 - acc: 0.6823 - val_loss: 2.1023 - val_acc: 0.6811\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9241 - acc: 0.6819 - val_loss: 2.1205 - val_acc: 0.6811\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9735 - acc: 0.6810 - val_loss: 2.0239 - val_acc: 0.6790\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9089 - acc: 0.6809 - val_loss: 2.0365 - val_acc: 0.6794\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8962 - acc: 0.6822 - val_loss: 2.0326 - val_acc: 0.6803\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9112 - acc: 0.6818 - val_loss: 2.0683 - val_acc: 0.6774\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9377 - acc: 0.6813 - val_loss: 2.0910 - val_acc: 0.6754\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9338 - acc: 0.6813 - val_loss: 2.1072 - val_acc: 0.6788\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9032 - acc: 0.6820 - val_loss: 2.0625 - val_acc: 0.6782\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9179 - acc: 0.6818 - val_loss: 2.1381 - val_acc: 0.6788\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9160 - acc: 0.6819 - val_loss: 2.0572 - val_acc: 0.6802\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9478 - acc: 0.6814 - val_loss: 2.0599 - val_acc: 0.6784\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9154 - acc: 0.6809 - val_loss: 2.0756 - val_acc: 0.6774\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9295 - acc: 0.6811 - val_loss: 2.0889 - val_acc: 0.6789\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9469 - acc: 0.6817 - val_loss: 2.0742 - val_acc: 0.6806\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1612 - acc: 0.9925 - val_loss: 0.1636 - val_acc: 0.9903\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1624 - acc: 0.9922 - val_loss: 0.1660 - val_acc: 0.9902\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1658 - acc: 0.9922 - val_loss: 0.1650 - val_acc: 0.9904\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1619 - acc: 0.9924 - val_loss: 0.1663 - val_acc: 0.9896\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1644 - acc: 0.9919 - val_loss: 0.1675 - val_acc: 0.9894\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1686 - acc: 0.9914 - val_loss: 0.1740 - val_acc: 0.9892\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1711 - acc: 0.9916 - val_loss: 0.1795 - val_acc: 0.9902\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1833 - acc: 0.9925 - val_loss: 0.1762 - val_acc: 0.9907\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1677 - acc: 0.9927 - val_loss: 0.1612 - val_acc: 0.9907\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1561 - acc: 0.9928 - val_loss: 0.1566 - val_acc: 0.9906\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1537 - acc: 0.9927 - val_loss: 0.1570 - val_acc: 0.9907\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1564 - acc: 0.9926 - val_loss: 0.1622 - val_acc: 0.9907\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1663 - acc: 0.9928 - val_loss: 0.1750 - val_acc: 0.9908\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1654 - acc: 0.9927 - val_loss: 0.1669 - val_acc: 0.9906\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1632 - acc: 0.9924 - val_loss: 0.1653 - val_acc: 0.9905\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1668 - acc: 0.9927 - val_loss: 0.1657 - val_acc: 0.9908\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1621 - acc: 0.9925 - val_loss: 0.1673 - val_acc: 0.9901\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1675 - acc: 0.9917 - val_loss: 0.1741 - val_acc: 0.9893\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1678 - acc: 0.9918 - val_loss: 0.1667 - val_acc: 0.9903\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1644 - acc: 0.9919 - val_loss: 0.1650 - val_acc: 0.9905\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1661 - acc: 0.9924 - val_loss: 0.1801 - val_acc: 0.9905\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1798 - acc: 0.9927 - val_loss: 0.1752 - val_acc: 0.9908\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1728 - acc: 0.9928 - val_loss: 0.1918 - val_acc: 0.9908\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1790 - acc: 0.9927 - val_loss: 0.1729 - val_acc: 0.9906\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1593 - acc: 0.9928 - val_loss: 0.1606 - val_acc: 0.9905\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1563 - acc: 0.9927 - val_loss: 0.1617 - val_acc: 0.9904\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1620 - acc: 0.9922 - val_loss: 0.1676 - val_acc: 0.9898\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1658 - acc: 0.9919 - val_loss: 0.1690 - val_acc: 0.9902\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1643 - acc: 0.9919 - val_loss: 0.1626 - val_acc: 0.9904\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1610 - acc: 0.9926 - val_loss: 0.1643 - val_acc: 0.9907\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1670 - acc: 0.9927 - val_loss: 0.1707 - val_acc: 0.9909\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1732 - acc: 0.9928 - val_loss: 0.1744 - val_acc: 0.9907\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1620 - acc: 0.9928 - val_loss: 0.1582 - val_acc: 0.9907\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1546 - acc: 0.9928 - val_loss: 0.1568 - val_acc: 0.9908\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1548 - acc: 0.9927 - val_loss: 0.1572 - val_acc: 0.9908\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1554 - acc: 0.9927 - val_loss: 0.1573 - val_acc: 0.9908\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1589 - acc: 0.9928 - val_loss: 0.1665 - val_acc: 0.9907\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.1618 - acc: 0.9927 - val_loss: 0.1680 - val_acc: 0.9906\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1692 - acc: 0.9927 - val_loss: 0.1745 - val_acc: 0.9903\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1712 - acc: 0.9925 - val_loss: 0.1653 - val_acc: 0.9906\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1594 - acc: 0.9927 - val_loss: 0.1620 - val_acc: 0.9906\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1602 - acc: 0.9927 - val_loss: 0.1660 - val_acc: 0.9906\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1715 - acc: 0.9927 - val_loss: 0.1748 - val_acc: 0.9906\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1625 - acc: 0.9928 - val_loss: 0.1610 - val_acc: 0.9906\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1622 - acc: 0.9922 - val_loss: 0.1676 - val_acc: 0.9900\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1699 - acc: 0.9912 - val_loss: 0.1960 - val_acc: 0.9869\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1771 - acc: 0.9904 - val_loss: 0.1647 - val_acc: 0.9897\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1615 - acc: 0.9921 - val_loss: 0.1703 - val_acc: 0.9904\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1784 - acc: 0.9925 - val_loss: 0.1842 - val_acc: 0.9907\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1737 - acc: 0.9927 - val_loss: 0.1633 - val_acc: 0.9906\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9593 - val_loss: 0.0039 - val_acc: 0.9506\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0031 - acc: 0.9558 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9658\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0035 - val_acc: 0.9584\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9581 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9625 - val_loss: 0.0031 - val_acc: 0.9655\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0031 - val_acc: 0.9619\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9558 - val_loss: 0.0030 - val_acc: 0.9641\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9616 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0031 - acc: 0.9565 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9564 - val_loss: 0.0031 - val_acc: 0.9627\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9594 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9586 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9596 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0032 - val_acc: 0.9619\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9616 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9571 - val_loss: 0.0031 - val_acc: 0.9624\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9594 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9591 - val_loss: 0.0031 - val_acc: 0.9603\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9589 - val_loss: 0.0030 - val_acc: 0.9649\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0030 - val_acc: 0.9631\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9611 - val_loss: 0.0030 - val_acc: 0.9638\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9597 - val_loss: 0.0030 - val_acc: 0.9634\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9579 - val_loss: 0.0031 - val_acc: 0.9635\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9634\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0032 - val_acc: 0.9614\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9580 - val_loss: 0.0032 - val_acc: 0.9610\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9601 - val_loss: 0.0031 - val_acc: 0.9653\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9583 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0030 - val_acc: 0.9643\n",
      "start training round 38\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2223 - acc: 0.6933 - val_loss: 0.2336 - val_acc: 0.6914\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2189 - acc: 0.6941 - val_loss: 0.2368 - val_acc: 0.6894\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2205 - acc: 0.6931 - val_loss: 0.2346 - val_acc: 0.6891\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2184 - acc: 0.6936 - val_loss: 0.2310 - val_acc: 0.6920\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2187 - acc: 0.6938 - val_loss: 0.2332 - val_acc: 0.6906\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2195 - acc: 0.6936 - val_loss: 0.2344 - val_acc: 0.6902\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2210 - acc: 0.6928 - val_loss: 0.2316 - val_acc: 0.6923\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2220 - acc: 0.6916 - val_loss: 0.2347 - val_acc: 0.6887\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2252 - acc: 0.6929 - val_loss: 0.2391 - val_acc: 0.6898\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2226 - acc: 0.6937 - val_loss: 0.2296 - val_acc: 0.6928\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2184 - acc: 0.6948 - val_loss: 0.2386 - val_acc: 0.6894\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2218 - acc: 0.6944 - val_loss: 0.2320 - val_acc: 0.6915\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2213 - acc: 0.6936 - val_loss: 0.2367 - val_acc: 0.6889\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2185 - acc: 0.6943 - val_loss: 0.2317 - val_acc: 0.6913\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2222 - acc: 0.6919 - val_loss: 0.2337 - val_acc: 0.6908\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2195 - acc: 0.6941 - val_loss: 0.2329 - val_acc: 0.6910\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2204 - acc: 0.6929 - val_loss: 0.2337 - val_acc: 0.6904\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2213 - acc: 0.6929 - val_loss: 0.2388 - val_acc: 0.6883\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2223 - acc: 0.6922 - val_loss: 0.2359 - val_acc: 0.6902\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2235 - acc: 0.6922 - val_loss: 0.2324 - val_acc: 0.6903\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2183 - acc: 0.6935 - val_loss: 0.2314 - val_acc: 0.6892\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2189 - acc: 0.6934 - val_loss: 0.2348 - val_acc: 0.6915\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2210 - acc: 0.6943 - val_loss: 0.2306 - val_acc: 0.6915\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2198 - acc: 0.6947 - val_loss: 0.2339 - val_acc: 0.6917\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2192 - acc: 0.6939 - val_loss: 0.2359 - val_acc: 0.6895\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2221 - acc: 0.6926 - val_loss: 0.2324 - val_acc: 0.6899\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2203 - acc: 0.6927 - val_loss: 0.2322 - val_acc: 0.6910\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2199 - acc: 0.6938 - val_loss: 0.2378 - val_acc: 0.6890\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2187 - acc: 0.6938 - val_loss: 0.2299 - val_acc: 0.6923\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2171 - acc: 0.6950 - val_loss: 0.2374 - val_acc: 0.6884\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2262 - acc: 0.6908 - val_loss: 0.2368 - val_acc: 0.6900\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2206 - acc: 0.6939 - val_loss: 0.2315 - val_acc: 0.6900\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2195 - acc: 0.6929 - val_loss: 0.2344 - val_acc: 0.6886\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2208 - acc: 0.6934 - val_loss: 0.2317 - val_acc: 0.6918\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2180 - acc: 0.6949 - val_loss: 0.2320 - val_acc: 0.6919\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2205 - acc: 0.6936 - val_loss: 0.2308 - val_acc: 0.6912\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2166 - acc: 0.6947 - val_loss: 0.2308 - val_acc: 0.6910\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2181 - acc: 0.6939 - val_loss: 0.2332 - val_acc: 0.6906\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2214 - acc: 0.6932 - val_loss: 0.2364 - val_acc: 0.6907\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2179 - acc: 0.6944 - val_loss: 0.2328 - val_acc: 0.6909\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2186 - acc: 0.6949 - val_loss: 0.2331 - val_acc: 0.6910\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2261 - acc: 0.6940 - val_loss: 0.2343 - val_acc: 0.6911\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2198 - acc: 0.6940 - val_loss: 0.2393 - val_acc: 0.6874\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2204 - acc: 0.6927 - val_loss: 0.2307 - val_acc: 0.6918\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2180 - acc: 0.6946 - val_loss: 0.2324 - val_acc: 0.6914\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2208 - acc: 0.6926 - val_loss: 0.2381 - val_acc: 0.6879\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2218 - acc: 0.6922 - val_loss: 0.2300 - val_acc: 0.6911\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2167 - acc: 0.6947 - val_loss: 0.2318 - val_acc: 0.6906\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2196 - acc: 0.6932 - val_loss: 0.2474 - val_acc: 0.6858\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2228 - acc: 0.6938 - val_loss: 0.2338 - val_acc: 0.6922\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9283 - acc: 0.6814 - val_loss: 2.0919 - val_acc: 0.6798\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9251 - acc: 0.6815 - val_loss: 2.1012 - val_acc: 0.6809\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9303 - acc: 0.6810 - val_loss: 2.0470 - val_acc: 0.6819\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9142 - acc: 0.6817 - val_loss: 2.0378 - val_acc: 0.6807\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9204 - acc: 0.6821 - val_loss: 2.0848 - val_acc: 0.6771\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9478 - acc: 0.6806 - val_loss: 2.1003 - val_acc: 0.6796\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9223 - acc: 0.6825 - val_loss: 2.0677 - val_acc: 0.6817\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9415 - acc: 0.6815 - val_loss: 2.0631 - val_acc: 0.6806\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9241 - acc: 0.6818 - val_loss: 2.0455 - val_acc: 0.6784\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9150 - acc: 0.6812 - val_loss: 2.0496 - val_acc: 0.6781\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9302 - acc: 0.6821 - val_loss: 2.0255 - val_acc: 0.6799\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9402 - acc: 0.6818 - val_loss: 2.0530 - val_acc: 0.6796\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9142 - acc: 0.6817 - val_loss: 2.1282 - val_acc: 0.6754\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9186 - acc: 0.6810 - val_loss: 2.0492 - val_acc: 0.6780\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9231 - acc: 0.6818 - val_loss: 2.1467 - val_acc: 0.6760\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9207 - acc: 0.6825 - val_loss: 2.0392 - val_acc: 0.6792\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9105 - acc: 0.6813 - val_loss: 2.1831 - val_acc: 0.6747\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9298 - acc: 0.6822 - val_loss: 2.0610 - val_acc: 0.6789\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9183 - acc: 0.6820 - val_loss: 2.0652 - val_acc: 0.6765\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9114 - acc: 0.6811 - val_loss: 2.1100 - val_acc: 0.6755\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9271 - acc: 0.6805 - val_loss: 2.1048 - val_acc: 0.6789\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9245 - acc: 0.6824 - val_loss: 2.1369 - val_acc: 0.6815\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9521 - acc: 0.6817 - val_loss: 2.1122 - val_acc: 0.6794\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9357 - acc: 0.6806 - val_loss: 2.0606 - val_acc: 0.6812\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9366 - acc: 0.6821 - val_loss: 2.0313 - val_acc: 0.6801\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.8985 - acc: 0.6824 - val_loss: 2.0397 - val_acc: 0.6805\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9200 - acc: 0.6810 - val_loss: 2.0398 - val_acc: 0.6794\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8971 - acc: 0.6821 - val_loss: 2.1389 - val_acc: 0.6810\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9405 - acc: 0.6821 - val_loss: 2.1283 - val_acc: 0.6792\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9219 - acc: 0.6816 - val_loss: 2.0617 - val_acc: 0.6798\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9223 - acc: 0.6825 - val_loss: 2.0974 - val_acc: 0.6796\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9501 - acc: 0.6822 - val_loss: 2.0414 - val_acc: 0.6801\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9077 - acc: 0.6822 - val_loss: 2.0789 - val_acc: 0.6766\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8973 - acc: 0.6819 - val_loss: 2.0671 - val_acc: 0.6780\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9325 - acc: 0.6816 - val_loss: 2.0983 - val_acc: 0.6769\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9173 - acc: 0.6817 - val_loss: 2.0237 - val_acc: 0.6800\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9226 - acc: 0.6811 - val_loss: 2.0216 - val_acc: 0.6809\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9076 - acc: 0.6813 - val_loss: 2.0341 - val_acc: 0.6800\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9052 - acc: 0.6815 - val_loss: 2.0383 - val_acc: 0.6822\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9139 - acc: 0.6824 - val_loss: 2.0898 - val_acc: 0.6809\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9274 - acc: 0.6825 - val_loss: 2.0710 - val_acc: 0.6809\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9486 - acc: 0.6817 - val_loss: 2.0180 - val_acc: 0.6812\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9075 - acc: 0.6819 - val_loss: 2.0283 - val_acc: 0.6803\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9209 - acc: 0.6822 - val_loss: 2.0573 - val_acc: 0.6776\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9310 - acc: 0.6817 - val_loss: 2.0882 - val_acc: 0.6801\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9190 - acc: 0.6826 - val_loss: 2.1164 - val_acc: 0.6816\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9495 - acc: 0.6822 - val_loss: 2.0610 - val_acc: 0.6817\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9383 - acc: 0.6805 - val_loss: 2.0386 - val_acc: 0.6813\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8892 - acc: 0.6820 - val_loss: 2.0877 - val_acc: 0.6777\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9247 - acc: 0.6815 - val_loss: 2.0674 - val_acc: 0.6771\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1649 - acc: 0.9927 - val_loss: 0.1634 - val_acc: 0.9906\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1636 - acc: 0.9927 - val_loss: 0.1685 - val_acc: 0.9906\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1586 - acc: 0.9928 - val_loss: 0.1570 - val_acc: 0.9907\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1550 - acc: 0.9927 - val_loss: 0.1581 - val_acc: 0.9905\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1648 - acc: 0.9926 - val_loss: 0.1795 - val_acc: 0.9903\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1798 - acc: 0.9923 - val_loss: 0.1864 - val_acc: 0.9903\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1705 - acc: 0.9925 - val_loss: 0.1648 - val_acc: 0.9904\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1600 - acc: 0.9927 - val_loss: 0.1602 - val_acc: 0.9907\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1578 - acc: 0.9928 - val_loss: 0.1558 - val_acc: 0.9907\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1540 - acc: 0.9927 - val_loss: 0.1556 - val_acc: 0.9908\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1630 - acc: 0.9926 - val_loss: 0.1838 - val_acc: 0.9903\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1810 - acc: 0.9921 - val_loss: 0.1740 - val_acc: 0.9897\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1623 - acc: 0.9921 - val_loss: 0.1608 - val_acc: 0.9905\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1615 - acc: 0.9923 - val_loss: 0.1724 - val_acc: 0.9902\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1703 - acc: 0.9918 - val_loss: 0.1761 - val_acc: 0.9901\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1679 - acc: 0.9923 - val_loss: 0.1636 - val_acc: 0.9906\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1631 - acc: 0.9927 - val_loss: 0.1679 - val_acc: 0.9908\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1644 - acc: 0.9928 - val_loss: 0.1713 - val_acc: 0.9907\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1643 - acc: 0.9927 - val_loss: 0.1705 - val_acc: 0.9906\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1658 - acc: 0.9926 - val_loss: 0.1626 - val_acc: 0.9906\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1585 - acc: 0.9928 - val_loss: 0.1651 - val_acc: 0.9908\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1631 - acc: 0.9924 - val_loss: 0.1737 - val_acc: 0.9898\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1748 - acc: 0.9912 - val_loss: 0.1721 - val_acc: 0.9900\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1583 - acc: 0.9922 - val_loss: 0.1595 - val_acc: 0.9905\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1548 - acc: 0.9926 - val_loss: 0.1561 - val_acc: 0.9908\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1521 - acc: 0.9928 - val_loss: 0.1550 - val_acc: 0.9907\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1625 - acc: 0.9927 - val_loss: 0.1834 - val_acc: 0.9906\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1931 - acc: 0.9928 - val_loss: 0.1823 - val_acc: 0.9904\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1663 - acc: 0.9927 - val_loss: 0.1628 - val_acc: 0.9905\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1580 - acc: 0.9927 - val_loss: 0.1547 - val_acc: 0.9907\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1537 - acc: 0.9927 - val_loss: 0.1597 - val_acc: 0.9901\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.1618 - acc: 0.9922 - val_loss: 0.1718 - val_acc: 0.9899\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1774 - acc: 0.9908 - val_loss: 0.1708 - val_acc: 0.9888\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1614 - acc: 0.9922 - val_loss: 0.1606 - val_acc: 0.9907\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1561 - acc: 0.9927 - val_loss: 0.1615 - val_acc: 0.9908\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1693 - acc: 0.9927 - val_loss: 0.1749 - val_acc: 0.9908\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1653 - acc: 0.9927 - val_loss: 0.1640 - val_acc: 0.9907\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1655 - acc: 0.9926 - val_loss: 0.1694 - val_acc: 0.9907\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1659 - acc: 0.9925 - val_loss: 0.1684 - val_acc: 0.9905\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1640 - acc: 0.9922 - val_loss: 0.1642 - val_acc: 0.9904\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1606 - acc: 0.9922 - val_loss: 0.1650 - val_acc: 0.9902\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1651 - acc: 0.9916 - val_loss: 0.1600 - val_acc: 0.9905\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1583 - acc: 0.9923 - val_loss: 0.1640 - val_acc: 0.9904\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1704 - acc: 0.9923 - val_loss: 0.1778 - val_acc: 0.9907\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1704 - acc: 0.9927 - val_loss: 0.1616 - val_acc: 0.9907\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1584 - acc: 0.9928 - val_loss: 0.1578 - val_acc: 0.9907\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1579 - acc: 0.9928 - val_loss: 0.1565 - val_acc: 0.9908\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1635 - acc: 0.9928 - val_loss: 0.1749 - val_acc: 0.9908\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1723 - acc: 0.9928 - val_loss: 0.1709 - val_acc: 0.9909\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1587 - acc: 0.9927 - val_loss: 0.1575 - val_acc: 0.9907\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9581 - val_loss: 0.0030 - val_acc: 0.9638\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9637\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9587 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9602 - val_loss: 0.0031 - val_acc: 0.9621\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0031 - acc: 0.9550 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9602 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0034 - val_acc: 0.9604\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0032 - acc: 0.9544 - val_loss: 0.0030 - val_acc: 0.9658\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9592 - val_loss: 0.0030 - val_acc: 0.9633\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9588 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 242us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9588 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9613\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9614 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0032 - val_acc: 0.9613\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0031 - acc: 0.9583 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0029 - val_acc: 0.9654\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9590\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9575 - val_loss: 0.0031 - val_acc: 0.9621\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9618 - val_loss: 0.0035 - val_acc: 0.9534\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9583 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9638\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9614 - val_loss: 0.0030 - val_acc: 0.9629\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9581 - val_loss: 0.0030 - val_acc: 0.9636\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0029 - val_acc: 0.9657\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0029 - acc: 0.9598 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0030 - acc: 0.9573 - val_loss: 0.0032 - val_acc: 0.9631\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0031 - val_acc: 0.9646\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0032 - val_acc: 0.9627\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0029 - acc: 0.9584 - val_loss: 0.0030 - val_acc: 0.9662\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0031 - val_acc: 0.9653\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9643\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9608 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9612 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9592 - val_loss: 0.0032 - val_acc: 0.9583\n",
      "start training round 39\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2212 - acc: 0.6930 - val_loss: 0.2354 - val_acc: 0.6903\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2198 - acc: 0.6932 - val_loss: 0.2335 - val_acc: 0.6900\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2208 - acc: 0.6929 - val_loss: 0.2320 - val_acc: 0.6919\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2206 - acc: 0.6939 - val_loss: 0.2320 - val_acc: 0.6912\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2196 - acc: 0.6945 - val_loss: 0.2313 - val_acc: 0.6917\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2181 - acc: 0.6943 - val_loss: 0.2385 - val_acc: 0.6877\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2185 - acc: 0.6936 - val_loss: 0.2346 - val_acc: 0.6897\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2197 - acc: 0.6943 - val_loss: 0.2348 - val_acc: 0.6916\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2198 - acc: 0.6942 - val_loss: 0.2321 - val_acc: 0.6903\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2234 - acc: 0.6919 - val_loss: 0.2360 - val_acc: 0.6895\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2177 - acc: 0.6945 - val_loss: 0.2389 - val_acc: 0.6892\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2219 - acc: 0.6923 - val_loss: 0.2313 - val_acc: 0.6910\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2188 - acc: 0.6932 - val_loss: 0.2306 - val_acc: 0.6915\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2166 - acc: 0.6952 - val_loss: 0.2361 - val_acc: 0.6923\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2213 - acc: 0.6949 - val_loss: 0.2387 - val_acc: 0.6916\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2237 - acc: 0.6928 - val_loss: 0.2385 - val_acc: 0.6877\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2216 - acc: 0.6922 - val_loss: 0.2327 - val_acc: 0.6913\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2188 - acc: 0.6938 - val_loss: 0.2323 - val_acc: 0.6902\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2219 - acc: 0.6936 - val_loss: 0.2326 - val_acc: 0.6913\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2206 - acc: 0.6931 - val_loss: 0.2352 - val_acc: 0.6890\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2197 - acc: 0.6936 - val_loss: 0.2376 - val_acc: 0.6889\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2178 - acc: 0.6951 - val_loss: 0.2359 - val_acc: 0.6913\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2196 - acc: 0.6945 - val_loss: 0.2305 - val_acc: 0.6919\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2176 - acc: 0.6936 - val_loss: 0.2354 - val_acc: 0.6898\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2220 - acc: 0.6930 - val_loss: 0.2373 - val_acc: 0.6902\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2177 - acc: 0.6949 - val_loss: 0.2321 - val_acc: 0.6914\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2222 - acc: 0.6929 - val_loss: 0.2351 - val_acc: 0.6891\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2183 - acc: 0.6940 - val_loss: 0.2322 - val_acc: 0.6902\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2193 - acc: 0.6928 - val_loss: 0.2372 - val_acc: 0.6869\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2209 - acc: 0.6922 - val_loss: 0.2302 - val_acc: 0.6921\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2179 - acc: 0.6945 - val_loss: 0.2332 - val_acc: 0.6912\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2216 - acc: 0.6936 - val_loss: 0.2307 - val_acc: 0.6918\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2180 - acc: 0.6949 - val_loss: 0.2348 - val_acc: 0.6920\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2239 - acc: 0.6942 - val_loss: 0.2332 - val_acc: 0.6924\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2168 - acc: 0.6949 - val_loss: 0.2319 - val_acc: 0.6904\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2182 - acc: 0.6940 - val_loss: 0.2321 - val_acc: 0.6928\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2190 - acc: 0.6945 - val_loss: 0.2361 - val_acc: 0.6898\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2228 - acc: 0.6917 - val_loss: 0.2336 - val_acc: 0.6915\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2206 - acc: 0.6926 - val_loss: 0.2360 - val_acc: 0.6893\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2184 - acc: 0.6945 - val_loss: 0.2312 - val_acc: 0.6928\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2186 - acc: 0.6949 - val_loss: 0.2357 - val_acc: 0.6907\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2242 - acc: 0.6919 - val_loss: 0.2344 - val_acc: 0.6907\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2168 - acc: 0.6949 - val_loss: 0.2318 - val_acc: 0.6923\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2185 - acc: 0.6949 - val_loss: 0.2293 - val_acc: 0.6921\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2182 - acc: 0.6943 - val_loss: 0.2390 - val_acc: 0.6887\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2217 - acc: 0.6942 - val_loss: 0.2302 - val_acc: 0.6909\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2169 - acc: 0.6944 - val_loss: 0.2333 - val_acc: 0.6914\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2206 - acc: 0.6937 - val_loss: 0.2311 - val_acc: 0.6909\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2186 - acc: 0.6936 - val_loss: 0.2428 - val_acc: 0.6895\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2204 - acc: 0.6928 - val_loss: 0.2351 - val_acc: 0.6889\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9065 - acc: 0.6812 - val_loss: 2.0651 - val_acc: 0.6776\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9291 - acc: 0.6808 - val_loss: 2.0272 - val_acc: 0.6786\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 1.9057 - acc: 0.6818 - val_loss: 2.0750 - val_acc: 0.6783\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9016 - acc: 0.6820 - val_loss: 2.0434 - val_acc: 0.6816\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9439 - acc: 0.6821 - val_loss: 2.0818 - val_acc: 0.6823\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9313 - acc: 0.6812 - val_loss: 2.0656 - val_acc: 0.6797\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8992 - acc: 0.6820 - val_loss: 2.0598 - val_acc: 0.6770\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9297 - acc: 0.6807 - val_loss: 2.2397 - val_acc: 0.6779\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9421 - acc: 0.6816 - val_loss: 2.0320 - val_acc: 0.6807\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9168 - acc: 0.6818 - val_loss: 2.1145 - val_acc: 0.6760\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9381 - acc: 0.6812 - val_loss: 2.0901 - val_acc: 0.6803\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9275 - acc: 0.6824 - val_loss: 2.0493 - val_acc: 0.6814\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9304 - acc: 0.6823 - val_loss: 2.0573 - val_acc: 0.6803\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9233 - acc: 0.6816 - val_loss: 2.0671 - val_acc: 0.6807\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9129 - acc: 0.6828 - val_loss: 2.0706 - val_acc: 0.6811\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9284 - acc: 0.6810 - val_loss: 2.0302 - val_acc: 0.6805\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9074 - acc: 0.6820 - val_loss: 2.0455 - val_acc: 0.6806\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9298 - acc: 0.6818 - val_loss: 2.0349 - val_acc: 0.6796\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9006 - acc: 0.6826 - val_loss: 2.0790 - val_acc: 0.6782\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9188 - acc: 0.6816 - val_loss: 2.0545 - val_acc: 0.6805\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9154 - acc: 0.6820 - val_loss: 2.1220 - val_acc: 0.6821\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9401 - acc: 0.6822 - val_loss: 2.0492 - val_acc: 0.6792\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9203 - acc: 0.6818 - val_loss: 2.0778 - val_acc: 0.6764\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9048 - acc: 0.6824 - val_loss: 2.0911 - val_acc: 0.6788\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9319 - acc: 0.6808 - val_loss: 2.0545 - val_acc: 0.6789\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9348 - acc: 0.6822 - val_loss: 2.0609 - val_acc: 0.6812\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9067 - acc: 0.6826 - val_loss: 2.0341 - val_acc: 0.6810\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9114 - acc: 0.6824 - val_loss: 2.0787 - val_acc: 0.6782\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8939 - acc: 0.6825 - val_loss: 2.0920 - val_acc: 0.6772\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9234 - acc: 0.6811 - val_loss: 2.0356 - val_acc: 0.6795\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 1.9192 - acc: 0.6815 - val_loss: 2.0514 - val_acc: 0.6782\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 1.9040 - acc: 0.6815 - val_loss: 2.0226 - val_acc: 0.6809\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 1.9383 - acc: 0.6815 - val_loss: 2.0529 - val_acc: 0.6813\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9119 - acc: 0.6827 - val_loss: 2.0546 - val_acc: 0.6814\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9024 - acc: 0.6829 - val_loss: 2.0795 - val_acc: 0.6790\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9306 - acc: 0.6812 - val_loss: 2.0385 - val_acc: 0.6798\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9331 - acc: 0.6820 - val_loss: 2.0735 - val_acc: 0.6814\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9314 - acc: 0.6820 - val_loss: 2.1138 - val_acc: 0.6802\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9280 - acc: 0.6815 - val_loss: 2.0612 - val_acc: 0.6807\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9140 - acc: 0.6816 - val_loss: 2.0370 - val_acc: 0.6790\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9341 - acc: 0.6822 - val_loss: 2.0742 - val_acc: 0.6805\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9125 - acc: 0.6820 - val_loss: 2.0629 - val_acc: 0.6772\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9165 - acc: 0.6810 - val_loss: 2.0681 - val_acc: 0.6799\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9016 - acc: 0.6827 - val_loss: 2.1210 - val_acc: 0.6797\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9464 - acc: 0.6819 - val_loss: 2.1708 - val_acc: 0.6788\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9217 - acc: 0.6820 - val_loss: 2.0958 - val_acc: 0.6813\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9486 - acc: 0.6818 - val_loss: 2.0679 - val_acc: 0.6825\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9101 - acc: 0.6824 - val_loss: 2.1066 - val_acc: 0.6816\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9370 - acc: 0.6817 - val_loss: 2.0885 - val_acc: 0.6785\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9465 - acc: 0.6811 - val_loss: 2.0610 - val_acc: 0.6804\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1628 - acc: 0.9924 - val_loss: 0.1627 - val_acc: 0.9907\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1561 - acc: 0.9928 - val_loss: 0.1625 - val_acc: 0.9908\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1719 - acc: 0.9926 - val_loss: 0.1785 - val_acc: 0.9900\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1639 - acc: 0.9923 - val_loss: 0.1636 - val_acc: 0.9902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1581 - acc: 0.9925 - val_loss: 0.1637 - val_acc: 0.9905\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1625 - acc: 0.9923 - val_loss: 0.1709 - val_acc: 0.9897\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1636 - acc: 0.9919 - val_loss: 0.1609 - val_acc: 0.9907\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 247us/step - loss: 0.1567 - acc: 0.9927 - val_loss: 0.1612 - val_acc: 0.9908\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1635 - acc: 0.9927 - val_loss: 0.1728 - val_acc: 0.9907\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1718 - acc: 0.9923 - val_loss: 0.1747 - val_acc: 0.9905\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1670 - acc: 0.9923 - val_loss: 0.1754 - val_acc: 0.9897\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1708 - acc: 0.9918 - val_loss: 0.1724 - val_acc: 0.9907\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1745 - acc: 0.9925 - val_loss: 0.1908 - val_acc: 0.9909\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1760 - acc: 0.9927 - val_loss: 0.1682 - val_acc: 0.9906\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1572 - acc: 0.9927 - val_loss: 0.1570 - val_acc: 0.9908\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1538 - acc: 0.9928 - val_loss: 0.1560 - val_acc: 0.9907\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1513 - acc: 0.9928 - val_loss: 0.1537 - val_acc: 0.9907\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1518 - acc: 0.9928 - val_loss: 0.1562 - val_acc: 0.9907\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1603 - acc: 0.9928 - val_loss: 0.1585 - val_acc: 0.9907\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1639 - acc: 0.9924 - val_loss: 0.1715 - val_acc: 0.9898\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1675 - acc: 0.9913 - val_loss: 0.1743 - val_acc: 0.9891\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1680 - acc: 0.9913 - val_loss: 0.1626 - val_acc: 0.9900\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1689 - acc: 0.9924 - val_loss: 0.1819 - val_acc: 0.9906\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1812 - acc: 0.9928 - val_loss: 0.1741 - val_acc: 0.9907\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1635 - acc: 0.9928 - val_loss: 0.1604 - val_acc: 0.9906\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1576 - acc: 0.9927 - val_loss: 0.1628 - val_acc: 0.9906\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1583 - acc: 0.9927 - val_loss: 0.1613 - val_acc: 0.9905\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1613 - acc: 0.9922 - val_loss: 0.1622 - val_acc: 0.9908\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1581 - acc: 0.9928 - val_loss: 0.1622 - val_acc: 0.9908\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1660 - acc: 0.9928 - val_loss: 0.1849 - val_acc: 0.9908\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1810 - acc: 0.9925 - val_loss: 0.1805 - val_acc: 0.9908\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1634 - acc: 0.9928 - val_loss: 0.1616 - val_acc: 0.9908\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.1565 - acc: 0.9928 - val_loss: 0.1561 - val_acc: 0.9908\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1544 - acc: 0.9928 - val_loss: 0.1557 - val_acc: 0.9908\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1557 - acc: 0.9928 - val_loss: 0.1623 - val_acc: 0.9906\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1596 - acc: 0.9925 - val_loss: 0.1657 - val_acc: 0.9903\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1684 - acc: 0.9920 - val_loss: 0.1742 - val_acc: 0.9892\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1645 - acc: 0.9917 - val_loss: 0.1607 - val_acc: 0.9901\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1547 - acc: 0.9924 - val_loss: 0.1593 - val_acc: 0.9901\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1564 - acc: 0.9922 - val_loss: 0.1583 - val_acc: 0.9905\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1562 - acc: 0.9924 - val_loss: 0.1567 - val_acc: 0.9906\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1614 - acc: 0.9926 - val_loss: 0.1764 - val_acc: 0.9904\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1729 - acc: 0.9927 - val_loss: 0.1738 - val_acc: 0.9906\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1716 - acc: 0.9927 - val_loss: 0.1687 - val_acc: 0.9906\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1661 - acc: 0.9928 - val_loss: 0.1612 - val_acc: 0.9907\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1568 - acc: 0.9926 - val_loss: 0.1592 - val_acc: 0.9906\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1595 - acc: 0.9922 - val_loss: 0.1576 - val_acc: 0.9905\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1589 - acc: 0.9927 - val_loss: 0.1650 - val_acc: 0.9906\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1722 - acc: 0.9927 - val_loss: 0.1832 - val_acc: 0.9902\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.1777 - acc: 0.9921 - val_loss: 0.1693 - val_acc: 0.9898\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 252us/step - loss: 0.0029 - acc: 0.9598 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 247us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 254us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 252us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0030 - val_acc: 0.9637\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 242us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 254us/step - loss: 0.0029 - acc: 0.9593 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 247us/step - loss: 0.0028 - acc: 0.9627 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9658\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0032 - val_acc: 0.9635\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9605 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0030 - acc: 0.9585 - val_loss: 0.0033 - val_acc: 0.9628\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9581 - val_loss: 0.0030 - val_acc: 0.9628\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9582 - val_loss: 0.0031 - val_acc: 0.9625\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9536 - val_loss: 0.0029 - val_acc: 0.9655\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9630 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9593 - val_loss: 0.0031 - val_acc: 0.9644\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9631 - val_loss: 0.0029 - val_acc: 0.9662\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0031 - val_acc: 0.9594\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9567 - val_loss: 0.0030 - val_acc: 0.9625\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9609 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0031 - val_acc: 0.9637\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9591 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0029 - acc: 0.9591 - val_loss: 0.0030 - val_acc: 0.9649\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0029 - val_acc: 0.9657\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9627 - val_loss: 0.0031 - val_acc: 0.9613\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9582 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9607 - val_loss: 0.0033 - val_acc: 0.9587\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9563 - val_loss: 0.0030 - val_acc: 0.9619\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0029 - acc: 0.9601 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9595 - val_loss: 0.0029 - val_acc: 0.9658\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9583 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9597 - val_loss: 0.0031 - val_acc: 0.9651\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0031 - val_acc: 0.9654\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9597 - val_loss: 0.0029 - val_acc: 0.9654\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0031 - val_acc: 0.9650\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9619 - val_loss: 0.0031 - val_acc: 0.9627\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9646\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9613 - val_loss: 0.0030 - val_acc: 0.9649\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0030 - acc: 0.9580 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "start training round 40\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2189 - acc: 0.6935 - val_loss: 0.2308 - val_acc: 0.6916\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2203 - acc: 0.6944 - val_loss: 0.2375 - val_acc: 0.6901\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2234 - acc: 0.6917 - val_loss: 0.2358 - val_acc: 0.6900\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2218 - acc: 0.6940 - val_loss: 0.2316 - val_acc: 0.6921\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2185 - acc: 0.6943 - val_loss: 0.2319 - val_acc: 0.6912\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2177 - acc: 0.6944 - val_loss: 0.2309 - val_acc: 0.6911\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2176 - acc: 0.6944 - val_loss: 0.2292 - val_acc: 0.6927\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2164 - acc: 0.6954 - val_loss: 0.2309 - val_acc: 0.6909\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2172 - acc: 0.6947 - val_loss: 0.2302 - val_acc: 0.6920\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2204 - acc: 0.6926 - val_loss: 0.2419 - val_acc: 0.6864\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2194 - acc: 0.6931 - val_loss: 0.2336 - val_acc: 0.6921\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2170 - acc: 0.6952 - val_loss: 0.2330 - val_acc: 0.6901\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2240 - acc: 0.6917 - val_loss: 0.2343 - val_acc: 0.6904\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2190 - acc: 0.6941 - val_loss: 0.2363 - val_acc: 0.6892\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2190 - acc: 0.6944 - val_loss: 0.2350 - val_acc: 0.6909\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2188 - acc: 0.6946 - val_loss: 0.2334 - val_acc: 0.6915\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2217 - acc: 0.6932 - val_loss: 0.2329 - val_acc: 0.6910\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2188 - acc: 0.6936 - val_loss: 0.2387 - val_acc: 0.6868\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2180 - acc: 0.6935 - val_loss: 0.2331 - val_acc: 0.6897\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2202 - acc: 0.6934 - val_loss: 0.2442 - val_acc: 0.6884\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2209 - acc: 0.6941 - val_loss: 0.2294 - val_acc: 0.6929\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2190 - acc: 0.6951 - val_loss: 0.2362 - val_acc: 0.6920\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2191 - acc: 0.6944 - val_loss: 0.2377 - val_acc: 0.6898\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2243 - acc: 0.6924 - val_loss: 0.2294 - val_acc: 0.6925\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2166 - acc: 0.6950 - val_loss: 0.2331 - val_acc: 0.6907\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2176 - acc: 0.6941 - val_loss: 0.2353 - val_acc: 0.6886\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2176 - acc: 0.6939 - val_loss: 0.2301 - val_acc: 0.6916\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2166 - acc: 0.6948 - val_loss: 0.2306 - val_acc: 0.6925\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2168 - acc: 0.6947 - val_loss: 0.2343 - val_acc: 0.6907\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2211 - acc: 0.6937 - val_loss: 0.2384 - val_acc: 0.6908\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2211 - acc: 0.6943 - val_loss: 0.2283 - val_acc: 0.6923\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2218 - acc: 0.6943 - val_loss: 0.2396 - val_acc: 0.6899\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2212 - acc: 0.6930 - val_loss: 0.2351 - val_acc: 0.6901\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2192 - acc: 0.6935 - val_loss: 0.2301 - val_acc: 0.6929\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2183 - acc: 0.6937 - val_loss: 0.2325 - val_acc: 0.6904\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2184 - acc: 0.6941 - val_loss: 0.2372 - val_acc: 0.6897\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2200 - acc: 0.6949 - val_loss: 0.2307 - val_acc: 0.6914\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2171 - acc: 0.6941 - val_loss: 0.2346 - val_acc: 0.6894\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2219 - acc: 0.6928 - val_loss: 0.2317 - val_acc: 0.6912\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2167 - acc: 0.6952 - val_loss: 0.2301 - val_acc: 0.6927\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2169 - acc: 0.6944 - val_loss: 0.2331 - val_acc: 0.6919\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2176 - acc: 0.6957 - val_loss: 0.2347 - val_acc: 0.6909\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2235 - acc: 0.6945 - val_loss: 0.2291 - val_acc: 0.6927\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2167 - acc: 0.6948 - val_loss: 0.2386 - val_acc: 0.6891\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2213 - acc: 0.6927 - val_loss: 0.2318 - val_acc: 0.6919\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2185 - acc: 0.6940 - val_loss: 0.2356 - val_acc: 0.6867\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2181 - acc: 0.6936 - val_loss: 0.2319 - val_acc: 0.6909\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2192 - acc: 0.6944 - val_loss: 0.2328 - val_acc: 0.6906\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2181 - acc: 0.6946 - val_loss: 0.2326 - val_acc: 0.6916\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2196 - acc: 0.6936 - val_loss: 0.2291 - val_acc: 0.6928\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9169 - acc: 0.6819 - val_loss: 2.0563 - val_acc: 0.6791\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9145 - acc: 0.6820 - val_loss: 2.0708 - val_acc: 0.6777\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9229 - acc: 0.6823 - val_loss: 2.0898 - val_acc: 0.6776\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9010 - acc: 0.6829 - val_loss: 2.0621 - val_acc: 0.6802\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9206 - acc: 0.6822 - val_loss: 2.0297 - val_acc: 0.6796\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9155 - acc: 0.6822 - val_loss: 2.0290 - val_acc: 0.6799\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8987 - acc: 0.6822 - val_loss: 2.0753 - val_acc: 0.6793\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9224 - acc: 0.6820 - val_loss: 2.0412 - val_acc: 0.6794\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9214 - acc: 0.6823 - val_loss: 2.0511 - val_acc: 0.6792\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8976 - acc: 0.6822 - val_loss: 2.0619 - val_acc: 0.6788\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9271 - acc: 0.6821 - val_loss: 2.1056 - val_acc: 0.6784\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9363 - acc: 0.6816 - val_loss: 2.0577 - val_acc: 0.6769\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9085 - acc: 0.6828 - val_loss: 2.0423 - val_acc: 0.6778\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9233 - acc: 0.6808 - val_loss: 2.0742 - val_acc: 0.6812\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9057 - acc: 0.6820 - val_loss: 2.0592 - val_acc: 0.6795\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8917 - acc: 0.6818 - val_loss: 2.0594 - val_acc: 0.6806\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9225 - acc: 0.6818 - val_loss: 2.0867 - val_acc: 0.6802\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9214 - acc: 0.6826 - val_loss: 2.1414 - val_acc: 0.6759\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9269 - acc: 0.6821 - val_loss: 2.0450 - val_acc: 0.6783\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9315 - acc: 0.6809 - val_loss: 2.1083 - val_acc: 0.6814\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9274 - acc: 0.6819 - val_loss: 2.0769 - val_acc: 0.6817\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9085 - acc: 0.6829 - val_loss: 2.1329 - val_acc: 0.6797\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9250 - acc: 0.6821 - val_loss: 2.0554 - val_acc: 0.6794\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9300 - acc: 0.6817 - val_loss: 2.0444 - val_acc: 0.6797\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8981 - acc: 0.6824 - val_loss: 2.0648 - val_acc: 0.6825\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9360 - acc: 0.6812 - val_loss: 2.0925 - val_acc: 0.6765\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9208 - acc: 0.6817 - val_loss: 2.0301 - val_acc: 0.6823\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9284 - acc: 0.6828 - val_loss: 2.1388 - val_acc: 0.6798\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9315 - acc: 0.6813 - val_loss: 2.0446 - val_acc: 0.6790\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9275 - acc: 0.6821 - val_loss: 2.1545 - val_acc: 0.6765\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9202 - acc: 0.6819 - val_loss: 2.0538 - val_acc: 0.6808\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9118 - acc: 0.6826 - val_loss: 2.1281 - val_acc: 0.6809\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9320 - acc: 0.6823 - val_loss: 2.0425 - val_acc: 0.6817\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9190 - acc: 0.6823 - val_loss: 2.0589 - val_acc: 0.6825\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9223 - acc: 0.6813 - val_loss: 2.1025 - val_acc: 0.6760\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9230 - acc: 0.6821 - val_loss: 2.0583 - val_acc: 0.6782\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9035 - acc: 0.6830 - val_loss: 2.1002 - val_acc: 0.6788\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9335 - acc: 0.6819 - val_loss: 2.0311 - val_acc: 0.6813\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9165 - acc: 0.6821 - val_loss: 2.1042 - val_acc: 0.6776\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9265 - acc: 0.6812 - val_loss: 2.0750 - val_acc: 0.6766\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9372 - acc: 0.6817 - val_loss: 2.0390 - val_acc: 0.6791\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9166 - acc: 0.6828 - val_loss: 2.0347 - val_acc: 0.6807\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8955 - acc: 0.6827 - val_loss: 2.0289 - val_acc: 0.6792\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9118 - acc: 0.6823 - val_loss: 2.0587 - val_acc: 0.6795\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8994 - acc: 0.6825 - val_loss: 2.0464 - val_acc: 0.6814\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9263 - acc: 0.6824 - val_loss: 2.0771 - val_acc: 0.6825\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9242 - acc: 0.6826 - val_loss: 2.0643 - val_acc: 0.6769\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9211 - acc: 0.6818 - val_loss: 2.0444 - val_acc: 0.6786\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9056 - acc: 0.6815 - val_loss: 2.1016 - val_acc: 0.6754\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9085 - acc: 0.6823 - val_loss: 2.0633 - val_acc: 0.6806\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1610 - acc: 0.9924 - val_loss: 0.1580 - val_acc: 0.9906\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1541 - acc: 0.9928 - val_loss: 0.1559 - val_acc: 0.9908\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1557 - acc: 0.9928 - val_loss: 0.1621 - val_acc: 0.9907\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1614 - acc: 0.9928 - val_loss: 0.1632 - val_acc: 0.9907\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1597 - acc: 0.9928 - val_loss: 0.1633 - val_acc: 0.9906\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1675 - acc: 0.9928 - val_loss: 0.1709 - val_acc: 0.9906\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1681 - acc: 0.9928 - val_loss: 0.1631 - val_acc: 0.9906\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1667 - acc: 0.9928 - val_loss: 0.1615 - val_acc: 0.9905\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1573 - acc: 0.9924 - val_loss: 0.1576 - val_acc: 0.9902\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1612 - acc: 0.9917 - val_loss: 0.1719 - val_acc: 0.9891\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1733 - acc: 0.9911 - val_loss: 0.1698 - val_acc: 0.9893\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1664 - acc: 0.9918 - val_loss: 0.1606 - val_acc: 0.9905\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1579 - acc: 0.9926 - val_loss: 0.1578 - val_acc: 0.9907\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1628 - acc: 0.9928 - val_loss: 0.1762 - val_acc: 0.9909\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1690 - acc: 0.9927 - val_loss: 0.1660 - val_acc: 0.9908\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1613 - acc: 0.9926 - val_loss: 0.1645 - val_acc: 0.9907\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1591 - acc: 0.9927 - val_loss: 0.1629 - val_acc: 0.9909\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1622 - acc: 0.9928 - val_loss: 0.1654 - val_acc: 0.9908\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1642 - acc: 0.9927 - val_loss: 0.1749 - val_acc: 0.9907\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1653 - acc: 0.9924 - val_loss: 0.1555 - val_acc: 0.9907\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1550 - acc: 0.9925 - val_loss: 0.1571 - val_acc: 0.9907\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1564 - acc: 0.9927 - val_loss: 0.1541 - val_acc: 0.9908\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1554 - acc: 0.9926 - val_loss: 0.1611 - val_acc: 0.9909\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1665 - acc: 0.9928 - val_loss: 0.1708 - val_acc: 0.9908\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1734 - acc: 0.9926 - val_loss: 0.1758 - val_acc: 0.9907\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1605 - acc: 0.9927 - val_loss: 0.1608 - val_acc: 0.9905\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1592 - acc: 0.9922 - val_loss: 0.1669 - val_acc: 0.9897\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1622 - acc: 0.9920 - val_loss: 0.1598 - val_acc: 0.9902\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1561 - acc: 0.9925 - val_loss: 0.1615 - val_acc: 0.9908\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1639 - acc: 0.9927 - val_loss: 0.1835 - val_acc: 0.9908\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1779 - acc: 0.9923 - val_loss: 0.1776 - val_acc: 0.9901\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1648 - acc: 0.9924 - val_loss: 0.1618 - val_acc: 0.9908\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1584 - acc: 0.9928 - val_loss: 0.1672 - val_acc: 0.9908\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 220us/step - loss: 0.1661 - acc: 0.9928 - val_loss: 0.1623 - val_acc: 0.9908\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1548 - acc: 0.9929 - val_loss: 0.1596 - val_acc: 0.9909\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1579 - acc: 0.9928 - val_loss: 0.1617 - val_acc: 0.9908\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1611 - acc: 0.9925 - val_loss: 0.1608 - val_acc: 0.9907\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1583 - acc: 0.9921 - val_loss: 0.1679 - val_acc: 0.9896\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1754 - acc: 0.9907 - val_loss: 0.1869 - val_acc: 0.9888\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1712 - acc: 0.9919 - val_loss: 0.1676 - val_acc: 0.9908\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1646 - acc: 0.9928 - val_loss: 0.1618 - val_acc: 0.9906\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1571 - acc: 0.9928 - val_loss: 0.1572 - val_acc: 0.9906\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1560 - acc: 0.9926 - val_loss: 0.1604 - val_acc: 0.9907\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1596 - acc: 0.9925 - val_loss: 0.1626 - val_acc: 0.9905\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1726 - acc: 0.9924 - val_loss: 0.1818 - val_acc: 0.9906\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1729 - acc: 0.9928 - val_loss: 0.1655 - val_acc: 0.9909\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1580 - acc: 0.9928 - val_loss: 0.1669 - val_acc: 0.9909\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1608 - acc: 0.9928 - val_loss: 0.1690 - val_acc: 0.9907\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1681 - acc: 0.9928 - val_loss: 0.1685 - val_acc: 0.9907\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1658 - acc: 0.9928 - val_loss: 0.1699 - val_acc: 0.9907\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0032 - val_acc: 0.9619\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9575 - val_loss: 0.0031 - val_acc: 0.9652\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9614 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9577 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9608 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9627 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0032 - val_acc: 0.9609\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0031 - acc: 0.9551 - val_loss: 0.0031 - val_acc: 0.9650\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0031 - val_acc: 0.9646\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9650\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9612 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0031 - val_acc: 0.9654\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9620 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9630 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9609 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9607 - val_loss: 0.0031 - val_acc: 0.9643\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9569 - val_loss: 0.0031 - val_acc: 0.9642\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0033 - val_acc: 0.9574\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9596 - val_loss: 0.0032 - val_acc: 0.9588\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9597 - val_loss: 0.0032 - val_acc: 0.9639\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0031 - val_acc: 0.9653\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0030 - val_acc: 0.9658\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9638\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0030 - acc: 0.9570 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9603 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9611 - val_loss: 0.0030 - val_acc: 0.9629\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9596 - val_loss: 0.0030 - val_acc: 0.9636\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0030 - acc: 0.9572 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9586 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0029 - val_acc: 0.9648\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0031 - val_acc: 0.9616\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9606 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9597 - val_loss: 0.0030 - val_acc: 0.9661\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9630 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9617 - val_loss: 0.0031 - val_acc: 0.9609\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0031 - acc: 0.9542 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9645\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0032 - val_acc: 0.9634\n",
      "start training round 41\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2174 - acc: 0.6946 - val_loss: 0.2331 - val_acc: 0.6896\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2167 - acc: 0.6952 - val_loss: 0.2340 - val_acc: 0.6915\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2187 - acc: 0.6953 - val_loss: 0.2337 - val_acc: 0.6912\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2179 - acc: 0.6952 - val_loss: 0.2349 - val_acc: 0.6902\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2161 - acc: 0.6957 - val_loss: 0.2325 - val_acc: 0.6889\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2208 - acc: 0.6917 - val_loss: 0.2363 - val_acc: 0.6920\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2223 - acc: 0.6943 - val_loss: 0.2308 - val_acc: 0.6913\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2161 - acc: 0.6956 - val_loss: 0.2317 - val_acc: 0.6921\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2197 - acc: 0.6935 - val_loss: 0.2338 - val_acc: 0.6893\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2177 - acc: 0.6945 - val_loss: 0.2332 - val_acc: 0.6917\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2205 - acc: 0.6935 - val_loss: 0.2312 - val_acc: 0.6905\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2148 - acc: 0.6956 - val_loss: 0.2304 - val_acc: 0.6921\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2161 - acc: 0.6950 - val_loss: 0.2304 - val_acc: 0.6920\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2198 - acc: 0.6951 - val_loss: 0.2441 - val_acc: 0.6893\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2218 - acc: 0.6945 - val_loss: 0.2313 - val_acc: 0.6910\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2162 - acc: 0.6953 - val_loss: 0.2297 - val_acc: 0.6932\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2185 - acc: 0.6954 - val_loss: 0.2369 - val_acc: 0.6915\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2194 - acc: 0.6947 - val_loss: 0.2393 - val_acc: 0.6876\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2202 - acc: 0.6932 - val_loss: 0.2351 - val_acc: 0.6908\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2226 - acc: 0.6938 - val_loss: 0.2347 - val_acc: 0.6913\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2179 - acc: 0.6948 - val_loss: 0.2330 - val_acc: 0.6914\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2192 - acc: 0.6950 - val_loss: 0.2323 - val_acc: 0.6915\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2201 - acc: 0.6936 - val_loss: 0.2321 - val_acc: 0.6903\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2161 - acc: 0.6953 - val_loss: 0.2296 - val_acc: 0.6926\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2166 - acc: 0.6954 - val_loss: 0.2339 - val_acc: 0.6904\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2229 - acc: 0.6924 - val_loss: 0.2327 - val_acc: 0.6904\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2188 - acc: 0.6930 - val_loss: 0.2314 - val_acc: 0.6908\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2174 - acc: 0.6944 - val_loss: 0.2318 - val_acc: 0.6916\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2171 - acc: 0.6953 - val_loss: 0.2319 - val_acc: 0.6922\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2197 - acc: 0.6940 - val_loss: 0.2418 - val_acc: 0.6899\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2183 - acc: 0.6946 - val_loss: 0.2349 - val_acc: 0.6901\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2196 - acc: 0.6931 - val_loss: 0.2308 - val_acc: 0.6917\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2171 - acc: 0.6951 - val_loss: 0.2296 - val_acc: 0.6921\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2172 - acc: 0.6958 - val_loss: 0.2344 - val_acc: 0.6913\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2173 - acc: 0.6954 - val_loss: 0.2349 - val_acc: 0.6890\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2175 - acc: 0.6941 - val_loss: 0.2344 - val_acc: 0.6881\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2192 - acc: 0.6932 - val_loss: 0.2300 - val_acc: 0.6919\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2176 - acc: 0.6949 - val_loss: 0.2300 - val_acc: 0.6923\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2157 - acc: 0.6956 - val_loss: 0.2311 - val_acc: 0.6910\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2167 - acc: 0.6951 - val_loss: 0.2332 - val_acc: 0.6902\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2178 - acc: 0.6942 - val_loss: 0.2328 - val_acc: 0.6905\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2219 - acc: 0.6927 - val_loss: 0.2347 - val_acc: 0.6903\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2168 - acc: 0.6955 - val_loss: 0.2300 - val_acc: 0.6916\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2184 - acc: 0.6953 - val_loss: 0.2408 - val_acc: 0.6895\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2234 - acc: 0.6942 - val_loss: 0.2305 - val_acc: 0.6915\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2192 - acc: 0.6942 - val_loss: 0.2351 - val_acc: 0.6910\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2209 - acc: 0.6941 - val_loss: 0.2404 - val_acc: 0.6877\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2213 - acc: 0.6930 - val_loss: 0.2337 - val_acc: 0.6906\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2209 - acc: 0.6946 - val_loss: 0.2305 - val_acc: 0.6926\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2148 - acc: 0.6957 - val_loss: 0.2287 - val_acc: 0.6924\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9248 - acc: 0.6826 - val_loss: 2.1201 - val_acc: 0.6765\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9361 - acc: 0.6825 - val_loss: 2.1168 - val_acc: 0.6764\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9246 - acc: 0.6829 - val_loss: 2.0293 - val_acc: 0.6799\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9110 - acc: 0.6825 - val_loss: 2.0575 - val_acc: 0.6786\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9038 - acc: 0.6813 - val_loss: 2.0586 - val_acc: 0.6787\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9204 - acc: 0.6805 - val_loss: 2.0721 - val_acc: 0.6804\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9259 - acc: 0.6825 - val_loss: 2.0333 - val_acc: 0.6801\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9082 - acc: 0.6822 - val_loss: 2.0939 - val_acc: 0.6756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9225 - acc: 0.6812 - val_loss: 2.0872 - val_acc: 0.6774\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9426 - acc: 0.6813 - val_loss: 2.0960 - val_acc: 0.6801\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9134 - acc: 0.6823 - val_loss: 2.0215 - val_acc: 0.6823\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8870 - acc: 0.6827 - val_loss: 2.0312 - val_acc: 0.6800\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9227 - acc: 0.6823 - val_loss: 2.1037 - val_acc: 0.6807\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9308 - acc: 0.6829 - val_loss: 2.0599 - val_acc: 0.6817\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9063 - acc: 0.6830 - val_loss: 2.0602 - val_acc: 0.6800\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9176 - acc: 0.6825 - val_loss: 2.0517 - val_acc: 0.6791\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9149 - acc: 0.6817 - val_loss: 2.0666 - val_acc: 0.6783\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8994 - acc: 0.6818 - val_loss: 2.0687 - val_acc: 0.6775\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9240 - acc: 0.6821 - val_loss: 2.1390 - val_acc: 0.6781\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9163 - acc: 0.6817 - val_loss: 2.0726 - val_acc: 0.6790\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9090 - acc: 0.6818 - val_loss: 2.1794 - val_acc: 0.6799\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9526 - acc: 0.6812 - val_loss: 2.0908 - val_acc: 0.6807\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9351 - acc: 0.6823 - val_loss: 2.0962 - val_acc: 0.6785\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9274 - acc: 0.6819 - val_loss: 2.0379 - val_acc: 0.6791\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8973 - acc: 0.6830 - val_loss: 2.0383 - val_acc: 0.6785\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9254 - acc: 0.6814 - val_loss: 2.0603 - val_acc: 0.6803\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9266 - acc: 0.6827 - val_loss: 2.0295 - val_acc: 0.6804\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9210 - acc: 0.6818 - val_loss: 2.0488 - val_acc: 0.6807\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8975 - acc: 0.6822 - val_loss: 2.1370 - val_acc: 0.6757\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9298 - acc: 0.6820 - val_loss: 2.0311 - val_acc: 0.6800\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9159 - acc: 0.6826 - val_loss: 2.0438 - val_acc: 0.6797\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9341 - acc: 0.6818 - val_loss: 2.0571 - val_acc: 0.6803\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9055 - acc: 0.6823 - val_loss: 2.0395 - val_acc: 0.6806\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9216 - acc: 0.6825 - val_loss: 2.0838 - val_acc: 0.6810\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9225 - acc: 0.6822 - val_loss: 2.0487 - val_acc: 0.6821\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9290 - acc: 0.6818 - val_loss: 2.1511 - val_acc: 0.6786\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9253 - acc: 0.6813 - val_loss: 2.0275 - val_acc: 0.6806\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9056 - acc: 0.6815 - val_loss: 2.0891 - val_acc: 0.6793\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9087 - acc: 0.6820 - val_loss: 2.0515 - val_acc: 0.6807\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9248 - acc: 0.6827 - val_loss: 2.0941 - val_acc: 0.6809\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9091 - acc: 0.6834 - val_loss: 2.0412 - val_acc: 0.6805\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8926 - acc: 0.6829 - val_loss: 2.1201 - val_acc: 0.6755\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9512 - acc: 0.6819 - val_loss: 2.0276 - val_acc: 0.6806\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9061 - acc: 0.6824 - val_loss: 2.0691 - val_acc: 0.6768\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9127 - acc: 0.6816 - val_loss: 2.0664 - val_acc: 0.6794\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9119 - acc: 0.6814 - val_loss: 2.0137 - val_acc: 0.6809\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9085 - acc: 0.6830 - val_loss: 2.0419 - val_acc: 0.6802\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9313 - acc: 0.6825 - val_loss: 2.0488 - val_acc: 0.6834\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9044 - acc: 0.6834 - val_loss: 2.1418 - val_acc: 0.6800\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9284 - acc: 0.6816 - val_loss: 2.0480 - val_acc: 0.6801\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1645 - acc: 0.9926 - val_loss: 0.1635 - val_acc: 0.9907\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1613 - acc: 0.9926 - val_loss: 0.1627 - val_acc: 0.9904\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1620 - acc: 0.9923 - val_loss: 0.1683 - val_acc: 0.9906\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1685 - acc: 0.9918 - val_loss: 0.1617 - val_acc: 0.9905\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1580 - acc: 0.9921 - val_loss: 0.1596 - val_acc: 0.9906\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1555 - acc: 0.9926 - val_loss: 0.1544 - val_acc: 0.9909\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1527 - acc: 0.9928 - val_loss: 0.1589 - val_acc: 0.9908\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1639 - acc: 0.9925 - val_loss: 0.1630 - val_acc: 0.9907\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1604 - acc: 0.9929 - val_loss: 0.1651 - val_acc: 0.9909\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1566 - acc: 0.9928 - val_loss: 0.1526 - val_acc: 0.9907\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1517 - acc: 0.9927 - val_loss: 0.1568 - val_acc: 0.9905\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1586 - acc: 0.9922 - val_loss: 0.1703 - val_acc: 0.9893\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1754 - acc: 0.9917 - val_loss: 0.1707 - val_acc: 0.9900\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1614 - acc: 0.9922 - val_loss: 0.1644 - val_acc: 0.9900\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1651 - acc: 0.9920 - val_loss: 0.1670 - val_acc: 0.9901\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1637 - acc: 0.9923 - val_loss: 0.1592 - val_acc: 0.9909\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1589 - acc: 0.9927 - val_loss: 0.1651 - val_acc: 0.9908\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1580 - acc: 0.9927 - val_loss: 0.1618 - val_acc: 0.9908\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1633 - acc: 0.9925 - val_loss: 0.1729 - val_acc: 0.9908\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1667 - acc: 0.9928 - val_loss: 0.1735 - val_acc: 0.9906\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1714 - acc: 0.9927 - val_loss: 0.1691 - val_acc: 0.9908\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1632 - acc: 0.9928 - val_loss: 0.1605 - val_acc: 0.9908\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1590 - acc: 0.9927 - val_loss: 0.1660 - val_acc: 0.9908\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1625 - acc: 0.9925 - val_loss: 0.1659 - val_acc: 0.9906\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1586 - acc: 0.9924 - val_loss: 0.1593 - val_acc: 0.9906\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1640 - acc: 0.9919 - val_loss: 0.1687 - val_acc: 0.9891\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1638 - acc: 0.9915 - val_loss: 0.1616 - val_acc: 0.9898\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1555 - acc: 0.9922 - val_loss: 0.1590 - val_acc: 0.9905\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1648 - acc: 0.9922 - val_loss: 0.1790 - val_acc: 0.9902\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1763 - acc: 0.9926 - val_loss: 0.1682 - val_acc: 0.9906\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1599 - acc: 0.9928 - val_loss: 0.1636 - val_acc: 0.9907\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1713 - acc: 0.9928 - val_loss: 0.1816 - val_acc: 0.9907\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1661 - acc: 0.9928 - val_loss: 0.1620 - val_acc: 0.9906\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1610 - acc: 0.9924 - val_loss: 0.1666 - val_acc: 0.9894\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1657 - acc: 0.9920 - val_loss: 0.1616 - val_acc: 0.9907\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1556 - acc: 0.9927 - val_loss: 0.1560 - val_acc: 0.9907\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1531 - acc: 0.9928 - val_loss: 0.1541 - val_acc: 0.9907\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1516 - acc: 0.9929 - val_loss: 0.1588 - val_acc: 0.9906\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1587 - acc: 0.9928 - val_loss: 0.1698 - val_acc: 0.9906\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1748 - acc: 0.9928 - val_loss: 0.1804 - val_acc: 0.9906\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1671 - acc: 0.9928 - val_loss: 0.1582 - val_acc: 0.9907\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1576 - acc: 0.9926 - val_loss: 0.1565 - val_acc: 0.9906\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 220us/step - loss: 0.1528 - acc: 0.9927 - val_loss: 0.1563 - val_acc: 0.9906\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.1592 - acc: 0.9925 - val_loss: 0.1639 - val_acc: 0.9907\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.1560 - acc: 0.9927 - val_loss: 0.1621 - val_acc: 0.9909\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.1633 - acc: 0.9928 - val_loss: 0.1679 - val_acc: 0.9908\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.1564 - acc: 0.9928 - val_loss: 0.1569 - val_acc: 0.9908\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1581 - acc: 0.9926 - val_loss: 0.1603 - val_acc: 0.9908\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1592 - acc: 0.9927 - val_loss: 0.1604 - val_acc: 0.9908\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1559 - acc: 0.9926 - val_loss: 0.1563 - val_acc: 0.9908\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0030 - acc: 0.9584 - val_loss: 0.0030 - val_acc: 0.9658\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9630 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9662\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0030 - val_acc: 0.9625\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0032 - val_acc: 0.9605\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9598 - val_loss: 0.0029 - val_acc: 0.9654\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0029 - val_acc: 0.9652\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9580 - val_loss: 0.0029 - val_acc: 0.9658\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9612 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9618 - val_loss: 0.0031 - val_acc: 0.9606\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0031 - acc: 0.9568 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0030 - acc: 0.9590 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0031 - val_acc: 0.9610\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9589 - val_loss: 0.0034 - val_acc: 0.9548\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9577 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9630 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0035 - val_acc: 0.9555\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9590 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9586 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9618 - val_loss: 0.0038 - val_acc: 0.9476\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0031 - acc: 0.9550 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9630 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0040 - val_acc: 0.9396\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0031 - acc: 0.9548 - val_loss: 0.0030 - val_acc: 0.9649\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9631 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9658\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9618 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9637\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0030 - acc: 0.9562 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0030 - val_acc: 0.9640\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0030 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9647\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9618 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9602 - val_loss: 0.0042 - val_acc: 0.9341\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0030 - acc: 0.9562 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0030 - val_acc: 0.9649\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0030 - acc: 0.9590 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0029 - acc: 0.9602 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9618 - val_loss: 0.0030 - val_acc: 0.9649\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0032 - val_acc: 0.9629\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9623 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9633 - val_loss: 0.0030 - val_acc: 0.9661\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9662\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0029 - val_acc: 0.9662\n",
      "start training round 42\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2165 - acc: 0.6952 - val_loss: 0.2300 - val_acc: 0.6928\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2181 - acc: 0.6938 - val_loss: 0.2362 - val_acc: 0.6889\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2212 - acc: 0.6928 - val_loss: 0.2343 - val_acc: 0.6911\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2199 - acc: 0.6955 - val_loss: 0.2302 - val_acc: 0.6914\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2168 - acc: 0.6955 - val_loss: 0.2312 - val_acc: 0.6919\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2156 - acc: 0.6957 - val_loss: 0.2327 - val_acc: 0.6907\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2185 - acc: 0.6945 - val_loss: 0.2384 - val_acc: 0.6891\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2196 - acc: 0.6945 - val_loss: 0.2308 - val_acc: 0.6922\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2185 - acc: 0.6949 - val_loss: 0.2321 - val_acc: 0.6917\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2195 - acc: 0.6940 - val_loss: 0.2303 - val_acc: 0.6909\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2173 - acc: 0.6955 - val_loss: 0.2332 - val_acc: 0.6907\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2196 - acc: 0.6933 - val_loss: 0.2300 - val_acc: 0.6913\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2168 - acc: 0.6946 - val_loss: 0.2355 - val_acc: 0.6890\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2196 - acc: 0.6934 - val_loss: 0.2342 - val_acc: 0.6898\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2191 - acc: 0.6941 - val_loss: 0.2299 - val_acc: 0.6920\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2169 - acc: 0.6952 - val_loss: 0.2308 - val_acc: 0.6922\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2181 - acc: 0.6952 - val_loss: 0.2404 - val_acc: 0.6905\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2198 - acc: 0.6952 - val_loss: 0.2311 - val_acc: 0.6931\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2153 - acc: 0.6961 - val_loss: 0.2307 - val_acc: 0.6925\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2190 - acc: 0.6948 - val_loss: 0.2325 - val_acc: 0.6920\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2168 - acc: 0.6958 - val_loss: 0.2306 - val_acc: 0.6935\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2184 - acc: 0.6950 - val_loss: 0.2290 - val_acc: 0.6925\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2197 - acc: 0.6940 - val_loss: 0.2324 - val_acc: 0.6903\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2176 - acc: 0.6944 - val_loss: 0.2342 - val_acc: 0.6909\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2184 - acc: 0.6948 - val_loss: 0.2280 - val_acc: 0.6926\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2169 - acc: 0.6950 - val_loss: 0.2319 - val_acc: 0.6917\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2163 - acc: 0.6953 - val_loss: 0.2354 - val_acc: 0.6897\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2170 - acc: 0.6950 - val_loss: 0.2318 - val_acc: 0.6904\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2175 - acc: 0.6940 - val_loss: 0.2318 - val_acc: 0.6915\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2192 - acc: 0.6934 - val_loss: 0.2330 - val_acc: 0.6909\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2193 - acc: 0.6946 - val_loss: 0.2363 - val_acc: 0.6904\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2204 - acc: 0.6944 - val_loss: 0.2312 - val_acc: 0.6919\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2159 - acc: 0.6959 - val_loss: 0.2288 - val_acc: 0.6919\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2200 - acc: 0.6947 - val_loss: 0.2295 - val_acc: 0.6918\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2164 - acc: 0.6941 - val_loss: 0.2294 - val_acc: 0.6926\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2173 - acc: 0.6951 - val_loss: 0.2340 - val_acc: 0.6905\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2179 - acc: 0.6949 - val_loss: 0.2340 - val_acc: 0.6897\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2199 - acc: 0.6934 - val_loss: 0.2286 - val_acc: 0.6923\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2213 - acc: 0.6952 - val_loss: 0.2337 - val_acc: 0.6923\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2180 - acc: 0.6946 - val_loss: 0.2324 - val_acc: 0.6907\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2196 - acc: 0.6932 - val_loss: 0.2310 - val_acc: 0.6918\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2178 - acc: 0.6942 - val_loss: 0.2308 - val_acc: 0.6913\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2158 - acc: 0.6955 - val_loss: 0.2322 - val_acc: 0.6916\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2175 - acc: 0.6955 - val_loss: 0.2312 - val_acc: 0.6908\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2204 - acc: 0.6926 - val_loss: 0.2301 - val_acc: 0.6917\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2156 - acc: 0.6961 - val_loss: 0.2297 - val_acc: 0.6924\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2174 - acc: 0.6951 - val_loss: 0.2304 - val_acc: 0.6916\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2199 - acc: 0.6932 - val_loss: 0.2332 - val_acc: 0.6906\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2164 - acc: 0.6946 - val_loss: 0.2308 - val_acc: 0.6921\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2157 - acc: 0.6951 - val_loss: 0.2327 - val_acc: 0.6922\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9221 - acc: 0.6816 - val_loss: 2.0673 - val_acc: 0.6805\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9023 - acc: 0.6821 - val_loss: 2.0307 - val_acc: 0.6816\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8927 - acc: 0.6829 - val_loss: 2.1409 - val_acc: 0.6801\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9412 - acc: 0.6821 - val_loss: 2.0536 - val_acc: 0.6813\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9015 - acc: 0.6827 - val_loss: 2.0187 - val_acc: 0.6809\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9085 - acc: 0.6817 - val_loss: 2.0286 - val_acc: 0.6803\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8948 - acc: 0.6825 - val_loss: 2.0630 - val_acc: 0.6798\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9142 - acc: 0.6827 - val_loss: 2.0721 - val_acc: 0.6820\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9107 - acc: 0.6818 - val_loss: 2.1435 - val_acc: 0.6763\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9164 - acc: 0.6823 - val_loss: 2.0283 - val_acc: 0.6809\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9181 - acc: 0.6827 - val_loss: 2.0527 - val_acc: 0.6824\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9265 - acc: 0.6826 - val_loss: 2.0293 - val_acc: 0.6827\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9144 - acc: 0.6817 - val_loss: 2.0579 - val_acc: 0.6796\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9211 - acc: 0.6812 - val_loss: 2.1083 - val_acc: 0.6760\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9043 - acc: 0.6827 - val_loss: 2.1219 - val_acc: 0.6778\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9247 - acc: 0.6828 - val_loss: 2.0310 - val_acc: 0.6793\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9220 - acc: 0.6825 - val_loss: 2.0534 - val_acc: 0.6790\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9240 - acc: 0.6814 - val_loss: 2.1018 - val_acc: 0.6798\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9432 - acc: 0.6820 - val_loss: 2.0694 - val_acc: 0.6812\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9023 - acc: 0.6823 - val_loss: 2.0430 - val_acc: 0.6825\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9106 - acc: 0.6827 - val_loss: 2.0526 - val_acc: 0.6820\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9338 - acc: 0.6822 - val_loss: 2.0281 - val_acc: 0.6810\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8983 - acc: 0.6817 - val_loss: 2.0216 - val_acc: 0.6812\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8855 - acc: 0.6830 - val_loss: 2.0616 - val_acc: 0.6816\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9339 - acc: 0.6808 - val_loss: 2.0355 - val_acc: 0.6816\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9202 - acc: 0.6813 - val_loss: 2.0942 - val_acc: 0.6781\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9415 - acc: 0.6826 - val_loss: 2.1105 - val_acc: 0.6778\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9170 - acc: 0.6827 - val_loss: 2.0520 - val_acc: 0.6788\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9056 - acc: 0.6824 - val_loss: 2.0469 - val_acc: 0.6791\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8940 - acc: 0.6820 - val_loss: 2.0712 - val_acc: 0.6797\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9226 - acc: 0.6825 - val_loss: 2.0443 - val_acc: 0.6805\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9108 - acc: 0.6819 - val_loss: 2.0671 - val_acc: 0.6800\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9493 - acc: 0.6821 - val_loss: 2.0551 - val_acc: 0.6820\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9103 - acc: 0.6826 - val_loss: 2.0517 - val_acc: 0.6810\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8950 - acc: 0.6830 - val_loss: 2.1396 - val_acc: 0.6753\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9297 - acc: 0.6822 - val_loss: 2.1327 - val_acc: 0.6764\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9217 - acc: 0.6805 - val_loss: 2.0583 - val_acc: 0.6796\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9188 - acc: 0.6827 - val_loss: 2.0445 - val_acc: 0.6789\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8947 - acc: 0.6830 - val_loss: 2.0460 - val_acc: 0.6806\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9432 - acc: 0.6819 - val_loss: 2.0817 - val_acc: 0.6779\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9282 - acc: 0.6814 - val_loss: 2.0160 - val_acc: 0.6795\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8890 - acc: 0.6829 - val_loss: 2.0601 - val_acc: 0.6796\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9027 - acc: 0.6825 - val_loss: 2.0563 - val_acc: 0.6790\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9079 - acc: 0.6831 - val_loss: 2.0246 - val_acc: 0.6806\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9152 - acc: 0.6819 - val_loss: 2.0310 - val_acc: 0.6811\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9207 - acc: 0.6819 - val_loss: 2.0887 - val_acc: 0.6775\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9203 - acc: 0.6822 - val_loss: 2.0814 - val_acc: 0.6794\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9201 - acc: 0.6826 - val_loss: 2.0504 - val_acc: 0.6801\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9188 - acc: 0.6823 - val_loss: 2.1190 - val_acc: 0.6761\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9580 - acc: 0.6818 - val_loss: 2.0332 - val_acc: 0.6809\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1513 - acc: 0.9929 - val_loss: 0.1574 - val_acc: 0.9906\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1614 - acc: 0.9925 - val_loss: 0.1768 - val_acc: 0.9900\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1764 - acc: 0.9922 - val_loss: 0.1634 - val_acc: 0.9906\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1612 - acc: 0.9927 - val_loss: 0.1627 - val_acc: 0.9908\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1556 - acc: 0.9928 - val_loss: 0.1547 - val_acc: 0.9906\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1599 - acc: 0.9927 - val_loss: 0.1787 - val_acc: 0.9902\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1765 - acc: 0.9924 - val_loss: 0.1690 - val_acc: 0.9902\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1643 - acc: 0.9924 - val_loss: 0.1549 - val_acc: 0.9907\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1508 - acc: 0.9929 - val_loss: 0.1518 - val_acc: 0.9907\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1493 - acc: 0.9928 - val_loss: 0.1526 - val_acc: 0.9909\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1562 - acc: 0.9925 - val_loss: 0.1641 - val_acc: 0.9904\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1694 - acc: 0.9913 - val_loss: 0.1861 - val_acc: 0.9887\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1817 - acc: 0.9907 - val_loss: 0.1639 - val_acc: 0.9903\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1580 - acc: 0.9926 - val_loss: 0.1600 - val_acc: 0.9908\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1579 - acc: 0.9928 - val_loss: 0.1601 - val_acc: 0.9907\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1652 - acc: 0.9928 - val_loss: 0.1750 - val_acc: 0.9906\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1660 - acc: 0.9928 - val_loss: 0.1603 - val_acc: 0.9907\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1557 - acc: 0.9928 - val_loss: 0.1585 - val_acc: 0.9905\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1554 - acc: 0.9928 - val_loss: 0.1605 - val_acc: 0.9907\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1574 - acc: 0.9927 - val_loss: 0.1570 - val_acc: 0.9905\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1580 - acc: 0.9923 - val_loss: 0.1678 - val_acc: 0.9898\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1656 - acc: 0.9916 - val_loss: 0.1719 - val_acc: 0.9886\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1639 - acc: 0.9913 - val_loss: 0.1563 - val_acc: 0.9904\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1526 - acc: 0.9926 - val_loss: 0.1521 - val_acc: 0.9907\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1493 - acc: 0.9929 - val_loss: 0.1526 - val_acc: 0.9908\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1531 - acc: 0.9926 - val_loss: 0.1634 - val_acc: 0.9906\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1660 - acc: 0.9926 - val_loss: 0.1721 - val_acc: 0.9909\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1793 - acc: 0.9927 - val_loss: 0.1739 - val_acc: 0.9908\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1628 - acc: 0.9928 - val_loss: 0.1650 - val_acc: 0.9909\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1602 - acc: 0.9928 - val_loss: 0.1648 - val_acc: 0.9909\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1580 - acc: 0.9928 - val_loss: 0.1556 - val_acc: 0.9908\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1541 - acc: 0.9928 - val_loss: 0.1546 - val_acc: 0.9907\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1515 - acc: 0.9928 - val_loss: 0.1558 - val_acc: 0.9905\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1559 - acc: 0.9927 - val_loss: 0.1598 - val_acc: 0.9907\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1718 - acc: 0.9929 - val_loss: 0.1778 - val_acc: 0.9907\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1668 - acc: 0.9928 - val_loss: 0.1600 - val_acc: 0.9906\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1554 - acc: 0.9926 - val_loss: 0.1568 - val_acc: 0.9907\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1619 - acc: 0.9915 - val_loss: 0.1635 - val_acc: 0.9899\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.1599 - acc: 0.9918 - val_loss: 0.1679 - val_acc: 0.9897\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1635 - acc: 0.9912 - val_loss: 0.1619 - val_acc: 0.9898\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1572 - acc: 0.9920 - val_loss: 0.1525 - val_acc: 0.9908\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1497 - acc: 0.9928 - val_loss: 0.1526 - val_acc: 0.9908\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1548 - acc: 0.9928 - val_loss: 0.1656 - val_acc: 0.9908\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1706 - acc: 0.9928 - val_loss: 0.1741 - val_acc: 0.9909\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1697 - acc: 0.9929 - val_loss: 0.1674 - val_acc: 0.9908\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1569 - acc: 0.9928 - val_loss: 0.1539 - val_acc: 0.9908\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1518 - acc: 0.9929 - val_loss: 0.1559 - val_acc: 0.9907\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1604 - acc: 0.9929 - val_loss: 0.1721 - val_acc: 0.9906\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1702 - acc: 0.9929 - val_loss: 0.1652 - val_acc: 0.9907\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1643 - acc: 0.9927 - val_loss: 0.1637 - val_acc: 0.9904\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9616 - val_loss: 0.0031 - val_acc: 0.9599\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0030 - acc: 0.9562 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0031 - val_acc: 0.9640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0033 - val_acc: 0.9602\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0029 - acc: 0.9601 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9606 - val_loss: 0.0030 - val_acc: 0.9613\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9591 - val_loss: 0.0030 - val_acc: 0.9629\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9592 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0036 - val_acc: 0.9491\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0029 - acc: 0.9573 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9606 - val_loss: 0.0029 - val_acc: 0.9642\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9576 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0029 - acc: 0.9574 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0031 - val_acc: 0.9658\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9618 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9604 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0031 - val_acc: 0.9630\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0030 - acc: 0.9586 - val_loss: 0.0033 - val_acc: 0.9608\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9609 - val_loss: 0.0030 - val_acc: 0.9661\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9631 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9627 - val_loss: 0.0030 - val_acc: 0.9658\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9604 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9591 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9570 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9600 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9627 - val_loss: 0.0032 - val_acc: 0.9554\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9567 - val_loss: 0.0031 - val_acc: 0.9619\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9611 - val_loss: 0.0030 - val_acc: 0.9636\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0029 - acc: 0.9596 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0032 - val_acc: 0.9588\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0029 - acc: 0.9593 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9616 - val_loss: 0.0029 - val_acc: 0.9639\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0028 - acc: 0.9614 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9646\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9588 - val_loss: 0.0029 - val_acc: 0.9654\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0028 - acc: 0.9632 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 243us/step - loss: 0.0030 - acc: 0.9562 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "start training round 43\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2218 - acc: 0.6952 - val_loss: 0.2322 - val_acc: 0.6913\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2169 - acc: 0.6954 - val_loss: 0.2296 - val_acc: 0.6933\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2156 - acc: 0.6962 - val_loss: 0.2322 - val_acc: 0.6918\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2194 - acc: 0.6942 - val_loss: 0.2312 - val_acc: 0.6924\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2199 - acc: 0.6936 - val_loss: 0.2326 - val_acc: 0.6928\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2178 - acc: 0.6962 - val_loss: 0.2290 - val_acc: 0.6916\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2178 - acc: 0.6951 - val_loss: 0.2314 - val_acc: 0.6919\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2173 - acc: 0.6959 - val_loss: 0.2290 - val_acc: 0.6934\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2158 - acc: 0.6961 - val_loss: 0.2334 - val_acc: 0.6906\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2196 - acc: 0.6949 - val_loss: 0.2291 - val_acc: 0.6917\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2134 - acc: 0.6965 - val_loss: 0.2281 - val_acc: 0.6937\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2223 - acc: 0.6931 - val_loss: 0.2349 - val_acc: 0.6918\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2159 - acc: 0.6958 - val_loss: 0.2364 - val_acc: 0.6879\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2188 - acc: 0.6931 - val_loss: 0.2304 - val_acc: 0.6921\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2195 - acc: 0.6936 - val_loss: 0.2280 - val_acc: 0.6922\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2181 - acc: 0.6948 - val_loss: 0.2345 - val_acc: 0.6922\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2198 - acc: 0.6953 - val_loss: 0.2291 - val_acc: 0.6930\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2155 - acc: 0.6953 - val_loss: 0.2350 - val_acc: 0.6868\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2165 - acc: 0.6944 - val_loss: 0.2297 - val_acc: 0.6922\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2137 - acc: 0.6963 - val_loss: 0.2271 - val_acc: 0.6934\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2149 - acc: 0.6965 - val_loss: 0.2353 - val_acc: 0.6912\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2208 - acc: 0.6934 - val_loss: 0.2333 - val_acc: 0.6901\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2178 - acc: 0.6947 - val_loss: 0.2282 - val_acc: 0.6918\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2154 - acc: 0.6956 - val_loss: 0.2296 - val_acc: 0.6909\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2176 - acc: 0.6936 - val_loss: 0.2290 - val_acc: 0.6922\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2181 - acc: 0.6957 - val_loss: 0.2308 - val_acc: 0.6918\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2188 - acc: 0.6941 - val_loss: 0.2362 - val_acc: 0.6901\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2211 - acc: 0.6932 - val_loss: 0.2339 - val_acc: 0.6908\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2199 - acc: 0.6947 - val_loss: 0.2377 - val_acc: 0.6919\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2193 - acc: 0.6956 - val_loss: 0.2285 - val_acc: 0.6931\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2166 - acc: 0.6953 - val_loss: 0.2349 - val_acc: 0.6895\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2168 - acc: 0.6953 - val_loss: 0.2305 - val_acc: 0.6925\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2157 - acc: 0.6958 - val_loss: 0.2297 - val_acc: 0.6924\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2171 - acc: 0.6953 - val_loss: 0.2319 - val_acc: 0.6899\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2199 - acc: 0.6941 - val_loss: 0.2309 - val_acc: 0.6929\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2163 - acc: 0.6951 - val_loss: 0.2295 - val_acc: 0.6938\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2158 - acc: 0.6963 - val_loss: 0.2319 - val_acc: 0.6923\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2172 - acc: 0.6948 - val_loss: 0.2315 - val_acc: 0.6911\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2149 - acc: 0.6960 - val_loss: 0.2296 - val_acc: 0.6918\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2149 - acc: 0.6964 - val_loss: 0.2294 - val_acc: 0.6916\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2188 - acc: 0.6936 - val_loss: 0.2309 - val_acc: 0.6910\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2169 - acc: 0.6954 - val_loss: 0.2334 - val_acc: 0.6914\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2201 - acc: 0.6951 - val_loss: 0.2307 - val_acc: 0.6928\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2175 - acc: 0.6940 - val_loss: 0.2288 - val_acc: 0.6919\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2172 - acc: 0.6948 - val_loss: 0.2349 - val_acc: 0.6910\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2173 - acc: 0.6955 - val_loss: 0.2285 - val_acc: 0.6924\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2151 - acc: 0.6957 - val_loss: 0.2294 - val_acc: 0.6924\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2186 - acc: 0.6951 - val_loss: 0.2303 - val_acc: 0.6927\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2178 - acc: 0.6962 - val_loss: 0.2301 - val_acc: 0.6922\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2148 - acc: 0.6966 - val_loss: 0.2312 - val_acc: 0.6929\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8963 - acc: 0.6828 - val_loss: 2.0488 - val_acc: 0.6790\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9346 - acc: 0.6825 - val_loss: 2.0480 - val_acc: 0.6794\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9149 - acc: 0.6834 - val_loss: 2.0226 - val_acc: 0.6800\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9165 - acc: 0.6824 - val_loss: 2.0290 - val_acc: 0.6809\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9028 - acc: 0.6825 - val_loss: 2.0770 - val_acc: 0.6815\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9227 - acc: 0.6826 - val_loss: 2.0401 - val_acc: 0.6788\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9529 - acc: 0.6805 - val_loss: 2.0639 - val_acc: 0.6769\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9057 - acc: 0.6817 - val_loss: 2.1396 - val_acc: 0.6743\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8887 - acc: 0.6825 - val_loss: 2.0871 - val_acc: 0.6767\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9102 - acc: 0.6819 - val_loss: 2.0496 - val_acc: 0.6794\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9090 - acc: 0.6820 - val_loss: 2.0734 - val_acc: 0.6795\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9162 - acc: 0.6829 - val_loss: 2.0549 - val_acc: 0.6803\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9197 - acc: 0.6824 - val_loss: 2.0524 - val_acc: 0.6805\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9186 - acc: 0.6823 - val_loss: 2.0433 - val_acc: 0.6827\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9236 - acc: 0.6831 - val_loss: 2.0270 - val_acc: 0.6803\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9305 - acc: 0.6824 - val_loss: 2.0283 - val_acc: 0.6804\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9365 - acc: 0.6820 - val_loss: 2.0665 - val_acc: 0.6809\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9128 - acc: 0.6822 - val_loss: 2.0268 - val_acc: 0.6803\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9174 - acc: 0.6828 - val_loss: 2.0899 - val_acc: 0.6778\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9175 - acc: 0.6826 - val_loss: 2.0290 - val_acc: 0.6810\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9220 - acc: 0.6823 - val_loss: 2.0295 - val_acc: 0.6811\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8851 - acc: 0.6831 - val_loss: 2.0565 - val_acc: 0.6827\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9224 - acc: 0.6823 - val_loss: 2.0405 - val_acc: 0.6801\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9006 - acc: 0.6826 - val_loss: 2.0926 - val_acc: 0.6774\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9320 - acc: 0.6817 - val_loss: 2.0590 - val_acc: 0.6808\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9069 - acc: 0.6827 - val_loss: 2.0486 - val_acc: 0.6822\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 1.8922 - acc: 0.6831 - val_loss: 2.0690 - val_acc: 0.6804\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9065 - acc: 0.6818 - val_loss: 2.0555 - val_acc: 0.6813\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9300 - acc: 0.6815 - val_loss: 2.0275 - val_acc: 0.6806\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8915 - acc: 0.6828 - val_loss: 2.1151 - val_acc: 0.6796\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9305 - acc: 0.6823 - val_loss: 2.0620 - val_acc: 0.6774\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9511 - acc: 0.6820 - val_loss: 2.0223 - val_acc: 0.6813\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8917 - acc: 0.6830 - val_loss: 2.0314 - val_acc: 0.6805\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8844 - acc: 0.6831 - val_loss: 2.0378 - val_acc: 0.6807\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9189 - acc: 0.6818 - val_loss: 2.0771 - val_acc: 0.6789\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9224 - acc: 0.6812 - val_loss: 2.0562 - val_acc: 0.6787\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9153 - acc: 0.6825 - val_loss: 2.0727 - val_acc: 0.6777\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9365 - acc: 0.6824 - val_loss: 2.0379 - val_acc: 0.6802\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8889 - acc: 0.6829 - val_loss: 2.0560 - val_acc: 0.6793\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.8956 - acc: 0.6821 - val_loss: 2.0230 - val_acc: 0.6812\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9146 - acc: 0.6820 - val_loss: 2.1908 - val_acc: 0.6763\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9343 - acc: 0.6822 - val_loss: 2.0869 - val_acc: 0.6800\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9072 - acc: 0.6834 - val_loss: 2.0292 - val_acc: 0.6800\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8959 - acc: 0.6833 - val_loss: 2.0307 - val_acc: 0.6792\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8984 - acc: 0.6824 - val_loss: 2.1093 - val_acc: 0.6766\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9183 - acc: 0.6823 - val_loss: 2.0719 - val_acc: 0.6789\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9072 - acc: 0.6827 - val_loss: 2.0294 - val_acc: 0.6817\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9009 - acc: 0.6831 - val_loss: 2.0598 - val_acc: 0.6790\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9222 - acc: 0.6820 - val_loss: 2.0953 - val_acc: 0.6783\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9154 - acc: 0.6816 - val_loss: 2.0960 - val_acc: 0.6769\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1575 - acc: 0.9926 - val_loss: 0.1673 - val_acc: 0.9901\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1547 - acc: 0.9927 - val_loss: 0.1560 - val_acc: 0.9905\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1536 - acc: 0.9928 - val_loss: 0.1557 - val_acc: 0.9908\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1583 - acc: 0.9928 - val_loss: 0.1703 - val_acc: 0.9906\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1575 - acc: 0.9928 - val_loss: 0.1604 - val_acc: 0.9907\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1562 - acc: 0.9927 - val_loss: 0.1571 - val_acc: 0.9906\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1576 - acc: 0.9928 - val_loss: 0.1611 - val_acc: 0.9906\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1582 - acc: 0.9928 - val_loss: 0.1644 - val_acc: 0.9907\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1611 - acc: 0.9928 - val_loss: 0.1676 - val_acc: 0.9907\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1685 - acc: 0.9927 - val_loss: 0.1640 - val_acc: 0.9907\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1579 - acc: 0.9928 - val_loss: 0.1614 - val_acc: 0.9909\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1625 - acc: 0.9927 - val_loss: 0.1709 - val_acc: 0.9908\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1697 - acc: 0.9923 - val_loss: 0.1735 - val_acc: 0.9907\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1591 - acc: 0.9927 - val_loss: 0.1541 - val_acc: 0.9909\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1514 - acc: 0.9927 - val_loss: 0.1557 - val_acc: 0.9907\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1569 - acc: 0.9925 - val_loss: 0.1694 - val_acc: 0.9901\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1677 - acc: 0.9915 - val_loss: 0.1720 - val_acc: 0.9900\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1630 - acc: 0.9916 - val_loss: 0.1648 - val_acc: 0.9905\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1587 - acc: 0.9922 - val_loss: 0.1583 - val_acc: 0.9907\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1633 - acc: 0.9926 - val_loss: 0.1692 - val_acc: 0.9908\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1632 - acc: 0.9927 - val_loss: 0.1769 - val_acc: 0.9906\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1689 - acc: 0.9926 - val_loss: 0.1596 - val_acc: 0.9907\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1583 - acc: 0.9928 - val_loss: 0.1633 - val_acc: 0.9903\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1601 - acc: 0.9925 - val_loss: 0.1649 - val_acc: 0.9904\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1621 - acc: 0.9925 - val_loss: 0.1609 - val_acc: 0.9906\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1537 - acc: 0.9927 - val_loss: 0.1511 - val_acc: 0.9907\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1528 - acc: 0.9927 - val_loss: 0.1586 - val_acc: 0.9901\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1589 - acc: 0.9925 - val_loss: 0.1614 - val_acc: 0.9901\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1568 - acc: 0.9926 - val_loss: 0.1602 - val_acc: 0.9905\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1522 - acc: 0.9926 - val_loss: 0.1576 - val_acc: 0.9904\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1564 - acc: 0.9927 - val_loss: 0.1672 - val_acc: 0.9905\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1781 - acc: 0.9929 - val_loss: 0.1822 - val_acc: 0.9907\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1711 - acc: 0.9928 - val_loss: 0.1658 - val_acc: 0.9906\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1570 - acc: 0.9923 - val_loss: 0.1536 - val_acc: 0.9907\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1536 - acc: 0.9924 - val_loss: 0.1594 - val_acc: 0.9903\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1537 - acc: 0.9925 - val_loss: 0.1578 - val_acc: 0.9908\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1620 - acc: 0.9926 - val_loss: 0.1669 - val_acc: 0.9909\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1553 - acc: 0.9928 - val_loss: 0.1560 - val_acc: 0.9909\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1527 - acc: 0.9928 - val_loss: 0.1563 - val_acc: 0.9909\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1613 - acc: 0.9928 - val_loss: 0.1692 - val_acc: 0.9908\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1620 - acc: 0.9929 - val_loss: 0.1636 - val_acc: 0.9909\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1641 - acc: 0.9929 - val_loss: 0.1698 - val_acc: 0.9908\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1580 - acc: 0.9929 - val_loss: 0.1562 - val_acc: 0.9909\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1556 - acc: 0.9925 - val_loss: 0.1632 - val_acc: 0.9903\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1613 - acc: 0.9917 - val_loss: 0.1595 - val_acc: 0.9903\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1565 - acc: 0.9920 - val_loss: 0.1601 - val_acc: 0.9904\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1641 - acc: 0.9920 - val_loss: 0.1776 - val_acc: 0.9894\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1699 - acc: 0.9914 - val_loss: 0.1617 - val_acc: 0.9906\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1566 - acc: 0.9927 - val_loss: 0.1621 - val_acc: 0.9908\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1679 - acc: 0.9929 - val_loss: 0.1683 - val_acc: 0.9905\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9630 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.0028 - acc: 0.9632 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0030 - acc: 0.9578 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0032 - val_acc: 0.9625\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9662\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9633 - val_loss: 0.0030 - val_acc: 0.9649\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9597 - val_loss: 0.0031 - val_acc: 0.9655\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0030 - acc: 0.9576 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0030 - val_acc: 0.9630\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0029 - acc: 0.9595 - val_loss: 0.0037 - val_acc: 0.9476\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0029 - acc: 0.9588 - val_loss: 0.0034 - val_acc: 0.9545\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9587 - val_loss: 0.0029 - val_acc: 0.9657\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.0028 - acc: 0.9618 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0029 - val_acc: 0.9657\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9591 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0029 - val_acc: 0.9658\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9594 - val_loss: 0.0032 - val_acc: 0.9607\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9594 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9596 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0027 - acc: 0.9629 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0030 - val_acc: 0.9661\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9658\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9659\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9627 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9618 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0031 - val_acc: 0.9613\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9553 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9661\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0031 - val_acc: 0.9617\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9606 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9630 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9618 - val_loss: 0.0035 - val_acc: 0.9572\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9654\n",
      "start training round 44\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2171 - acc: 0.6954 - val_loss: 0.2303 - val_acc: 0.6928\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2164 - acc: 0.6960 - val_loss: 0.2301 - val_acc: 0.6922\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2185 - acc: 0.6941 - val_loss: 0.2301 - val_acc: 0.6922\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2169 - acc: 0.6957 - val_loss: 0.2289 - val_acc: 0.6924\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2167 - acc: 0.6959 - val_loss: 0.2345 - val_acc: 0.6915\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2171 - acc: 0.6952 - val_loss: 0.2288 - val_acc: 0.6939\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2198 - acc: 0.6961 - val_loss: 0.2284 - val_acc: 0.6932\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2176 - acc: 0.6944 - val_loss: 0.2332 - val_acc: 0.6902\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2183 - acc: 0.6942 - val_loss: 0.2292 - val_acc: 0.6929\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2166 - acc: 0.6953 - val_loss: 0.2308 - val_acc: 0.6908\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2132 - acc: 0.6967 - val_loss: 0.2281 - val_acc: 0.6925\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2164 - acc: 0.6954 - val_loss: 0.2275 - val_acc: 0.6932\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2174 - acc: 0.6960 - val_loss: 0.2345 - val_acc: 0.6916\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2182 - acc: 0.6948 - val_loss: 0.2325 - val_acc: 0.6911\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2189 - acc: 0.6945 - val_loss: 0.2404 - val_acc: 0.6912\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2175 - acc: 0.6955 - val_loss: 0.2307 - val_acc: 0.6917\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2163 - acc: 0.6948 - val_loss: 0.2292 - val_acc: 0.6925\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2144 - acc: 0.6959 - val_loss: 0.2310 - val_acc: 0.6922\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2175 - acc: 0.6951 - val_loss: 0.2286 - val_acc: 0.6921\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2193 - acc: 0.6954 - val_loss: 0.2287 - val_acc: 0.6931\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2162 - acc: 0.6949 - val_loss: 0.2275 - val_acc: 0.6929\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2136 - acc: 0.6964 - val_loss: 0.2314 - val_acc: 0.6926\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2202 - acc: 0.6943 - val_loss: 0.2363 - val_acc: 0.6904\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2203 - acc: 0.6944 - val_loss: 0.2334 - val_acc: 0.6902\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2180 - acc: 0.6943 - val_loss: 0.2293 - val_acc: 0.6937\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2166 - acc: 0.6964 - val_loss: 0.2317 - val_acc: 0.6928\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2145 - acc: 0.6968 - val_loss: 0.2337 - val_acc: 0.6932\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2201 - acc: 0.6946 - val_loss: 0.2310 - val_acc: 0.6929\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2154 - acc: 0.6967 - val_loss: 0.2308 - val_acc: 0.6940\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2170 - acc: 0.6953 - val_loss: 0.2325 - val_acc: 0.6913\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2181 - acc: 0.6949 - val_loss: 0.2307 - val_acc: 0.6923\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2152 - acc: 0.6965 - val_loss: 0.2312 - val_acc: 0.6935\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2154 - acc: 0.6966 - val_loss: 0.2306 - val_acc: 0.6926\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2192 - acc: 0.6949 - val_loss: 0.2318 - val_acc: 0.6911\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2176 - acc: 0.6947 - val_loss: 0.2283 - val_acc: 0.6937\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2159 - acc: 0.6962 - val_loss: 0.2420 - val_acc: 0.6882\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2200 - acc: 0.6934 - val_loss: 0.2314 - val_acc: 0.6923\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2148 - acc: 0.6958 - val_loss: 0.2290 - val_acc: 0.6933\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2176 - acc: 0.6947 - val_loss: 0.2306 - val_acc: 0.6922\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2150 - acc: 0.6965 - val_loss: 0.2310 - val_acc: 0.6911\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2151 - acc: 0.6956 - val_loss: 0.2287 - val_acc: 0.6924\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2157 - acc: 0.6964 - val_loss: 0.2318 - val_acc: 0.6911\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2166 - acc: 0.6945 - val_loss: 0.2278 - val_acc: 0.6931\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2178 - acc: 0.6950 - val_loss: 0.2311 - val_acc: 0.6916\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2174 - acc: 0.6948 - val_loss: 0.2301 - val_acc: 0.6923\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2195 - acc: 0.6947 - val_loss: 0.2316 - val_acc: 0.6934\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2199 - acc: 0.6953 - val_loss: 0.2269 - val_acc: 0.6934\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2143 - acc: 0.6967 - val_loss: 0.2314 - val_acc: 0.6921\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2163 - acc: 0.6958 - val_loss: 0.2270 - val_acc: 0.6939\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2153 - acc: 0.6967 - val_loss: 0.2303 - val_acc: 0.6934\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9037 - acc: 0.6825 - val_loss: 2.0326 - val_acc: 0.6794\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8969 - acc: 0.6828 - val_loss: 2.1085 - val_acc: 0.6755\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9317 - acc: 0.6821 - val_loss: 2.0632 - val_acc: 0.6795\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9095 - acc: 0.6832 - val_loss: 2.0450 - val_acc: 0.6790\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9044 - acc: 0.6825 - val_loss: 2.0534 - val_acc: 0.6808\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9290 - acc: 0.6821 - val_loss: 2.0354 - val_acc: 0.6810\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9099 - acc: 0.6827 - val_loss: 2.0303 - val_acc: 0.6816\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9117 - acc: 0.6820 - val_loss: 2.0561 - val_acc: 0.6791\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9129 - acc: 0.6817 - val_loss: 2.1669 - val_acc: 0.6758\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9008 - acc: 0.6828 - val_loss: 2.0290 - val_acc: 0.6795\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9003 - acc: 0.6829 - val_loss: 2.0807 - val_acc: 0.6816\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9326 - acc: 0.6825 - val_loss: 2.0133 - val_acc: 0.6815\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8857 - acc: 0.6829 - val_loss: 2.0239 - val_acc: 0.6818\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9342 - acc: 0.6825 - val_loss: 2.0613 - val_acc: 0.6830\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9158 - acc: 0.6836 - val_loss: 2.0804 - val_acc: 0.6823\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9162 - acc: 0.6829 - val_loss: 2.0233 - val_acc: 0.6820\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9067 - acc: 0.6817 - val_loss: 2.0546 - val_acc: 0.6802\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9261 - acc: 0.6825 - val_loss: 2.0734 - val_acc: 0.6821\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9005 - acc: 0.6832 - val_loss: 2.0396 - val_acc: 0.6804\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9078 - acc: 0.6824 - val_loss: 2.0520 - val_acc: 0.6802\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9371 - acc: 0.6818 - val_loss: 2.0510 - val_acc: 0.6801\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8801 - acc: 0.6835 - val_loss: 2.0937 - val_acc: 0.6821\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9222 - acc: 0.6825 - val_loss: 2.0862 - val_acc: 0.6811\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9128 - acc: 0.6828 - val_loss: 2.0784 - val_acc: 0.6817\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9067 - acc: 0.6834 - val_loss: 2.0506 - val_acc: 0.6821\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9048 - acc: 0.6817 - val_loss: 2.0295 - val_acc: 0.6804\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8979 - acc: 0.6831 - val_loss: 2.0779 - val_acc: 0.6793\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9220 - acc: 0.6830 - val_loss: 2.0447 - val_acc: 0.6813\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9050 - acc: 0.6832 - val_loss: 2.0477 - val_acc: 0.6818\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8934 - acc: 0.6828 - val_loss: 2.0393 - val_acc: 0.6812\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8999 - acc: 0.6825 - val_loss: 2.0205 - val_acc: 0.6817\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9134 - acc: 0.6819 - val_loss: 2.0716 - val_acc: 0.6786\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9217 - acc: 0.6832 - val_loss: 2.0355 - val_acc: 0.6804\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8940 - acc: 0.6833 - val_loss: 2.2134 - val_acc: 0.6803\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9227 - acc: 0.6825 - val_loss: 2.0642 - val_acc: 0.6790\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9074 - acc: 0.6826 - val_loss: 2.0867 - val_acc: 0.6798\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9175 - acc: 0.6823 - val_loss: 2.1471 - val_acc: 0.6798\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9239 - acc: 0.6830 - val_loss: 2.0483 - val_acc: 0.6820\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9046 - acc: 0.6834 - val_loss: 2.0442 - val_acc: 0.6786\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9213 - acc: 0.6832 - val_loss: 2.0869 - val_acc: 0.6797\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9382 - acc: 0.6817 - val_loss: 2.0171 - val_acc: 0.6809\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8888 - acc: 0.6826 - val_loss: 2.0943 - val_acc: 0.6799\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9204 - acc: 0.6822 - val_loss: 2.0597 - val_acc: 0.6811\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9071 - acc: 0.6825 - val_loss: 2.0773 - val_acc: 0.6805\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9219 - acc: 0.6829 - val_loss: 2.1027 - val_acc: 0.6808\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9273 - acc: 0.6819 - val_loss: 2.0351 - val_acc: 0.6809\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9097 - acc: 0.6834 - val_loss: 2.0998 - val_acc: 0.6787\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9170 - acc: 0.6830 - val_loss: 2.0538 - val_acc: 0.6774\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9211 - acc: 0.6826 - val_loss: 2.0332 - val_acc: 0.6805\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8914 - acc: 0.6837 - val_loss: 2.0512 - val_acc: 0.6807\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1586 - acc: 0.9928 - val_loss: 0.1588 - val_acc: 0.9907\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1573 - acc: 0.9928 - val_loss: 0.1597 - val_acc: 0.9904\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1531 - acc: 0.9927 - val_loss: 0.1503 - val_acc: 0.9907\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1497 - acc: 0.9929 - val_loss: 0.1509 - val_acc: 0.9906\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1531 - acc: 0.9927 - val_loss: 0.1632 - val_acc: 0.9901\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1610 - acc: 0.9920 - val_loss: 0.1628 - val_acc: 0.9897\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1613 - acc: 0.9923 - val_loss: 0.1605 - val_acc: 0.9902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1584 - acc: 0.9925 - val_loss: 0.1581 - val_acc: 0.9904\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1556 - acc: 0.9927 - val_loss: 0.1603 - val_acc: 0.9907\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1550 - acc: 0.9929 - val_loss: 0.1523 - val_acc: 0.9908\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1519 - acc: 0.9929 - val_loss: 0.1636 - val_acc: 0.9907\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1752 - acc: 0.9928 - val_loss: 0.1676 - val_acc: 0.9907\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1613 - acc: 0.9926 - val_loss: 0.1576 - val_acc: 0.9908\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1526 - acc: 0.9928 - val_loss: 0.1519 - val_acc: 0.9907\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1559 - acc: 0.9928 - val_loss: 0.1669 - val_acc: 0.9903\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1682 - acc: 0.9925 - val_loss: 0.1634 - val_acc: 0.9907\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1539 - acc: 0.9929 - val_loss: 0.1520 - val_acc: 0.9907\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1514 - acc: 0.9927 - val_loss: 0.1566 - val_acc: 0.9907\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1642 - acc: 0.9915 - val_loss: 0.1690 - val_acc: 0.9899\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1645 - acc: 0.9914 - val_loss: 0.1632 - val_acc: 0.9897\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1548 - acc: 0.9925 - val_loss: 0.1535 - val_acc: 0.9907\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1490 - acc: 0.9929 - val_loss: 0.1538 - val_acc: 0.9910\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1540 - acc: 0.9929 - val_loss: 0.1715 - val_acc: 0.9909\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1766 - acc: 0.9928 - val_loss: 0.1834 - val_acc: 0.9909\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1717 - acc: 0.9927 - val_loss: 0.1618 - val_acc: 0.9908\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1589 - acc: 0.9924 - val_loss: 0.1562 - val_acc: 0.9908\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1550 - acc: 0.9928 - val_loss: 0.1585 - val_acc: 0.9910\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1606 - acc: 0.9928 - val_loss: 0.1705 - val_acc: 0.9909\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1592 - acc: 0.9928 - val_loss: 0.1560 - val_acc: 0.9909\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1526 - acc: 0.9929 - val_loss: 0.1591 - val_acc: 0.9908\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1582 - acc: 0.9923 - val_loss: 0.1677 - val_acc: 0.9897\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1679 - acc: 0.9913 - val_loss: 0.1568 - val_acc: 0.9904\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1510 - acc: 0.9928 - val_loss: 0.1539 - val_acc: 0.9908\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1561 - acc: 0.9926 - val_loss: 0.1642 - val_acc: 0.9905\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1703 - acc: 0.9926 - val_loss: 0.1687 - val_acc: 0.9907\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1638 - acc: 0.9928 - val_loss: 0.1749 - val_acc: 0.9907\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1628 - acc: 0.9928 - val_loss: 0.1540 - val_acc: 0.9906\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1546 - acc: 0.9924 - val_loss: 0.1541 - val_acc: 0.9902\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1506 - acc: 0.9926 - val_loss: 0.1551 - val_acc: 0.9905\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1532 - acc: 0.9924 - val_loss: 0.1578 - val_acc: 0.9903\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1561 - acc: 0.9925 - val_loss: 0.1585 - val_acc: 0.9906\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1570 - acc: 0.9929 - val_loss: 0.1563 - val_acc: 0.9908\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1564 - acc: 0.9929 - val_loss: 0.1681 - val_acc: 0.9909\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1702 - acc: 0.9929 - val_loss: 0.1691 - val_acc: 0.9910\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1657 - acc: 0.9929 - val_loss: 0.1602 - val_acc: 0.9908\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1583 - acc: 0.9929 - val_loss: 0.1587 - val_acc: 0.9910\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1530 - acc: 0.9927 - val_loss: 0.1549 - val_acc: 0.9908\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1533 - acc: 0.9924 - val_loss: 0.1569 - val_acc: 0.9907\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1577 - acc: 0.9923 - val_loss: 0.1558 - val_acc: 0.9908\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1539 - acc: 0.9927 - val_loss: 0.1615 - val_acc: 0.9907\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9630 - val_loss: 0.0029 - val_acc: 0.9655\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9577 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9603 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0031 - val_acc: 0.9601\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9596 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9590 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0030 - val_acc: 0.9640\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0035 - val_acc: 0.9545\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9562 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9603 - val_loss: 0.0029 - val_acc: 0.9653\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9616 - val_loss: 0.0033 - val_acc: 0.9532\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0029 - acc: 0.9623 - val_loss: 0.0031 - val_acc: 0.9650\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9608 - val_loss: 0.0031 - val_acc: 0.9636\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9593 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9598 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0032 - val_acc: 0.9615\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9636 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9611 - val_loss: 0.0030 - val_acc: 0.9628\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9618 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9629 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9610 - val_loss: 0.0029 - val_acc: 0.9644\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0031 - val_acc: 0.9639\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9627 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9627 - val_loss: 0.0032 - val_acc: 0.9612\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9588 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9607 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0027 - acc: 0.9635 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0027 - acc: 0.9631 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9614 - val_loss: 0.0032 - val_acc: 0.9606\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9611 - val_loss: 0.0031 - val_acc: 0.9634\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9606 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9614 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9612 - val_loss: 0.0030 - val_acc: 0.9631\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0029 - val_acc: 0.9654\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9657\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9621\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9586 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0029 - val_acc: 0.9662\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9635 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "start training round 45\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2166 - acc: 0.6959 - val_loss: 0.2309 - val_acc: 0.6937\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2174 - acc: 0.6959 - val_loss: 0.2336 - val_acc: 0.6902\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2153 - acc: 0.6956 - val_loss: 0.2328 - val_acc: 0.6880\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2167 - acc: 0.6947 - val_loss: 0.2316 - val_acc: 0.6914\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2177 - acc: 0.6946 - val_loss: 0.2353 - val_acc: 0.6913\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2187 - acc: 0.6944 - val_loss: 0.2294 - val_acc: 0.6925\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2140 - acc: 0.6963 - val_loss: 0.2282 - val_acc: 0.6933\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2159 - acc: 0.6967 - val_loss: 0.2322 - val_acc: 0.6908\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2142 - acc: 0.6963 - val_loss: 0.2298 - val_acc: 0.6918\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2150 - acc: 0.6962 - val_loss: 0.2302 - val_acc: 0.6936\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2177 - acc: 0.6959 - val_loss: 0.2355 - val_acc: 0.6932\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2140 - acc: 0.6967 - val_loss: 0.2270 - val_acc: 0.6937\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2164 - acc: 0.6960 - val_loss: 0.2397 - val_acc: 0.6908\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2200 - acc: 0.6956 - val_loss: 0.2275 - val_acc: 0.6935\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2138 - acc: 0.6972 - val_loss: 0.2261 - val_acc: 0.6934\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2163 - acc: 0.6961 - val_loss: 0.2333 - val_acc: 0.6909\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2182 - acc: 0.6941 - val_loss: 0.2392 - val_acc: 0.6888\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2174 - acc: 0.6948 - val_loss: 0.2366 - val_acc: 0.6903\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2187 - acc: 0.6949 - val_loss: 0.2300 - val_acc: 0.6941\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2168 - acc: 0.6961 - val_loss: 0.2381 - val_acc: 0.6928\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2192 - acc: 0.6961 - val_loss: 0.2261 - val_acc: 0.6936\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2164 - acc: 0.6951 - val_loss: 0.2285 - val_acc: 0.6914\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2159 - acc: 0.6950 - val_loss: 0.2276 - val_acc: 0.6931\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2168 - acc: 0.6946 - val_loss: 0.2276 - val_acc: 0.6933\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2177 - acc: 0.6948 - val_loss: 0.2359 - val_acc: 0.6902\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2175 - acc: 0.6950 - val_loss: 0.2261 - val_acc: 0.6944\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2165 - acc: 0.6961 - val_loss: 0.2333 - val_acc: 0.6906\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2172 - acc: 0.6952 - val_loss: 0.2308 - val_acc: 0.6940\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2145 - acc: 0.6968 - val_loss: 0.2286 - val_acc: 0.6928\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2135 - acc: 0.6970 - val_loss: 0.2320 - val_acc: 0.6912\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2179 - acc: 0.6950 - val_loss: 0.2348 - val_acc: 0.6913\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2162 - acc: 0.6958 - val_loss: 0.2277 - val_acc: 0.6944\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2168 - acc: 0.6964 - val_loss: 0.2270 - val_acc: 0.6935\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2130 - acc: 0.6975 - val_loss: 0.2309 - val_acc: 0.6942\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2184 - acc: 0.6962 - val_loss: 0.2287 - val_acc: 0.6931\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2158 - acc: 0.6965 - val_loss: 0.2292 - val_acc: 0.6929\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2139 - acc: 0.6964 - val_loss: 0.2306 - val_acc: 0.6924\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2159 - acc: 0.6959 - val_loss: 0.2296 - val_acc: 0.6933\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2178 - acc: 0.6948 - val_loss: 0.2310 - val_acc: 0.6920\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2205 - acc: 0.6942 - val_loss: 0.2297 - val_acc: 0.6918\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2144 - acc: 0.6959 - val_loss: 0.2315 - val_acc: 0.6898\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2172 - acc: 0.6944 - val_loss: 0.2295 - val_acc: 0.6924\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2185 - acc: 0.6953 - val_loss: 0.2304 - val_acc: 0.6929\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2139 - acc: 0.6968 - val_loss: 0.2305 - val_acc: 0.6917\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2182 - acc: 0.6964 - val_loss: 0.2340 - val_acc: 0.6918\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2150 - acc: 0.6967 - val_loss: 0.2284 - val_acc: 0.6946\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2149 - acc: 0.6967 - val_loss: 0.2302 - val_acc: 0.6915\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2143 - acc: 0.6959 - val_loss: 0.2287 - val_acc: 0.6924\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2184 - acc: 0.6957 - val_loss: 0.2297 - val_acc: 0.6920\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2190 - acc: 0.6932 - val_loss: 0.2290 - val_acc: 0.6926\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9106 - acc: 0.6821 - val_loss: 2.0995 - val_acc: 0.6819\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9570 - acc: 0.6816 - val_loss: 2.0441 - val_acc: 0.6801\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9100 - acc: 0.6835 - val_loss: 2.0417 - val_acc: 0.6800\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8955 - acc: 0.6836 - val_loss: 2.1002 - val_acc: 0.6775\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9264 - acc: 0.6827 - val_loss: 2.0233 - val_acc: 0.6822\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.8733 - acc: 0.6839 - val_loss: 2.0451 - val_acc: 0.6817\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9157 - acc: 0.6821 - val_loss: 2.0403 - val_acc: 0.6811\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8919 - acc: 0.6827 - val_loss: 2.0657 - val_acc: 0.6787\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9251 - acc: 0.6825 - val_loss: 2.0971 - val_acc: 0.6785\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9214 - acc: 0.6826 - val_loss: 2.0659 - val_acc: 0.6799\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9067 - acc: 0.6830 - val_loss: 2.0515 - val_acc: 0.6798\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9396 - acc: 0.6817 - val_loss: 2.1076 - val_acc: 0.6768\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9221 - acc: 0.6827 - val_loss: 2.0704 - val_acc: 0.6771\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9149 - acc: 0.6815 - val_loss: 2.0625 - val_acc: 0.6803\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9330 - acc: 0.6828 - val_loss: 2.0734 - val_acc: 0.6826\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9035 - acc: 0.6830 - val_loss: 2.0898 - val_acc: 0.6776\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9101 - acc: 0.6823 - val_loss: 2.0885 - val_acc: 0.6777\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9034 - acc: 0.6835 - val_loss: 2.0535 - val_acc: 0.6800\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9009 - acc: 0.6837 - val_loss: 2.0890 - val_acc: 0.6776\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8994 - acc: 0.6830 - val_loss: 2.0876 - val_acc: 0.6779\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8877 - acc: 0.6834 - val_loss: 2.0581 - val_acc: 0.6801\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8842 - acc: 0.6832 - val_loss: 2.0608 - val_acc: 0.6818\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9100 - acc: 0.6815 - val_loss: 2.0434 - val_acc: 0.6792\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8876 - acc: 0.6828 - val_loss: 2.0569 - val_acc: 0.6800\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9423 - acc: 0.6824 - val_loss: 2.0377 - val_acc: 0.6820\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9147 - acc: 0.6820 - val_loss: 2.0377 - val_acc: 0.6801\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9114 - acc: 0.6829 - val_loss: 2.1523 - val_acc: 0.6800\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9212 - acc: 0.6829 - val_loss: 2.0416 - val_acc: 0.6821\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9001 - acc: 0.6839 - val_loss: 2.1514 - val_acc: 0.6805\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9066 - acc: 0.6824 - val_loss: 2.0534 - val_acc: 0.6801\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9089 - acc: 0.6830 - val_loss: 2.0660 - val_acc: 0.6821\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9487 - acc: 0.6829 - val_loss: 2.0755 - val_acc: 0.6791\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9133 - acc: 0.6827 - val_loss: 2.0272 - val_acc: 0.6818\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9065 - acc: 0.6825 - val_loss: 2.0477 - val_acc: 0.6801\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8969 - acc: 0.6831 - val_loss: 2.0644 - val_acc: 0.6787\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9023 - acc: 0.6823 - val_loss: 2.0663 - val_acc: 0.6789\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9138 - acc: 0.6832 - val_loss: 2.0457 - val_acc: 0.6789\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8924 - acc: 0.6834 - val_loss: 2.0167 - val_acc: 0.6799\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9068 - acc: 0.6830 - val_loss: 2.0345 - val_acc: 0.6789\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9139 - acc: 0.6830 - val_loss: 2.0472 - val_acc: 0.6789\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9014 - acc: 0.6834 - val_loss: 2.1134 - val_acc: 0.6786\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9164 - acc: 0.6818 - val_loss: 2.0391 - val_acc: 0.6788\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9121 - acc: 0.6826 - val_loss: 2.1006 - val_acc: 0.6768\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9236 - acc: 0.6828 - val_loss: 2.0224 - val_acc: 0.6811\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8920 - acc: 0.6835 - val_loss: 2.1016 - val_acc: 0.6801\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9394 - acc: 0.6827 - val_loss: 2.1145 - val_acc: 0.6787\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9426 - acc: 0.6829 - val_loss: 2.0237 - val_acc: 0.6814\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8872 - acc: 0.6832 - val_loss: 2.0490 - val_acc: 0.6812\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9100 - acc: 0.6827 - val_loss: 2.0231 - val_acc: 0.6813\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8994 - acc: 0.6828 - val_loss: 2.0297 - val_acc: 0.6820\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1580 - acc: 0.9927 - val_loss: 0.1526 - val_acc: 0.9909\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1523 - acc: 0.9927 - val_loss: 0.1578 - val_acc: 0.9908\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1616 - acc: 0.9923 - val_loss: 0.1605 - val_acc: 0.9909\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1575 - acc: 0.9928 - val_loss: 0.1576 - val_acc: 0.9908\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1568 - acc: 0.9929 - val_loss: 0.1680 - val_acc: 0.9908\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1675 - acc: 0.9929 - val_loss: 0.1711 - val_acc: 0.9909\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1602 - acc: 0.9926 - val_loss: 0.1507 - val_acc: 0.9907\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1512 - acc: 0.9929 - val_loss: 0.1551 - val_acc: 0.9909\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1536 - acc: 0.9923 - val_loss: 0.1571 - val_acc: 0.9907\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1537 - acc: 0.9924 - val_loss: 0.1592 - val_acc: 0.9908\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1559 - acc: 0.9925 - val_loss: 0.1551 - val_acc: 0.9909\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1496 - acc: 0.9927 - val_loss: 0.1503 - val_acc: 0.9909\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1546 - acc: 0.9924 - val_loss: 0.1670 - val_acc: 0.9897\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1686 - acc: 0.9917 - val_loss: 0.1596 - val_acc: 0.9904\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1589 - acc: 0.9929 - val_loss: 0.1735 - val_acc: 0.9909\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1661 - acc: 0.9929 - val_loss: 0.1633 - val_acc: 0.9909\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1617 - acc: 0.9928 - val_loss: 0.1624 - val_acc: 0.9907\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1564 - acc: 0.9925 - val_loss: 0.1651 - val_acc: 0.9901\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1593 - acc: 0.9924 - val_loss: 0.1542 - val_acc: 0.9906\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1544 - acc: 0.9927 - val_loss: 0.1624 - val_acc: 0.9906\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1618 - acc: 0.9927 - val_loss: 0.1606 - val_acc: 0.9908\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1538 - acc: 0.9929 - val_loss: 0.1513 - val_acc: 0.9910\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1528 - acc: 0.9927 - val_loss: 0.1560 - val_acc: 0.9910\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1533 - acc: 0.9929 - val_loss: 0.1617 - val_acc: 0.9909\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1581 - acc: 0.9929 - val_loss: 0.1618 - val_acc: 0.9908\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1655 - acc: 0.9929 - val_loss: 0.1729 - val_acc: 0.9906\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1645 - acc: 0.9928 - val_loss: 0.1611 - val_acc: 0.9907\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1584 - acc: 0.9928 - val_loss: 0.1633 - val_acc: 0.9903\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1596 - acc: 0.9926 - val_loss: 0.1575 - val_acc: 0.9906\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1543 - acc: 0.9928 - val_loss: 0.1554 - val_acc: 0.9907\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1520 - acc: 0.9928 - val_loss: 0.1503 - val_acc: 0.9908\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1515 - acc: 0.9929 - val_loss: 0.1540 - val_acc: 0.9908\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1524 - acc: 0.9928 - val_loss: 0.1566 - val_acc: 0.9904\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1564 - acc: 0.9926 - val_loss: 0.1714 - val_acc: 0.9899\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1668 - acc: 0.9922 - val_loss: 0.1671 - val_acc: 0.9903\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1610 - acc: 0.9924 - val_loss: 0.1642 - val_acc: 0.9900\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1588 - acc: 0.9920 - val_loss: 0.1595 - val_acc: 0.9902\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1545 - acc: 0.9925 - val_loss: 0.1536 - val_acc: 0.9906\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1499 - acc: 0.9929 - val_loss: 0.1548 - val_acc: 0.9906\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1608 - acc: 0.9929 - val_loss: 0.1710 - val_acc: 0.9908\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1642 - acc: 0.9928 - val_loss: 0.1758 - val_acc: 0.9904\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1637 - acc: 0.9925 - val_loss: 0.1595 - val_acc: 0.9909\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1548 - acc: 0.9927 - val_loss: 0.1602 - val_acc: 0.9904\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1540 - acc: 0.9926 - val_loss: 0.1583 - val_acc: 0.9910\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1530 - acc: 0.9927 - val_loss: 0.1565 - val_acc: 0.9909\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1562 - acc: 0.9924 - val_loss: 0.1591 - val_acc: 0.9904\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1613 - acc: 0.9924 - val_loss: 0.1593 - val_acc: 0.9908\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1599 - acc: 0.9927 - val_loss: 0.1567 - val_acc: 0.9907\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1537 - acc: 0.9926 - val_loss: 0.1630 - val_acc: 0.9909\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1593 - acc: 0.9928 - val_loss: 0.1575 - val_acc: 0.9910\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9592 - val_loss: 0.0031 - val_acc: 0.9618\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9599 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9612 - val_loss: 0.0031 - val_acc: 0.9624\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9591 - val_loss: 0.0031 - val_acc: 0.9603\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9628 - val_loss: 0.0029 - val_acc: 0.9653\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0031 - val_acc: 0.9623\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9596 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0030 - val_acc: 0.9631\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9611 - val_loss: 0.0031 - val_acc: 0.9647\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9616 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0030 - acc: 0.9586 - val_loss: 0.0029 - val_acc: 0.9669\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9638 - val_loss: 0.0029 - val_acc: 0.9658\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9608 - val_loss: 0.0030 - val_acc: 0.9629\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9585 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9635 - val_loss: 0.0029 - val_acc: 0.9650\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9610 - val_loss: 0.0030 - val_acc: 0.9661\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9606 - val_loss: 0.0032 - val_acc: 0.9571\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9577 - val_loss: 0.0030 - val_acc: 0.9635\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0029 - val_acc: 0.9655\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9614 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0032 - val_acc: 0.9620\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0029 - acc: 0.9599 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0029 - acc: 0.9598 - val_loss: 0.0030 - val_acc: 0.9661\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9610 - val_loss: 0.0029 - val_acc: 0.9648\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9600 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9662\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9603 - val_loss: 0.0029 - val_acc: 0.9657\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9630 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0030 - val_acc: 0.9638\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0031 - val_acc: 0.9633\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9611 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9612\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9593 - val_loss: 0.0029 - val_acc: 0.9648\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0027 - acc: 0.9637 - val_loss: 0.0029 - val_acc: 0.9651\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9623 - val_loss: 0.0029 - val_acc: 0.9662\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0027 - acc: 0.9638 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9627 - val_loss: 0.0031 - val_acc: 0.9628\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0031 - acc: 0.9577 - val_loss: 0.0031 - val_acc: 0.9614\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9591 - val_loss: 0.0030 - val_acc: 0.9650\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9627 - val_loss: 0.0030 - val_acc: 0.9632\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0029 - acc: 0.9568 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0030 - val_acc: 0.9646\n",
      "start training round 46\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2153 - acc: 0.6965 - val_loss: 0.2337 - val_acc: 0.6924\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2172 - acc: 0.6971 - val_loss: 0.2287 - val_acc: 0.6922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2214 - acc: 0.6931 - val_loss: 0.2328 - val_acc: 0.6923\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2167 - acc: 0.6963 - val_loss: 0.2288 - val_acc: 0.6940\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2137 - acc: 0.6971 - val_loss: 0.2280 - val_acc: 0.6920\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2149 - acc: 0.6960 - val_loss: 0.2288 - val_acc: 0.6915\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2169 - acc: 0.6944 - val_loss: 0.2342 - val_acc: 0.6896\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2190 - acc: 0.6937 - val_loss: 0.2324 - val_acc: 0.6917\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2155 - acc: 0.6962 - val_loss: 0.2281 - val_acc: 0.6935\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2172 - acc: 0.6964 - val_loss: 0.2290 - val_acc: 0.6944\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2137 - acc: 0.6976 - val_loss: 0.2309 - val_acc: 0.6931\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2173 - acc: 0.6961 - val_loss: 0.2278 - val_acc: 0.6926\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2148 - acc: 0.6963 - val_loss: 0.2263 - val_acc: 0.6938\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2145 - acc: 0.6968 - val_loss: 0.2340 - val_acc: 0.6919\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2176 - acc: 0.6956 - val_loss: 0.2266 - val_acc: 0.6939\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2151 - acc: 0.6957 - val_loss: 0.2394 - val_acc: 0.6889\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2182 - acc: 0.6943 - val_loss: 0.2295 - val_acc: 0.6941\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2170 - acc: 0.6958 - val_loss: 0.2287 - val_acc: 0.6922\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2162 - acc: 0.6949 - val_loss: 0.2265 - val_acc: 0.6933\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2144 - acc: 0.6966 - val_loss: 0.2274 - val_acc: 0.6938\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2187 - acc: 0.6964 - val_loss: 0.2280 - val_acc: 0.6940\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2162 - acc: 0.6968 - val_loss: 0.2303 - val_acc: 0.6940\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2161 - acc: 0.6961 - val_loss: 0.2290 - val_acc: 0.6923\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2153 - acc: 0.6954 - val_loss: 0.2287 - val_acc: 0.6920\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2132 - acc: 0.6976 - val_loss: 0.2277 - val_acc: 0.6936\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2139 - acc: 0.6971 - val_loss: 0.2287 - val_acc: 0.6937\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2139 - acc: 0.6964 - val_loss: 0.2315 - val_acc: 0.6896\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2152 - acc: 0.6954 - val_loss: 0.2314 - val_acc: 0.6916\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2164 - acc: 0.6952 - val_loss: 0.2275 - val_acc: 0.6938\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2176 - acc: 0.6947 - val_loss: 0.2271 - val_acc: 0.6941\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2159 - acc: 0.6972 - val_loss: 0.2306 - val_acc: 0.6935\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2181 - acc: 0.6962 - val_loss: 0.2264 - val_acc: 0.6939\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2126 - acc: 0.6974 - val_loss: 0.2345 - val_acc: 0.6908\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2180 - acc: 0.6945 - val_loss: 0.2267 - val_acc: 0.6931\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2151 - acc: 0.6972 - val_loss: 0.2286 - val_acc: 0.6932\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2123 - acc: 0.6978 - val_loss: 0.2260 - val_acc: 0.6933\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2179 - acc: 0.6941 - val_loss: 0.2270 - val_acc: 0.6918\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2145 - acc: 0.6967 - val_loss: 0.2286 - val_acc: 0.6930\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2132 - acc: 0.6967 - val_loss: 0.2279 - val_acc: 0.6917\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2145 - acc: 0.6961 - val_loss: 0.2323 - val_acc: 0.6917\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2162 - acc: 0.6953 - val_loss: 0.2321 - val_acc: 0.6921\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2170 - acc: 0.6968 - val_loss: 0.2264 - val_acc: 0.6937\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2157 - acc: 0.6966 - val_loss: 0.2337 - val_acc: 0.6919\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2177 - acc: 0.6950 - val_loss: 0.2301 - val_acc: 0.6906\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2141 - acc: 0.6968 - val_loss: 0.2295 - val_acc: 0.6929\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2147 - acc: 0.6963 - val_loss: 0.2274 - val_acc: 0.6922\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2155 - acc: 0.6969 - val_loss: 0.2382 - val_acc: 0.6933\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2210 - acc: 0.6960 - val_loss: 0.2308 - val_acc: 0.6921\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2163 - acc: 0.6954 - val_loss: 0.2464 - val_acc: 0.6840\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2178 - acc: 0.6946 - val_loss: 0.2283 - val_acc: 0.6931\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9132 - acc: 0.6818 - val_loss: 2.1006 - val_acc: 0.6790\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9270 - acc: 0.6824 - val_loss: 2.0789 - val_acc: 0.6791\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8938 - acc: 0.6826 - val_loss: 2.0917 - val_acc: 0.6772\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9162 - acc: 0.6824 - val_loss: 2.0514 - val_acc: 0.6815\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9065 - acc: 0.6835 - val_loss: 2.0967 - val_acc: 0.6827\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9039 - acc: 0.6824 - val_loss: 2.0800 - val_acc: 0.6792\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9184 - acc: 0.6825 - val_loss: 2.0279 - val_acc: 0.6802\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9060 - acc: 0.6830 - val_loss: 2.0540 - val_acc: 0.6781\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.8961 - acc: 0.6833 - val_loss: 2.0761 - val_acc: 0.6788\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9044 - acc: 0.6830 - val_loss: 2.0478 - val_acc: 0.6824\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8930 - acc: 0.6835 - val_loss: 2.0314 - val_acc: 0.6809\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9222 - acc: 0.6823 - val_loss: 2.0466 - val_acc: 0.6798\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8920 - acc: 0.6824 - val_loss: 2.0738 - val_acc: 0.6775\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 1.9178 - acc: 0.6822 - val_loss: 2.0337 - val_acc: 0.6791\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9179 - acc: 0.6825 - val_loss: 2.1092 - val_acc: 0.6794\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9257 - acc: 0.6829 - val_loss: 2.0507 - val_acc: 0.6801\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 1.9223 - acc: 0.6830 - val_loss: 2.0572 - val_acc: 0.6795\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 1.9182 - acc: 0.6830 - val_loss: 2.0922 - val_acc: 0.6768\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 1.8985 - acc: 0.6824 - val_loss: 2.0973 - val_acc: 0.6795\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9015 - acc: 0.6825 - val_loss: 2.1035 - val_acc: 0.6798\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9360 - acc: 0.6830 - val_loss: 2.0379 - val_acc: 0.6794\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9258 - acc: 0.6823 - val_loss: 2.0747 - val_acc: 0.6780\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9147 - acc: 0.6835 - val_loss: 2.0732 - val_acc: 0.6768\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9022 - acc: 0.6835 - val_loss: 2.0357 - val_acc: 0.6797\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9096 - acc: 0.6823 - val_loss: 2.0381 - val_acc: 0.6802\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9156 - acc: 0.6820 - val_loss: 2.0747 - val_acc: 0.6792\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9320 - acc: 0.6833 - val_loss: 2.2392 - val_acc: 0.6785\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9273 - acc: 0.6824 - val_loss: 2.0302 - val_acc: 0.6798\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9046 - acc: 0.6826 - val_loss: 2.0282 - val_acc: 0.6810\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9140 - acc: 0.6826 - val_loss: 2.0651 - val_acc: 0.6790\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9057 - acc: 0.6824 - val_loss: 2.0399 - val_acc: 0.6808\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8858 - acc: 0.6831 - val_loss: 2.0752 - val_acc: 0.6804\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9038 - acc: 0.6832 - val_loss: 2.0111 - val_acc: 0.6817\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8828 - acc: 0.6826 - val_loss: 2.0230 - val_acc: 0.6814\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8843 - acc: 0.6840 - val_loss: 2.0619 - val_acc: 0.6810\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9232 - acc: 0.6834 - val_loss: 2.1057 - val_acc: 0.6800\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9072 - acc: 0.6827 - val_loss: 2.0356 - val_acc: 0.6790\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8784 - acc: 0.6833 - val_loss: 2.0758 - val_acc: 0.6829\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9354 - acc: 0.6826 - val_loss: 2.0273 - val_acc: 0.6820\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8979 - acc: 0.6833 - val_loss: 2.0984 - val_acc: 0.6811\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9376 - acc: 0.6832 - val_loss: 2.0421 - val_acc: 0.6807\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8926 - acc: 0.6833 - val_loss: 2.0571 - val_acc: 0.6809\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9367 - acc: 0.6822 - val_loss: 2.0350 - val_acc: 0.6805\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8816 - acc: 0.6840 - val_loss: 2.0900 - val_acc: 0.6786\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9209 - acc: 0.6832 - val_loss: 2.0163 - val_acc: 0.6811\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9142 - acc: 0.6828 - val_loss: 2.0912 - val_acc: 0.6800\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9299 - acc: 0.6824 - val_loss: 2.0173 - val_acc: 0.6820\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8795 - acc: 0.6837 - val_loss: 2.0757 - val_acc: 0.6811\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9164 - acc: 0.6814 - val_loss: 2.0927 - val_acc: 0.6764\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9002 - acc: 0.6831 - val_loss: 2.0598 - val_acc: 0.6787\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1552 - acc: 0.9928 - val_loss: 0.1616 - val_acc: 0.9909\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1661 - acc: 0.9929 - val_loss: 0.1726 - val_acc: 0.9910\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1607 - acc: 0.9929 - val_loss: 0.1663 - val_acc: 0.9907\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1559 - acc: 0.9926 - val_loss: 0.1567 - val_acc: 0.9905\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1565 - acc: 0.9925 - val_loss: 0.1642 - val_acc: 0.9907\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1582 - acc: 0.9927 - val_loss: 0.1592 - val_acc: 0.9907\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1599 - acc: 0.9925 - val_loss: 0.1567 - val_acc: 0.9907\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1535 - acc: 0.9927 - val_loss: 0.1576 - val_acc: 0.9905\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1579 - acc: 0.9922 - val_loss: 0.1598 - val_acc: 0.9907\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1507 - acc: 0.9927 - val_loss: 0.1556 - val_acc: 0.9909\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1574 - acc: 0.9925 - val_loss: 0.1594 - val_acc: 0.9907\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1662 - acc: 0.9921 - val_loss: 0.1727 - val_acc: 0.9898\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1645 - acc: 0.9917 - val_loss: 0.1624 - val_acc: 0.9906\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1609 - acc: 0.9924 - val_loss: 0.1587 - val_acc: 0.9909\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.1555 - acc: 0.9925 - val_loss: 0.1604 - val_acc: 0.9907\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1538 - acc: 0.9927 - val_loss: 0.1588 - val_acc: 0.9907\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1582 - acc: 0.9923 - val_loss: 0.1533 - val_acc: 0.9909\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1503 - acc: 0.9930 - val_loss: 0.1554 - val_acc: 0.9910\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1620 - acc: 0.9929 - val_loss: 0.1661 - val_acc: 0.9908\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1595 - acc: 0.9928 - val_loss: 0.1575 - val_acc: 0.9907\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1607 - acc: 0.9927 - val_loss: 0.1603 - val_acc: 0.9908\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1512 - acc: 0.9929 - val_loss: 0.1516 - val_acc: 0.9906\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1492 - acc: 0.9927 - val_loss: 0.1559 - val_acc: 0.9904\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1602 - acc: 0.9917 - val_loss: 0.1659 - val_acc: 0.9896\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1586 - acc: 0.9923 - val_loss: 0.1541 - val_acc: 0.9904\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1536 - acc: 0.9927 - val_loss: 0.1569 - val_acc: 0.9906\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1591 - acc: 0.9928 - val_loss: 0.1651 - val_acc: 0.9906\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1646 - acc: 0.9928 - val_loss: 0.1640 - val_acc: 0.9907\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1638 - acc: 0.9928 - val_loss: 0.1611 - val_acc: 0.9908\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1573 - acc: 0.9928 - val_loss: 0.1569 - val_acc: 0.9906\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1596 - acc: 0.9921 - val_loss: 0.1558 - val_acc: 0.9908\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1532 - acc: 0.9927 - val_loss: 0.1555 - val_acc: 0.9909\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1590 - acc: 0.9928 - val_loss: 0.1617 - val_acc: 0.9908\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1579 - acc: 0.9929 - val_loss: 0.1654 - val_acc: 0.9903\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1600 - acc: 0.9926 - val_loss: 0.1558 - val_acc: 0.9903\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1545 - acc: 0.9922 - val_loss: 0.1538 - val_acc: 0.9902\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1492 - acc: 0.9925 - val_loss: 0.1528 - val_acc: 0.9904\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1589 - acc: 0.9919 - val_loss: 0.1609 - val_acc: 0.9907\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1501 - acc: 0.9928 - val_loss: 0.1523 - val_acc: 0.9905\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1570 - acc: 0.9927 - val_loss: 0.1531 - val_acc: 0.9906\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1502 - acc: 0.9929 - val_loss: 0.1555 - val_acc: 0.9908\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1681 - acc: 0.9927 - val_loss: 0.1720 - val_acc: 0.9904\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.1618 - acc: 0.9929 - val_loss: 0.1548 - val_acc: 0.9908\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1597 - acc: 0.9929 - val_loss: 0.1584 - val_acc: 0.9908\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1555 - acc: 0.9929 - val_loss: 0.1540 - val_acc: 0.9908\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1558 - acc: 0.9929 - val_loss: 0.1592 - val_acc: 0.9908\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1558 - acc: 0.9929 - val_loss: 0.1601 - val_acc: 0.9909\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1529 - acc: 0.9929 - val_loss: 0.1486 - val_acc: 0.9910\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1504 - acc: 0.9927 - val_loss: 0.1578 - val_acc: 0.9906\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1600 - acc: 0.9921 - val_loss: 0.1686 - val_acc: 0.9897\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9598 - val_loss: 0.0034 - val_acc: 0.9552\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9582 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9624 - val_loss: 0.0031 - val_acc: 0.9601\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0030 - acc: 0.9563 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9637 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0031 - val_acc: 0.9631\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9595 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9635 - val_loss: 0.0030 - val_acc: 0.9653\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9631 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0030 - val_acc: 0.9626\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9590 - val_loss: 0.0029 - val_acc: 0.9651\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0029 - val_acc: 0.9653\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0027 - acc: 0.9635 - val_loss: 0.0029 - val_acc: 0.9649\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9594 - val_loss: 0.0031 - val_acc: 0.9620\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9586 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9655\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9618 - val_loss: 0.0031 - val_acc: 0.9616\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0032 - val_acc: 0.9612\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9564 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9607 - val_loss: 0.0031 - val_acc: 0.9619\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9608 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9667\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9632 - val_loss: 0.0030 - val_acc: 0.9662\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9636 - val_loss: 0.0030 - val_acc: 0.9658\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9634 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9630 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9608 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9610 - val_loss: 0.0042 - val_acc: 0.9436\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0029 - acc: 0.9564 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9638 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9609 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9611 - val_loss: 0.0029 - val_acc: 0.9668\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9609 - val_loss: 0.0029 - val_acc: 0.9657\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9600 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0027 - acc: 0.9627 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9610 - val_loss: 0.0031 - val_acc: 0.9609\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.0028 - acc: 0.9620 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0030 - val_acc: 0.9633\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.0031 - acc: 0.9558 - val_loss: 0.0029 - val_acc: 0.9654\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0029 - val_acc: 0.9652\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0029 - val_acc: 0.9654\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9627 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "start training round 47\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 220us/step - loss: 0.2145 - acc: 0.6964 - val_loss: 0.2296 - val_acc: 0.6913\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2160 - acc: 0.6955 - val_loss: 0.2276 - val_acc: 0.6926\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2126 - acc: 0.6974 - val_loss: 0.2322 - val_acc: 0.6936\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2176 - acc: 0.6959 - val_loss: 0.2301 - val_acc: 0.6920\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2141 - acc: 0.6964 - val_loss: 0.2255 - val_acc: 0.6942\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2130 - acc: 0.6969 - val_loss: 0.2313 - val_acc: 0.6923\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2147 - acc: 0.6970 - val_loss: 0.2301 - val_acc: 0.6938\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2176 - acc: 0.6970 - val_loss: 0.2305 - val_acc: 0.6941\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.2169 - acc: 0.6971 - val_loss: 0.2298 - val_acc: 0.6931\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2144 - acc: 0.6968 - val_loss: 0.2303 - val_acc: 0.6919\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2144 - acc: 0.6967 - val_loss: 0.2264 - val_acc: 0.6938\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2143 - acc: 0.6961 - val_loss: 0.2349 - val_acc: 0.6902\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2181 - acc: 0.6953 - val_loss: 0.2297 - val_acc: 0.6923\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2144 - acc: 0.6960 - val_loss: 0.2282 - val_acc: 0.6926\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2158 - acc: 0.6953 - val_loss: 0.2288 - val_acc: 0.6922\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.2142 - acc: 0.6964 - val_loss: 0.2261 - val_acc: 0.6944\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2169 - acc: 0.6960 - val_loss: 0.2287 - val_acc: 0.6926\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2146 - acc: 0.6959 - val_loss: 0.2298 - val_acc: 0.6922\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2168 - acc: 0.6959 - val_loss: 0.2289 - val_acc: 0.6937\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2170 - acc: 0.6965 - val_loss: 0.2393 - val_acc: 0.6929\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2201 - acc: 0.6960 - val_loss: 0.2268 - val_acc: 0.6938\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2149 - acc: 0.6957 - val_loss: 0.2257 - val_acc: 0.6938\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2124 - acc: 0.6973 - val_loss: 0.2306 - val_acc: 0.6918\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2165 - acc: 0.6960 - val_loss: 0.2266 - val_acc: 0.6942\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2132 - acc: 0.6970 - val_loss: 0.2316 - val_acc: 0.6925\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2145 - acc: 0.6964 - val_loss: 0.2285 - val_acc: 0.6926\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 242us/step - loss: 0.2162 - acc: 0.6953 - val_loss: 0.2334 - val_acc: 0.6896\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2143 - acc: 0.6962 - val_loss: 0.2308 - val_acc: 0.6920\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2163 - acc: 0.6963 - val_loss: 0.2330 - val_acc: 0.6924\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2164 - acc: 0.6960 - val_loss: 0.2283 - val_acc: 0.6932\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2150 - acc: 0.6965 - val_loss: 0.2342 - val_acc: 0.6911\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2171 - acc: 0.6964 - val_loss: 0.2264 - val_acc: 0.6939\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2127 - acc: 0.6978 - val_loss: 0.2267 - val_acc: 0.6942\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2151 - acc: 0.6977 - val_loss: 0.2287 - val_acc: 0.6944\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2141 - acc: 0.6974 - val_loss: 0.2286 - val_acc: 0.6944\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2161 - acc: 0.6965 - val_loss: 0.2261 - val_acc: 0.6950\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2137 - acc: 0.6975 - val_loss: 0.2294 - val_acc: 0.6940\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2157 - acc: 0.6973 - val_loss: 0.2284 - val_acc: 0.6925\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2144 - acc: 0.6965 - val_loss: 0.2308 - val_acc: 0.6933\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2155 - acc: 0.6960 - val_loss: 0.2346 - val_acc: 0.6905\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2196 - acc: 0.6937 - val_loss: 0.2269 - val_acc: 0.6932\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2113 - acc: 0.6978 - val_loss: 0.2271 - val_acc: 0.6939\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2159 - acc: 0.6967 - val_loss: 0.2323 - val_acc: 0.6927\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2130 - acc: 0.6974 - val_loss: 0.2255 - val_acc: 0.6941\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2151 - acc: 0.6969 - val_loss: 0.2349 - val_acc: 0.6917\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2167 - acc: 0.6960 - val_loss: 0.2271 - val_acc: 0.6941\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2121 - acc: 0.6976 - val_loss: 0.2315 - val_acc: 0.6939\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2149 - acc: 0.6961 - val_loss: 0.2280 - val_acc: 0.6925\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2128 - acc: 0.6973 - val_loss: 0.2275 - val_acc: 0.6932\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2188 - acc: 0.6958 - val_loss: 0.2298 - val_acc: 0.6913\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8827 - acc: 0.6839 - val_loss: 2.0434 - val_acc: 0.6789\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9039 - acc: 0.6833 - val_loss: 2.0355 - val_acc: 0.6804\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9193 - acc: 0.6830 - val_loss: 2.0830 - val_acc: 0.6775\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9069 - acc: 0.6828 - val_loss: 2.0613 - val_acc: 0.6795\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9258 - acc: 0.6835 - val_loss: 2.0408 - val_acc: 0.6806\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9015 - acc: 0.6831 - val_loss: 2.0382 - val_acc: 0.6822\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9026 - acc: 0.6833 - val_loss: 2.1616 - val_acc: 0.6753\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9319 - acc: 0.6831 - val_loss: 2.0191 - val_acc: 0.6820\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9020 - acc: 0.6835 - val_loss: 2.0794 - val_acc: 0.6812\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.8946 - acc: 0.6831 - val_loss: 2.0444 - val_acc: 0.6803\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9225 - acc: 0.6829 - val_loss: 2.0404 - val_acc: 0.6807\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9074 - acc: 0.6823 - val_loss: 2.0564 - val_acc: 0.6780\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8984 - acc: 0.6827 - val_loss: 2.0750 - val_acc: 0.6802\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9098 - acc: 0.6836 - val_loss: 2.1613 - val_acc: 0.6795\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9071 - acc: 0.6831 - val_loss: 2.1208 - val_acc: 0.6807\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9133 - acc: 0.6828 - val_loss: 2.0516 - val_acc: 0.6798\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9201 - acc: 0.6825 - val_loss: 2.1023 - val_acc: 0.6774\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8974 - acc: 0.6838 - val_loss: 2.0958 - val_acc: 0.6777\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9168 - acc: 0.6835 - val_loss: 2.0453 - val_acc: 0.6797\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9051 - acc: 0.6838 - val_loss: 2.0650 - val_acc: 0.6785\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8980 - acc: 0.6836 - val_loss: 2.0724 - val_acc: 0.6798\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9219 - acc: 0.6822 - val_loss: 2.0468 - val_acc: 0.6790\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8843 - acc: 0.6836 - val_loss: 2.0386 - val_acc: 0.6796\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9144 - acc: 0.6826 - val_loss: 2.0355 - val_acc: 0.6801\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8893 - acc: 0.6825 - val_loss: 2.0437 - val_acc: 0.6800\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9150 - acc: 0.6833 - val_loss: 2.0232 - val_acc: 0.6804\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9003 - acc: 0.6831 - val_loss: 2.1326 - val_acc: 0.6767\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9269 - acc: 0.6831 - val_loss: 2.2832 - val_acc: 0.6789\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9116 - acc: 0.6837 - val_loss: 2.0178 - val_acc: 0.6816\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9084 - acc: 0.6828 - val_loss: 2.0272 - val_acc: 0.6822\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8870 - acc: 0.6831 - val_loss: 2.1385 - val_acc: 0.6779\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9400 - acc: 0.6820 - val_loss: 2.0972 - val_acc: 0.6805\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9274 - acc: 0.6834 - val_loss: 2.0161 - val_acc: 0.6825\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9106 - acc: 0.6827 - val_loss: 2.0108 - val_acc: 0.6807\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8797 - acc: 0.6835 - val_loss: 2.0365 - val_acc: 0.6795\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9044 - acc: 0.6834 - val_loss: 2.1171 - val_acc: 0.6773\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9183 - acc: 0.6831 - val_loss: 2.1053 - val_acc: 0.6766\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9122 - acc: 0.6827 - val_loss: 2.0342 - val_acc: 0.6803\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9155 - acc: 0.6832 - val_loss: 2.0331 - val_acc: 0.6804\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8982 - acc: 0.6841 - val_loss: 2.1787 - val_acc: 0.6802\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9120 - acc: 0.6835 - val_loss: 2.0797 - val_acc: 0.6836\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9293 - acc: 0.6829 - val_loss: 2.0385 - val_acc: 0.6822\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9097 - acc: 0.6831 - val_loss: 2.0787 - val_acc: 0.6793\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9218 - acc: 0.6823 - val_loss: 2.0590 - val_acc: 0.6780\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.8955 - acc: 0.6825 - val_loss: 2.0409 - val_acc: 0.6793\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9141 - acc: 0.6829 - val_loss: 2.0356 - val_acc: 0.6794\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9090 - acc: 0.6827 - val_loss: 2.0458 - val_acc: 0.6789\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9213 - acc: 0.6829 - val_loss: 2.0362 - val_acc: 0.6823\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8970 - acc: 0.6839 - val_loss: 2.0378 - val_acc: 0.6810\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8820 - acc: 0.6828 - val_loss: 2.0263 - val_acc: 0.6807\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1603 - acc: 0.9920 - val_loss: 0.1582 - val_acc: 0.9908\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1586 - acc: 0.9928 - val_loss: 0.1574 - val_acc: 0.9908\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1493 - acc: 0.9929 - val_loss: 0.1488 - val_acc: 0.9909\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1497 - acc: 0.9928 - val_loss: 0.1519 - val_acc: 0.9911\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1528 - acc: 0.9929 - val_loss: 0.1702 - val_acc: 0.9909\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1704 - acc: 0.9929 - val_loss: 0.1840 - val_acc: 0.9910\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1723 - acc: 0.9929 - val_loss: 0.1636 - val_acc: 0.9910\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1512 - acc: 0.9930 - val_loss: 0.1516 - val_acc: 0.9909\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1473 - acc: 0.9930 - val_loss: 0.1493 - val_acc: 0.9910\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1476 - acc: 0.9928 - val_loss: 0.1493 - val_acc: 0.9910\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1496 - acc: 0.9927 - val_loss: 0.1581 - val_acc: 0.9904\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1555 - acc: 0.9925 - val_loss: 0.1549 - val_acc: 0.9910\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1551 - acc: 0.9929 - val_loss: 0.1635 - val_acc: 0.9910\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1562 - acc: 0.9929 - val_loss: 0.1593 - val_acc: 0.9911\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1666 - acc: 0.9929 - val_loss: 0.1767 - val_acc: 0.9908\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1648 - acc: 0.9927 - val_loss: 0.1602 - val_acc: 0.9908\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1542 - acc: 0.9928 - val_loss: 0.1540 - val_acc: 0.9906\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1486 - acc: 0.9927 - val_loss: 0.1524 - val_acc: 0.9906\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1518 - acc: 0.9926 - val_loss: 0.1596 - val_acc: 0.9905\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1607 - acc: 0.9922 - val_loss: 0.1664 - val_acc: 0.9896\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1579 - acc: 0.9920 - val_loss: 0.1524 - val_acc: 0.9903\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1550 - acc: 0.9920 - val_loss: 0.1593 - val_acc: 0.9903\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1553 - acc: 0.9921 - val_loss: 0.1565 - val_acc: 0.9898\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1492 - acc: 0.9925 - val_loss: 0.1508 - val_acc: 0.9905\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1491 - acc: 0.9927 - val_loss: 0.1488 - val_acc: 0.9908\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1464 - acc: 0.9929 - val_loss: 0.1506 - val_acc: 0.9904\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1528 - acc: 0.9926 - val_loss: 0.1639 - val_acc: 0.9901\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1569 - acc: 0.9928 - val_loss: 0.1686 - val_acc: 0.9908\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1748 - acc: 0.9929 - val_loss: 0.1751 - val_acc: 0.9908\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1604 - acc: 0.9929 - val_loss: 0.1511 - val_acc: 0.9908\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1488 - acc: 0.9929 - val_loss: 0.1508 - val_acc: 0.9908\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1519 - acc: 0.9929 - val_loss: 0.1553 - val_acc: 0.9908\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1541 - acc: 0.9928 - val_loss: 0.1543 - val_acc: 0.9909\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1525 - acc: 0.9925 - val_loss: 0.1553 - val_acc: 0.9907\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1534 - acc: 0.9926 - val_loss: 0.1565 - val_acc: 0.9909\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1552 - acc: 0.9929 - val_loss: 0.1605 - val_acc: 0.9908\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1652 - acc: 0.9929 - val_loss: 0.1624 - val_acc: 0.9907\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1524 - acc: 0.9927 - val_loss: 0.1614 - val_acc: 0.9900\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1588 - acc: 0.9924 - val_loss: 0.1545 - val_acc: 0.9904\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1516 - acc: 0.9925 - val_loss: 0.1547 - val_acc: 0.9906\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1460 - acc: 0.9929 - val_loss: 0.1474 - val_acc: 0.9908\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1459 - acc: 0.9927 - val_loss: 0.1499 - val_acc: 0.9906\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1495 - acc: 0.9926 - val_loss: 0.1539 - val_acc: 0.9906\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1528 - acc: 0.9926 - val_loss: 0.1547 - val_acc: 0.9906\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1602 - acc: 0.9924 - val_loss: 0.1690 - val_acc: 0.9897\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1625 - acc: 0.9918 - val_loss: 0.1794 - val_acc: 0.9889\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1757 - acc: 0.9918 - val_loss: 0.1680 - val_acc: 0.9908\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1679 - acc: 0.9928 - val_loss: 0.1671 - val_acc: 0.9908\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1583 - acc: 0.9926 - val_loss: 0.1528 - val_acc: 0.9909\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1477 - acc: 0.9929 - val_loss: 0.1490 - val_acc: 0.9910\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9616 - val_loss: 0.0030 - val_acc: 0.9652\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0030 - val_acc: 0.9640\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9602 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9613 - val_loss: 0.0033 - val_acc: 0.9605\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0029 - val_acc: 0.9671\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9640 - val_loss: 0.0030 - val_acc: 0.9656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9589 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9631 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9641 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0027 - acc: 0.9636 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9626 - val_loss: 0.0030 - val_acc: 0.9664\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9576 - val_loss: 0.0029 - val_acc: 0.9655\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9637 - val_loss: 0.0029 - val_acc: 0.9651\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9624 - val_loss: 0.0029 - val_acc: 0.9651\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.0028 - acc: 0.9593 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9612 - val_loss: 0.0029 - val_acc: 0.9654\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9612 - val_loss: 0.0032 - val_acc: 0.9622\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0029 - val_acc: 0.9653\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0027 - acc: 0.9630 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 242us/step - loss: 0.0027 - acc: 0.9640 - val_loss: 0.0029 - val_acc: 0.9662\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 246us/step - loss: 0.0027 - acc: 0.9637 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 243us/step - loss: 0.0027 - acc: 0.9637 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0027 - acc: 0.9635 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 239us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0031 - val_acc: 0.9645\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9645\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 244us/step - loss: 0.0029 - acc: 0.9577 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0027 - acc: 0.9635 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 241us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9662\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0027 - acc: 0.9629 - val_loss: 0.0030 - val_acc: 0.9662\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0030 - acc: 0.9581 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0030 - val_acc: 0.9636\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0029 - val_acc: 0.9668\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9599 - val_loss: 0.0029 - val_acc: 0.9655\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0027 - acc: 0.9636 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9590 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9622 - val_loss: 0.0033 - val_acc: 0.9562\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9577 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0029 - acc: 0.9603 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9638 - val_loss: 0.0029 - val_acc: 0.9667\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9641 - val_loss: 0.0029 - val_acc: 0.9669\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0027 - acc: 0.9626 - val_loss: 0.0029 - val_acc: 0.9637\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9583 - val_loss: 0.0030 - val_acc: 0.9617\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9613 - val_loss: 0.0030 - val_acc: 0.9661\n",
      "start training round 48\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2142 - acc: 0.6976 - val_loss: 0.2307 - val_acc: 0.6935\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2124 - acc: 0.6977 - val_loss: 0.2267 - val_acc: 0.6932\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2117 - acc: 0.6982 - val_loss: 0.2263 - val_acc: 0.6939\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2185 - acc: 0.6958 - val_loss: 0.2317 - val_acc: 0.6913\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2157 - acc: 0.6959 - val_loss: 0.2284 - val_acc: 0.6949\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2170 - acc: 0.6961 - val_loss: 0.2315 - val_acc: 0.6936\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2153 - acc: 0.6975 - val_loss: 0.2314 - val_acc: 0.6918\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2166 - acc: 0.6960 - val_loss: 0.2282 - val_acc: 0.6936\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2167 - acc: 0.6963 - val_loss: 0.2302 - val_acc: 0.6914\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2143 - acc: 0.6961 - val_loss: 0.2315 - val_acc: 0.6902\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2138 - acc: 0.6967 - val_loss: 0.2259 - val_acc: 0.6942\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2182 - acc: 0.6964 - val_loss: 0.2273 - val_acc: 0.6943\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2130 - acc: 0.6967 - val_loss: 0.2341 - val_acc: 0.6900\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2204 - acc: 0.6937 - val_loss: 0.2302 - val_acc: 0.6933\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2162 - acc: 0.6971 - val_loss: 0.2296 - val_acc: 0.6923\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2137 - acc: 0.6969 - val_loss: 0.2292 - val_acc: 0.6935\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2141 - acc: 0.6967 - val_loss: 0.2288 - val_acc: 0.6939\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2183 - acc: 0.6970 - val_loss: 0.2284 - val_acc: 0.6945\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2136 - acc: 0.6975 - val_loss: 0.2287 - val_acc: 0.6918\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2165 - acc: 0.6957 - val_loss: 0.2283 - val_acc: 0.6928\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2143 - acc: 0.6964 - val_loss: 0.2258 - val_acc: 0.6938\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2125 - acc: 0.6978 - val_loss: 0.2270 - val_acc: 0.6943\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2146 - acc: 0.6975 - val_loss: 0.2307 - val_acc: 0.6920\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2165 - acc: 0.6961 - val_loss: 0.2249 - val_acc: 0.6938\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2115 - acc: 0.6981 - val_loss: 0.2281 - val_acc: 0.6931\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2190 - acc: 0.6942 - val_loss: 0.2294 - val_acc: 0.6921\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2155 - acc: 0.6958 - val_loss: 0.2261 - val_acc: 0.6941\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2129 - acc: 0.6966 - val_loss: 0.2277 - val_acc: 0.6919\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2157 - acc: 0.6971 - val_loss: 0.2255 - val_acc: 0.6946\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2186 - acc: 0.6959 - val_loss: 0.2261 - val_acc: 0.6941\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2110 - acc: 0.6984 - val_loss: 0.2257 - val_acc: 0.6932\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2120 - acc: 0.6978 - val_loss: 0.2313 - val_acc: 0.6944\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2175 - acc: 0.6975 - val_loss: 0.2288 - val_acc: 0.6924\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2157 - acc: 0.6952 - val_loss: 0.2384 - val_acc: 0.6855\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2130 - acc: 0.6973 - val_loss: 0.2330 - val_acc: 0.6934\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.2146 - acc: 0.6973 - val_loss: 0.2295 - val_acc: 0.6923\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2185 - acc: 0.6956 - val_loss: 0.2354 - val_acc: 0.6908\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2158 - acc: 0.6963 - val_loss: 0.2264 - val_acc: 0.6935\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2144 - acc: 0.6967 - val_loss: 0.2309 - val_acc: 0.6930\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2164 - acc: 0.6962 - val_loss: 0.2246 - val_acc: 0.6948\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2128 - acc: 0.6966 - val_loss: 0.2329 - val_acc: 0.6917\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2167 - acc: 0.6954 - val_loss: 0.2300 - val_acc: 0.6923\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2166 - acc: 0.6955 - val_loss: 0.2262 - val_acc: 0.6934\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2114 - acc: 0.6983 - val_loss: 0.2294 - val_acc: 0.6932\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2149 - acc: 0.6975 - val_loss: 0.2302 - val_acc: 0.6933\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2137 - acc: 0.6980 - val_loss: 0.2266 - val_acc: 0.6962\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2146 - acc: 0.6974 - val_loss: 0.2303 - val_acc: 0.6936\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2148 - acc: 0.6972 - val_loss: 0.2254 - val_acc: 0.6941\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2137 - acc: 0.6975 - val_loss: 0.2312 - val_acc: 0.6916\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2155 - acc: 0.6963 - val_loss: 0.2304 - val_acc: 0.6926\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9144 - acc: 0.6836 - val_loss: 2.0279 - val_acc: 0.6824\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9262 - acc: 0.6833 - val_loss: 2.0406 - val_acc: 0.6790\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9141 - acc: 0.6831 - val_loss: 2.1196 - val_acc: 0.6749\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9148 - acc: 0.6826 - val_loss: 2.0579 - val_acc: 0.6791\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9063 - acc: 0.6828 - val_loss: 2.0575 - val_acc: 0.6784\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9089 - acc: 0.6832 - val_loss: 2.0482 - val_acc: 0.6791\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8943 - acc: 0.6836 - val_loss: 2.0440 - val_acc: 0.6780\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8947 - acc: 0.6825 - val_loss: 2.0846 - val_acc: 0.6796\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9080 - acc: 0.6830 - val_loss: 2.1150 - val_acc: 0.6798\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9156 - acc: 0.6828 - val_loss: 2.0109 - val_acc: 0.6811\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8994 - acc: 0.6832 - val_loss: 2.1138 - val_acc: 0.6799\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9395 - acc: 0.6830 - val_loss: 2.0513 - val_acc: 0.6809\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 1.8780 - acc: 0.6840 - val_loss: 2.0592 - val_acc: 0.6811\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8897 - acc: 0.6835 - val_loss: 2.1522 - val_acc: 0.6762\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9295 - acc: 0.6834 - val_loss: 2.0725 - val_acc: 0.6829\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8983 - acc: 0.6834 - val_loss: 2.0292 - val_acc: 0.6815\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8927 - acc: 0.6836 - val_loss: 2.3527 - val_acc: 0.6739\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9076 - acc: 0.6829 - val_loss: 2.0191 - val_acc: 0.6810\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9138 - acc: 0.6831 - val_loss: 2.0596 - val_acc: 0.6783\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9094 - acc: 0.6823 - val_loss: 2.0378 - val_acc: 0.6823\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9039 - acc: 0.6829 - val_loss: 2.0980 - val_acc: 0.6782\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8836 - acc: 0.6831 - val_loss: 2.0144 - val_acc: 0.6814\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8902 - acc: 0.6839 - val_loss: 2.1129 - val_acc: 0.6765\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9310 - acc: 0.6831 - val_loss: 2.0960 - val_acc: 0.6772\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9039 - acc: 0.6828 - val_loss: 2.0762 - val_acc: 0.6793\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9034 - acc: 0.6833 - val_loss: 2.1366 - val_acc: 0.6743\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9343 - acc: 0.6820 - val_loss: 2.0368 - val_acc: 0.6797\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8945 - acc: 0.6834 - val_loss: 2.0870 - val_acc: 0.6819\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9194 - acc: 0.6830 - val_loss: 2.1195 - val_acc: 0.6779\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9346 - acc: 0.6831 - val_loss: 2.1347 - val_acc: 0.6766\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9033 - acc: 0.6831 - val_loss: 2.0670 - val_acc: 0.6786\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9369 - acc: 0.6826 - val_loss: 2.0988 - val_acc: 0.6778\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9037 - acc: 0.6839 - val_loss: 2.1195 - val_acc: 0.6797\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9112 - acc: 0.6835 - val_loss: 2.0477 - val_acc: 0.6799\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9107 - acc: 0.6833 - val_loss: 2.0275 - val_acc: 0.6793\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9150 - acc: 0.6829 - val_loss: 2.0808 - val_acc: 0.6772\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9188 - acc: 0.6825 - val_loss: 2.0363 - val_acc: 0.6799\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.8960 - acc: 0.6834 - val_loss: 2.0901 - val_acc: 0.6787\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9037 - acc: 0.6824 - val_loss: 2.0757 - val_acc: 0.6803\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9092 - acc: 0.6832 - val_loss: 2.0292 - val_acc: 0.6796\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8918 - acc: 0.6831 - val_loss: 2.0607 - val_acc: 0.6795\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8887 - acc: 0.6826 - val_loss: 2.0633 - val_acc: 0.6810\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.8881 - acc: 0.6837 - val_loss: 2.0257 - val_acc: 0.6814\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9112 - acc: 0.6833 - val_loss: 2.0437 - val_acc: 0.6809\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9088 - acc: 0.6838 - val_loss: 2.0219 - val_acc: 0.6817\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9060 - acc: 0.6835 - val_loss: 2.0383 - val_acc: 0.6816\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9179 - acc: 0.6841 - val_loss: 2.1168 - val_acc: 0.6826\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9143 - acc: 0.6834 - val_loss: 2.0610 - val_acc: 0.6787\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8977 - acc: 0.6836 - val_loss: 2.0328 - val_acc: 0.6804\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9201 - acc: 0.6836 - val_loss: 2.0982 - val_acc: 0.6797\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1509 - acc: 0.9929 - val_loss: 0.1642 - val_acc: 0.9908\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1612 - acc: 0.9929 - val_loss: 0.1610 - val_acc: 0.9908\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1580 - acc: 0.9927 - val_loss: 0.1564 - val_acc: 0.9908\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1598 - acc: 0.9925 - val_loss: 0.1603 - val_acc: 0.9906\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.1590 - acc: 0.9923 - val_loss: 0.1605 - val_acc: 0.9905\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1571 - acc: 0.9925 - val_loss: 0.1667 - val_acc: 0.9907\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1568 - acc: 0.9927 - val_loss: 0.1625 - val_acc: 0.9908\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1542 - acc: 0.9927 - val_loss: 0.1533 - val_acc: 0.9911\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1490 - acc: 0.9930 - val_loss: 0.1522 - val_acc: 0.9910\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1506 - acc: 0.9928 - val_loss: 0.1635 - val_acc: 0.9907\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1657 - acc: 0.9925 - val_loss: 0.1652 - val_acc: 0.9907\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1617 - acc: 0.9929 - val_loss: 0.1652 - val_acc: 0.9909\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1524 - acc: 0.9930 - val_loss: 0.1527 - val_acc: 0.9909\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1546 - acc: 0.9930 - val_loss: 0.1540 - val_acc: 0.9910\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1568 - acc: 0.9926 - val_loss: 0.1509 - val_acc: 0.9910\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1491 - acc: 0.9928 - val_loss: 0.1507 - val_acc: 0.9911\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1458 - acc: 0.9929 - val_loss: 0.1487 - val_acc: 0.9908\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1500 - acc: 0.9930 - val_loss: 0.1695 - val_acc: 0.9909\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1614 - acc: 0.9930 - val_loss: 0.1580 - val_acc: 0.9909\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1544 - acc: 0.9929 - val_loss: 0.1570 - val_acc: 0.9908\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1627 - acc: 0.9929 - val_loss: 0.1617 - val_acc: 0.9908\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1527 - acc: 0.9929 - val_loss: 0.1521 - val_acc: 0.9908\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1510 - acc: 0.9928 - val_loss: 0.1547 - val_acc: 0.9903\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1568 - acc: 0.9922 - val_loss: 0.1631 - val_acc: 0.9904\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1642 - acc: 0.9916 - val_loss: 0.1671 - val_acc: 0.9895\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1636 - acc: 0.9917 - val_loss: 0.1655 - val_acc: 0.9901\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1598 - acc: 0.9921 - val_loss: 0.1654 - val_acc: 0.9903\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1564 - acc: 0.9927 - val_loss: 0.1492 - val_acc: 0.9907\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1477 - acc: 0.9929 - val_loss: 0.1516 - val_acc: 0.9908\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1544 - acc: 0.9930 - val_loss: 0.1598 - val_acc: 0.9909\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1582 - acc: 0.9930 - val_loss: 0.1653 - val_acc: 0.9908\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1612 - acc: 0.9929 - val_loss: 0.1604 - val_acc: 0.9909\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1511 - acc: 0.9928 - val_loss: 0.1599 - val_acc: 0.9907\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1537 - acc: 0.9924 - val_loss: 0.1533 - val_acc: 0.9906\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1517 - acc: 0.9925 - val_loss: 0.1487 - val_acc: 0.9909\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1476 - acc: 0.9925 - val_loss: 0.1504 - val_acc: 0.9908\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1490 - acc: 0.9925 - val_loss: 0.1502 - val_acc: 0.9910\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1530 - acc: 0.9926 - val_loss: 0.1543 - val_acc: 0.9908\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1517 - acc: 0.9928 - val_loss: 0.1544 - val_acc: 0.9911\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1603 - acc: 0.9930 - val_loss: 0.1647 - val_acc: 0.9910\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1613 - acc: 0.9930 - val_loss: 0.1506 - val_acc: 0.9911\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1489 - acc: 0.9930 - val_loss: 0.1526 - val_acc: 0.9908\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1516 - acc: 0.9929 - val_loss: 0.1648 - val_acc: 0.9906\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1633 - acc: 0.9919 - val_loss: 0.1668 - val_acc: 0.9896\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1619 - acc: 0.9917 - val_loss: 0.1602 - val_acc: 0.9903\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1544 - acc: 0.9924 - val_loss: 0.1510 - val_acc: 0.9910\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1533 - acc: 0.9928 - val_loss: 0.1577 - val_acc: 0.9909\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1514 - acc: 0.9929 - val_loss: 0.1501 - val_acc: 0.9910\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1466 - acc: 0.9929 - val_loss: 0.1529 - val_acc: 0.9909\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1570 - acc: 0.9926 - val_loss: 0.1627 - val_acc: 0.9909\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9631 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0031 - val_acc: 0.9632\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9587 - val_loss: 0.0032 - val_acc: 0.9576\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9575 - val_loss: 0.0029 - val_acc: 0.9672\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9636 - val_loss: 0.0029 - val_acc: 0.9655\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0030 - val_acc: 0.9654\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 243us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9654\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9610 - val_loss: 0.0033 - val_acc: 0.9544\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9580 - val_loss: 0.0029 - val_acc: 0.9660\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0029 - val_acc: 0.9667\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0027 - acc: 0.9640 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9610 - val_loss: 0.0030 - val_acc: 0.9641\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 240us/step - loss: 0.0028 - acc: 0.9606 - val_loss: 0.0030 - val_acc: 0.9634\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0030 - val_acc: 0.9612\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9600 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9660\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9624 - val_loss: 0.0031 - val_acc: 0.9641\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 244us/step - loss: 0.0028 - acc: 0.9614 - val_loss: 0.0029 - val_acc: 0.9668\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9670\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9611 - val_loss: 0.0029 - val_acc: 0.9655\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9612 - val_loss: 0.0029 - val_acc: 0.9657\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9635 - val_loss: 0.0029 - val_acc: 0.9662\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9661\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0027 - acc: 0.9640 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9636 - val_loss: 0.0030 - val_acc: 0.9665\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9636 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9622 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9636 - val_loss: 0.0029 - val_acc: 0.9662\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9605 - val_loss: 0.0029 - val_acc: 0.9657\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9652\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9633 - val_loss: 0.0030 - val_acc: 0.9647\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9597 - val_loss: 0.0030 - val_acc: 0.9635\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9616 - val_loss: 0.0030 - val_acc: 0.9632\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0027 - acc: 0.9634 - val_loss: 0.0029 - val_acc: 0.9654\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9611 - val_loss: 0.0030 - val_acc: 0.9644\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0029 - acc: 0.9587 - val_loss: 0.0030 - val_acc: 0.9648\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9609 - val_loss: 0.0030 - val_acc: 0.9630\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0027 - acc: 0.9621 - val_loss: 0.0029 - val_acc: 0.9670\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9604 - val_loss: 0.0032 - val_acc: 0.9587\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9593 - val_loss: 0.0029 - val_acc: 0.9657\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0027 - acc: 0.9627 - val_loss: 0.0029 - val_acc: 0.9647\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0027 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9623\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9599 - val_loss: 0.0029 - val_acc: 0.9648\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0027 - acc: 0.9636 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0027 - acc: 0.9631 - val_loss: 0.0029 - val_acc: 0.9643\n",
      "start training round 49\n",
      "training gyro model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2161 - acc: 0.6952 - val_loss: 0.2295 - val_acc: 0.6928\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2149 - acc: 0.6969 - val_loss: 0.2276 - val_acc: 0.6925\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2150 - acc: 0.6966 - val_loss: 0.2313 - val_acc: 0.6927\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2159 - acc: 0.6961 - val_loss: 0.2286 - val_acc: 0.6936\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2168 - acc: 0.6966 - val_loss: 0.2258 - val_acc: 0.6936\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2134 - acc: 0.6962 - val_loss: 0.2286 - val_acc: 0.6924\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2135 - acc: 0.6966 - val_loss: 0.2343 - val_acc: 0.6928\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2176 - acc: 0.6966 - val_loss: 0.2290 - val_acc: 0.6944\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2126 - acc: 0.6977 - val_loss: 0.2306 - val_acc: 0.6904\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2167 - acc: 0.6951 - val_loss: 0.2302 - val_acc: 0.6935\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2151 - acc: 0.6965 - val_loss: 0.2255 - val_acc: 0.6942\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2121 - acc: 0.6979 - val_loss: 0.2268 - val_acc: 0.6945\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2147 - acc: 0.6976 - val_loss: 0.2324 - val_acc: 0.6927\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2165 - acc: 0.6971 - val_loss: 0.2270 - val_acc: 0.6933\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.2130 - acc: 0.6970 - val_loss: 0.2275 - val_acc: 0.6930\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2130 - acc: 0.6972 - val_loss: 0.2249 - val_acc: 0.6945\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2134 - acc: 0.6984 - val_loss: 0.2289 - val_acc: 0.6946\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2167 - acc: 0.6966 - val_loss: 0.2263 - val_acc: 0.6930\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2120 - acc: 0.6975 - val_loss: 0.2282 - val_acc: 0.6930\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2136 - acc: 0.6972 - val_loss: 0.2316 - val_acc: 0.6897\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2150 - acc: 0.6971 - val_loss: 0.2293 - val_acc: 0.6932\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2165 - acc: 0.6963 - val_loss: 0.2275 - val_acc: 0.6936\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2134 - acc: 0.6970 - val_loss: 0.2257 - val_acc: 0.6948\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2160 - acc: 0.6977 - val_loss: 0.2263 - val_acc: 0.6938\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2124 - acc: 0.6981 - val_loss: 0.2282 - val_acc: 0.6938\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2133 - acc: 0.6972 - val_loss: 0.2270 - val_acc: 0.6918\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2148 - acc: 0.6959 - val_loss: 0.2314 - val_acc: 0.6919\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2162 - acc: 0.6956 - val_loss: 0.2341 - val_acc: 0.6917\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2147 - acc: 0.6969 - val_loss: 0.2255 - val_acc: 0.6947\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.2134 - acc: 0.6976 - val_loss: 0.2237 - val_acc: 0.6949\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2122 - acc: 0.6986 - val_loss: 0.2321 - val_acc: 0.6939\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2189 - acc: 0.6975 - val_loss: 0.2261 - val_acc: 0.6951\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.2117 - acc: 0.6976 - val_loss: 0.2272 - val_acc: 0.6923\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2174 - acc: 0.6942 - val_loss: 0.2298 - val_acc: 0.6920\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2143 - acc: 0.6976 - val_loss: 0.2321 - val_acc: 0.6919\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2129 - acc: 0.6971 - val_loss: 0.2285 - val_acc: 0.6935\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.2171 - acc: 0.6955 - val_loss: 0.2275 - val_acc: 0.6947\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2126 - acc: 0.6980 - val_loss: 0.2272 - val_acc: 0.6936\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2147 - acc: 0.6966 - val_loss: 0.2295 - val_acc: 0.6923\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2150 - acc: 0.6966 - val_loss: 0.2276 - val_acc: 0.6931\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2120 - acc: 0.6984 - val_loss: 0.2242 - val_acc: 0.6944\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2107 - acc: 0.6985 - val_loss: 0.2248 - val_acc: 0.6950\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.2134 - acc: 0.6978 - val_loss: 0.2290 - val_acc: 0.6935\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.2194 - acc: 0.6951 - val_loss: 0.2398 - val_acc: 0.6895\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2171 - acc: 0.6965 - val_loss: 0.2251 - val_acc: 0.6950\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2135 - acc: 0.6982 - val_loss: 0.2288 - val_acc: 0.6934\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2145 - acc: 0.6976 - val_loss: 0.2253 - val_acc: 0.6941\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.2141 - acc: 0.6970 - val_loss: 0.2339 - val_acc: 0.6911\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2148 - acc: 0.6970 - val_loss: 0.2263 - val_acc: 0.6944\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.2128 - acc: 0.6978 - val_loss: 0.2282 - val_acc: 0.6924\n",
      "training linearAcc model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9026 - acc: 0.6841 - val_loss: 2.0566 - val_acc: 0.6798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9015 - acc: 0.6830 - val_loss: 2.0307 - val_acc: 0.6791\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8969 - acc: 0.6836 - val_loss: 2.0222 - val_acc: 0.6807\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 1.8946 - acc: 0.6835 - val_loss: 2.0381 - val_acc: 0.6794\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.8918 - acc: 0.6835 - val_loss: 2.1548 - val_acc: 0.6804\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9216 - acc: 0.6833 - val_loss: 2.1009 - val_acc: 0.6793\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9130 - acc: 0.6833 - val_loss: 2.1302 - val_acc: 0.6820\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9333 - acc: 0.6833 - val_loss: 2.0419 - val_acc: 0.6803\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.8990 - acc: 0.6832 - val_loss: 2.1134 - val_acc: 0.6816\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9235 - acc: 0.6836 - val_loss: 2.0419 - val_acc: 0.6794\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.8843 - acc: 0.6833 - val_loss: 2.0046 - val_acc: 0.6801\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8928 - acc: 0.6827 - val_loss: 2.0169 - val_acc: 0.6795\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9031 - acc: 0.6831 - val_loss: 2.1052 - val_acc: 0.6826\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9231 - acc: 0.6840 - val_loss: 2.0903 - val_acc: 0.6819\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8982 - acc: 0.6832 - val_loss: 2.0789 - val_acc: 0.6777\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9071 - acc: 0.6830 - val_loss: 2.0219 - val_acc: 0.6793\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8843 - acc: 0.6836 - val_loss: 2.1215 - val_acc: 0.6805\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9202 - acc: 0.6832 - val_loss: 2.0209 - val_acc: 0.6803\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9277 - acc: 0.6824 - val_loss: 2.0690 - val_acc: 0.6791\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9186 - acc: 0.6839 - val_loss: 2.0225 - val_acc: 0.6810\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9019 - acc: 0.6839 - val_loss: 2.0461 - val_acc: 0.6778\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9249 - acc: 0.6831 - val_loss: 2.0604 - val_acc: 0.6782\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9030 - acc: 0.6825 - val_loss: 2.0471 - val_acc: 0.6779\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8923 - acc: 0.6833 - val_loss: 2.0743 - val_acc: 0.6781\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9026 - acc: 0.6836 - val_loss: 2.0087 - val_acc: 0.6814\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.8884 - acc: 0.6839 - val_loss: 2.0357 - val_acc: 0.6817\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.8754 - acc: 0.6839 - val_loss: 2.1172 - val_acc: 0.6772\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9238 - acc: 0.6821 - val_loss: 2.1027 - val_acc: 0.6795\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9179 - acc: 0.6831 - val_loss: 2.1182 - val_acc: 0.6795\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 1.9204 - acc: 0.6822 - val_loss: 2.0520 - val_acc: 0.6832\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.8948 - acc: 0.6838 - val_loss: 2.0279 - val_acc: 0.6818\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.8985 - acc: 0.6832 - val_loss: 2.0455 - val_acc: 0.6801\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9000 - acc: 0.6832 - val_loss: 2.0261 - val_acc: 0.6816\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.9019 - acc: 0.6835 - val_loss: 2.0487 - val_acc: 0.6814\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.8936 - acc: 0.6839 - val_loss: 2.0501 - val_acc: 0.6783\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.8976 - acc: 0.6841 - val_loss: 2.0524 - val_acc: 0.6814\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9106 - acc: 0.6836 - val_loss: 2.0100 - val_acc: 0.6804\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 1.8962 - acc: 0.6821 - val_loss: 2.0410 - val_acc: 0.6816\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9002 - acc: 0.6836 - val_loss: 2.0780 - val_acc: 0.6806\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 1.9100 - acc: 0.6838 - val_loss: 2.1361 - val_acc: 0.6803\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 1.9072 - acc: 0.6838 - val_loss: 2.0412 - val_acc: 0.6795\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 1.9160 - acc: 0.6828 - val_loss: 2.0283 - val_acc: 0.6814\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9001 - acc: 0.6834 - val_loss: 2.0671 - val_acc: 0.6799\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.8941 - acc: 0.6835 - val_loss: 2.0823 - val_acc: 0.6803\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 1.9031 - acc: 0.6833 - val_loss: 2.0475 - val_acc: 0.6819\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.9199 - acc: 0.6823 - val_loss: 2.0578 - val_acc: 0.6820\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 1.9062 - acc: 0.6832 - val_loss: 2.0278 - val_acc: 0.6813\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 1.8986 - acc: 0.6832 - val_loss: 2.1086 - val_acc: 0.6780\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 1.9442 - acc: 0.6828 - val_loss: 2.0918 - val_acc: 0.6801\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 1.9113 - acc: 0.6837 - val_loss: 2.1014 - val_acc: 0.6791\n",
      "training gravity model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1669 - acc: 0.9929 - val_loss: 0.1696 - val_acc: 0.9908\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1591 - acc: 0.9929 - val_loss: 0.1605 - val_acc: 0.9908\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1554 - acc: 0.9929 - val_loss: 0.1546 - val_acc: 0.9907\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1536 - acc: 0.9928 - val_loss: 0.1489 - val_acc: 0.9905\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1476 - acc: 0.9926 - val_loss: 0.1525 - val_acc: 0.9905\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.1539 - acc: 0.9918 - val_loss: 0.1556 - val_acc: 0.9898\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1515 - acc: 0.9922 - val_loss: 0.1540 - val_acc: 0.9902\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1486 - acc: 0.9926 - val_loss: 0.1545 - val_acc: 0.9907\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1581 - acc: 0.9929 - val_loss: 0.1568 - val_acc: 0.9909\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1483 - acc: 0.9927 - val_loss: 0.1505 - val_acc: 0.9908\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1571 - acc: 0.9928 - val_loss: 0.1702 - val_acc: 0.9909\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1739 - acc: 0.9930 - val_loss: 0.1787 - val_acc: 0.9911\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1577 - acc: 0.9929 - val_loss: 0.1508 - val_acc: 0.9910\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 222us/step - loss: 0.1467 - acc: 0.9930 - val_loss: 0.1478 - val_acc: 0.9910\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 221us/step - loss: 0.1455 - acc: 0.9929 - val_loss: 0.1491 - val_acc: 0.9910\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1502 - acc: 0.9930 - val_loss: 0.1553 - val_acc: 0.9909\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1545 - acc: 0.9929 - val_loss: 0.1540 - val_acc: 0.9907\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1594 - acc: 0.9920 - val_loss: 0.1685 - val_acc: 0.9892\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1553 - acc: 0.9920 - val_loss: 0.1602 - val_acc: 0.9904\n",
      "Epoch 20/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1529 - acc: 0.9924 - val_loss: 0.1532 - val_acc: 0.9906\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1536 - acc: 0.9923 - val_loss: 0.1552 - val_acc: 0.9903\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1538 - acc: 0.9926 - val_loss: 0.1517 - val_acc: 0.9905\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1550 - acc: 0.9928 - val_loss: 0.1597 - val_acc: 0.9907\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 223us/step - loss: 0.1584 - acc: 0.9930 - val_loss: 0.1633 - val_acc: 0.9909\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1719 - acc: 0.9930 - val_loss: 0.1615 - val_acc: 0.9908\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1539 - acc: 0.9930 - val_loss: 0.1491 - val_acc: 0.9909\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1471 - acc: 0.9930 - val_loss: 0.1465 - val_acc: 0.9909\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1478 - acc: 0.9930 - val_loss: 0.1527 - val_acc: 0.9904\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1487 - acc: 0.9930 - val_loss: 0.1532 - val_acc: 0.9906\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1576 - acc: 0.9926 - val_loss: 0.1746 - val_acc: 0.9901\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1614 - acc: 0.9919 - val_loss: 0.1512 - val_acc: 0.9905\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1496 - acc: 0.9925 - val_loss: 0.1498 - val_acc: 0.9905\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 224us/step - loss: 0.1475 - acc: 0.9925 - val_loss: 0.1485 - val_acc: 0.9907\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1511 - acc: 0.9924 - val_loss: 0.1564 - val_acc: 0.9907\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1563 - acc: 0.9928 - val_loss: 0.1598 - val_acc: 0.9909\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1593 - acc: 0.9930 - val_loss: 0.1599 - val_acc: 0.9910\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1555 - acc: 0.9929 - val_loss: 0.1511 - val_acc: 0.9910\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1450 - acc: 0.9930 - val_loss: 0.1465 - val_acc: 0.9910\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1443 - acc: 0.9930 - val_loss: 0.1508 - val_acc: 0.9911\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1498 - acc: 0.9929 - val_loss: 0.1537 - val_acc: 0.9911\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1557 - acc: 0.9925 - val_loss: 0.1659 - val_acc: 0.9905\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1677 - acc: 0.9921 - val_loss: 0.1608 - val_acc: 0.9910\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1494 - acc: 0.9930 - val_loss: 0.1489 - val_acc: 0.9909\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 227us/step - loss: 0.1492 - acc: 0.9927 - val_loss: 0.1661 - val_acc: 0.9898\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1651 - acc: 0.9918 - val_loss: 0.1765 - val_acc: 0.9894\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 226us/step - loss: 0.1607 - acc: 0.9921 - val_loss: 0.1493 - val_acc: 0.9909\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 228us/step - loss: 0.1446 - acc: 0.9929 - val_loss: 0.1459 - val_acc: 0.9909\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 225us/step - loss: 0.1459 - acc: 0.9929 - val_loss: 0.1505 - val_acc: 0.9907\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 230us/step - loss: 0.1525 - acc: 0.9928 - val_loss: 0.1678 - val_acc: 0.9904\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.1652 - acc: 0.9928 - val_loss: 0.1637 - val_acc: 0.9908\n",
      "training gameVec model\n",
      "Train on 8564 samples, validate on 952 samples\n",
      "Epoch 1/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0027 - acc: 0.9638 - val_loss: 0.0029 - val_acc: 0.9656\n",
      "Epoch 2/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0029 - acc: 0.9598 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 3/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9633 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 4/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0030 - val_acc: 0.9627\n",
      "Epoch 5/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0029 - acc: 0.9575 - val_loss: 0.0029 - val_acc: 0.9658\n",
      "Epoch 6/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9640 - val_loss: 0.0030 - val_acc: 0.9639\n",
      "Epoch 7/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9596 - val_loss: 0.0031 - val_acc: 0.9571\n",
      "Epoch 8/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9574 - val_loss: 0.0029 - val_acc: 0.9657\n",
      "Epoch 9/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9631 - val_loss: 0.0029 - val_acc: 0.9664\n",
      "Epoch 10/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0027 - acc: 0.9631 - val_loss: 0.0029 - val_acc: 0.9651\n",
      "Epoch 11/50\n",
      "8564/8564 [==============================] - 2s 238us/step - loss: 0.0027 - acc: 0.9641 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 12/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9640 - val_loss: 0.0030 - val_acc: 0.9663\n",
      "Epoch 13/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9620 - val_loss: 0.0031 - val_acc: 0.9651\n",
      "Epoch 14/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0029 - acc: 0.9615 - val_loss: 0.0029 - val_acc: 0.9662\n",
      "Epoch 15/50\n",
      "8564/8564 [==============================] - 2s 236us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0030 - val_acc: 0.9662\n",
      "Epoch 16/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0027 - acc: 0.9631 - val_loss: 0.0030 - val_acc: 0.9657\n",
      "Epoch 17/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9610 - val_loss: 0.0032 - val_acc: 0.9561\n",
      "Epoch 18/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9613 - val_loss: 0.0030 - val_acc: 0.9655\n",
      "Epoch 19/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9616 - val_loss: 0.0030 - val_acc: 0.9642\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0029 - acc: 0.9585 - val_loss: 0.0032 - val_acc: 0.9597\n",
      "Epoch 21/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9604 - val_loss: 0.0029 - val_acc: 0.9665\n",
      "Epoch 22/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9619 - val_loss: 0.0029 - val_acc: 0.9674\n",
      "Epoch 23/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9638 - val_loss: 0.0030 - val_acc: 0.9663\n",
      "Epoch 24/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9628 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 25/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0027 - acc: 0.9639 - val_loss: 0.0028 - val_acc: 0.9670\n",
      "Epoch 26/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0027 - acc: 0.9642 - val_loss: 0.0029 - val_acc: 0.9670\n",
      "Epoch 27/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0027 - acc: 0.9641 - val_loss: 0.0029 - val_acc: 0.9667\n",
      "Epoch 28/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0027 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9622\n",
      "Epoch 29/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9595 - val_loss: 0.0029 - val_acc: 0.9671\n",
      "Epoch 30/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0028 - acc: 0.9614 - val_loss: 0.0029 - val_acc: 0.9667\n",
      "Epoch 31/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0028 - acc: 0.9616 - val_loss: 0.0029 - val_acc: 0.9655\n",
      "Epoch 32/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9634 - val_loss: 0.0030 - val_acc: 0.9621\n",
      "Epoch 33/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0028 - acc: 0.9623 - val_loss: 0.0030 - val_acc: 0.9651\n",
      "Epoch 34/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9615 - val_loss: 0.0029 - val_acc: 0.9667\n",
      "Epoch 35/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9626 - val_loss: 0.0029 - val_acc: 0.9654\n",
      "Epoch 36/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0027 - acc: 0.9636 - val_loss: 0.0029 - val_acc: 0.9659\n",
      "Epoch 37/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9636 - val_loss: 0.0031 - val_acc: 0.9621\n",
      "Epoch 38/50\n",
      "8564/8564 [==============================] - 2s 235us/step - loss: 0.0028 - acc: 0.9590 - val_loss: 0.0029 - val_acc: 0.9648\n",
      "Epoch 39/50\n",
      "8564/8564 [==============================] - 2s 237us/step - loss: 0.0028 - acc: 0.9617 - val_loss: 0.0030 - val_acc: 0.9637\n",
      "Epoch 40/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0029 - acc: 0.9587 - val_loss: 0.0030 - val_acc: 0.9627\n",
      "Epoch 41/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9638 - val_loss: 0.0029 - val_acc: 0.9663\n",
      "Epoch 42/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9638 - val_loss: 0.0030 - val_acc: 0.9656\n",
      "Epoch 43/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.0028 - acc: 0.9625 - val_loss: 0.0029 - val_acc: 0.9670\n",
      "Epoch 44/50\n",
      "8564/8564 [==============================] - 2s 231us/step - loss: 0.0027 - acc: 0.9639 - val_loss: 0.0029 - val_acc: 0.9671\n",
      "Epoch 45/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.0028 - acc: 0.9621 - val_loss: 0.0029 - val_acc: 0.9668\n",
      "Epoch 46/50\n",
      "8564/8564 [==============================] - 2s 229us/step - loss: 0.0027 - acc: 0.9627 - val_loss: 0.0030 - val_acc: 0.9661\n",
      "Epoch 47/50\n",
      "8564/8564 [==============================] - 2s 233us/step - loss: 0.0028 - acc: 0.9629 - val_loss: 0.0029 - val_acc: 0.9666\n",
      "Epoch 48/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9632 - val_loss: 0.0029 - val_acc: 0.9658\n",
      "Epoch 49/50\n",
      "8564/8564 [==============================] - 2s 234us/step - loss: 0.0027 - acc: 0.9628 - val_loss: 0.0029 - val_acc: 0.9667\n",
      "Epoch 50/50\n",
      "8564/8564 [==============================] - 2s 232us/step - loss: 0.0027 - acc: 0.9624 - val_loss: 0.0030 - val_acc: 0.9634\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print('start training round '+str(i))\n",
    "    print('training gyro model')\n",
    "    gyroModel.fit(gyro_train,gyro_train,batch_size=256,epochs=50,validation_split=0.1)\n",
    "    print('training linearAcc model')\n",
    "    linearAccModel.fit(linearAcc_train,linearAcc_train,batch_size=256,epochs=50,validation_split=0.1)\n",
    "    print('training gravity model')\n",
    "    gravityModel.fit(gravity_train,gravity_train,batch_size=256,epochs=50,validation_split=0.1)\n",
    "    print('training gameVec model')\n",
    "    gameVecModel.fit(gameVec_train,gameVec_train,batch_size=256,epochs=50,validation_split=0.1)\n",
    "    gyroModel.save('gyroModel.h5')\n",
    "    linearAccModel.save('linearAccModel.h5')\n",
    "    gravityModel.save('gravityModel.h5')\n",
    "    gameVecModel.save('gameVecModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = 33\n",
    "gyroy = gyroModel.predict(gyro_train[sample].reshape(1,128,3))\n",
    "fig=plt.figure(figsize=(20,7))\n",
    "for channel in range(3):\n",
    "    plt.subplot(1,3,channel+1)\n",
    "    plot(gyro_train[sample,:,channel],'b')\n",
    "    plot(gyroy[0,:,channel],'r')\n",
    "linearAccy = linearAccModel.predict(linearAcc_train[sample].reshape(1,128,3))\n",
    "fig=plt.figure(figsize=(20,7))\n",
    "for channel in range(3):\n",
    "    plt.subplot(1,3,channel+1)\n",
    "    plot(linearAcc_train[sample,:,channel],'b')\n",
    "    plot(linearAccy[0,:,channel],'r')\n",
    "gravityy = gravityModel.predict(gravity_train[sample].reshape(1,128,3))\n",
    "fig=plt.figure(figsize=(20,7))\n",
    "for channel in range(3):\n",
    "    plt.subplot(1,3,channel+1)\n",
    "    plot(gravity_train[sample,:,channel],'b')\n",
    "    plot(gravityy[0,:,channel],'r')\n",
    "gameVecy = gameVecModel.predict(gameVec_train[sample].reshape(1,128,4))\n",
    "fig=plt.figure(figsize=(20,7))\n",
    "for channel in range(4):\n",
    "    plt.subplot(1,4,channel+1)\n",
    "    plot(gameVec_train[sample,:,channel],'b')\n",
    "    plot(gameVecy[0,:,channel],'r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
