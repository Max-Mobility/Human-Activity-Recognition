{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow.nn.rnn_cell as rnn\n",
    "import numpy as np\n",
    "#import tensorflow.keras as keras\n",
    "#from tensorflow.keras.initializers import Constant\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(predicts,raw,windows=16,threshold=0.8,raw_threshold=-10):\n",
    "    taps=np.zeros_like(predicts)\n",
    "    windows_count=0\n",
    "    buff_size=25\n",
    "    \n",
    "    for i in np.arange(buff_size,len(taps)):\n",
    "        raw_buff=raw[i-buff_size:i+1,0,2]# only z acc\n",
    "        #print(raw_buff.min())\n",
    "        diff=abs(raw_buff.max()-raw_buff.min())\n",
    "        buff_sum = 0\n",
    "        for x in raw_buff:\n",
    "            if x <0:\n",
    "                buff_sum+= x*-1\n",
    "        \n",
    "        if predicts[i]>threshold and windows_count==0  and buff_sum>raw_threshold:# and diff>6:# and predicts[i-1]>threshold:\n",
    "            #print(diff)\n",
    "            taps[i]=1\n",
    "            windows_count=windows\n",
    "            #print(buff_sum)\n",
    "        else:\n",
    "            windows_count=max(windows_count-1,0)\n",
    "    return taps\n",
    "\n",
    "\n",
    "def verify(taps,label_taps):\n",
    "    False_positive= np.zeros_like(taps)\n",
    "    False_negtive = np.zeros_like(taps)\n",
    "    True_positive = np.zeros_like(taps)\n",
    "    #taps=np.append(np.zeros([1]),taps)\n",
    "    #taps=np.append(taps,np.zeros([1]))\n",
    "    #label_taps=np.append(np.zeros([1]),label_taps)\n",
    "    #label_taps=np.append(label_taps,np.zeros([1]))\n",
    "    for i in range(len(taps)):\n",
    "        if label_taps[i] ==1:\n",
    "            if taps[i-2:i+3].sum()==0:\n",
    "                False_negtive[i]=1\n",
    "            else:\n",
    "                True_positive[i]=1\n",
    "\n",
    "        if taps[i] ==1:\n",
    "            if label_taps[i-2:i+4].sum()==0:\n",
    "                False_positive[i]=1\n",
    "                #raw_buff=raw[i-4:i+1,2]# only z acc\n",
    "                #diff=abs(raw_buff.max()-raw_buff.min())\n",
    "                #print(i,raw_buff,diff)\n",
    "            \n",
    "    return [False_positive,  False_negtive ,    True_positive ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_train=True\n",
    "time_steps=1\n",
    "n_input =3\n",
    "num_units=64\n",
    "n_classes=1\n",
    "lr =0.00001\n",
    "logFile = './traing.txt'\n",
    "\n",
    "#data_x=np.loadtxt('./data_raw_v2.csv',delimiter=\",\")\n",
    "#data_y=np.loadtxt('./data_y_v2.csv',delimiter=\",\")\n",
    "#preY = np.loadtxt('./data_preY_v2.csv',delimiter=\",\")\n",
    "data_x=np.loadtxt('./TapData/data_raw_100Hz.csv',delimiter=\",\")\n",
    "data_y=np.loadtxt('./TapData/data_100Hz_y.csv',delimiter=\",\")\n",
    "preY = np.loadtxt('./TapData/data_100Hz_y.csv',delimiter=\",\")\n",
    "\n",
    "datay=data_y\n",
    "data_y=data_y.reshape(len(data_y),1,1)\n",
    "data_x=data_x[:,(6-n_input):6].reshape((len(data_x),3))\n",
    "data_x=data_x.reshape([len(data_x),1,n_input])\n",
    "data_state = np.zeros([1,num_units*2],dtype='float')\n",
    "taps_label = detect(data_y,raw=data_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0730 11:51:18.597246 22984 deprecation.py:323] From <ipython-input-4-0a8655580e6f>:50: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0730 11:51:18.601214 22984 rnn_cell_impl.py:697] <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000002127F749630>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "W0730 11:51:18.603208 22984 deprecation.py:323] From <ipython-input-4-0a8655580e6f>:51: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "W0730 11:51:18.621159 22984 deprecation.py:506] From C:\\Users\\Guo\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0730 11:51:18.630135 22984 deprecation.py:506] From C:\\Users\\Guo\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0730 11:51:18.901402 22984 deprecation.py:323] From C:\\Users\\Guo\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "100%|██████████| 512141/512141 [06:45<00:00, 1262.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "mse:0.13603867113486698\n",
      "mse_weight:7.91382450869126\n",
      "total taps:4352.0\n",
      "FP,FN,TP:3775.0, 1076.0, 460.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512141/512141 [06:44<00:00, 1267.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "mse:0.09190779665789237\n",
      "mse_weight:3.3130402172001787\n",
      "total taps:3950.0\n",
      "FP,FN,TP:3372.0, 1088.0, 448.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512141/512141 [06:44<00:00, 1267.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "mse:0.09707107693058441\n",
      "mse_weight:2.63566827659099\n",
      "total taps:4194.0\n",
      "FP,FN,TP:3578.0, 1063.0, 473.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512141/512141 [06:44<00:00, 1266.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "mse:0.10531185161691727\n",
      "mse_weight:2.6485544461727697\n",
      "total taps:4458.0\n",
      "FP,FN,TP:3859.0, 1072.0, 464.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512141/512141 [06:44<00:00, 1266.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "mse:0.09713338660450944\n",
      "mse_weight:2.9886669990975876\n",
      "total taps:4200.0\n",
      "FP,FN,TP:3567.0, 1044.0, 492.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512141/512141 [06:43<00:00, 1267.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "mse:0.09061700771688756\n",
      "mse_weight:3.166344235711757\n",
      "total taps:4024.0\n",
      "FP,FN,TP:3385.0, 1058.0, 478.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512141/512141 [06:44<00:00, 1267.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "mse:0.08405186918727188\n",
      "mse_weight:3.0903681976679813\n",
      "total taps:3854.0\n",
      "FP,FN,TP:3210.0, 1053.0, 483.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512141/512141 [06:44<00:00, 1267.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "mse:0.07831643541142638\n",
      "mse_weight:2.774623580909756\n",
      "total taps:3710.0\n",
      "FP,FN,TP:3024.0, 1009.0, 527.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512141/512141 [06:43<00:00, 1268.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "mse:0.07024271256631494\n",
      "mse_weight:2.878850340227098\n",
      "total taps:3494.0\n",
      "FP,FN,TP:2816.0, 1030.0, 506.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512141/512141 [06:43<00:00, 1267.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "mse:0.0714469918096357\n",
      "mse_weight:3.4862057662531427\n",
      "total taps:3482.0\n",
      "FP,FN,TP:2786.0, 997.0, 539.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512141/512141 [06:44<00:00, 1265.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "mse:0.06339145609890777\n",
      "mse_weight:1.0639983099995245\n",
      "total taps:3275.0\n",
      "FP,FN,TP:2550.0, 979.0, 557.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 92296/512141 [01:12<05:36, 1246.07it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0a8655580e6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m                }\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mre_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mdata_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_predictY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss_weight = preY*len(preY)/preY.sum()+datay*len(datay)/datay.sum()+1\n",
    "loss_weight = loss_weight.reshape([len(loss_weight),1])\n",
    "\n",
    "x= tf.placeholder('float',[None,1,n_input],name='input_tensor')\n",
    "y = tf.placeholder('float',[None,1,n_classes],name='labels')\n",
    "#inputs = tf.unstack(x,time_steps,1,name='input_tensor')\n",
    "#state_h = tf.placeholder('float',[None,num_units],name='input_h')\n",
    "#state_c = tf.placeholder('float',[None,num_units],name='input_c')\n",
    "state_in   = tf.placeholder('float',[None,num_units*2],name='input_state')\n",
    "loss_weight_in = tf.placeholder('float',[None,1],name='loss_weight')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "#     wi=tf.Variable(name='wi',initial_value=tf.random_normal([n_input, num_units], stddev=0.35))\n",
    "#     wf=tf.Variable(name='wf',initial_value=tf.random_normal([n_input, num_units], stddev=0.35))\n",
    "#     wc=tf.Variable(name='wc',initial_value=tf.random_normal([n_input, num_units], stddev=0.35))\n",
    "#     wo=tf.Variable(name='wo',initial_value=tf.random_normal([n_input, num_units], stddev=0.35))\n",
    "#     ui=tf.Variable(name='ui',initial_value=tf.random_normal([num_units, num_units], stddev=0.35))\n",
    "#     uf=tf.Variable(name='uf',initial_value=tf.random_normal([num_units, num_units], stddev=0.35))\n",
    "#     uc=tf.Variable(name='uc',initial_value=tf.random_normal([num_units, num_units], stddev=0.35))\n",
    "#     uo=tf.Variable(name='uo',initial_value=tf.random_normal([num_units, num_units], stddev=0.35))\n",
    "#     \n",
    "#     bi=tf.Variable(name='bi',initial_value=tf.random_normal([num_units], stddev=0.35))\n",
    "#     bf=tf.Variable(name='bf',initial_value=tf.random_normal([num_units], stddev=0.35))\n",
    "#     bc=tf.Variable(name='bc',initial_value=tf.random_normal([num_units], stddev=0.35))\n",
    "#     bo=tf.Variable(name='bo',initial_value=tf.random_normal([num_units], stddev=0.35))\n",
    "#     \n",
    "# =============================================================================\n",
    "\n",
    "out_weights1=tf.Variable(name=\"weights1\",initial_value=tf.random.normal([num_units, 16], stddev=0.35))\n",
    "out_weights2=tf.Variable(name=\"weights2\",initial_value=tf.random.normal([16, 1], stddev=0.35))\n",
    "out_bias1=tf.Variable(name=\"bias1\",initial_value=tf.random.normal([16], stddev=0.35))\n",
    "out_bias2=tf.Variable(name=\"bias2\",initial_value=tf.random.normal([1], stddev=0.35))\n",
    "\n",
    "\n",
    "state_h,state_c = tf.split(state_in,num_or_size_splits=2,axis=1)\n",
    "# =============================================================================\n",
    "#     x_i = K.dot(x,wi)\n",
    "#     x_f = K.dot(x,wf)\n",
    "#     x_c = K.dot(x,wc)\n",
    "#     x_o = K.dot(x,wo)\n",
    "#     \n",
    "#     i = K.hard_sigmoid(tf.add(tf.add(x_i,bi),K.dot(state_h,ui)))\n",
    "#     f = K.hard_sigmoid(tf.add(tf.add(x_f,bf),K.dot(state_h,uf)))\n",
    "#     c = tf.add(tf.multiply(f,state_c),K.tanh(tf.add(tf.add(x_c,bc),K.dot(state_h,uc))),name='output_c')\n",
    "#     o = K.hard_sigmoid(tf.add(tf.add(x_o,bo),K.dot(state_h,uo)))\n",
    "#     h = tf.multiply(o,tf.tanh(c),name='output_h')\n",
    "# =============================================================================\n",
    "inputX=tf.unstack(x ,1,1)\n",
    "lstm_layer=tf.nn.rnn_cell.BasicLSTMCell(num_units,state_is_tuple=False)\n",
    "outputs,state_output=tf.nn.static_rnn(lstm_layer,inputX,dtype=\"float32\",initial_state = state_in ,sequence_length=[1])\n",
    "\n",
    "\n",
    "dense1  = tf.nn.relu(tf.add(tf.matmul(outputs,out_weights1), out_bias1))\n",
    "prediction=tf.nn.relu(tf.add(tf.matmul(dense1,out_weights2), out_bias2,name='output_forRelu'), name=\"output\")\n",
    "#prediction=tf.nn.relu(tf.add(tf.matmul(h,out_weights), out_bias,name='output_forRelu'), name=\"output\")\n",
    "state_out = tf.concat(state_output,axis=1,name='output_state')\n",
    "prediction_weight=tf.matmul(prediction,loss_weight_in)\n",
    "y_weight=tf.matmul(y,loss_weight_in)\n",
    "\n",
    "#loss=tf.losses.mean_squared_error(predictions=prediction,labels=y)\n",
    "loss=tf.losses.mean_squared_error(predictions=prediction_weight,labels=y_weight)\n",
    "opt=tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "tf.train.Saver()\n",
    "iters=1\n",
    "predictY=np.zeros([len(data_x)])\n",
    "\n",
    "while iters<100:\n",
    "    for i in tqdm(range(len(data_x))):\n",
    "        feed={x:data_x[i:i+1],\n",
    "              state_in:data_state,\n",
    "                y:data_y[i:i+1],\n",
    "              loss_weight_in:loss_weight[i:i+1]\n",
    "               }\n",
    "        if re_train:\n",
    "            sess.run(opt,feed_dict=feed)\n",
    "\n",
    "        data_state,_predictY = sess.run([state_out,prediction],feed_dict=feed)\n",
    "        #print(data_h.shape)\n",
    "        #data_c = sess.run(c,feed_dict=feed)\n",
    "        predictY[i]=_predictY[0]\n",
    "        #print(i)\n",
    "    if iters%1==0:\n",
    "        print(iters)\n",
    "        mse = (np.square(predictY-data_y.reshape([len(data_x)]))).mean(axis=0)\n",
    "        loss_weight = loss_weight.reshape([len(loss_weight)])\n",
    "        mse_weight =np.square(np. multiply((predictY-data_y.reshape([len(data_x)])),loss_weight)).mean(axis=0)\n",
    "        loss_weight = loss_weight.reshape([len(loss_weight),1])\n",
    "        taps_predict = detect(predictY,raw=data_x)\n",
    "        FP,FN,TP = verify(taps_predict,taps_label)\n",
    "        file = open(logFile,'a+')\n",
    "        file.write('\\niters:'+str(iters))\n",
    "        file.write('\\nmse:'+str(mse))\n",
    "        file.write('\\nmse_weight:'+str(mse_weight))\n",
    "        file.write('\\ntotal taps:'+str(taps_predict.sum()))\n",
    "        file.write('\\nFP,FN,TP:'+str(FP.sum())+', '+str(FN.sum())+', '+str(TP.sum()))\n",
    "        file.close()\n",
    "        print('mse:'+str(mse))\n",
    "        print('mse_weight:'+str(mse_weight))\n",
    "        print('total taps:'+str(taps_predict.sum()))\n",
    "        print('FP,FN,TP:'+str(FP.sum())+', '+str(FN.sum())+', '+str(TP.sum()))\n",
    "        if iters%10==0:\n",
    "\n",
    "            loss_weight = predictY*len(predictY)/predictY.sum()/100+datay*len(datay)/datay.sum()+1\n",
    "            loss_weight = loss_weight.reshape([len(loss_weight),1])\n",
    "            print('noneTapWeight'+str(len(predictY)/predictY.sum()))\n",
    "\n",
    "\n",
    "    #output_graph='../models/100hz/TapModels/3C/realLSTM_dataV2_U'+str(num_units)+'_i'+str(iters)+'_mse'+'{0:.2f}'.format(mse*100)+'_'+'{0:.2f}'.format(mse_weight)+'.pb'\n",
    "    output_graph='./models/100hz/realLSTM_V3_data_U'+str(num_units)+'_i'+str(iters)+'_mse'+'{0:.2f}'.format(mse*100)+'_'+'{0:.2f}'.format(mse_weight)+'.pb'\n",
    "    \n",
    "    #output_graph='TF_LSTM_V2.pb'\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess, # The session is used to retrieve the weights\n",
    "            tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "            ['output','output_state'] # The output node names are used to select the usefull nodes\n",
    "        ) \n",
    "    with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "    iters=iters+1\n",
    "    out_preY = output_graph.split('.pb')[0]+'_preY.csv'\n",
    "    np.savetxt(out_preY,predictY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0730 13:09:26.161826 22984 deprecation.py:323] From <ipython-input-5-565ebe9b10e9>:7: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0730 13:09:26.163822 22984 deprecation.py:323] From C:\\Users\\Guo\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    }
   ],
   "source": [
    "output_graph='./models/100hz/realLSTM_V3_data_U'+str(num_units)+'_i'+str(iters)+'_mse'+'{0:.2f}'.format(mse*100)+'_'+'{0:.2f}'.format(mse_weight)+'.pb'\n",
    "\n",
    "#output_graph='TF_LSTM_V2.pb'\n",
    "output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "        sess, # The session is used to retrieve the weights\n",
    "        tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "        ['output','output_state'] # The output node names are used to select the usefull nodes\n",
    "    ) \n",
    "with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "iters=iters+1\n",
    "out_preY = output_graph.split('.pb')[0]+'_preY.csv'\n",
    "np.savetxt(out_preY,predictY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConverterError",
     "evalue": "TOCO failed. See console for info.\n2019-07-30 13:09:37.522804: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 67 operators, 113 arrays (0 quantized)\n2019-07-30 13:09:37.523543: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 65 operators, 110 arrays (0 quantized)\n2019-07-30 13:09:37.524229: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 65 operators, 110 arrays (0 quantized)\n2019-07-30 13:09:37.525344: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 49 operators, 87 arrays (0 quantized)\n2019-07-30 13:09:37.526111: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 49 operators, 87 arrays (0 quantized)\n2019-07-30 13:09:37.526697: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 49 operators, 87 arrays (0 quantized)\n2019-07-30 13:09:37.527380: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 256 bytes, theoretical optimal value: 128 bytes.\n2019-07-30 13:09:37.527969: E tensorflow/lite/toco/toco_tooling.cc:456] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n and pasting the following:\n\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, FULLY_CONNECTED, GREATER, LESS_EQUAL, LOGISTIC, MUL, PACK, REDUCE_MAX, REDUCE_MIN, SELECT, SPLIT, TANH, TRANSPOSE, UNPACK. Here is a list of operators for which you will need custom implementations: BatchMatMul, Merge, Switch.\nTraceback (most recent call last):\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\Guo\\Anaconda3\\envs\\tf_1_14\\Scripts\\toco_from_protos.exe\\__main__.py\", line 9, in <module>\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 59, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\site-packages\\absl\\app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 33, in execute\r\n    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, FULLY_CONNECTED, GREATER, LESS_EQUAL, LOGISTIC, MUL, PACK, REDUCE_MAX, REDUCE_MIN, SELECT, SPLIT, TANH, TRANSPOSE, UNPACK. Here is a list of operators for which you will need custom implementations: BatchMatMul, Merge, Switch.\r\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-647e6fe58eae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m converter=tf.lite.TFLiteConverter.from_frozen_graph(output_graph,input_arrays={'input_tensor'},#'input_state'},\n\u001b[0;32m      3\u001b[0m                                                     output_arrays={'output','output_state'})\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./TF_LSTM_V2.tflite\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    896\u001b[0m           \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m           \u001b[0moutput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m           **converter_kwargs)\n\u001b[0m\u001b[0;32m    899\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m       result = _toco_convert_graph_def(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[1;34m(input_data, input_tensors, output_tensors, *args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m   data = toco_convert_protos(model_flags.SerializeToString(),\n\u001b[0;32m    403\u001b[0m                              \u001b[0mtoco_flags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m                              input_data.SerializeToString())\n\u001b[0m\u001b[0;32m    405\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str)\u001b[0m\n\u001b[0;32m    170\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m       raise ConverterError(\n\u001b[1;32m--> 172\u001b[1;33m           \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n\u001b[0m\u001b[0;32m    173\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;31m# Must manually cleanup files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConverterError\u001b[0m: TOCO failed. See console for info.\n2019-07-30 13:09:37.522804: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 67 operators, 113 arrays (0 quantized)\n2019-07-30 13:09:37.523543: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 65 operators, 110 arrays (0 quantized)\n2019-07-30 13:09:37.524229: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 65 operators, 110 arrays (0 quantized)\n2019-07-30 13:09:37.525344: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 49 operators, 87 arrays (0 quantized)\n2019-07-30 13:09:37.526111: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 49 operators, 87 arrays (0 quantized)\n2019-07-30 13:09:37.526697: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 49 operators, 87 arrays (0 quantized)\n2019-07-30 13:09:37.527380: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 256 bytes, theoretical optimal value: 128 bytes.\n2019-07-30 13:09:37.527969: E tensorflow/lite/toco/toco_tooling.cc:456] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n and pasting the following:\n\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, FULLY_CONNECTED, GREATER, LESS_EQUAL, LOGISTIC, MUL, PACK, REDUCE_MAX, REDUCE_MIN, SELECT, SPLIT, TANH, TRANSPOSE, UNPACK. Here is a list of operators for which you will need custom implementations: BatchMatMul, Merge, Switch.\nTraceback (most recent call last):\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\Guo\\Anaconda3\\envs\\tf_1_14\\Scripts\\toco_from_protos.exe\\__main__.py\", line 9, in <module>\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 59, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\site-packages\\absl\\app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"c:\\users\\guo\\anaconda3\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 33, in execute\r\n    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, FULLY_CONNECTED, GREATER, LESS_EQUAL, LOGISTIC, MUL, PACK, REDUCE_MAX, REDUCE_MIN, SELECT, SPLIT, TANH, TRANSPOSE, UNPACK. Here is a list of operators for which you will need custom implementations: BatchMatMul, Merge, Switch.\r\n\n\n"
     ]
    }
   ],
   "source": [
    "#output_graph='./tmp/model/real_LSTM_fullData_dynamicW_tfTrain_2Dense_7_8_92.pb'\n",
    "converter=tf.lite.TFLiteConverter.from_frozen_graph(output_graph,input_arrays={'input_tensor'},#'input_state'},\n",
    "                                                    output_arrays={'output','output_state'})\n",
    "tflite_model = converter.convert()\n",
    "open(\"./TF_LSTM_V2.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
